test_method,isEagerTest
"@Test
    public void testHostPermanentlyNotAvailable() throws Throwable {
        ComputeState state = new ComputeState();
        state.powerState = PowerState.SUSPEND;
        Map<String, String> properties = new HashMap<>();
        properties.put(ContainerHostService.RETRIES_COUNT_PROP_NAME, ""2"");
        state.customProperties = properties;
        doOperation(state,
                UriUtils.buildUri(host, dockerHostState.documentSelfLink), false,
                Action.PATCH);
        waitFor(() -> {
            dockerHostState = retrieveDockerHostState();
            return PowerState.SUSPEND == dockerHostState.powerState;
        }",1
"@Test
    public void testNetworkInspect() throws Throwable {
        // Network creation is not direct operation, this means it will take some time.
        while ((MockDockerNetworkService.networksMap == null
                || MockDockerNetworkService.networksMap.isEmpty())
                && NETWORK_LIST_RETRY_COUNT > 0) {
            Thread.sleep(TIME_BETWEEN_RETRIES_IN_MILSEC);
            NETWORK_LIST_RETRY_COUNT--;
        }",1
"@Test
    public void testGetFromUserResources() throws Throwable {
        Path testXenonImagesPath = Files.createTempDirectory(""test-xenon-images"");

        HostInitCommonServiceConfig.startServices(host);
        waitForServiceAvailability(ConfigurationFactoryService.SELF_LINK);
        waitForServiceAvailability(UriUtils.buildUriPath(UriUtils.buildUriPath(
                ConfigurationFactoryService.SELF_LINK, FileUtil.USER_RESOURCES_PATH_VARIABLE)));

        // Set expected configuration
        ConfigurationState config = new ConfigurationState();
        config.documentSelfLink = UriUtils.buildUriPath(ConfigurationFactoryService.SELF_LINK,
                FileUtil.USER_RESOURCES_PATH_VARIABLE);
        config.key = FileUtil.USER_RESOURCES_PATH_VARIABLE;
        config.value = testXenonImagesPath.toAbsolutePath().toString();

        doPut(config);

        File imageDir = new File(UriUtils.buildUriPath(testXenonImagesPath.toString(),
                SystemImageRetrievalManager.SYSTEM_IMAGES_PATH));
        imageDir.mkdir();

        byte[] content = IOUtils.toByteArray(Thread.currentThread().getContextClassLoader()
                .getResourceAsStream(TEST_IMAGE));
        // Basically, rename it so it must be loaded from user resources for sure
        File tmpFile = new File(
                UriUtils.buildUriPath(imageDir.getAbsolutePath(), TEST_IMAGE_RES));
        tmpFile.createNewFile();
        try (OutputStream os = new FileOutputStream(tmpFile)) {
            os.write(content);
        }",1
"@Test
    public void testValidateServicesAreDeployedFirst() throws Throwable {
        String wordpressTemplate = CommonTestStateFactory
                .getFileContent(""WordPress_with_MySQL_kubernetes.yaml"");

        String compositeDescriptionLink = importTemplate(wordpressTemplate);

        CompositeDescription compositeDescription = getCompositeDescription(
                compositeDescriptionLink);

        CompositeComponent compositeComponent = new CompositeComponent();
        compositeComponent.name = compositeDescription.name + ""-mcm-102"";
        compositeComponent.compositeDescriptionLink = compositeDescription.documentSelfLink;
        compositeComponent.customProperties = new HashMap<>();
        compositeComponent.customProperties.put(CUSTOM_PROPERTY_HOST_LINK,
                kubernetesHostState.documentSelfLink);
        compositeComponent = doPost(compositeComponent, CompositeComponentFactoryService.SELF_LINK);

        addPodsAndReplicaSetsForWordpressApp(extractId(compositeComponent.documentSelfLink));

        provisioningTaskLink = createProvisioningTask();

        ApplicationRequest appRequest = createApplicationRequest(
                compositeComponent.documentSelfLink);

        doOperation(ManagementUriParts.ADAPTER_KUBERNETES_APPLICATION, appRequest);

        // wait for provisioning task stage to change to finish
        waitForPropertyValue(provisioningTaskLink, MockTaskState.class, ""taskInfo.stage"",
                TaskState.TaskStage.FINISHED);

        assertEquals(10, service.deployedElements.size());

        List<BaseKubernetesObject> kubernetesElements = new ArrayList<>();
        service.deployedElements.forEach(e -> kubernetesElements.add(e));

        // Assert that services are deployed first.
        assertEquals(KubernetesUtil.SERVICE_TYPE, kubernetesElements.get(4).kind);
        assertEquals(KubernetesUtil.SERVICE_TYPE, kubernetesElements.get(5).kind);

        // Assert that states are created and they have correct compositeComponentLink.
        CompositeComponent finalCompositeComponent = compositeComponent;

        List<String> resourceLinks = getDocumentLinksOfType(ServiceState.class);
        assertEquals(2, resourceLinks.size());
        resourceLinks.forEach(link -> doOperation(Operation.createGet(host, link)
                .setCompletion((o, ex) -> {
                    if (ex != null) {
                        host.failIteration(ex);
                    }",1
"@Test
    public void testCreateUser() throws Throwable {
        PKSRemoteClientService client = new PKSRemoteClientService(null, host);
        assertNotNull(client);

        PKSContext ctx = new PKSContext();
        ctx.pksAPIUri = URI.create(""http://some.host"");

        ServiceClient mockClient = mockClient(client);
        ArgumentCaptor<Operation> valueCapture = ArgumentCaptor.forClass(Operation.class);
        doNothing().when(mockClient).send(valueCapture.capture());

        // test casual exception
        DeferredResult<KubeConfig> result = client.createUser(null, null);
        try {
            result.toCompletionStage().toCompletableFuture().get();
            fail(""should not reach here"");
        }",1
"@Test
    public void testGetClusters() throws Throwable {
        PKSRemoteClientService client = new PKSRemoteClientService(null, host);
        assertNotNull(client);

        PKSContext ctx = new PKSContext();
        ctx.pksAPIUri = URI.create(""http://some.host"");

        ServiceClient mockClient = mockClient(client);
        ArgumentCaptor<Operation> valueCapture = ArgumentCaptor.forClass(Operation.class);
        doNothing().when(mockClient).send(valueCapture.capture());

        // test casual exception
        DeferredResult<List<PKSCluster>> result = client.getClusters(null);
        try {
            result.toCompletionStage().toCompletableFuture().get();
            fail(""should not reach here"");
        }",1
"@Test
    public void testGetPlans() throws Throwable {
        PKSRemoteClientService client = new PKSRemoteClientService(null, host);
        assertNotNull(client);

        PKSContext ctx = new PKSContext();
        ctx.pksAPIUri = URI.create(""http://some.host"");

        ServiceClient mockClient = mockClient(client);
        ArgumentCaptor<Operation> valueCapture = ArgumentCaptor.forClass(Operation.class);
        doNothing().when(mockClient).send(valueCapture.capture());

        // test casual exception
        DeferredResult<List<PKSPlan>> result = client.getPlans(null);
        try {
            result.toCompletionStage().toCompletableFuture().get();
            fail(""should not reach here"");
        }",1
"@Test
    public void testImportContentWithProjectAndUsers() throws Throwable {
        AuthContentBody body = Utils.fromJson(authContent, AuthContentBody.class);
        loadAuthContent(body);

        List<String> projectLinks = getDocumentLinksOfType(ProjectState.class);
        projectLinks.remove(ProjectService.DEFAULT_PROJECT_LINK);

        assertEquals(body.projects.size(), projectLinks.size());

        List<String> projectToImportNames = body.projects.stream()
                .map(p -> p.name)
                .collect(Collectors.toList());

        for (String link : projectLinks) {
            ProjectState state = getDocument(ProjectState.class, link);
            assertTrue(projectToImportNames.contains(state.name));
        }",1
"@Test
    public void testGetPrincipalsOfTypeGroup() {
        String principalId = ""superusers@admiral.com"";
        DeferredResult<List<Principal>> result = provider.getPrincipals(null, principalId);

        TestContext ctx = testCreate(1);
        result.whenComplete((p, ex) -> {
            if (ex != null) {
                ctx.failIteration(ex);
                return;
            }",1
"@Test
    public void testGetAllRolesForPrincipalWithIndirectRoles() throws Throwable {
        host.assumeIdentity(buildUserServicePath(USER_EMAIL_ADMIN2));
        // Scenario: create a group which will contain Connie which is basic user and the group
        // will be assigned to cloud admins. Create nested groups and add Connie in them, assign
        // the nested groups to project roles. Verify that PrincipalRoles for Connie contains all
        // roles where he is assigned indirectly.

        // root is the group where Connie belongs and we assign the group to cloud admins role.
        LocalPrincipalState root = new LocalPrincipalState();
        root.type = LocalPrincipalType.GROUP;
        root.name = ""root"";
        root.groupMembersLinks = Collections.singletonList(UriUtils.buildUriPath(
                LocalPrincipalFactoryService.SELF_LINK, encode(USER_EMAIL_CONNIE)));
        root = doPost(root, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(root.documentSelfLink);

        // nestedGroup1 is the group where Connie belongs but we will add nestedGroup1 to
        // nestedGroup2 and we will indirectly assign roles to Connie as we assign a role to
        // nestedGroup2.
        LocalPrincipalState nestedGroup1 = new LocalPrincipalState();
        nestedGroup1.type = LocalPrincipalType.GROUP;
        nestedGroup1.name = ""nestedGroup1"";
        nestedGroup1.groupMembersLinks = Collections.singletonList(UriUtils.buildUriPath(
                LocalPrincipalFactoryService.SELF_LINK, encode(USER_EMAIL_CONNIE)));
        nestedGroup1 = doPost(nestedGroup1, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(nestedGroup1.documentSelfLink);

        // nestedGroup2 is the group which contains nestedGroup1
        LocalPrincipalState nestedGroup2 = new LocalPrincipalState();
        nestedGroup2.type = LocalPrincipalType.GROUP;
        nestedGroup2.name = ""nestedGroup2"";
        nestedGroup2.groupMembersLinks = Collections.singletonList(nestedGroup1.documentSelfLink);
        nestedGroup2 = doPost(nestedGroup2, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(nestedGroup2.documentSelfLink);

        // assign cloud admins role to root user group.
        PrincipalRoleAssignment roleAssignment = new PrincipalRoleAssignment();
        roleAssignment.add = Collections.singletonList(AuthRole.CLOUD_ADMIN.name());
        doPatch(roleAssignment, UriUtils.buildUriPath(PrincipalService.SELF_LINK, root.id,
                PrincipalService.ROLES_SUFFIX));

        // Create first project and assign nestedGroup1 as project admin.
        ProjectState firstProject = createProject(""first-project"");
        assertNotNull(firstProject.documentSelfLink);
        ProjectRoles projectRoles = new ProjectRoles();
        PrincipalRoleAssignment admins = new PrincipalRoleAssignment();
        admins.add = Collections.singletonList(nestedGroup1.id);
        projectRoles.administrators = admins;
        doPatch(projectRoles, firstProject.documentSelfLink);

        // Create second project and assign nestedGroup2 as project member.
        ProjectState secondProject = createProject(""second-project"");
        assertNotNull(secondProject.documentSelfLink);
        projectRoles = new ProjectRoles();
        PrincipalRoleAssignment members = new PrincipalRoleAssignment();
        members.add = Collections.singletonList(nestedGroup2.id);
        projectRoles.members = members;
        doPatch(projectRoles, secondProject.documentSelfLink);

        URI uri = UriUtils.buildUri(host, PrincipalService.SELF_LINK);
        uri = UriUtils.extendUriWithQuery(uri, PrincipalService.CRITERIA_QUERY, ""connie"",
                PrincipalService.ROLES_QUERY, PrincipalService.ROLES_QUERY_VALUE);

        List<PrincipalRoles> resultRoles = new ArrayList<>();

        TestContext ctx = testCreate(1);

        Operation getRoles = Operation
                .createGet(uri)
                .setReferer(host.getUri())
                .setCompletion((o, ex) -> {
                    if (ex != null) {
                        ctx.failIteration(ex);
                        return;
                    }",1
"@Test
    public void testProjectRolesPatchGroups() throws Throwable {
        // verify initial state
        ExpandedProjectState expandedState = getExpandedProjectState(project.documentSelfLink);
        assertNotNull(expandedState.administratorsUserGroupLinks);
        assertNotNull(expandedState.membersUserGroupLinks);
        assertNotNull(expandedState.administrators);
        assertNotNull(expandedState.members);
        assertNotNull(expandedState.viewers);
        assertEquals(1, expandedState.administrators.size());
        assertEquals(1, expandedState.members.size());
        assertEquals(1, expandedState.viewers.size());
        assertEquals(USER_EMAIL_ADMIN, expandedState.administrators.iterator().next().email);
        assertEquals(USER_EMAIL_ADMIN, expandedState.members.iterator().next().email);
        assertEquals(USER_EMAIL_BASIC_USER, expandedState.viewers.iterator().next().email);

        String expectedAdministratorsUserGroupLink = UriUtils.buildUriPath(
                UserGroupService.FACTORY_LINK,
                AuthRole.PROJECT_ADMIN
                        .buildRoleWithSuffix(Service.getId(project.documentSelfLink)));
        String expectedMembersUserGroupLink = UriUtils.buildUriPath(UserGroupService.FACTORY_LINK,
                AuthRole.PROJECT_MEMBER
                        .buildRoleWithSuffix(Service.getId(project.documentSelfLink)));

        assertEquals(expectedAdministratorsUserGroupLink,
                expandedState.administratorsUserGroupLinks.iterator().next());
        assertEquals(expectedMembersUserGroupLink,
                expandedState.membersUserGroupLinks.iterator().next());

        // make a batch user operation: add group
        ProjectRoles projectRoles = new ProjectRoles();
        projectRoles.members = new PrincipalRoleAssignment();
        projectRoles.members.add = Arrays.asList(USER_GROUP_DEVELOPERS);

        // assert that the new role does not exist
        String roleLink = UriUtils.buildUriPath(RoleService.FACTORY_LINK,
                AuthRole.PROJECT_MEMBER.buildRoleWithSuffix(Service.getId(project.documentSelfLink),
                        encode(USER_GROUP_DEVELOPERS)));
        assertDocumentNotExists(roleLink);

        host.testStart(1);

        Operation.createPatch(host, expandedState.documentSelfLink)
                .setReferer(host.getUri())
                .setBody(projectRoles)
                .setCompletion((o, e) -> {
                    if (e != null) {
                        host.log(Level.SEVERE, Utils.toString(e));
                        host.failIteration(e);
                    }",1
"@Test
    public void testGetAllRolesForPrincipal() throws Throwable {
        Operation testOperationByAdmin = createAuthorizedOperation(
                host.assumeIdentity(buildUserServicePath(USER_EMAIL_ADMIN2)));

        // Scenario: create 2 projects, assign fritz as project admin in 1st and as project
        // member in 2nd project.

        // Create first project and assign fritz as project admin.
        ProjectState firstProject = createProject(""first-project"");
        assertNotNull(firstProject.documentSelfLink);
        ProjectRoles projectRoles = new ProjectRoles();
        PrincipalRoleAssignment admins = new PrincipalRoleAssignment();
        admins.add = Collections.singletonList(USER_EMAIL_ADMIN);
        projectRoles.administrators = admins;
        doPatch(projectRoles, firstProject.documentSelfLink);

        // Create second project and assign fritz as project member.
        ProjectState secondProject = createProject(""second-project"");
        assertNotNull(secondProject.documentSelfLink);
        projectRoles = new ProjectRoles();
        PrincipalRoleAssignment members = new PrincipalRoleAssignment();
        members.add = Collections.singletonList(USER_EMAIL_ADMIN);
        projectRoles.members = members;
        doPatch(projectRoles, secondProject.documentSelfLink);

        Principal fritz = getPrincipal(USER_EMAIL_ADMIN);
        DeferredResult<PrincipalRoles> result = PrincipalRolesUtil.getAllRolesForPrincipal(
                privilegedTestService, testOperationByAdmin, fritz);

        final PrincipalRoles[] resultRoles = new PrincipalRoles[1];

        TestContext ctx = testCreate(1);
        result.whenComplete((principalRoles, ex) -> {
            if (ex != null) {
                ctx.failIteration(ex);
                return;
            }",1
"@Test
    public void testGetAllRolesForPrincipalWithIndirectRoles() throws Throwable {
        Operation testOperationByAdmin = createAuthorizedOperation(
                host.assumeIdentity(buildUserServicePath(USER_EMAIL_ADMIN2)));

        // Scenario: create a group which will contain Connie which is basic user and the group
        // will be assigned to cloud admins. Create nested groups and add Connie in them, assign
        // the nested groups to project roles. Verify that PrincipalRoles for Connie contains all
        // roles where he is assigned indirectly.

        // root is the group where Connie belongs and we assign the group to cloud admins role.
        LocalPrincipalState root = new LocalPrincipalState();
        root.type = LocalPrincipalType.GROUP;
        root.name = ""root@admiral.com"";
        root.groupMembersLinks = Collections.singletonList(UriUtils.buildUriPath(
                LocalPrincipalFactoryService.SELF_LINK, encode(USER_EMAIL_CONNIE)));
        root = doPost(root, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(root.documentSelfLink);

        // nestedGroup1 is the group where Connie belongs but we will add nestedGroup1 to
        // nestedGroup2 and we will indirectly assign roles to Connie as we assign a role to
        // nestedGroup2.
        LocalPrincipalState nestedGroup1 = new LocalPrincipalState();
        nestedGroup1.type = LocalPrincipalType.GROUP;
        nestedGroup1.name = ""nestedGroup1@admiral.com"";
        nestedGroup1.groupMembersLinks = Collections.singletonList(UriUtils.buildUriPath(
                LocalPrincipalFactoryService.SELF_LINK, encode(USER_EMAIL_CONNIE)));
        nestedGroup1 = doPost(nestedGroup1, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(nestedGroup1.documentSelfLink);

        // nestedGroup2 is the group which contains nestedGroup1
        LocalPrincipalState nestedGroup2 = new LocalPrincipalState();
        nestedGroup2.type = LocalPrincipalType.GROUP;
        nestedGroup2.name = ""nestedGroup2@admiral.com"";
        nestedGroup2.groupMembersLinks = Collections.singletonList(nestedGroup1.documentSelfLink);
        nestedGroup2 = doPost(nestedGroup2, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(nestedGroup2.documentSelfLink);

        // assign cloud admins role to root user group.
        PrincipalRoleAssignment roleAssignment = new PrincipalRoleAssignment();
        roleAssignment.add = Collections.singletonList(AuthRole.CLOUD_ADMIN.name());
        doPatch(roleAssignment, UriUtils.buildUriPath(PrincipalService.SELF_LINK, root.id,
                PrincipalService.ROLES_SUFFIX));

        // Create first project and assign nestedGroup1 as project admin.
        Map<String, String> customProperties = new HashMap<>();
        customProperties.put(""key1"", ""value1"");
        customProperties.put(""key2"", ""value2"");
        ProjectState firstProject = createProject(""first-project"", customProperties);
        assertNotNull(firstProject.documentSelfLink);
        ProjectRoles projectRoles = new ProjectRoles();
        PrincipalRoleAssignment admins = new PrincipalRoleAssignment();
        admins.add = Collections.singletonList(nestedGroup1.id);
        projectRoles.administrators = admins;
        doPatch(projectRoles, firstProject.documentSelfLink);

        // Create second project and assign nestedGroup2 as project member.
        ProjectState secondProject = createProject(""second-project"");
        assertNotNull(secondProject.documentSelfLink);
        projectRoles = new ProjectRoles();
        PrincipalRoleAssignment members = new PrincipalRoleAssignment();
        members.add = Collections.singletonList(nestedGroup2.id);
        projectRoles.members = members;
        doPatch(projectRoles, secondProject.documentSelfLink);

        Principal connie = getPrincipal(USER_EMAIL_CONNIE);
        DeferredResult<PrincipalRoles> result = PrincipalRolesUtil.getAllRolesForPrincipal(
                privilegedTestService, testOperationByAdmin, connie);

        final PrincipalRoles[] resultRoles = new PrincipalRoles[1];

        TestContext ctx = testCreate(1);
        result.whenComplete((principalRoles, ex) -> {
            if (ex != null) {
                ctx.failIteration(ex);
                return;
            }",1
"@Test
    public void testSecurityContextContainsAllRolesForMultipleProjects() throws Throwable {
        Operation testOperationByAdmin = createAuthorizedOperation(
                host.assumeIdentity(buildUserServicePath(USER_EMAIL_ADMIN)));
        host.assumeIdentity(buildUserServicePath(USER_EMAIL_ADMIN2));

        // Scenario: create 2 projects, assign fritz as project admin in 1st and as project
        // member in 2nd project.

        // Create first project and assign fritz as project admin.
        ProjectState firstProject = createProject(""first-project"");
        assertNotNull(firstProject.documentSelfLink);
        ProjectRoles projectRoles = new ProjectRoles();
        PrincipalRoleAssignment admins = new PrincipalRoleAssignment();
        admins.add = Collections.singletonList(USER_EMAIL_ADMIN);
        projectRoles.administrators = admins;
        doPatch(projectRoles, firstProject.documentSelfLink);

        // Create second project and assign fritz as project member.
        ProjectState secondProject = createProject(""second-project"");
        assertNotNull(secondProject.documentSelfLink);
        projectRoles = new ProjectRoles();
        PrincipalRoleAssignment members = new PrincipalRoleAssignment();
        members.add = Collections.singletonList(USER_EMAIL_ADMIN);
        projectRoles.members = members;
        doPatch(projectRoles, secondProject.documentSelfLink);

        DeferredResult<SecurityContext> result = SecurityContextUtil.getSecurityContext(
                privilegedTestService, testOperationByAdmin);

        final SecurityContext[] context = new SecurityContext[1];
        TestContext ctx = testCreate(1);
        result.whenComplete((securityContext, ex) -> {
            if (ex != null) {
                ctx.failIteration(ex);
                return;
            }",1
"@Test
    public void testSecurityContextContainsIndirectAssignedRoles() throws Throwable {
        Operation testOperationByBasicUser = createAuthorizedOperation(
                host.assumeIdentity(buildUserServicePath(USER_EMAIL_CONNIE)));
        host.assumeIdentity(buildUserServicePath(USER_EMAIL_ADMIN2));

        // Scenario: create a group which will contain Connie which is basic user and the group
        // will be assigned to cloud admins. Create nested groups and add Connie in them, assign
        // the nested groups to project roles. Verify that PrincipalRoles for Connie contains all
        // roles where he is assigned indirectly.

        // root is the group where Connie belongs and we assign the group to cloud admins role.
        LocalPrincipalState root = new LocalPrincipalState();
        root.type = LocalPrincipalType.GROUP;
        root.name = ""root@admiral.com"";
        root.groupMembersLinks = Collections.singletonList(UriUtils.buildUriPath(
                LocalPrincipalFactoryService.SELF_LINK, encode(USER_EMAIL_CONNIE)));
        root = doPost(root, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(root.documentSelfLink);

        // nestedGroup1 is the group where Connie belongs but we will add nestedGroup1 to
        // nestedGroup2 and we will indirectly assign roles to Connie as we assign a role to
        // nestedGroup2.
        LocalPrincipalState nestedGroup1 = new LocalPrincipalState();
        nestedGroup1.type = LocalPrincipalType.GROUP;
        nestedGroup1.name = ""nestedGroup1@admiral.com"";
        nestedGroup1.groupMembersLinks = Collections.singletonList(UriUtils.buildUriPath(
                LocalPrincipalFactoryService.SELF_LINK, encode(USER_EMAIL_CONNIE)));
        nestedGroup1 = doPost(nestedGroup1, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(nestedGroup1.documentSelfLink);

        // nestedGroup2 is the group which contains nestedGroup1
        LocalPrincipalState nestedGroup2 = new LocalPrincipalState();
        nestedGroup2.type = LocalPrincipalType.GROUP;
        nestedGroup2.name = ""nestedGroup2@admiral.com"";
        nestedGroup2.groupMembersLinks = Collections.singletonList(nestedGroup1.documentSelfLink);
        nestedGroup2 = doPost(nestedGroup2, LocalPrincipalFactoryService.SELF_LINK);
        assertNotNull(nestedGroup2.documentSelfLink);

        // assign cloud admins role to root user group.
        PrincipalRoleAssignment roleAssignment = new PrincipalRoleAssignment();
        roleAssignment.add = Collections.singletonList(AuthRole.CLOUD_ADMIN.name());
        doPatch(roleAssignment, UriUtils.buildUriPath(PrincipalService.SELF_LINK, root.id,
                PrincipalService.ROLES_SUFFIX));

        // Create first project and assign nestedGroup1 as project admin.
        ProjectState firstProject = createProject(""first-project"");
        assertNotNull(firstProject.documentSelfLink);
        ProjectRoles projectRoles = new ProjectRoles();
        PrincipalRoleAssignment admins = new PrincipalRoleAssignment();
        admins.add = Collections.singletonList(nestedGroup1.id);
        projectRoles.administrators = admins;
        doPatch(projectRoles, firstProject.documentSelfLink);

        // Create second project and assign nestedGroup2 as project member.
        ProjectState secondProject = createProject(""second-project"");
        assertNotNull(secondProject.documentSelfLink);
        projectRoles = new ProjectRoles();
        PrincipalRoleAssignment members = new PrincipalRoleAssignment();
        members.add = Collections.singletonList(nestedGroup2.id);
        projectRoles.members = members;
        doPatch(projectRoles, secondProject.documentSelfLink);

        DeferredResult<SecurityContext> result = SecurityContextUtil.getSecurityContext(
                privilegedTestService, testOperationByBasicUser);

        final SecurityContext[] context = new SecurityContext[1];
        TestContext ctx = testCreate(1);
        result.whenComplete((securityContext, ex) -> {
            if (ex != null) {
                ctx.failIteration(ex);
                return;
            }",1
"@Test
    public void testUserGroupsUpdater() throws Throwable {
        // Create test user group.
        String userGroupSelfLink = UriUtils.buildUriPath(UserGroupService.FACTORY_LINK, encode(""testId""));
        Query userGroupQuery = AuthUtil.buildQueryForUsers(userGroupSelfLink);
        UserGroupState userGroupState = UserGroupState.Builder
                .create()
                .withQuery(userGroupQuery)
                .withSelfLink(userGroupSelfLink)
                .build();

        userGroupState = doPost(userGroupState, UserGroupService.FACTORY_LINK);
        assertNotNull(userGroupState);

        // Add users.
        DeferredResult<Void> result = UserGroupsUpdater.create()
                .setService(privilegedTestService)
                .setGroupLink(userGroupSelfLink)
                .setUsersToAdd(Arrays.asList(encode(USER_EMAIL_ADMIN), encode(USER_EMAIL_CONNIE)))
                .update();

        TestContext ctx = testCreate(1);
        result.whenComplete((o, ex) -> {
            if (ex != null) {
                ctx.failIteration(ex);
                return;
            }",1
"@Test
    public void executeJavaExtSourceAsZIPTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        int expectedInVar = 3;
        int expectedInVar2 = 4;
        int expectedResult = 7;

        closureDescState.sourceURL = testWebserverUri + ""/test_script_java.zip"";
        closureDescState.source = ""should not be used"";
        closureDescState.runtime = RUNTIME_JAVA_8;
        closureDescState.entrypoint = ""testpackage.Test.test"";

        ResourceConstraints constraints = new ResourceConstraints();
        constraints.timeoutSeconds = 10;
        constraints.ramMB = 300;
        closureDescState.resources = constraints;

        String taskDefPayload = Utils.toJson(closureDescState);
        ClosureDescription closureDescription = createClosureDescription(taskDefPayload,
                serviceClient);
        assertNotNull(closureDescription);

        // Create Closure
        Closure createdClosure = createClosure(closureDescription, serviceClient);
        assertEquals(closureDescription.documentSelfLink, createdClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CREATED, createdClosure.state);

        // Execute the created Closure
        Closure closureRequest = new Closure();
        Map inputs = new HashMap<>();
        inputs.put(""a"", new JsonPrimitive(expectedInVar));
        inputs.put(""b"", new JsonPrimitive(expectedInVar2));
        closureRequest.inputs = inputs;

        executeClosure(createdClosure, closureRequest, serviceClient);

        // Wait for the completion timeout
        String imageRequestLink = waitForBuildCompletion(IMAGE_NAME, closureDescription);

        waitForTaskState(createdClosure.documentSelfLink, TaskState.TaskStage.FINISHED,
                serviceClient);

        Closure fetchedClosure = getClosure(createdClosure.documentSelfLink, serviceClient);

        assertEquals(closureDescription.documentSelfLink, fetchedClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.FINISHED, fetchedClosure.state);

        assertEquals(expectedInVar, fetchedClosure.inputs.get(""a"").getAsInt());
        assertEquals(expectedInVar2, fetchedClosure.inputs.get(""b"").getAsInt());
        assertEquals(expectedResult, fetchedClosure.outputs.get(""result"").getAsInt(), 0);

        cleanResource(imageRequestLink, serviceClient);
        cleanResource(createdClosure.documentSelfLink, serviceClient);
        cleanResource(closureDescription.documentSelfLink, serviceClient);
    }",1
"@Test
    public void executeJSArrayOfNumberParametersTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        Integer[] expectedInVar = { 1, 2, 3 }",1
"@Test
    public void executeJSDependenciesTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        int expectedInVar = 3;
        double expectedResult = 4.0; // TODO: fix types
        closureDescState.source = ""var _ = require('lodash');""
                + ""var moment = require('moment');""
                + ""module.exports = function test(context) {""
                + "" console.log('Executed at : ' + moment().valueOf());""
                + "" context.outputs.result = context.inputs.a + 1;""
                + ""}",1
"@Test
    public void executeJSExtSourceAsZIPNoPackageJsonEntrypointTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";
        closureDescState.entrypoint = ""index.test"";

        String expectedInVar = ""a"";
        String expectedOutVar = ""b"";
        String expectedResult = ""ac"";

        closureDescState.sourceURL = testWebserverUri + ""/test_script_no_packagejson.zip"";
        closureDescState.source = ""should not be used"";
        closureDescState.runtime = RUNTIME_NODEJS_4;
        closureDescState.outputNames = new ArrayList<>(Collections.singletonList(""result""));
        ResourceConstraints constraints = new ResourceConstraints();
        constraints.timeoutSeconds = 20;
        constraints.ramMB = 300;
        closureDescState.resources = constraints;

        String taskDefPayload = Utils.toJson(closureDescState);
        ClosureDescription closureDescription = createClosureDescription(taskDefPayload,
                serviceClient);
        assertNotNull(closureDescription);

        // Create Closure
        Closure createdClosure = createClosure(closureDescription, serviceClient);
        assertEquals(closureDescription.documentSelfLink, createdClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CREATED, createdClosure.state);

        // Execute the created Closure
        Closure closureRequest = new Closure();
        Map inputs = new HashMap<>();
        inputs.put(""a"", new JsonPrimitive(expectedInVar));
        closureRequest.inputs = inputs;

        executeClosure(createdClosure, closureRequest, serviceClient);

        // Wait for the completion timeout
        String imageRequestLink = waitForBuildCompletion(IMAGE_NAME, closureDescription);

        waitForTaskState(createdClosure.documentSelfLink, TaskState.TaskStage.FINISHED,
                serviceClient);
        Closure fetchedClosure = getClosure(createdClosure.documentSelfLink, serviceClient);

        assertEquals(closureDescription.documentSelfLink, fetchedClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.FINISHED, fetchedClosure.state);

        verifyRunDuration(fetchedClosure);

        assertEquals(expectedInVar, fetchedClosure.inputs.get(""a"").getAsString());
        assertEquals(expectedResult, fetchedClosure.outputs.get(""result"").getAsString());

        cleanResource(imageRequestLink, serviceClient);
        cleanResource(createdClosure.documentSelfLink, serviceClient);
        cleanResource(closureDescription.documentSelfLink, serviceClient);
    }",1
"@Test
    public void executeJSObjectParametersTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        TestObject expectedInVar = new TestObject();
        expectedInVar.strTest = ""test"";
        expectedInVar.intTest = 1;
        expectedInVar.boolTest = true;
        int expectedOutVar = 3;
        String expectedResult = expectedInVar.strTest + ""_changed"";

        closureDescState.source = ""module.exports = function test(context) {""
                + "" var x = context.inputs.a;""
                + "" console.log('Hello object: ' + x.strTest);""
                + "" x.strTest = x.strTest + '_changed';""
                + "" x.intTest = x.intTest + 1; x.boolTest = !x.boolTest;""
                + "" context.outputs.result = x;""
                + ""}",1
"@Test
    public void completeFailTimeoutedJSScriptTaskTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        closureDescState.source = ""#!/usr/bin/powershell\n""
                + ""function test($context)\n""
                + ""{\n""
                + ""    Write-Host \""Waiting...\""\n""
                + ""    Start-Sleep -s 60\n""
                + ""    Write-Host \""After sleep\""\n""
                + ""}",1
"@Test
    public void completeOrFailOutdatedJSScriptTaskTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";
        closureDescState.source = ""#!/usr/bin/python\n""
                + ""import time\n""
                + ""\n""
                + ""def test(ctx):\n""
                + ""     print('Waiting....')\n""
                + ""     time.sleep(60)\n""
                + ""\n"";
        closureDescState.runtime = RUNTIME_PYTHON_3;
        closureDescState.outputNames = new ArrayList<>(Collections.singletonList(""result""));
        ResourceConstraints constraints = new ResourceConstraints();
        constraints.timeoutSeconds = 1;
        closureDescState.resources = constraints;

        String taskDefPayload = Utils.toJson(closureDescState);
        ClosureDescription closureDescription = createClosureDescription(taskDefPayload,
                serviceClient);
        assertNotNull(closureDescription);

        // Create Closure
        Closure createdClosure = createClosure(closureDescription, serviceClient);
        assertEquals(closureDescription.documentSelfLink, createdClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CREATED, createdClosure.state);

        // Executing the created Closure
        executeClosure(createdClosure, new Closure(), serviceClient);

        // Wait for the completion timeout
        waitForBuildCompletion(IMAGE_NAME, closureDescription);

        waitForTaskState(createdClosure.documentSelfLink, TaskState.TaskStage.CANCELLED,
                serviceClient);

        Closure fetchedClosure = getClosure(createdClosure.documentSelfLink, serviceClient);

        assertEquals(closureDescription.documentSelfLink, fetchedClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CANCELLED, fetchedClosure.state);

        // Request bring new execution of the created Closure.
        executeClosure(createdClosure, fetchedClosure, serviceClient);

        // Wait for the completion timeout
        waitForBuildCompletion(IMAGE_NAME, closureDescription);

        waitForTaskState(createdClosure.documentSelfLink, TaskState.TaskStage.CANCELLED,
                serviceClient);

        fetchedClosure = getClosure(createdClosure.documentSelfLink, serviceClient);

        assertEquals(closureDescription.documentSelfLink, fetchedClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CANCELLED, fetchedClosure.state);

        // Try to complete outdated Closure
        try {
            fetchedClosure.state = TaskState.TaskStage.FINISHED;
            SimpleHttpsClient.HttpResponse response = SimpleHttpsClient
                    .execute(SimpleHttpsClient.HttpMethod.PATCH, fetchedClosure.documentSelfLink,
                            Utils
                                    .toJson(fetchedClosure));
            if (response != null) {
                assertNotEquals(""Closure is not allowed to complete once it is CANCELLED"", 200,
                        response.statusCode);
            }",1
"@Test
    public void executePythonArrayOfBooleanParametersTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        Boolean[] expectedInVar = { true, true, true }",1
"@Test
    public void executePythonArrayOfNumberParametersTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        Integer[] expectedInVar = { 1, 2, 3 }",1
"@Test
    public void executePythonExtSourceAsZIPTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        String expectedInVar = ""a"";
        String expectedOutVar = ""b"";
        String expectedResult = ""ac"";

        closureDescState.sourceURL = testWebserverUri + ""/test_script_python.zip"";
        closureDescState.source = ""should not be used"";
        closureDescState.runtime = RUNTIME_PYTHON_3;
        closureDescState.outputNames = new ArrayList<>(Collections.singletonList(""result""));
        ResourceConstraints constraints = new ResourceConstraints();
        constraints.timeoutSeconds = 2;
        constraints.ramMB = 300;
        closureDescState.resources = constraints;

        String taskDefPayload = Utils.toJson(closureDescState);
        ClosureDescription closureDescription = createClosureDescription(taskDefPayload,
                serviceClient);
        assertNotNull(closureDescription);

        // Create Closure
        Closure createdClosure = createClosure(closureDescription, serviceClient);
        assertEquals(closureDescription.documentSelfLink, createdClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CREATED, createdClosure.state);

        // Execute the created Closure
        Closure closureRequest = new Closure();
        Map inputs = new HashMap<>();
        inputs.put(""a"", new JsonPrimitive(expectedInVar));
        closureRequest.inputs = inputs;

        executeClosure(createdClosure, closureRequest, serviceClient);

        // Wait for the completion timeout
        String imageRequestLink = waitForBuildCompletion(IMAGE_NAME, closureDescription);

        waitForTaskState(createdClosure.documentSelfLink, TaskState.TaskStage.FINISHED,
                serviceClient);

        Closure fetchedClosure = getClosure(createdClosure.documentSelfLink, serviceClient);

        assertEquals(closureDescription.documentSelfLink, fetchedClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.FINISHED, fetchedClosure.state);

        verifyRunDuration(fetchedClosure);

        assertEquals(expectedInVar, fetchedClosure.inputs.get(""a"").getAsString());
        assertEquals(expectedResult, fetchedClosure.outputs.get(""result"").getAsString());

        cleanResource(imageRequestLink, serviceClient);
        cleanResource(createdClosure.documentSelfLink, serviceClient);
        cleanResource(closureDescription.documentSelfLink, serviceClient);
    }",1
"@Test
    public void executePythonNonExistingZIPTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        String expectedInVar = ""a"";
        String expectedOutVar = ""b"";
        String expectedResult = ""ac"";

        closureDescState.sourceURL = testWebserverUri + ""/non_existing.zip"";
        closureDescState.source = ""should not be used"";
        closureDescState.runtime = RUNTIME_PYTHON_3;
        closureDescState.outputNames = new ArrayList<>(Collections.singletonList(""result""));
        ResourceConstraints constraints = new ResourceConstraints();
        constraints.timeoutSeconds = 2;
        constraints.ramMB = 300;
        closureDescState.resources = constraints;

        String taskDefPayload = Utils.toJson(closureDescState);
        ClosureDescription closureDescription = createClosureDescription(taskDefPayload,
                serviceClient);
        assertNotNull(closureDescription);

        // Create Closure
        Closure createdClosure = createClosure(closureDescription, serviceClient);
        assertEquals(closureDescription.documentSelfLink, createdClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CREATED, createdClosure.state);

        // Execute the created Closure
        Closure closureRequest = new Closure();
        Map inputs = new HashMap<>();
        inputs.put(""a"", new JsonPrimitive(expectedInVar));
        closureRequest.inputs = inputs;

        executeClosure(createdClosure, closureRequest, serviceClient);

        // Wait for the completion timeout
        try {
            String imageRequestLink = waitForBuildCompletion(IMAGE_NAME, closureDescription);
            fail(""Build of the image is expected to fail!"");
        }",1
"@Test
    public void executePythonWithBilliardDependencyTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        int expectedInVar = 3;
        int expectedOutVar = 3;
        double expectedResult = 4;

        closureDescState.source = ""import billiard\n""
                + ""\n""
                + ""\n""
                + ""def f():\n""
                + ""    print('ok!')\n""
                + ""\n""
                + ""def test(context):\n""
                + ""    inputs = context.inputs\n""
                + ""    print('Hello number  {}",1
"@Test
    public void executeJSArrayOfObjectParametersTest() throws Throwable {
        // Create Closure Definition
        URI factoryUri = UriUtils
                .buildFactoryUri(this.host, ClosureDescriptionFactoryService.class);
        this.host.testStart(1);
        ClosureDescription closureDefState = new ClosureDescription();
        closureDefState.name = ""test"";

        TestObject expectedInVar = new TestObject();
        expectedInVar.strTest = ""test"";
        expectedInVar.intTest = 1;
        expectedInVar.boolTest = true;
        int expectedOutVar = 3;
        String expectedResult = expectedInVar.strTest + ""_changed"";

        closureDefState.source = ""function test(x) { print('Hello object: ' + x[0].strTest);""
                + "" x[0].strTest = x[0].strTest + '_changed';""
                + "" x[0].intTest = x[0].intTest + 1; x[0].boolTest = !x[0].boolTest; return x;""
                + ""}",1
"@Test
    public void executeJSArrayOfStringParametersTest() throws Throwable {
        // Create Closure Definition
        URI factoryUri = UriUtils
                .buildFactoryUri(this.host, ClosureDescriptionFactoryService.class);
        this.host.testStart(1);
        ClosureDescription closureDefState = new ClosureDescription();
        closureDefState.name = ""test"";

        String[] expectedInVar = { ""a"", ""b"", ""c"" }",1
"@Test
    public void executeJSStringParametersTest() throws Throwable {
        // Create Closure Definition
        URI factoryUri = UriUtils
                .buildFactoryUri(this.host, ClosureDescriptionFactoryService.class);
        this.host.testStart(1);
        ClosureDescription closureDefState = new ClosureDescription();
        closureDefState.name = ""test"";

        String expectedInVar = ""a"";
        String expectedOutVar = ""b"";
        String expectedResult = ""ac"";

        closureDefState.source =
                ""function test(x) {print('Hello string: ' + x); return x.concat(\""c\"");}",1
"@Test
    public void executeTimeoutedJSScriptTaskTest() throws Throwable {
        // Create Closure Definition
        URI factoryUri = UriUtils
                .buildFactoryUri(this.host, ClosureDescriptionFactoryService.class);
        this.host.testStart(1);
        ClosureDescription closureDefState = new ClosureDescription();
        closureDefState.name = ""test"";
        closureDefState.source = ""function sleep(delay) {var start = new Date().getTime();while (new Date().getTime() < start + delay) {}",1
"@Test
    public void editClosureDescriptionTest() throws Throwable {
        URI factoryUri = UriUtils.buildFactoryUri(this.host, ClosureDescriptionFactoryService.class);
        this.host.testStart(1);
        ClosureDescription initialState = new ClosureDescription();
        initialState.name = ""test"";
        initialState.runtime = DriverConstants.RUNTIME_NODEJS_4;
        initialState.source = ""var a = 1; print(\""Hello \"" + a);"";
        Map inputs = new HashMap<>();
        inputs.put(""a"", new JsonPrimitive(10));
        initialState.inputs = inputs;
        initialState.entrypoint = ""modulename.handlername"";
        initialState.documentSelfLink = UUID.randomUUID().toString();
        ClosureDescription[] responses = new ClosureDescription[1];
        URI childURI = UriUtils.buildUri(this.host, ClosureDescriptionFactoryService.FACTORY_LINK + ""/"" + initialState
                .documentSelfLink);
        Operation post = Operation
                .createPost(factoryUri)
                .setBody(initialState)
                .setCompletion(getSafeHandler((o, e) -> {
                    assertNull(e);
                    responses[0] = o.getBody(ClosureDescription.class);

                    assertEquals(initialState.source, responses[0].source);
                    assertEquals(initialState.runtime, responses[0].runtime);
                    assertEquals(initialState.entrypoint, responses[0].entrypoint);
                    assertNotNull(initialState.inputs);
                    assertEquals(10, initialState.inputs.get(""a"").getAsInt());
                    assertNotNull(responses[0].resources);
                    assertEquals(ClosureProps.DEFAULT_CPU_SHARES, responses[0].resources.cpuShares);
                    assertEquals(ClosureProps.DEFAULT_MEMORY_MB_RES_CONSTRAINT, responses[0].resources.ramMB);
                    assertEquals(ClosureProps.DEFAULT_EXEC_TIMEOUT_SECONDS, responses[0].resources
                            .timeoutSeconds);
                }",1
"@Test
    public void testShouldUpdateContainerLinksWhenUpdatesToContainers() throws Throwable {
        compositeComponent = createCompositeComponent();
        ContainerState containerState1 = createContainer(compositeComponent.documentSelfLink);

        // add a new container:
        waitFor(() -> {
            compositeComponent = getDocument(CompositeComponent.class,
                    compositeComponent.documentSelfLink);
            if (compositeComponent.componentLinks == null
                    || compositeComponent.componentLinks.isEmpty()) {
                return false;
            }",1
"@Test
    public void testDataCollectionDuringProvisioning() throws Throwable {
        // stop the mock adapter service and start the mock inspector adapter service:
        stopService(mockAdapterService);
        mockAdapterService = null;
        final MockInspectAdapterService mockInspectAdapterService = new MockInspectAdapterService();
        String containerBeingProvisioned = ""containerBeingProvisioned"";
        try {
            String hostId = UUID.randomUUID().toString();
            String hostLink = UriUtils.buildUriPath(ComputeService.FACTORY_LINK, hostId);
            // add preexisting container
            addContainerToMockAdapter(hostLink, preexistingContainerId, preexistingContainerNames);

            URI adapterServiceUri = UriUtils.buildUri(host, ManagementUriParts.ADAPTER_DOCKER);
            host.startService(Operation.createPost(adapterServiceUri), mockInspectAdapterService);
            waitForServiceAvailability(ManagementUriParts.ADAPTER_DOCKER);

            ComputeDescription hostDescription = createComputeDescription();
            hostDescription = doPost(hostDescription, ComputeDescriptionService.FACTORY_LINK);

            ComputeState cs = createComputeState(hostId, hostDescription);

            cs = doPost(cs, ComputeService.FACTORY_LINK);

            // container being provisioned should not be discovered by the data collection
            // Do not set id - the container is still being provisioned
            ContainerState containerState = new ContainerState();
            containerState.names = containerNames;
            containerState.parentLink = UriUtils.buildUriPath(
                    ComputeService.FACTORY_LINK,
                    hostId);
            containerState.powerState = PowerState.PROVISIONING;
            containerState = doPost(containerState, ContainerFactoryService.SELF_LINK);
            addContainerToMockAdapter(hostLink, containerBeingProvisioned, containerState.names);

            doOperation(new ContainerHostDataCollectionState(), UriUtils.buildUri(host,
                    ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK),
                    false,
                    Service.Action.PATCH);

            host.log("">>>> testDiscoverCreateAndInspectContainer: Container Host %s created.""
                            + "" Waiting for data collection..."", cs.documentSelfLink);
            String csLink = cs.documentSelfLink;
            waitFor(() -> {
                ComputeState computeState = getDocument(ComputeState.class, csLink);
                String containers = computeState.customProperties == null ? null
                        : computeState.customProperties
                                .get(ContainerHostService.NUMBER_OF_CONTAINERS_PER_HOST_PROP_NAME);

                if (containers != null) {
                    host.log("">>>> # of containers per host %s is %s"",
                            computeState.documentSelfLink, containers);
                }",1
"@Test
    public void testDataCollectionDuringProvisioning() throws Throwable {
        // stop the mock adapter service and start the mock inspector adapter service:
        stopService(mockAdapterService);
        mockAdapterService = null;
        final MockInspectAdapterService mockInspectAdapterService = new MockInspectAdapterService();
        String containerBeingProvisioned = ""containerBeingProvisioned"";
        try {
            String hostId = UUID.randomUUID().toString();
            String hostLink = UriUtils.buildUriPath(ComputeService.FACTORY_LINK, hostId);
            // add preexisting container
            addContainerToMockAdapter(hostLink, preexistingContainerId, preexistingContainerNames);

            URI adapterServiceUri = UriUtils.buildUri(host, ManagementUriParts.ADAPTER_DOCKER);
            host.startService(Operation.createPost(adapterServiceUri), mockInspectAdapterService);
            waitForServiceAvailability(ManagementUriParts.ADAPTER_DOCKER);

            ComputeDescription hostDescription = createComputeDescription();
            hostDescription = doPost(hostDescription, ComputeDescriptionService.FACTORY_LINK);

            ComputeState cs = createComputeState(hostId, hostDescription);

            cs = doPost(cs, ComputeService.FACTORY_LINK);

            // container being provisioned should not be discovered by the data collection
            // Do not set id - the container is still being provisioned
            ContainerState containerState = new ContainerState();
            containerState.names = containerNames;
            containerState.parentLink = UriUtils.buildUriPath(
                    ComputeService.FACTORY_LINK,
                    hostId);
            containerState.powerState = PowerState.PROVISIONING;
            containerState = doPost(containerState, ContainerFactoryService.SELF_LINK);
            addContainerToMockAdapter(hostLink, containerBeingProvisioned, containerState.names);

            doOperation(new ContainerHostDataCollectionState(), UriUtils.buildUri(host,
                    ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK),
                    false,
                    Service.Action.PATCH);

            host.log("">>>> testDiscoverCreateAndInspectContainer: Container Host %s created.""
                            + "" Waiting for data collection..."", cs.documentSelfLink);
            String csLink = cs.documentSelfLink;
            waitFor(() -> {
                ComputeState computeState = getDocument(ComputeState.class, csLink);
                String containers = computeState.customProperties == null ? null
                        : computeState.customProperties
                                .get(ContainerHostService.NUMBER_OF_CONTAINERS_PER_HOST_PROP_NAME);

                if (containers != null) {
                    host.log("">>>> # of containers per host %s is %s"",
                            computeState.documentSelfLink, containers);
                }",1
"@Test
    public void testGetGroupResourcePlacementState() throws Throwable {
        GroupResourcePlacementState placementState = new GroupResourcePlacementState();
        placementState.name = ""reservation-test"";
        placementState.tenantLinks = Collections.singletonList(""testGroup"");
        placementState.maxNumberInstances = 10;
        placementState.resourcePoolLink = resourcePool.documentSelfLink;

        GroupResourcePlacementState outPlacementState = doPost(placementState,
                GroupResourcePlacementService.FACTORY_LINK);

        GroupResourcePlacementState[] result = new GroupResourcePlacementState[] { null }",1
"@Test
    public void testRemoveTagFromContainerImageName() {
        String[] input = new String[] { ""postgres"", ""postgres:9.4"", ""test-repo/postgres"",
                ""test-repo/postgres:9.4"", ""test-repo:5005/postgres"",
                ""test-repo:5005/postgres:9.4"" }",1
"@Test
    public void testConvertDockerComposeToCompositeTemplate() throws IOException {
        CompositeTemplate expectedTemplate = deserializeCompositeTemplate(
                getContent(""composite.wordpress.yaml""));

        String expectedTemplateYaml = serializeCompositeTemplate(expectedTemplate);

        // Docker Compose with environment values as array

        DockerCompose compose1 = deserializeDockerCompose(
                getContent(""docker.wordpress.1.yaml""));

        CompositeTemplate template1 = fromDockerComposeToCompositeTemplate(compose1);
        template1.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template1.components);

        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 2,
                template1.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 0,
                template1.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template1.components);

        String template1Yaml = serializeCompositeTemplate(template1);

        assertEqualsYamls(expectedTemplateYaml, template1Yaml, true);

        // Docker Compose with environment values as dictionary

        DockerCompose compose2 = deserializeDockerCompose(
                getContent(""docker.wordpress.2.yaml""));

        CompositeTemplate template2 = fromDockerComposeToCompositeTemplate(compose2);
        template2.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template2.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 2,
                template1.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 0,
                template1.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template1.components);

        String template2Yaml = serializeCompositeTemplate(template2);

        assertEqualsYamls(expectedTemplateYaml, template2Yaml, true);
    }",1
"@Test
    public void testConvertDockerComposeToCompositeTemplateWithNetwork() throws IOException {

        // Docker Compose with simple network entities

        CompositeTemplate expectedTemplate = deserializeCompositeTemplate(
                getContent(""composite.simple.network.yaml""));

        String expectedTemplateYaml = serializeCompositeTemplate(expectedTemplate);

        DockerCompose compose1 = deserializeDockerCompose(
                getContent(""docker.simple.network.yaml""));

        CompositeTemplate template1 = fromDockerComposeToCompositeTemplate(compose1);
        template1.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template1.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 3,
                template1.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 2,
                template1.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template1.components);

        String template1Yaml = serializeCompositeTemplate(template1);

        assertEqualsYamls(toUnixLineEnding(expectedTemplateYaml),
                toUnixLineEnding(getContent(""composite.simple.network.expected2.yaml"")), true);
        assertEqualsYamls(toUnixLineEnding(template1Yaml),
                toUnixLineEnding(getContent(""composite.simple.network.yaml"")), true);

        // Docker Compose with complex network entities

        expectedTemplate = deserializeCompositeTemplate(
                getContent(""composite.complex.network.yaml""));

        expectedTemplateYaml = serializeCompositeTemplate(expectedTemplate);

        DockerCompose compose2 = deserializeDockerCompose(
                getContent(""docker.complex.network.yaml""));

        CompositeTemplate template2 = fromDockerComposeToCompositeTemplate(compose2);
        template2.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template2.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 3,
                template2.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 3,
                template2.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template2.components);

        String template2Yaml = serializeCompositeTemplate(template2);

        assertEqualsYamls(toUnixLineEnding(getContent(""composite.simple.network.expected.yaml"")),
                toUnixLineEnding(template2Yaml), true);
    }",1
"@Test
    public void testDeserializeCompositeTemplateWithBindings() throws IOException {
        String expectedContent = getContent(""composite.bindings.yaml"");

        CompositeTemplate compositeTemplate = deserializeCompositeTemplate(expectedContent);

        ContainerDescription wpData = (ContainerDescription) compositeTemplate.components
                .get(""wordpress"").data;
        assertEquals(null, wpData._cluster);
        assertFalse(wpData.customProperties.containsKey(""mysql_user""));

        assertEquals(1, compositeTemplate.bindings.size());

        List<Binding> bindings = compositeTemplate.bindings.iterator().next().bindings;
        assertEquals(3, bindings.size());

        Map<Boolean, List<Binding>> partitionedBindings = bindings.stream()
                .collect(Collectors.partitioningBy(b -> b.isProvisioningTimeBinding()));

        assertEquals(1, partitionedBindings.get(false).size());

        Binding binding = partitionedBindings.get(false).get(0);
        assertFalse(binding.isProvisioningTimeBinding());
        assertEquals(""db~_cluster"", binding.placeholder.bindingExpression);

        // provisioning time bindings
        assertEquals(2, partitionedBindings.get(true).size());

        binding = partitionedBindings.get(true).get(0);
        assertTrue(binding.isProvisioningTimeBinding());
        assertEquals(""_resource~db~address"", binding.placeholder.bindingExpression);

        binding = partitionedBindings.get(true).get(1);
        assertTrue(binding.isProvisioningTimeBinding());
        assertEquals(""_resource~db~env~MYSQL_USER"", binding.placeholder.bindingExpression);

        // validate ""normalizeBindings""

        String expectedContentSerialized = serializeCompositeTemplate(compositeTemplate);

        assertFalse(expectedContent.contains(""bindings:""));
        assertFalse(expectedContentSerialized.contains(""bindings:""));

        assertTrue(expectedContent.contains(""${db~_cluster}",1
"@Test
    public void testDeserializeSerializeComplexDockerComposeWithNetwork() throws IOException {

        String expectedContent = getContent(""docker.complex.network.yaml"");

        DockerCompose compose = deserializeDockerCompose(expectedContent);

        String content = serializeDockerCompose(compose);

        assertEqualsYamls(toUnixLineEnding(expectedContent), toUnixLineEnding(content));

        CompositeTemplate template = fromDockerComposeToCompositeTemplate(compose);

        assertNull(template.id);
        assertNull(template.status);
        assertComponentTypes(template.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 3,
                template.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 3,
                template.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template.components);

        String contentTemplate = serializeCompositeTemplate(template);

        assertTrue((contentTemplate != null) && (!contentTemplate.isEmpty()));
    }",1
"@Test
    public void testSeriaizeDeserializeCompositeTemplateWithHealthCheck() throws IOException {

        // Assert that healthConfig.ignoreOnProvision is serialized when false
        String expectedContent = getContent(""composite.simple.health.yaml"");

        CompositeTemplate template = deserializeCompositeTemplate(expectedContent);

        ContainerDescription data = (ContainerDescription) template.components.get(""hello"").data;
        assertNotNull(data.healthConfig);
        assertEquals(false, data.healthConfig.ignoreOnProvision);

        // Assert that healthConfig.ignoreOnProvision is serialized when true
        data.healthConfig.ignoreOnProvision = true;
        String content = serializeCompositeTemplate(template);

        template = deserializeCompositeTemplate(content);

        data = (ContainerDescription) template.components.get(""hello"").data;
        assertNotNull(data.healthConfig);
        assertEquals(true, data.healthConfig.ignoreOnProvision);

        // Assert that healthConfig.ignoreOnProvision is not serialized when null
        data.healthConfig = null;
        content = serializeCompositeTemplate(template);
        assertFalse(content.contains(""health_config""));
    }",1
"@Test
    public void testWrongDeserializationExceptions() throws IOException {
        try {
            deserializeCompositeTemplate(getContent(""composite.bad.yaml""));
            fail(""wrong content!"");
        }",1
"@Test
    public void testFromContainerDescriptionHealthConfigToPodContainerProbe() {
        Probe expectedProbe1 = new Probe();
        expectedProbe1.exec = new ExecAction();
        expectedProbe1.exec.command = new String[] { ""test"", ""command"" }",1
"@Test
    public void testAllocationOfContainersWithAffinityAndVolumeFrom() throws Throwable {
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);

        // create first container:
        ContainerDescription desc1 = TestRequestStateFactory.createContainerDescription();
        desc1.documentSelfLink = UUID.randomUUID().toString();
        desc1.name = ""name1"";
        desc1.portBindings = null;
        desc1 = doPost(desc1, ContainerDescriptionService.FACTORY_LINK);
        assertNotNull(desc1);
        addForDeletion(desc1);

        String contextId = UUID.randomUUID().toString();
        // all instances of this request should be allocated on the same hosts because of the pod.
        ContainerAllocationTaskState allocationTask1 = createContainerAllocationTask(
                desc1.documentSelfLink, 1);
        allocationTask1.customProperties.put(RequestUtils.FIELD_NAME_CONTEXT_ID_KEY, contextId);
        allocationTask1 = allocate(allocationTask1);
        ContainerState container1 = getDocument(ContainerState.class,
                allocationTask1.resourceLinks.iterator().next());

        // create second container with afinity dependent on the first container:
        ContainerDescription desc2 = TestRequestStateFactory.createContainerDescription();
        desc2.documentSelfLink = UUID.randomUUID().toString();
        desc2.name = ""name2-links"";
        desc2.portBindings = null;
        desc2.affinity = new String[] { desc1.name }",1
"@Test
    public void testAllocationOfContainersWithSameHostPodConstraint() throws Throwable {
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);

        String pod = ""host-pod1"";

        // create a description with a pod defined:
        ContainerDescription desc1 = TestRequestStateFactory.createContainerDescription();
        desc1.documentSelfLink = UUID.randomUUID().toString();
        desc1.name = ""linked-container1"";
        desc1.pod = pod;
        desc1.portBindings = null;
        desc1 = doPost(desc1, ContainerDescriptionService.FACTORY_LINK);
        assertNotNull(desc1);
        addForDeletion(desc1);

        String contextId = UUID.randomUUID().toString();
        // all instances of this request should be allocated on the same hosts because of the pod.
        ContainerAllocationTaskState allocationTask1 = createContainerAllocationTask(
                desc1.documentSelfLink, 1);
        allocationTask1.customProperties.put(RequestUtils.FIELD_NAME_CONTEXT_ID_KEY, contextId);
        allocationTask1 = allocate(allocationTask1);
        ContainerState container = getDocument(ContainerState.class,
                allocationTask1.resourceLinks.iterator().next());

        String hostLink = container.parentLink;

        // loop a few times to make sure the right host is not chosen by a chance
        for (int i = 0; i < 5; i++) {
            ContainerDescription desc2 = TestRequestStateFactory.createContainerDescription();
            desc2.documentSelfLink = UUID.randomUUID().toString();
            desc2.name = ""linked-container"" + i;
            desc2.pod = pod;
            desc2.portBindings = null;
            desc2 = doPost(desc2, ContainerDescriptionService.FACTORY_LINK);
            assertNotNull(desc2);
            addForDeletion(desc2);

            // all instances of this request should be allocated on the same host as the one already
            // selected by the previous request since the desc1.pod == desc2.pod
            ContainerAllocationTaskState allocationTask2 = createContainerAllocationTask(
                    desc2.documentSelfLink, 2);
            allocationTask2.customProperties.put(RequestUtils.FIELD_NAME_CONTEXT_ID_KEY, contextId);
            allocationTask2 = allocate(allocationTask2);
            for (String resourceLink : allocationTask2.resourceLinks) {
                ContainerState currContainer = getDocument(ContainerState.class, resourceLink);
                assertEquals(""Same host not selected for allocation request: ""
                        + allocationTask2.documentSelfLink + "" - in iteration: "" + i, hostLink,
                        currContainer.parentLink);
            }",1
"@Test
    public void testRequestLifeCycle() throws Throwable {
        host.log(""########  Start of testRequestLifeCycle ######## "");
        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();
        createDockerHost(dockerHostDesc, resourcePool);

        // setup Container desc:
        ContainerDescription containerDesc = createContainerDescription();

        // setup Group Placement:
        GroupResourcePlacementState groupPlacementState = createGroupResourcePlacement(
                resourcePool);

        // 1. Request a container instance:
        RequestBrokerState request = TestRequestStateFactory.createRequestState();
        request.resourceDescriptionLink = containerDesc.documentSelfLink;
        request.tenantLinks = groupPlacementState.tenantLinks;
        host.log(""########  Start of request ######## "");
        request = startRequest(request);

        // wait for request completed state:
        request = waitForRequestToComplete(request);

        RequestBrokerGraphResponse graph = getDocument(RequestBrokerGraphResponse.class,
                ManagementUriParts.REQUEST_GRAPH, RequestBrokerGraphService.QUERY_PARAM,
                extractId(request.documentSelfLink));
        assertNotNull(graph);
        assertNotNull(graph.tasks);

        TaskServiceDocumentHistory requestTask = graph.tasks.remove(0);
        assertTaskPassingStages(requestTask, RequestBrokerFactoryService.SELF_LINK,
                RequestBrokerState.SubStage.values());

        TaskServiceDocumentHistory reservationTask = graph.tasks.remove(0);
        assertTaskPassingStages(reservationTask, ReservationTaskFactoryService.SELF_LINK,
                ReservationTaskState.SubStage.values());

        TaskServiceDocumentHistory placementReservationTask = graph.tasks.remove(0);
        assertTaskPassingStages(placementReservationTask,
                PlacementHostSelectionTaskService.FACTORY_LINK,
                PlacementHostSelectionTaskState.SubStage.values());

        TaskServiceDocumentHistory allocationTask = graph.tasks.remove(0);
        assertTaskPassingStages(allocationTask, ContainerAllocationTaskFactoryService.SELF_LINK,
                ContainerAllocationTaskState.SubStage.values());

        TaskServiceDocumentHistory placementTask = graph.tasks.remove(0);
        assertTaskPassingStages(placementTask, PlacementHostSelectionTaskService.FACTORY_LINK,
                PlacementHostSelectionTaskState.SubStage.values());
    }",1
"@Test
    public void testCompositeComponentWithClusterAndLocalContainerVolumeRequestLifeCycle()
            throws Throwable {
        host.log(
                ""########  Start of testCompositeComponentWithClusterAndLocalContainerVolumeRequestLifeCycle ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        String sharedVolumeName = ""Postgres"";
        String volumeName = String.format(""%s:/etc/pgdata/postgres"", sharedVolumeName);

        ContainerVolumeDescription volumeDesc = TestRequestStateFactory
                .createContainerVolumeDescription(sharedVolumeName);
        volumeDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory.createContainerDescription();
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.name = ""Container1"";
        container1Desc.volumes = new String[] { volumeName }",1
"@Test
    public void testCompositeComponentWithContainerNetworkRequestLifeCycle() throws Throwable {
        host.log(
                ""########  Start of testCompositeComponentWithContainerNetworkRequestLifeCycle ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        // ""set"" the same KV-store for the Docker Hosts created
        dockerHostDesc.customProperties.put(
                ContainerHostService.DOCKER_HOST_CLUSTER_STORE_PROP_NAME, ""my-kv-store"");

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        // setup Composite description with 2 containers and 1 network

        String networkName = ""MyNet"";

        ContainerNetworkDescription networkDesc = TestRequestStateFactory
                .createContainerNetworkDescription(networkName);
        networkDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory.createContainerDescription();
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.name = ""Container1"";
        container1Desc.networks = new HashMap<>();
        container1Desc.networks.put(networkName, new ServiceNetwork());

        ContainerDescription container2Desc = TestRequestStateFactory.createContainerDescription();
        container2Desc.documentSelfLink = UUID.randomUUID().toString();
        container2Desc.name = ""Container2"";
        container2Desc.affinity = new String[] { ""!Container1:hard"" }",1
"@Test
    public void testCompositeComponentWithContainerVolumeRequestLifeCycle() throws Throwable {
        host.log(
                ""########  Start of testCompositeComponentWithContainerVolumeRequestLifeCycle ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        String sharedVolumeName = ""Postgres"";
        String volumeName = String.format(""%s:/etc/pgdata/postgres"", sharedVolumeName);

        ContainerVolumeDescription volumeDesc = TestRequestStateFactory
                .createContainerVolumeDescription(sharedVolumeName);
        volumeDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory.createContainerDescription();
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.name = ""Container1"";
        container1Desc.volumes = new String[] { volumeName }",1
"@Test
    public void testStoreHostSelfSignedCertificateAndAddHost() throws Throwable {
        computeState.address = VALID_DOCKER_HOST_NODE1_ADDRESS;
        SslTrustCertificateState[] certs = new SslTrustCertificateState[] { null }",1
"@Test
    public void testMultipleHosts() throws Throwable {
        List<String> tenantLinksHost1 = new ArrayList<String>();
        tenantLinksHost1.add(""project1"");
        tenantLinksHost1.add(""project2"");
        List<String> tenantLinksHost2 = new ArrayList<String>();
        tenantLinksHost2.add(""host2-project"");

        ComputeState cs = createComputeState(""TestID1"", tenantLinksHost1);
        cs = doPost(cs, ComputeService.FACTORY_LINK);
        ComputeState cs2 = createComputeState(""TestID2"", tenantLinksHost2);
        cs2 = doPost(cs2, ComputeService.FACTORY_LINK);

        ContainerState firstContainerHost1 = createContainer(cs.documentSelfLink);
        firstContainerHost1 = doPost(firstContainerHost1, ContainerFactoryService.SELF_LINK);
        ContainerState secondContainerHost1 = createContainer(cs.documentSelfLink);
        secondContainerHost1 = doPost(secondContainerHost1, ContainerFactoryService.SELF_LINK);

        ContainerState firstContainerHost2 = createContainer(cs2.documentSelfLink);
        firstContainerHost2 = doPost(firstContainerHost2, ContainerFactoryService.SELF_LINK);
        ContainerState secondContainerHost2 = createContainer(cs2.documentSelfLink);
        // set tenant links to the container to check that the old tenant links are not overwritten
        secondContainerHost2.tenantLinks = new ArrayList<>();
        String containerTenantLink = ""test-business-group"";
        secondContainerHost2.tenantLinks.add(containerTenantLink);
        secondContainerHost2 = doPost(secondContainerHost2, ContainerFactoryService.SELF_LINK);
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ContainersTransformationService.SELF_LINK), false,
                Service.Action.POST);

        firstContainerHost1 = getDocument(ContainerState.class,
                firstContainerHost1.documentSelfLink);
        secondContainerHost1 = getDocument(ContainerState.class,
                secondContainerHost1.documentSelfLink);
        firstContainerHost2 = getDocument(ContainerState.class,
                firstContainerHost2.documentSelfLink);
        secondContainerHost2 = getDocument(ContainerState.class,
                secondContainerHost2.documentSelfLink);

        Assert.assertTrue(firstContainerHost1.tenantLinks.containsAll(tenantLinksHost1));
        Assert.assertTrue(secondContainerHost1.tenantLinks.containsAll(tenantLinksHost1));
        Assert.assertTrue(secondContainerHost1.tenantLinks.equals(firstContainerHost1.tenantLinks));

        Assert.assertTrue(firstContainerHost2.tenantLinks.containsAll(tenantLinksHost2));
        Assert.assertTrue(secondContainerHost2.tenantLinks.containsAll(tenantLinksHost2));
        Assert.assertTrue(secondContainerHost2.tenantLinks
                .size() == firstContainerHost2.tenantLinks.size() + 1);
        Assert.assertTrue(secondContainerHost2.tenantLinks.contains(containerTenantLink));
    }",1
"@Test
    public void testNormal01() throws Exception {
        // start mock fluentd
        int port = MockFluentd.randomPort();
        final List<Event> elist = new ArrayList<Event>();
        MockFluentd fluentd = new MockFluentd(port, new MockFluentd.MockProcess() {
            public void process(MessagePack msgpack, Socket socket) throws IOException {
                BufferedInputStream in = new BufferedInputStream(socket.getInputStream());
                try {
                    Unpacker unpacker = msgpack.createUnpacker(in);
                    while (true) {
                        Event e = unpacker.read(Event.class);
                        elist.add(e);
                    }",1
"@Test
    public void testReconnection() throws Exception {
        // start mock fluentd
        int port = MockFluentd.randomPort();
        String host = ""localhost"";
        final List<Event> elist1 = new ArrayList<Event>();
        final AtomicReference<Exception> lastError = new AtomicReference<Exception>();

        FixedThreadManager threadManager = new FixedThreadManager(2);

        // run a fluentd
        MockFluentd fluentd1 = new MockFluentd(port, new MockFluentd.MockProcess() {
            public void process(MessagePack msgpack, Socket socket) throws IOException {
                BufferedInputStream in = new BufferedInputStream(socket.getInputStream());
                try {
                    Unpacker unpacker = msgpack.createUnpacker(in);
                    while (true) {
                        Event e = unpacker.read(Event.class);
                        elist1.add(e);

                        if (elist1.size() >= 1)
                            break;
                    }",1
"@Test
	public void testSupportedTypesRegistered() {
		for (SentenceId id : SentenceId.values()) {
			String msg = ""Parser not registered: "" + id;
			assertTrue(msg, instance.hasParser(id.toString()));
		}",1
"@Test
	public void testSetYearTwoDigit() {
		int century = 2000;
		for (int year = 0; year < 100; year++) {
			instance.setYear(year);
			assertEquals((century + year), instance.getYear());
			if (year == Date.PIVOT_YEAR) {
				century = 1900;
			}",1
"@Test
    public void map4() {
        CloseableIterator<Map<Map<Integer, String>, String>> results = MAP4_RESULTS.transform(
            groupBy(postId).iterate(map(map(postId, commentText), postName)));
        List<Map<Map<Integer, String>, String>> actual = IteratorAdapter.asList(results);

        Object commentId = null;
        Map<Map<Integer, String>, String> comments = null;
        List<Map<Map<Integer, String>, String>> expected = new LinkedList<Map<Map<Integer, String>, String>>();
        for (Iterator<Tuple> iterator = MAP4_RESULTS.iterate(); iterator.hasNext();) {
            Tuple tuple = iterator.next();
            Object[] array = tuple.toArray();

            if (comments == null || !(commentId == array[0] || commentId != null && commentId.equals(array[0]))) {
                comments = new LinkedHashMap<Map<Integer, String>, String>();
                expected.add(comments);
            }",1
"@Test
    public void map3() {
        Map<Integer, Map<Integer, Map<Integer, String>>> actual = MAP3_RESULTS.transform(
            groupBy(postId).as(map(postId, map(commentId, commentText))));

        Map<Integer, Map<Integer, Map<Integer, String>>> expected = new LinkedHashMap<Integer, Map<Integer, Map<Integer, String>>>();
        for (Iterator<Tuple> iterator = MAP3_RESULTS.iterate(); iterator.hasNext();) {
            Tuple tuple = iterator.next();
            Object[] array = tuple.toArray();

            Map<Integer, Map<Integer, String>> posts = expected.get(array[0]);
            if (posts == null) {
                posts = new LinkedHashMap<Integer, Map<Integer,String>>();
                expected.put((Integer) array[0], posts);
            }",1
"@Test
    public void addJoin() {
        List<JoinExpression> joins = new ArrayList<JoinExpression>();
        joins.add(new JoinExpression(JoinType.DEFAULT, x));
        joins.add(new JoinExpression(JoinType.DEFAULT, y));
        joins.add(new JoinExpression(JoinType.INNERJOIN, y));
        joins.add(new JoinExpression(JoinType.INNERJOIN, x_a));
        joins.add(new JoinExpression(JoinType.INNERJOIN, x_a_a));
        joins.add(new JoinExpression(JoinType.INNERJOIN, x_a_b));
        joins.add(new JoinExpression(JoinType.INNERJOIN, x_b));
        joins.add(new JoinExpression(JoinType.INNERJOIN, y_a));
        joins.add(new JoinExpression(JoinType.INNERJOIN, y_b));

        for (JoinExpression join1 : joins) {
            for (JoinExpression join2 : joins) {
                QueryMetadata md = new OrderedQueryMetadata();
                addJoin(md, join1);
                addJoin(md, join2);
                validate(md.getJoins());

                for (JoinExpression join3 : joins) {
                    md = new OrderedQueryMetadata();
                    addJoin(md, join1);
                    addJoin(md, join2);
                    addJoin(md, join3);
                    validate(md.getJoins());

                    for (JoinExpression join4 : joins) {
                        md = new OrderedQueryMetadata();
                        addJoin(md, join1);
                        addJoin(md, join2);
                        addJoin(md, join3);
                        addJoin(md, join4);
                        validate(md.getJoins());
                    }",1
"@Test
    public void  Signature() throws NoSuchMethodException {
        List<String> types = Arrays.asList(""boolean"", ""comparable"", ""date"", ""dsl"", ""dateTime"",
                ""enum"", ""number"", ""simple"", ""string"", ""time"");
        for (String type : types) {
            if (type.equals(""boolean"") || type.equals(""string"")) {
                assertReturnType(Expressions.class.getMethod(type + ""Path"", String.class));
                assertReturnType(Expressions.class.getMethod(type + ""Path"", Path.class, String.class));
                assertReturnType(Expressions.class.getMethod(type + ""Path"", PathMetadata.class));
                assertReturnType(Expressions.class.getMethod(type + ""Operation"", Operator.class, Expression[].class));
                assertReturnType(Expressions.class.getMethod(type + ""Template"", String.class, Object[].class));
                assertReturnType(Expressions.class.getMethod(type + ""Template"", String.class, List.class));
                assertReturnType(Expressions.class.getMethod(type + ""Template"", Template.class, Object[].class));
                assertReturnType(Expressions.class.getMethod(type + ""Template"", Template.class, List.class));
            }",1
"@Test
    public void expressions() throws Exception {
        Map<Class<?>, Object> args = new HashMap<>();
        args.put(Object.class, ""obj"");
        args.put(BeanPath.class, new EntityPathBase<Object>(Object.class, ""obj""));
        args.put(Class.class, Integer.class);
        args.put(Class[].class, new Class<?>[]{Object.class, Object.class}",1
"@Test
    public void get_all_with_tweet_count() {
        User user = new User();
        user.setUsername(""jimmy"");
        Long posterId = repository.save(user);

        Tweet tw3 = new Tweet();
        tw3.setPosterId(posterId);
        tw3.setContent(""#EpicFail"");
        tweetRepository.save(tw3);

        List<UserInfo> infos = repository.allWithTweetCount();
        assertFalse(infos.isEmpty());
        for (UserInfo info : infos) {
            assertNotNull(info.getUsername());
        }",1
"@Test
    public void scrollTuple() throws IOException {
        CloseableIterator<Tuple> rows = new ScrollableResultsIterator<Tuple>(query()
                .from(cat)
                .select(cat.name, cat.birthdate).createQuery().scroll());
        assertTrue(rows.hasNext());
        while (rows.hasNext()) {
            Tuple row = rows.next();
            assertEquals(2, row.size());
        }",1
"@Test
    public void various() throws Exception {
        MatchingFiltersFactory filters = new MatchingFiltersFactory(QuerydslModule.LUCENE, Target.LUCENE);
        for (Predicate filter : filters.string(title, StringConstant.create(""jurassic park""))) {
            if (unsupportedOperation(filter)) {
                continue;
            }",1
"@Test
    public void various() throws Exception {
        MatchingFiltersFactory filters = new MatchingFiltersFactory(QuerydslModule.LUCENE, Target.LUCENE);
        for (Predicate filter : filters.string(title, StringConstant.create(""jurassic park""))) {
            if (unsupportedOperation(filter)) {
                continue;
            }",1
"@Test
    public void allMapped() {
        Map<Operator, String> mapping = HibernateSpatialSupport.getSpatialOps();
        for (Operator operator : SpatialOps.values()) {
            assertTrue(operator + "" missing"", mapping.containsKey(operator));
        }",1
"@Test
    public void array_projection() {
        List<String[]> results = query().from(employee).select(
                new ArrayConstructorExpression<String>(String[].class, employee.firstname)).fetch();
        assertFalse(results.isEmpty());
        for (String[] result : results) {
            assertNotNull(result[0]);
        }",1
"@Test
    public void casts() throws SQLException {
        NumberExpression<?> num = employee.id;
        List<Expression<?>> exprs = new ArrayList<>();

        add(exprs, num.byteValue(), MYSQL);
        add(exprs, num.doubleValue());
        add(exprs, num.floatValue());
        add(exprs, num.intValue());
        add(exprs, num.longValue(), MYSQL);
        add(exprs, num.shortValue(), MYSQL);
        add(exprs, num.stringValue(), DERBY);

        for (Expression<?> expr : exprs) {
            for (Object o : query().from(employee).select(expr).fetch()) {
                assertEquals(expr.getType(), o.getClass());
            }",1
"@Test
    public void compact_join() {
        // verbose
        assertEquals(8, query().from(employee)
            .innerJoin(employee2)
            .on(employee.superiorId.eq(employee2.id))
            .select(employee.id, employee2.id).fetch().size());

        // compact
        assertEquals(8, query().from(employee)
            .innerJoin(employee.superiorIdKey, employee2)
            .select(employee.id, employee2.id).fetch().size());

    }",1
"@Test
    public void joins() throws SQLException {
        for (Tuple row : query().from(employee).innerJoin(employee2)
                .on(employee.superiorId.eq(employee2.superiorId))
                .where(employee2.id.eq(10))
                .select(employee.id, employee2.id).fetch()) {
            assertNotNull(row.get(employee.id));
            assertNotNull(row.get(employee2.id));
        }",1
"@Test
    public void nested_tuple_projection() {
        Concatenation concat = new Concatenation(employee.firstname, employee.lastname);
        List<Tuple> tuples = query().from(employee)
                .select(employee.firstname, employee.lastname, concat).fetch();
        assertFalse(tuples.isEmpty());
        for (Tuple tuple : tuples) {
            String firstName = tuple.get(employee.firstname);
            String lastName = tuple.get(employee.lastname);
            assertEquals(firstName + lastName, tuple.get(concat));
        }",1
"@Test
    public void array_projection() {
        List<String[]> results = query().from(employee).select(
                new ArrayConstructorExpression<String>(String[].class, employee.firstname)).fetch();
        assertFalse(results.isEmpty());
        for (String[] result : results) {
            assertNotNull(result[0]);
        }",1
"@Test
    public void constructor_projection2() {
        List<SimpleProjection> projections = query().from(employee).select(
                Projections.constructor(SimpleProjection.class,
                        employee.firstname, employee.lastname)).fetch();
        assertFalse(projections.isEmpty());
        for (SimpleProjection projection : projections) {
            assertNotNull(projection);
        }",1
"@Test
    public void query_with_constant() throws Exception {
        for (Tuple row : query().from(survey)
                .where(survey.id.eq(1))
                .select(survey.id, survey.name).fetch()) {
            assertNotNull(row.get(survey.id));
            assertNotNull(row.get(survey.name));
        }",1
"@Test
    public void nested_tuple_projection() {
        Concatenation concat = new Concatenation(employee.firstname, employee.lastname);
        List<Tuple> tuples = query().from(employee)
                .select(employee.firstname, employee.lastname, concat).fetch();
        assertFalse(tuples.isEmpty());
        for (Tuple tuple : tuples) {
            String firstName = tuple.get(employee.firstname);
            String lastName = tuple.get(employee.lastname);
            assertEquals(firstName + lastName, tuple.get(concat));
        }",1
"@Test
    public void unique_wildcard() {
        // unique wildcard
        Tuple row = query().from(survey).limit(1).select(survey.all()).fetchFirst();
        assertNotNull(row);
        assertEquals(3, row.size());
        assertNotNull(row.get(0, Object.class));
        assertNotNull(row.get(0, Object.class) + "" is not null"", row.get(1, Object.class));
    }",1
"@Test
    public void windowFunctions_manual_paging() {
        Expression<Long> rowNumber = SQLExpressions.rowNumber().over().orderBy(employee.lastname.asc()).as(""rn"");
        Expression<Object[]> all = Wildcard.all;

        // simple
        System.out.println(""#1"");
        for (Tuple row : query().from(employee).select(employee.firstname, employee.lastname, rowNumber).fetch()) {
            System.out.println(row);
        }",1
"@Test
    public void lineString_instances() {
        List<Geometry> results = withLineStrings().select(shapes.geometry).fetch();
        assertFalse(results.isEmpty());
        for (Geometry row : results) {
            assertNotNull(row);
            assertTrue(row instanceof LineString);
        }",1
"@Test
    public void multiLineString_instances() {
        List<Geometry> results = withMultiLineStrings().select(shapes.geometry).fetch();
        assertFalse(results.isEmpty());
        for (Geometry row : results) {
            assertNotNull(row);
            assertTrue(row instanceof MultiLineString);
        }",1
"@Test
    public void multiPoint_methods() {
        MultiPointPath<MultiPoint> multipoint = shapes.geometry.asMultiPoint();

        List<Expression<?>> expressions = new ArrayList<>();
        add(expressions, multipoint.asBinary(), H2);
        add(expressions, multipoint.asText());
        add(expressions, multipoint.boundary(), H2, MYSQL);
        add(expressions, multipoint.convexHull(), H2, MYSQL);
        add(expressions, multipoint.dimension());
        add(expressions, multipoint.envelope(), H2);
        add(expressions, multipoint.geometryType(), H2);
        add(expressions, multipoint.isEmpty());
        add(expressions, multipoint.isSimple());
        // multipoint specific
        add(expressions, multipoint.numGeometries(), H2);
        add(expressions, multipoint.geometryN(1), H2);

        for (Expression<?> expr : expressions) {
            boolean logged = false;
            for (Object row : withMultipoints().select(expr).fetch()) {
                if (row == null && !logged) {
                    System.err.println(expr.toString());
                    logged = true;
                }",1
"@Test
    public void multiPolygon_instances() {
        List<Geometry> results = withMultiPolygons().select(shapes.geometry).fetch();
        assertFalse(results.isEmpty());
        for (Geometry row : results) {
            assertNotNull(row);
            assertTrue(row instanceof MultiPolygon);
        }",1
"@Test
    public void iterate() {
        try (CloseableIterator<Employee> it = query.iterate()) {
            while (it.hasNext()) {
                it.next();
            }",1
"@Test
    public void complex_subQuery() {
        // create sub queries
        List<SubQueryExpression<Tuple>> sq = new ArrayList<SubQueryExpression<Tuple>>();
        String[] strs = new String[]{""a"",""b"",""c""}",1
"@Test
  public void testConcurrent() throws Exception {
    FeatureVectorsPartition fv = new FeatureVectorsPartition();
    AtomicInteger counter = new AtomicInteger();
    int numWorkers = 16;
    int numIterations = 10000;
    ExecUtils.doInParallel(numWorkers, i -> {
      for (int j = 0; j < numIterations; j++) {
        int c = counter.getAndIncrement();
        fv.setVector(Integer.toString(c), new float[] { c }",1
"@Test
  public void testRDF() throws Exception {
    Path tempDir = getTempDir();
    Path dataDir = tempDir.resolve(""data"");
    Path modelDir = tempDir.resolve(""model"");

    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.batch.update-class"", RDFUpdate.class.getName());
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.data-dir"", dataDir);
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.model-dir"", modelDir);
    overlayConfig.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC);
    overlayConfig.put(""oryx.rdf.num-trees"", 10);
    // Low values like 1 are deliberately bad, won't work
    overlayConfig.put(""oryx.rdf.hyperparams.max-depth"", ""[1,"" + MAX_DEPTH + ""]"");
    overlayConfig.put(""oryx.rdf.hyperparams.max-split-candidates"", MAX_SPLIT_CANDIDATES);
    overlayConfig.put(""oryx.input-schema.num-features"", 5);
    overlayConfig.put(""oryx.input-schema.categorical-features"", ""[\""4\""]"");
    overlayConfig.put(""oryx.input-schema.id-features"", ""[\""0\""]"");
    overlayConfig.put(""oryx.input-schema.target-feature"", ""\""4\"""");
    overlayConfig.put(""oryx.ml.eval.candidates"", 2);
    overlayConfig.put(""oryx.ml.eval.parallelism"", 2);
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    startServerProduceConsumeTopics(
        config,
        new RandomCategoricalRDFDataGenerator(3),
        DATA_TO_WRITE,
        WRITE_INTERVAL_MSEC);

    List<Path> modelInstanceDirs = IOUtils.listFiles(modelDir, ""*"");

    checkIntervals(modelInstanceDirs.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC);

    Path latestModelDir = modelInstanceDirs.get(modelInstanceDirs.size() - 1);
    Path modelFile = latestModelDir.resolve(MLUpdate.MODEL_FILE_NAME);
    assertTrue(""No such model file: "" + modelFile, Files.exists(modelFile));

    PMML pmml = PMMLUtils.read(modelFile);

    assertEquals(3, pmml.getExtensions().size());
    Map<String,Object> expected = new HashMap<>();
    expected.put(""maxSplitCandidates"", MAX_SPLIT_CANDIDATES);
    expected.put(""maxDepth"", MAX_DEPTH);
    expected.put(""impurity"", IMPURITY);
    checkExtensions(pmml, expected);

    Pair<DecisionForest,CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(pmml);
    DecisionForest forest = forestEncoding.getFirst();
    CategoricalValueEncodings encoding = forestEncoding.getSecond();
    Map<String,Integer> targetEncoding = encoding.getValueEncodingMap(4);

    int[] zeroOne = { 0, 1 }",1
"@Test
  public void testLSHEffect() {
    RandomGenerator random = RandomManager.getRandom();
    PoissonDistribution itemPerUserDist = new PoissonDistribution(
        random,
        20,
        PoissonDistribution.DEFAULT_EPSILON,
        PoissonDistribution.DEFAULT_MAX_ITERATIONS);
    int features = 20;
    ALSServingModel mainModel = new ALSServingModel(features, true, 1.0, null);
    ALSServingModel lshModel = new ALSServingModel(features, true, 0.5, null);

    int userItemCount = 20000;
    for (int user = 0; user < userItemCount; user++) {
      String userID = ""U"" + user;
      float[] vec = VectorMath.randomVectorF(features, random);
      mainModel.setUserVector(userID, vec);
      lshModel.setUserVector(userID, vec);
      int itemsPerUser = itemPerUserDist.sample();
      Collection<String> knownIDs = new ArrayList<>(itemsPerUser);
      for (int i = 0; i < itemsPerUser; i++) {
        knownIDs.add(""I"" + random.nextInt(userItemCount));
      }",1
"@Test
  public void testManyCores() {
    // But 3 cores should allow 1 bit difference if 3/4 is to be evaluated
    doTestHashesBits(0.75, 3, 2, 1);
    // 2 cores, evaluate half: 2 hashes split in 1/4, but can only keep 1 core busy at 0 bits differing
    // Allow 1 bit differing even though means evaluating 3 partitions, but then that evaluates 3/4 = 0.75 of
    // candidates which is too much. Ends up needing 3 hashes.
    doTestHashesBits(0.5, 3, 3, 1);
    // Ends up needing 7 hashes, 1 bit differing (1+7=8 partitions to try) to achieve 8 / 2^7 <= 0.1 sampling
    doTestHashesBits(0.1, 8, 7, 1);
    doTestHashesBits(0.01, 8, 11, 1);
    doTestHashesBits(0.001, 8, 14, 1);
    // Near max hashes:
    doTestHashesBits(0.0001, 8, 16, 1);
    // Maxes out at 16 hashes
    doTestHashesBits(0.00001, 8, LocalitySensitiveHash.MAX_HASHES, 1);
  }",1
"@Test
  public void testOneCore() {
    // 1 core, evaluate all: no hashes necessary at all
    doTestHashesBits(1.0, 1, 0, 0);
    // 1 core, evaluate half: 1 hash to split in half, evaluate only half (0 bits differ)
    doTestHashesBits(0.5, 1, 1, 0);
    // 1 core, evaluate <= 0.1: need 4 hashes to split in 1/16, then evaluate 1/16th (0 bits differ)
    doTestHashesBits(0.1, 1, 4, 0);
  }",1
"@Test
  public void testConsole() {
    String html;
    try (Response response = target(""/index.html"").request().accept(MediaType.TEXT_HTML).get()) {
      Assert.assertEquals(""public"", response.getHeaderString(""Cache-Control""));
      Assert.assertEquals(""SAMEORIGIN"", response.getHeaderString(""X-Frame-Options""));
      html = response.readEntity(String.class);
    }",1
"@Test
  public void testConsole() {
    String html;
    try (Response response = target(""/index.html"").request().accept(MediaType.TEXT_HTML).get()) {
      Assert.assertEquals(""public"", response.getHeaderString(""Cache-Control""));
      Assert.assertEquals(""SAMEORIGIN"", response.getHeaderString(""X-Frame-Options""));
      html = response.readEntity(String.class);
    }",1
"@Test
  public void testFormPredict() throws Exception {
    checkResponse(getFormPostResponse(PREDICT_DATA, ""/predict"", null, null));
  }",1
"@Test
  public void testALSSpeed() throws Exception {
    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.speed.model-manager-class"", ALSSpeedModelManager.class.getName());
    overlayConfig.put(""oryx.speed.streaming.generation-interval-sec"", 5);
    overlayConfig.put(""oryx.als.hyperparams.features"", 2);
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    List<KeyMessage<String,String>> updates =
        startServerProduceConsumeTopics(config,
                                        new MockALSInputGenerator(),
                                        new MockALSModelUpdateGenerator(),
                                        10, 10);

    if (log.isDebugEnabled()) {
      updates.forEach(update -> log.debug(""{}",1
"@Test
  public void testRDFSpeedRegression() throws Exception {
    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.speed.model-manager-class"", RDFSpeedModelManager.class.getName());
    overlayConfig.put(""oryx.speed.streaming.generation-interval-sec"", 10);
    overlayConfig.put(""oryx.input-schema.feature-names"", ""[\""foo\"",\""bar\""]"");
    overlayConfig.put(""oryx.input-schema.categorical-features"", ""[]"");
    overlayConfig.put(""oryx.input-schema.target-feature"", ""bar"");
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    List<KeyMessage<String,String>> updates =
        startServerProduceConsumeTopics(config,
                                        new MockRDFRegressionInputGenerator(),
                                        new MockRDFRegressionModelGenerator(),
                                        NUM_INPUT,
                                        1);

    if (log.isDebugEnabled()) {
      updates.forEach(update -> log.debug(""{}",1
"@Test
  public void testComplex() {
    DoubleWeightedMean mean = new DoubleWeightedMean();
    for (int i = 1; i <= 5; i++) {
      mean.increment(1.0 / (i + 1), i);
    }",1
"@Test
  public void testMLUpdate() throws Exception {
    Path tempDir = getTempDir();
    Path dataDir = tempDir.resolve(""data"");
    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.batch.update-class"", MockMLUpdate.class.getName());
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.data-dir"", dataDir);
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.model-dir"", tempDir.resolve(""model""));
    overlayConfig.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC);
    overlayConfig.put(""oryx.ml.eval.test-fraction"", TEST_FRACTION);
    overlayConfig.put(""oryx.ml.eval.threshold"", DATA_TO_WRITE / 2); // Should easily pass threshold
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    List<Integer> trainCounts = MockMLUpdate.getResetTrainCounts();
    List<Integer> testCounts = MockMLUpdate.getResetTestCounts();

    startServerProduceConsumeTopics(config, DATA_TO_WRITE, WRITE_INTERVAL_MSEC);

    // If lists are unequal at this point, there must have been an empty test set
    // which yielded no call to evaluate(). Fill in the blank
    while (trainCounts.size() > testCounts.size()) {
      testCounts.add(0);
    }",1
"@Test
  public void testHistoryMode() throws Exception {
    // Test setup
    Set<Long> tagIds = new HashSet<>();
    tagIds.add(1L);
    tagIds.add(2L);
    Collection<TagUpdate> serverUpdates = new ArrayList<>(tagIds.size());
    for (Long tagId : tagIds) {
      serverUpdates.add(createValidTransferTag(tagId));
      prepareClientDataTagCreateMock(tagId);
    }",1
"@Test
  public void testNoHealthNotification() throws InterruptedException {
    wrapper.setNotificationTimeBeforeWarning(1000); //allow up to 1s
    mocksControl.reset();
    mocksControl.replay();
    int i = 0;
    while (i < 2) {
      wrapper.onMessage(mockMessage);
      Thread.sleep(300);
      i++;
    }",1
"@Test
    public void testApplyChange() {
        RequestController requestController = new RequestController(configurationControllerMock);
        List<Change> changes = new ArrayList<>();
        /*
         *  Values in this case don't matter.
         *  Just add to the configuration controller and check
         *  if the MessageHandler does the right thing.
         */
        DataTagAdd dataTagAdd = new DataTagAdd();
        changes.add(dataTagAdd);
        configurationControllerMock.onDataTagAdd(dataTagAdd);
        expectLastCall().andReturn(new ChangeReport(1L));

        DataTagRemove dataTagRemove = new DataTagRemove();
        changes.add(dataTagRemove);
        configurationControllerMock.onDataTagRemove(dataTagRemove);
        expectLastCall().andReturn(new ChangeReport(1L));

        DataTagUpdate dataTagUpdate = new DataTagUpdate();
        changes.add(dataTagUpdate);
        configurationControllerMock.onDataTagUpdate(dataTagUpdate);
        expectLastCall().andReturn(new ChangeReport(1L));

        CommandTagAdd commandTagAdd = new CommandTagAdd();
        changes.add(commandTagAdd);
        configurationControllerMock.onCommandTagAdd(commandTagAdd);
        expectLastCall().andReturn(new ChangeReport(1L));

        CommandTagRemove commandTagremove = new CommandTagRemove();
        changes.add(commandTagremove);
        configurationControllerMock.onCommandTagRemove(commandTagremove);
        expectLastCall().andReturn(new ChangeReport(1L));

        CommandTagUpdate commandTagUpdate = new CommandTagUpdate();
        changes.add(commandTagUpdate);
        configurationControllerMock.onCommandTagUpdate(commandTagUpdate);
        expectLastCall().andReturn(new ChangeReport(1L));

        EquipmentConfigurationUpdate equipmentConfigurationUpdate = new EquipmentConfigurationUpdate();
        changes.add(equipmentConfigurationUpdate);
        configurationControllerMock.onEquipmentConfigurationUpdate(equipmentConfigurationUpdate);
        expectLastCall().andReturn(new ChangeReport(1L));

        ProcessConfigurationUpdate processConfigurationUpdate = new ProcessConfigurationUpdate();
        changes.add(processConfigurationUpdate);
        configurationControllerMock.onProcessConfigurationUpdate(processConfigurationUpdate);
        expectLastCall().andReturn(new ChangeReport(1L));

        replay(configurationControllerMock);
        for (Change change : changes) {
            requestController.applyChange(change);
        }",1
"@Test
    public void testAverage() {
        int counterSwitches = 5;
        int numberOfCounts = 50;
        for (int i = 0; i < counterSwitches; i++) {
            for (int j = 0; j < numberOfCounts; j++) {
                counterMovingAverage.increaseCurrentCounter();
            }",1
"@Test
    public void testOnOff() throws InterruptedException {
        for (int i = 0; i < 100; i++) {
            getActivator().newTagValueSent(getTestKey());
        }",1
"@Test
  public void testCacheLoading() {
    assertNotNull(dataTagCache);
    
    List<DataTag> dataTagList = dataTagMapper.getAll();
    
    //test the cache was loaded correctly
    assertEquals(dataTagList.size(), dataTagCache.getCache().getKeys().size());
    //compare all the objects from the cache and buffer
    Iterator<DataTag> it = dataTagList.iterator();
    while (it.hasNext()) {
      DataTag currentTag = (DataTag) it.next();
      //equality of DataTagCacheObjects => currently only compares names (do not change when DAQs are running on same DB)
      assertEquals(currentTag.getName(), ((DataTagCacheObject) dataTagCache.getCopy(currentTag.getId())).getName());
    }",1
"@Test
  public void testUpdateDataTag() {
    // construct fake DataTagCacheObject
    DataTagCacheObject cacheObject = new DataTagCacheObject();
    cacheObject.setId(150000L); // must be non null in DB
    cacheObject.setName(""Junit_test_tag""); // non null
    cacheObject.setMode(DataTagConstants.MODE_TEST); // non null
    cacheObject.setDataType(""Boolean""); // non null
    cacheObject.setEquipmentId(150L); // need test equipment inserted
    Metadata metadata = new Metadata();
    metadata.addMetadata(""metadata"", 11);
    cacheObject.setMetadata(metadata);

    dataTagMapper.insertDataTag(cacheObject);

    cacheObject.setValue(Boolean.TRUE);
    cacheObject.setValueDescription(""test value description"");
    cacheObject.setSimulated(false); // null allowed
    cacheObject.setDataTagQuality(new DataTagQualityImpl(TagQualityStatus.UNDEFINED_VALUE, ""undefined value""));
    cacheObject.setCacheTimestamp(new Timestamp(System.currentTimeMillis()));
    cacheObject.setSourceTimestamp(new Timestamp(System.currentTimeMillis()));
    metadata = new Metadata();
    metadata.addMetadata(""metadata_boolean"", true);
    cacheObject.setMetadata(metadata);

    dataTagMapper.updateCacheable(cacheObject);

    DataTagCacheObject retrievedObject = (DataTagCacheObject) dataTagMapper.getItem(new Long(150000));

    // updated values are changed
    assertEquals(cacheObject.getValue(), retrievedObject.getValue());
    assertEquals(cacheObject.getValueDescription(), retrievedObject.getValueDescription());
    assertEquals(cacheObject.isSimulated(), retrievedObject.isSimulated());
    assertEquals(cacheObject.getDataTagQuality(), retrievedObject.getDataTagQuality());
    assertEquals(cacheObject.getTimestamp(), retrievedObject.getTimestamp());
    assertEquals(cacheObject.getSourceTimestamp(), retrievedObject.getSourceTimestamp());
    metadata = new Metadata();
    metadata.addMetadata(""metadata"", 11);
    assertEquals(metadata, retrievedObject.getMetadata());

    // other values should be the same or ...
    assertEquals(cacheObject.getId(), retrievedObject.getId());
    assertEquals(cacheObject.getName(), retrievedObject.getName());
    assertEquals(cacheObject.getMode(), retrievedObject.getMode());
    assertEquals(cacheObject.getDataType(), retrievedObject.getDataType());

    // ... null/default
    assertNull(retrievedObject.getDescription());
    assertEquals(false, retrievedObject.isLogged()); // default boolean
    assertNull(retrievedObject.getUnit());
    assertNull(retrievedObject.getDipAddress());
    assertNull(retrievedObject.getJapcAddress());
    assertNull(retrievedObject.getMinValue());
    assertNull(retrievedObject.getMaxValue());
    assertNull(retrievedObject.getAddress());

    dataTagMapper.deleteDataTag(cacheObject.getId());
  }",1
"@Test
  public void testGetAll() {
    List<DeviceClass> deviceClasses = deviceClassMapper.getAll();
    Assert.assertNotNull(deviceClasses);
    Assert.assertTrue(deviceClasses.size() == 2);

    for (DeviceClass deviceClass : deviceClasses) {
      Assert.assertFalse(deviceClass.getProperties().size() == 0);
    }",1
"@Test
  public void testInsertDeviceClass() throws ClassNotFoundException {
    DeviceClassCacheObject deviceClass = new DeviceClassCacheObject(402L, ""TEST_DEVICE_CLASS_3"", ""Description of TEST_DEVICE_CLASS_3"");

    List<Property> properties = new ArrayList<>();

    properties.add(new Property(10L, ""TEST_PROPERTY_1"", ""Test property 1""));
    properties.add(new Property(11L, ""TEST_PROPERTY_2"", ""Test property 2""));

    List<Property> fields = new ArrayList<>();
    fields.add(new Property(12L, ""TEST_FIELD_1"", null));
    fields.add(new Property(13L, ""TEST_FIELD_2"", null));

    properties.add(new Property(14L, ""TEST_PROPERTY_WITH_FIELDS"", ""Test property with fields"", fields));

    deviceClass.setProperties(properties);

    deviceClass.setCommands(Arrays.asList(new Command(10L, ""TEST_COMMAND_1"", ""Test command 1""), new Command(11L, ""TEST_COMMAND_2"", ""Test command 2"")));

    deviceClassMapper.insertDeviceClass(deviceClass);
    for (Property property : ((DeviceClassCacheObject) deviceClass).getProperties()) {
      deviceClassMapper.insertDeviceClassProperty(deviceClass.getId(), property);

      if (property.getFields() != null) {
        for (Property field : property.getFields()) {
          deviceClassMapper.insertDeviceClassField(property.getId(), field);
        }",1
"@Test
  public void testCacheLoading() {
    assertNotNull(ruleTagCache);

    List<RuleTag> ruleList = ruleTagMapper.getAll(); //IN FACT: GIVES TIME FOR CACHE TO FINISH LOADING ASYNCH BEFORE COMPARISON BELOW...

    //test the cache is the same size as in DB
    assertEquals(ruleList.size(), ruleTagCache.getCache().getKeys().size());
    //compare all the objects from the cache and buffer
    Iterator<RuleTag> it = ruleList.iterator();
    while (it.hasNext()) {
      RuleTagCacheObject currentRule = (RuleTagCacheObject) it.next();
      //only compares one field so far (name, which does not change when server is running!)
      assertEquals(currentRule.getName(), (((RuleTag) ruleTagCache.getCopy(currentRule.getId())).getName()));
    }",1
"@Test
  public void testConfigurationRequest() throws Exception {
    //fake DAQ responding to request
    final JmsTemplate daqTemplate = new JmsTemplate(connectionFactory);
    new Thread(new Runnable() {

      @Override
      public void run() {
        try {
          daqTemplate.execute(new SessionCallback<Object>() {
            String reportString = MessageConverter.responseToJson(new ConfigurationChangeEventReport());
            @Override
            public Object doInJms(Session session) throws JMSException {
              Process process = processCache.get(50L);
              String jmsDaqQueue = ""c2mon.process"" + "".command."" + process.getCurrentHost() + ""."" + process.getName() + ""."" + process.getProcessPIK();
              MessageConsumer consumer = session.createConsumer(new ActiveMQQueue(jmsDaqQueue));
              Message incomingMessage = consumer.receive(1000);
              MessageProducer messageProducer = session.createProducer(incomingMessage.getJMSReplyTo());
              TextMessage replyMessage = session.createTextMessage();
              replyMessage.setText(reportString);
              messageProducer.send(replyMessage);
              return null;
            }",1
"@Test
  public void testProcessAliveTag() throws InterruptedException {
    CountDownLatch latch = new CountDownLatch(6);
    supervisionListener.notifySupervisionEvent(EasyMock.isA(SupervisionEvent.class));
    cacheSupervisionListener.onSupervisionChange(EasyMock.isA(Tag.class));
    EasyMock.expectLastCall().andAnswer(() -> { latch.countDown(); return null; }",1
"@Test
  public void testConfigurationReportJsonMessageSerialization() {
    ClientRequestImpl<ConfigurationReport> tagRequest =
      new ClientRequestImpl<>(ConfigurationReport.class);
    tagRequest.addTagIds(Arrays.asList(123L, 4324L, 4535L, 123L));

    String json = tagRequest.toJson();
    ClientRequest receivedRequest = ClientRequestImpl.fromJson(json);
    assertEquals(ClientRequest.RequestType.APPLY_CONFIGURATION_REQUEST, receivedRequest.getRequestType());
    assertEquals(tagRequest.getTagIds().size(), receivedRequest.getTagIds().size());
    Collection<Long> receivedTags = receivedRequest.getTagIds();
    for (Long tagId : receivedTags) {
      assertFalse(tagRequest.addTagId(tagId));
    }",1
"@Test
  public void testConfigurationReportJsonResponseDeserialization() {
    ClientRequestImpl<ConfigurationReport> tagRequest =
      new ClientRequestImpl<>(ConfigurationReport.class);
    tagRequest.addTagIds(Arrays.asList(123L, 4324L, 4535L, 123L));

    ConfigurationReport originalConfigurationReport = createConfigurationReport(123L) ;

    Float responseTagValue = Float.valueOf(2342.456546f); // not used
    String serverResponse = mockTagValueResponse(tagRequest.toJson(), responseTagValue);
    Collection<ConfigurationReport> responseList = tagRequest.fromJsonResponse(serverResponse);

    assertEquals(tagRequest.getTagIds().size(), responseList.size());
    for (ConfigurationReport receivedReport : responseList) {
      assertTrue(tagRequest.getTagIds().contains(receivedReport.getId()));

      assertTrue(originalConfigurationReport.getName() .equals(receivedReport.getName()));
      assertTrue(originalConfigurationReport.getStatus() .equals(receivedReport.getStatus()));
      assertTrue(originalConfigurationReport.getStatusDescription() .equals(receivedReport.getStatusDescription()));

      assertTrue(originalConfigurationReport.getUser() .equals(receivedReport.getUser()));
      assertTrue(originalConfigurationReport.getElementReports() .equals(receivedReport.getElementReports()));
    }",1
"@Test
  public void testGetDescription() {
    DataTagQuality tagQuality = new DataTagQualityImpl();
    assertEquals("""", tagQuality.getDescription());
    
    tagQuality.validate();
    assertEquals(VALID_DESCR, tagQuality.getDescription());
    
    // Setting the status shall overwrite the others
    
    String undefined = ""Tag is not defined"";
    assertTrue(tagQuality.setInvalidStatus(TagQualityStatus.UNDEFINED_TAG, undefined));
    assertEquals(undefined, tagQuality.getDescription());
    
    String subEquipmentDown = ""Sub-equipment is down"";
    assertTrue(tagQuality.setInvalidStatus(TagQualityStatus.SUBEQUIPMENT_DOWN, subEquipmentDown));
    assertEquals(subEquipmentDown, tagQuality.getDescription());
    
    String equipmentDown = ""Equipment is down"";
    assertTrue(tagQuality.setInvalidStatus(TagQualityStatus.EQUIPMENT_DOWN, equipmentDown));
    assertEquals(equipmentDown, tagQuality.getDescription());
    
    String processDown = ""DAQ process is down"";
    assertTrue(tagQuality.setInvalidStatus(TagQualityStatus.PROCESS_DOWN, processDown));
    assertEquals(processDown, tagQuality.getDescription());
    
    // Adding the status shall return the description of the highest severity
    assertTrue(tagQuality.addInvalidStatus(TagQualityStatus.EQUIPMENT_DOWN, equipmentDown));
    assertEquals(processDown, tagQuality.getDescription());
    
    assertTrue(tagQuality.addInvalidStatus(TagQualityStatus.SUBEQUIPMENT_DOWN, subEquipmentDown));
    assertEquals(processDown, tagQuality.getDescription());
    
    assertTrue(tagQuality.addInvalidStatus(TagQualityStatus.UNDEFINED_TAG, undefined));
    assertEquals(undefined, tagQuality.getDescription());
    
    tagQuality.removeInvalidStatus(TagQualityStatus.PROCESS_DOWN);
    assertEquals(undefined, tagQuality.getDescription());
    
    tagQuality.removeInvalidStatus(TagQualityStatus.UNDEFINED_TAG);
    assertEquals(equipmentDown, tagQuality.getDescription());
    
    tagQuality.removeInvalidStatus(TagQualityStatus.EQUIPMENT_DOWN);
    assertEquals(subEquipmentDown, tagQuality.getDescription());
    
    tagQuality.removeInvalidStatus(TagQualityStatus.SUBEQUIPMENT_DOWN);
    assertEquals(VALID_DESCR, tagQuality.getDescription());
    
    // test concatenation of error messages with same severity
    final String separator = ""; ""; 
    String outOfBounds = ""Value is out of bounds"";
    assertTrue(tagQuality.addInvalidStatus(TagQualityStatus.VALUE_OUT_OF_BOUNDS, outOfBounds));
    assertEquals(outOfBounds, tagQuality.getDescription());
    
    String unknownReason = ""Unknown"";
    assertTrue(tagQuality.addInvalidStatus(TagQualityStatus.UNKNOWN_REASON, unknownReason));
    if ((outOfBounds + separator + unknownReason).equalsIgnoreCase(tagQuality.getDescription())) {
      assertTrue(true);
    }",1
"@Test
    public void testDoubleCast() {
      castTest(Boolean.TRUE, Double.class, new Double(1));
      castTest(Boolean.FALSE, Double.class, new Double(0));
      castTest(new Double(0), Double.class, new Double(0));
      castTest(new Double(1), Double.class, new Double(1));
      castTest(new Double(25.5), Double.class, new Double(25.5));
      castTest(new Float(0), Double.class, new Double(0));
      castTest(new Float(1), Double.class, new Double(1));
      castTest(new Float(25.5), Double.class, new Double(25.5));
      castTest(new Short((short) 0), Double.class, new Double(0));
      castTest(new Short((short) 1), Double.class, new Double(1));
      castTest(new Short((short) 25), Double.class, new Double(25));
      castTest(new Long(0), Double.class, new Double(0));
      castTest(new Long(1), Double.class, new Double(1));
      castTest(new Long(2123190123125l), Double.class, new Double(2123190123125l));
      castTest(new Integer(0), Double.class, new Double(0));
      castTest(new Integer(1), Double.class, new Double(1));
      castTest(new Integer(25), Double.class, new Double(25));
      castTest(""0"", Double.class, new Double(0));
      castTest(""25.5"", Double.class, new Double(25.5));
      castTest(""RUNNING"", SupervisionStatus.class, SupervisionStatus.RUNNING);
      castTest(""DOWN"", SupervisionStatus.class, SupervisionStatus.DOWN);

      castTest(Boolean.TRUE, Double.class.getName(), new Double(1));
      castTest(Boolean.FALSE, Double.class.getName(), new Double(0));
      castTest(new Double(0), Double.class.getName(), new Double(0));
      castTest(new Double(1), Double.class.getName(), new Double(1));
      castTest(new Double(25.5), Double.class.getName(), new Double(25.5));
      castTest(new Float(0), Double.class.getName(), new Double(0));
      castTest(new Float(1), Double.class.getName(), new Double(1));
      castTest(new Float(25.5), Double.class.getName(), new Double(25.5));
      castTest(new Short((short) 0), Double.class.getName(), new Double(0));
      castTest(new Short((short) 1), Double.class.getName(), new Double(1));
      castTest(new Short((short) 25), Double.class.getName(), new Double(25));
      castTest(new Long(0), Double.class.getName(), new Double(0));
      castTest(new Long(1), Double.class.getName(), new Double(1));
      castTest(new Long(2123190123125l), Double.class.getName(), new Double(2123190123125l));
      castTest(new Integer(0), Double.class.getName(), new Double(0));
      castTest(new Integer(1), Double.class.getName(), new Double(1));
      castTest(new Integer(25), Double.class.getName(), new Double(25));
      castTest(""0"", Double.class.getName(), new Double(0));
      castTest(""25.5"", Double.class.getName(), new Double(25.5));
      castTest(""RUNNING"", SupervisionStatus.class, SupervisionStatus.RUNNING);
      castTest(""DOWN"", SupervisionStatus.class, SupervisionStatus.DOWN);

      castTest(Boolean.TRUE, ""Double"", new Double(1));
      castTest(Boolean.FALSE, ""Double"", new Double(0));
      castTest(new Double(0), ""Double"", new Double(0));
      castTest(new Double(1), ""Double"", new Double(1));
      castTest(new Double(25.5), ""Double"", new Double(25.5));
      castTest(new Float(0), ""Double"", new Double(0));
      castTest(new Float(1), ""Double"", new Double(1));
      castTest(new Float(25.5), ""Double"", new Double(25.5));
      castTest(new Short((short) 0), ""Double"", new Double(0));
      castTest(new Short((short) 1), ""Double"", new Double(1));
      castTest(new Short((short) 25), ""Double"", new Double(25));
      castTest(new Long(0), ""Double"", new Double(0));
      castTest(new Long(1), ""Double"", new Double(1));
      castTest(new Long(2123190123125l), ""Double"", new Double(2123190123125l));
      castTest(new Integer(0), ""Double"", new Double(0));
      castTest(new Integer(1), ""Double"", new Double(1));
      castTest(new Integer(25), ""Double"", new Double(25));
      castTest(""0"", ""Double"", new Double(0));
      castTest(""25.5"", ""Double"", new Double(25.5));
      castTest(""RUNNING"", SupervisionStatus.class, SupervisionStatus.RUNNING);
      castTest(""DOWN"", SupervisionStatus.class, SupervisionStatus.DOWN);
    }",1
"@Test
    public void testShortCast() {
      castTest(Boolean.TRUE, Short.class, new Short((short) 1));
      castTest(Boolean.FALSE, Short.class, new Short((short) 0));
      castTest(new Double(0), Short.class, new Short((short) 0));
      castTest(new Double(1), Short.class, new Short((short) 1));
      castTest(new Double(25.5), Short.class, new Short((short) 26));
      castTest(new Float(0), Short.class, new Short((short) 0));
      castTest(new Float(1), Short.class, new Short((short) 1));
      castTest(new Float(25.5), Short.class, new Short((short) 26));
      castTest(new Short((short) 0), Short.class, new Short((short) 0));
      castTest(new Short((short) 1), Short.class, new Short((short) 1));
      castTest(new Short((short) 25), Short.class, new Short((short) 25));
      castTest(new Long(0), Short.class, new Short((short) 0));
      castTest(new Long(1), Short.class, new Short((short) 1));
      castTest(new Integer(0), Short.class, new Short((short) 0));
      castTest(new Integer(1), Short.class, new Short((short) 1));
      castTest(new Integer(25), Short.class, new Short((short) 25));
      castTest(""0"", Short.class, new Short((short) 0));
      castTest(""25.5"", Short.class, Short.valueOf((short) 26));

      castTest(Boolean.TRUE, Short.class.getName(), new Short((short) 1));
      castTest(Boolean.FALSE, Short.class.getName(), new Short((short) 0));
      castTest(new Double(0), Short.class.getName(), new Short((short) 0));
      castTest(new Double(1), Short.class.getName(), new Short((short) 1));
      castTest(new Double(25.5), Short.class.getName(), new Short((short) 26));
      castTest(new Float(0), Short.class.getName(), new Short((short) 0));
      castTest(new Float(1), Short.class.getName(), new Short((short) 1));
      castTest(new Float(25.5), Short.class.getName(), new Short((short) 26));
      castTest(new Short((short) 0), Short.class.getName(), new Short((short) 0));
      castTest(new Short((short) 1), Short.class.getName(), new Short((short) 1));
      castTest(new Short((short) 25), Short.class.getName(), new Short((short) 25));
      castTest(new Long(0), Short.class.getName(), new Short((short) 0));
      castTest(new Long(1), Short.class.getName(), new Short((short) 1));
      castTest(new Integer(0), Short.class.getName(), new Short((short) 0));
      castTest(new Integer(1), Short.class.getName(), new Short((short) 1));
      castTest(new Integer(25), Short.class.getName(), new Short((short) 25));
      castTest(""0"", Short.class.getName(), new Short((short) 0));
      castTest(""25.5"", Short.class.getName(), Short.valueOf((short) 26));

      castTest(Boolean.TRUE, ""Short"", new Short((short) 1));
      castTest(Boolean.FALSE, ""Short"", new Short((short) 0));
      castTest(new Double(0), ""Short"", new Short((short) 0));
      castTest(new Double(1), ""Short"", new Short((short) 1));
      castTest(new Double(25.5), ""Short"", new Short((short) 26));
      castTest(new Float(0), ""Short"", new Short((short) 0));
      castTest(new Float(1), ""Short"", new Short((short) 1));
      castTest(new Float(25.5), ""Short"", new Short((short) 26));
      castTest(new Short((short) 0), ""Short"", new Short((short) 0));
      castTest(new Short((short) 1), ""Short"", new Short((short) 1));
      castTest(new Short((short) 25), ""Short"", new Short((short) 25));
      castTest(new Long(0), ""Short"", new Short((short) 0));
      castTest(new Long(1), ""Short"", new Short((short) 1));
      castTest(new Integer(0), ""Short"", new Short((short) 0));
      castTest(new Integer(1), ""Short"", new Short((short) 1));
      castTest(new Integer(25), ""Short"", new Short((short) 25));
      castTest(""0"", ""Short"", new Short((short) 0));
      castTest(""25.5"", ""Short"", Short.valueOf((short) 26));
    }",1
"@Test
    public void testLdapUserImport() throws NamingException {
        Mockito.when(ldapTemplate.getContextSource()).thenReturn(Mockito.mock(ContextSource.class));
        int userCount = 10;
        List<User> users = prepareGetAllUserMock(userCount);

        // for each user we should check if it exists in the user repository and only if not then we add it.
        for (int i = 0; i < users.size(); i++) {
            User user = users.get(i);
            if (i % 2 == 0) {
                user.setLastName(""test"");
                Mockito.when(alienUserDao.find(user.getUsername())).thenReturn(user);
            }",1
"@Test
    public void validateApplicationIdTest() {
        NameValidationUtils.validateApplicationId(""app"");
        NameValidationUtils.validateApplicationId(""app_2"");

        List<String> invalids = Lists.newArrayList(""appè"", ""App-2"", ""App.unix"", ""App 2"");
        invalids.forEach(invalid -> {
            expectException(new Callable() {
                @Override
                public Object call() throws Exception {
                    NameValidationUtils.validateApplicationId(invalid);
                    return null;
                }",1
"@Test
    public void testVersionComparing() {
        assertVersionEqual(""1"", ""1"");
        assertVersionOlder(""1"", ""2"");
        assertVersionOlder(""1.5"", ""2"");
        assertVersionOlder(""1"", ""2.5"");
        assertVersionEqual(""1"", ""1.0"");
        assertVersionEqual(""1"", ""1.0.0"");
        assertVersionOlder(""1.0"", ""1.1"");
        assertVersionOlder(""1.1"", ""1.2"");
        assertVersionOlder(""1.0.0"", ""1.1"");
        assertVersionOlder(""1.7.3.0"", ""1.7.3.1"");
        assertVersionOlder(""1.1"", ""1.2.0"");

        assertVersionOlder(""1.1.2.alpha1"", ""1.1.2"");
        assertVersionOlder(""1.1.2.alpha1"", ""1.1.2.beta1"");
        assertVersionOlder(""1.1.2.beta1"", ""1.2"");

        assertVersionOlder(""1.0-alpha-1"", ""1.0"");
        assertVersionOlder(""1.0-alpha-1"", ""1.0-alpha-2"");
        assertVersionOlder(""1.0-alpha-2"", ""1.0-alpha-15"");
        assertVersionOlder(""1.0-alpha-1"", ""1.0-beta-1"");

        assertVersionOlder(""1.0-beta-1"", ""1.0-SNAPSHOT"");
        assertVersionOlder(""1.0-SNAPSHOT"", ""1.0"");
        assertVersionOlder(""1.0-alpha-1-SNAPSHOT"", ""1.0-alpha-1"");

        assertVersionOlder(""1.0"", ""1.0-1"");
        assertVersionOlder(""1.0-1"", ""1.0-2"");
        assertVersionEqual(""2.0-0"", ""2.0"");
        assertVersionOlder(""2.0"", ""2.0-1"");
        assertVersionOlder(""2.0.0"", ""2.0-1"");
        assertVersionOlder(""2.0-1"", ""2.0.1"");

        assertVersionOlder(""2.0.1-klm"", ""2.0.1-lmn"");
        assertVersionOlder(""2.0.1"", ""2.0.1-xyz"");
        assertVersionOlder(""2.0.1-xyz-1"", ""2.0.1-1-xyz"");

        assertVersionOlder(""2.0.1"", ""2.0.1-123"");
        assertVersionOlder(""2.0.1-xyz"", ""2.0.1-123"");

        assertVersionOlder(""1.2.3-10000000000"", ""1.2.3-10000000001"");
        assertVersionOlder(""1.2.3-1"", ""1.2.3-10000000001"");
        assertVersionOlder(""2.3.0-v200706262000"", ""2.3.0-v200706262130""); // org.eclipse:emf:2.3.0-v200706262000
        // org.eclipse.wst.common_core.feature_2.0.0.v200706041905-7C78EK9E_EkMNfNOd2d8qq
        assertVersionOlder(""2.0.0.v200706041905-7C78EK9E_EkMNfNOd2d8qq"", ""2.0.0.v200706041906-7C78EK9E_EkMNfNOd2d8qq"");
    }",1
"@Test
    public void testVersionParsing() {
        checkVersionParsing(""1"", 1, 0, 0, 0, null);
        checkVersionParsing(""1.2"", 1, 2, 0, 0, null);
        checkVersionParsing(""1.2.3"", 1, 2, 3, 0, null);
        checkVersionParsing(""1.2.3-1"", 1, 2, 3, 1, null);
        checkVersionParsing(""1.2.3-alpha-1"", 1, 2, 3, 0, ""alpha-1"");
        checkVersionParsing(""1.2-alpha-1"", 1, 2, 0, 0, ""alpha-1"");
        checkVersionParsing(""1.2-alpha-1-20050205.060708-1"", 1, 2, 0, 0, ""alpha-1-20050205.060708-1"");
        checkVersionParsing(""RELEASE"", 0, 0, 0, 0, ""RELEASE"");
        checkVersionParsing(""2.0-1"", 2, 0, 0, 1, null);

        // 0 at the beginning of a number has a special handling
        checkVersionParsing(""02"", 0, 0, 0, 0, ""02"");
        checkVersionParsing(""0.09"", 0, 0, 0, 0, ""0.09"");
        checkVersionParsing(""0.2.09"", 0, 0, 0, 0, ""0.2.09"");
        checkVersionParsing(""2.0-01"", 2, 0, 0, 0, ""01"");

        // version schemes not really supported: fully transformed as qualifier
        checkVersionParsing(""1.0.1b"", 0, 0, 0, 0, ""1.0.1b"");
        checkVersionParsing(""1.0M2"", 0, 0, 0, 0, ""1.0M2"");
        checkVersionParsing(""1.0RC2"", 0, 0, 0, 0, ""1.0RC2"");
        checkVersionParsing(""1.1.2.beta1"", 1, 1, 2, 0, ""beta1"");
        checkVersionParsing(""1.7.3.beta1"", 1, 7, 3, 0, ""beta1"");
        checkVersionParsing(""1.7.3.0"", 0, 0, 0, 0, ""1.7.3.0"");
        checkVersionParsing(""1.7.3.0-1"", 0, 0, 0, 0, ""1.7.3.0-1"");
        checkVersionParsing(""PATCH-1193602"", 0, 0, 0, 0, ""PATCH-1193602"");
        checkVersionParsing(""5.0.0alpha-2006020117"", 0, 0, 0, 0, ""5.0.0alpha-2006020117"");
        checkVersionParsing(""1.0.0.-SNAPSHOT"", 0, 0, 0, 0, ""1.0.0.-SNAPSHOT"");
        checkVersionParsing(""1..0-SNAPSHOT"", 0, 0, 0, 0, ""1..0-SNAPSHOT"");
        checkVersionParsing(""1.0.-SNAPSHOT"", 0, 0, 0, 0, ""1.0.-SNAPSHOT"");
        checkVersionParsing("".1.0-SNAPSHOT"", 0, 0, 0, 0, "".1.0-SNAPSHOT"");

        checkVersionParsing(""1.2.3.200705301630"", 0, 0, 0, 0, ""1.2.3.200705301630"");
        checkVersionParsing(""1.2.3-200705301630"", 1, 2, 3, 0, ""200705301630"");
    }",1
"@Test
    public void testBerkeleyDBInjector() throws Exception {
        BerkeleyDBManager dbManager = new BerkeleyDBManager(tempCrawlPath);
        testInject(dbManager);
    }",1
"@Test
    public void testLowerCaseString() {
        for (int i = 0; i < 1000; i++) {
            String result = util.randomLower(10);
            assertEquals(10, result.length());
            assertEquals(result.toLowerCase(), result);
        }",1
"@Test
  public void testManyPutsAndRemoves() {
    // test resizing/rehashing

    Set<DirectoryEntry> entriesInDir = new HashSet<>();
    entriesInDir.add(new DirectoryEntry(dir, Name.SELF, dir));
    entriesInDir.add(new DirectoryEntry(dir, Name.PARENT, root));

    // add 1000 entries
    for (int i = 0; i < 1000; i++) {
      DirectoryEntry entry = entry(String.valueOf(i));
      dir.put(entry);
      entriesInDir.add(entry);

      assertThat(ImmutableSet.copyOf(dir)).isEqualTo(entriesInDir);

      for (DirectoryEntry expected : entriesInDir) {
        assertThat(dir.get(expected.name())).isEqualTo(expected);
      }",1
"@Test
    public void testParseWithViz() throws Exception {
        PairLexicoder<String,Long> rowCoder = new PairLexicoder<>(new StringLexicoder(), new LongLexicoder());
        byte[] row = rowCoder.encode(new ComparablePair<>(""sys.cpu.user"", 1000L));
        byte[] value = new byte[Double.BYTES];
        ByteBuffer.wrap(value).putDouble(2.0D);
        PairLexicoder<Long,String> colQualCoder = new PairLexicoder<>(new LongLexicoder(), new StringLexicoder());
        Key k = new Key(row, ""tag1=value1"".getBytes(), colQualCoder.encode(new ComparablePair<>(new Long(1000), ""tag2=value2,tag3=value3"")),
                        ""(a&b)|(c&d)"".getBytes(), 1000);
        Value v = new Value(value);
        Metric m = MetricAdapter.parse(k, v, true);
        Assert.assertEquals(""sys.cpu.user"", m.getName());
        List<Tag> tags = new ArrayList<>();
        tags.add(new Tag(""tag1=value1""));
        tags.add(new Tag(""tag2=value2""));
        tags.add(new Tag(""tag3=value3""));
        tags.add(new Tag(""viz=(a&b)|(c&d)""));
        Assert.assertEquals(tags, m.getTags());
        Assert.assertEquals(new Long(1000), m.getValue().getTimestamp());
        Assert.assertEquals(2.0D, m.getValue().getMeasure(), 0.0D);
    }",1
"@Test
    public void testToMutationWithViz() {
        long ts = System.currentTimeMillis();
        List<Tag> tags = new ArrayList<>();
        tags.add(new Tag(""tag1"", ""value1""));
        Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(ts, 2.0D).tags(tags).tag(MetricAdapter.VISIBILITY_TAG, ""(a&b)|(c&d)"").build();

        Mutation mut = MetricAdapter.toMutation(m);

        PairLexicoder<String,Long> rowCoder = new PairLexicoder<>(new StringLexicoder(), new LongLexicoder());
        byte[] row = rowCoder.encode(new ComparablePair<>(""sys.cpu.user"", MetricAdapter.roundTimestampToLastHour(ts)));
        byte[] value = new byte[Double.BYTES];
        ByteBuffer.wrap(value).putDouble(2.0D);
        Assert.assertEquals(rowCoder.decode(row), rowCoder.decode(mut.getRow()));
        Assert.assertEquals(1, mut.getUpdates().size());
        ColumnUpdate up = mut.getUpdates().get(0);
        Assert.assertEquals(""tag1=value1"", new String(up.getColumnFamily()));
        PairLexicoder<Long,String> colQualCoder = new PairLexicoder<>(new LongLexicoder(), new StringLexicoder());
        Assert.assertEquals(new String(colQualCoder.encode(new ComparablePair<>(ts, """"))), new String(up.getColumnQualifier()));
        Assert.assertEquals(ts, up.getTimestamp());
        Assert.assertEquals(""(a&b)|(c&d)"", new String(up.getColumnVisibility()));
        Assert.assertArrayEquals(value, up.getValue());
    }",1
"@Test
    public void testGenerateHtmlWithIgnoredTags() {
        timelyProperties.getMetricsReportIgnoredTags().add(""instance"");
        metaCache.add(new Meta(""sys.cpu.user"", ""host"", ""localhost""));
        metaCache.add(new Meta(""sys.cpu.user"", ""instance"", ""0""));
        metaCache.add(new Meta(""sys.cpu.idle"", ""host"", ""localhost""));
        metaCache.add(new Meta(""sys.cpu.idle"", ""instance"", ""0""));
        MetricsResponse response = new MetricsResponse(metaCache, timelyProperties);
        String html = response.generateHtml().toString();
        Assert.assertTrue(html.contains(""<td>sys.cpu.idle</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost </td>""));
        Assert.assertTrue(html.contains(""<td>sys.cpu.user</td>""));
        Assert.assertTrue(html.contains(""<td>host=localhost </td>""));
    }",1
"@Test
    public void testOneResponse() throws Exception {
        QueryResponse r = new QueryResponse();
        r.setMetric(""sys.cpu.user"");
        r.putTag(""host"", ""localhost"");
        r.putTag(""rack"", ""r1"");
        r.putDps(""1234567890"", 4.5);
        r.putDps(""1234567900"", 3.5);
        r.putDps(""1234567910"", 2.5);
        String result = JsonUtil.getObjectMapper().writeValueAsString(Collections.singletonList(r));
        String expected = ""[{\""metric\"":\""sys.cpu.user\"",\""tags\"":{\""host\"":\""localhost\"",\""rack\"":\""r1\""}",1
"@Test
    public void testJson() throws IOException {
        ObjectMapper mapper = new ObjectMapper();

        String expectedJson = ""{\""name\"":\""m1\"",\""timestamp\"":1,\""measure\"":1.0,\""tags\"":[{\""k1\"":\""v1\""}",1
"@Test
    public void testCombineMissingReport() throws Exception {
        Downsample ds = new Downsample(0, 1000, 100, new Avg());
        for (int i = 0; i < 1000; i += 100) {
            if (i != 700) {
                ds.add(i, .2);
            }",1
"@Test
    public void simpleAggregatedSample() throws Exception {
        AggregationIterator iter = new AggregationIterator();
        Map<Set<Tag>,Aggregation> samples = runQuery(iter, testData2, 100);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>,Aggregation> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", "".*"")), tags);
            long ts = 0;
            int count = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.getTimestamp());
                ts += 100;
                assertEquals(count == 0 ? 0.2 : (count == 10 ? 0.5 : 0.35), sample.getValue(), 0.0001);
                count++;
            }",1
"@Test
    public void memoryEstimatorTestSmallObjects() {
        long maxMemory = 1000;
        long start = System.currentTimeMillis();
        long period = 500l;
        long sizeOfObjects = 20;
        SampleObject o = new SampleObject();
        DownsampleMemoryEstimator memoryEstimator = new DownsampleMemoryEstimator(maxMemory, start, period);
        boolean shouldReturn = false;
        for (long x = 100; x <= 5000; x += 100) {
            long timestamp = start + x;
            o.setSizeInBytes(o.sizeInBytes() + sizeOfObjects);
            shouldReturn = memoryEstimator.shouldReturnBasedOnMemoryUsage(timestamp, o);
            if (memoryEstimator.isNewBucket()) {
                long memoryPercentageUsedCalculated = Math.round((double) o.sizeInBytes() / maxMemory * 100);
                long memoryPercentageUsedEstimate = Math.round(memoryEstimator.getMemoryUsedPercentage());
                long percentError = Math.round(Math.abs(memoryPercentageUsedCalculated - memoryPercentageUsedEstimate) / memoryPercentageUsedCalculated * 100);
                assertTrue(percentError == 0);
            }",1
"@Test
    public void simpleGetOneSample() throws Exception {
        // check that data gets pulled out
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>,Downsample> samples = runQuery(iter, testData1, 100, -1);
        assertEquals(1, samples.size());
        for (Entry<Set<Tag>,Downsample> entry : samples.entrySet()) {
            Set<Tag> tags = entry.getKey();
            assertEquals(1, tags.size());
            assertEquals(Collections.singleton(new Tag(""host"", ""host1"")), tags);
            long ts = 0;
            for (Sample sample : entry.getValue()) {
                assertEquals(ts, sample.getTimestamp());
                ts += 100;
                assertEquals(0.2, sample.getValue(), 0.0001);
            }",1
"@Test
    public void simpleGetTwoSamples() throws Exception {
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>,Downsample> samples = runQuery(iter, testData2, 100, -1);
        assertEquals(2, samples.size());
        for (Tag tag : new Tag[] {new Tag(""host"", ""host1""), new Tag(""host"", ""host2"")}",1
"@Test
    public void testDownsampleCombining() throws Exception {

        int numTagVariations = 2;
        int sampleInterval = 50;
        int elapsedTime = 100;
        int skipInterval = 10;
        SortedMap<Key,Value> testData3 = createTestData3(elapsedTime, skipInterval, numTagVariations);
        DownsampleIterator iter = new DownsampleIterator();
        Map<Set<Tag>,Downsample> samples = runQuery(iter, testData3, sampleInterval, 1000);
        assertEquals(numTagVariations, samples.size());
        long totalBuckets = 0;
        for (Entry<Set<Tag>,Downsample> entry : samples.entrySet()) {
            totalBuckets = totalBuckets + entry.getValue().getNumBuckets();
        }",1
"@Test
    public void testCounterRate() throws Exception {
        table.clear();
        long ts = System.currentTimeMillis();
        for (int j = 0; j < 10; j++) {
            for (int i = 1; i <= 10; i++) {
                ts += 1000;
                Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags);
                byte[] row = MetricAdapter.encodeRowKey(m);
                Key k = new Key(row, tags.get(0).join().getBytes(StandardCharsets.UTF_8), MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
                table.put(k, v);
            }",1
"@Test
    public void testAdditionalTimeSeries() throws Exception {
        table.clear();
        long ts = ((System.currentTimeMillis() / 1000) * 1000);
        List<Tag> tags1 = new ArrayList<>();
        tags1.add(new Tag(""host"", ""r01n01""));
        List<Tag> tags2 = new ArrayList<>();
        tags2.add(new Tag(""host"", ""r01n02""));
        for (int i = 0; i < 100; i++) {
            ts += 1000;
            Metric m = new Metric(""sys.cpu.user"", ts, i * 1.0D, tags1);
            byte[] row = MetricAdapter.encodeRowKey(m);
            Key k = new Key(row, tags1.get(0).join().getBytes(StandardCharsets.UTF_8), MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
            Value v = new Value(MetricAdapter.encodeValue(m.getValue().getMeasure()));
            table.put(k, v);
            if (i > 50) {
                // only populate this series 50 times
                Metric m2 = new Metric(""sys.cpu.user"", ts, i * 2.0D, tags2);
                byte[] row2 = MetricAdapter.encodeRowKey(m2);
                Key k2 = new Key(row2, tags2.get(0).join().getBytes(StandardCharsets.UTF_8), MetricAdapter.encodeColQual(ts, """"), new byte[0], ts);
                Value v2 = new Value(MetricAdapter.encodeValue(m2.getValue().getMeasure()));
                table.put(k2, v2);
            }",1
"@Test
    public void testMixed() throws Exception {
        MetricAgeOffFilter filter = new MetricAgeOffFilter();
        HashMap<String,String> options = new HashMap<>();
        options.put(MetricAgeOffFilter.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        filter.init(null, options, null);
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME), new byte[0], new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 1), new byte[0], new byte[0], new byte[0], TEST_TIME + 1),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 2), new byte[0], new byte[0], new byte[0], TEST_TIME + 2),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 3), new byte[0], new byte[0], new byte[0], TEST_TIME + 3),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 4), new byte[0], new byte[0], new byte[0], TEST_TIME + 4),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.idle"", TEST_TIME + 5), new byte[0], new byte[0], new byte[0], TEST_TIME + 5),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0], TEST_TIME), null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0], new byte[0], TEST_TIME + 1),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0], new byte[0], TEST_TIME + 2),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0], new byte[0], TEST_TIME + 3),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0], new byte[0], TEST_TIME + 4),
                        null));
        assertTrue(filter.accept(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0], new byte[0], TEST_TIME + 5),
                        null));
    }",1
"@Test
    public void testDefault() throws Exception {
        SortedMap<Key,Value> table = new TreeMap<>();
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME), new byte[0], new byte[0], new byte[0], TEST_TIME), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 1), new byte[0], new byte[0], new byte[0], TEST_TIME + 1), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 2), new byte[0], new byte[0], new byte[0], TEST_TIME + 2), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 3), new byte[0], new byte[0], new byte[0], TEST_TIME + 3), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 4), new byte[0], new byte[0], new byte[0], TEST_TIME + 4), EMPTY_VALUE);
        table.put(new Key(MetricAdapter.encodeRowKey(""sys.cpu.user"", TEST_TIME + 5), new byte[0], new byte[0], new byte[0], TEST_TIME + 5), EMPTY_VALUE);

        SortedKeyValueIterator<Key,Value> source = new SortedMapIterator(table);
        MetricAgeOffIterator iter = new MetricAgeOffIterator();
        HashMap<String,String> options = new HashMap<>();
        options.put(MetricAgeOffIterator.AGE_OFF_PREFIX + ""default"", Integer.toString(1 * ONE_DAY));
        iter.init(source, options, null);
        iter.seek(new Range(), columnFamilies, true);
        int seen = 0;
        while (iter.hasTop()) {
            Key k = iter.getTopKey();
            Assert.assertTrue(k.getTimestamp() >= TEST_TIME && k.getTimestamp() <= TEST_TIME + 5);
            seen++;
            iter.next();
        }",1
"@Test
    public void testPersistenceWithVisibility() throws Exception {
        // @formatter:off
        put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2"",
                   ""sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4 viz=(A|B)"",
                   ""sys.cpu.idle "" + (TEST_TIME + 2) + "" 1.0 tag3=value3 tag4=value4 viz=(C&B)"");
        // @formatter:on
        dataStore.flush();
        sleepUninterruptibly(WAIT_SECONDS, TimeUnit.SECONDS);
        int count = 0;
        for (final Map.Entry<Key,Value> entry : accumuloClient.createScanner(timelyProperties.getMetricsTable(), Authorizations.EMPTY)) {
            final double value = ByteBuffer.wrap(entry.getValue().get()).getDouble();
            assertEquals(1.0, value, 1e-9);
            count++;
        }",1
"@Test
    public void testClientAuthAccess() throws Exception {
        WebSocketSubscriptionClient client = new WebSocketSubscriptionClient(outboundSSLContext, ""localhost"", httpProperties.getPort(),
                        websocketProperties.getPort(), true, false, false, 65536);
        testWorkflow(client);
    }",1
"@Test
    public void testMultipleAgeOffWithoutCache() throws Exception {
        cacheProperties.setEnabled(false);
        testMultipleAgeOff(timelyProperties, cacheProperties);
    }",1
"@Test
    public void testMetrics() throws Exception {
      // @formatter:off
        put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2"",
            ""sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4"",
            ""sys.cpu.idle "" + (TEST_TIME + 2) + "" 1.0 tag3=value3 tag4=value4 viz=(a|b|c)"",
            ""zzzz 1234567892 1.0 host=localhost"");
        // @formatter:on
        dataStore.flush();
        dataStoreCache.flushCaches(-1);
        // Latency in TestConfiguration is 2s, wait for it
        sleepUninterruptibly(TestConfiguration.WAIT_SECONDS, TimeUnit.SECONDS);

        String metrics = baseUrl + ""/api/metrics"";
        // Test prefix matching
        String result = query(metrics);
        Document doc = Jsoup.parse(result);
        Elements tableData = doc.select(""td"");

        assertEquals(1, tableData.select("":contains(sys.cpu.user)"").size());
        assertEquals(1, tableData.select("":contains(tag1=value1 tag2=value2)"").size());
        assertEquals(1, tableData.select("":contains(sys.cpu.idle)"").size());
        assertEquals(1, tableData.select("":contains(tag3=value3 tag4=value4)"").size());
        assertEquals(1, tableData.select("":contains(zzzz)"").size());
        assertEquals(1, tableData.select("":contains(host=localhost)"").size());
    }",1
"@Test
    public void testPutMetric() throws Exception {
        Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(TEST_TIME, 1.0D).tag(new Tag(""tag1"", ""value1"")).build();
        new Metric();
        URL url = new URL(baseUrl + ""/api/put"");
        HttpsURLConnection con = getUrlConnection(url);
        con.setRequestMethod(""POST"");
        con.setDoOutput(true);
        con.setRequestProperty(""Content-Type"", ""application/json"");
        String requestJSON = JsonUtil.getObjectMapper().writeValueAsString(m);
        con.setRequestProperty(""Content-Length"", String.valueOf(requestJSON.length()));
        OutputStream wr = con.getOutputStream();
        wr.write(requestJSON.getBytes(UTF_8));
        int responseCode = con.getResponseCode();
        Assert.assertEquals(200, responseCode);
    }",1
"@Test
    public void testQueryWithNoTagsMultipleSeries() throws Exception {
        // @formatter:off
        put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2 host=h1"",
           ""sys.cpu.user "" + TEST_TIME + "" 2.0 tag1=value1 tag2=value2 host=h2"",
           ""sys.cpu.user "" + (TEST_TIME + 1000) + "" 4.0 tag1=value1 tag2=value2 host=h1"",
           ""sys.cpu.user "" + (TEST_TIME + 1000) + "" 3.0 tag1=value1 tag2=value2 host=h2"",
           ""sys.cpu.user "" + (TEST_TIME + 2000) + "" 5.0 tag1=value1 tag2=value2 host=h1"",
           ""sys.cpu.user "" + (TEST_TIME + 2000) + "" 6.0 tag1=value1 tag2=value2 host=h2"");
        // @formatter:on
        dataStore.flush();
        dataStoreCache.flushCaches(-1);
        // Latency in TestConfiguration is 2s, wait for it
        sleepUninterruptibly(TestConfiguration.WAIT_SECONDS, TimeUnit.SECONDS);
        QueryRequest request = new QueryRequest();
        request.setStart(TEST_TIME);
        request.setEnd(TEST_TIME + 4000);
        SubQuery subQuery = new SubQuery();
        subQuery.setMetric(""sys.cpu.user"");
        subQuery.setDownsample(Optional.of(""1s-max""));
        request.addQuery(subQuery);
        List<QueryResponse> response = query(baseUrl + ""/api/query"", request);
        assertEquals(1, response.size());
        Map<String,String> tags = response.get(0).getTags();
        assertEquals(0, tags.size());
        Map<String,Object> dps = response.get(0).getDps();
        assertEquals(3, dps.size());
        Iterator<Entry<String,Object>> entries = dps.entrySet().iterator();
        Entry<String,Object> entry = entries.next();
        assertEquals(Long.toString((TEST_TIME / 1000)), entry.getKey());
        assertEquals(2.0, entry.getValue());
        entry = entries.next();
        assertEquals(Long.toString((TEST_TIME / 1000) + 1), entry.getKey());
        assertEquals(4.0, entry.getValue());
        entry = entries.next();
        assertEquals(Long.toString((TEST_TIME / 1000) + 2), entry.getKey());
        assertEquals(6.0, entry.getValue());
    }",1
"@Test
    public void testQueryWithoutMsResolution() throws Exception {
        // @formatter:off
        put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2"",
           ""sys.cpu.user "" + (TEST_TIME + 1) + "" 1.0 tag3=value3"",
           ""sys.cpu.idle "" + (TEST_TIME + 2) + "" 1.0 tag3=value3 tag4=value4"",
           ""sys.cpu.idle "" + (TEST_TIME + 1000) + "" 3.0 tag3=value3 tag4=value4"");
        // @formatter:on
        dataStore.flush();
        dataStoreCache.flushCaches(-1);
        // Latency in TestConfiguration is 2s, wait for it
        sleepUninterruptibly(TestConfiguration.WAIT_SECONDS, TimeUnit.SECONDS);
        QueryRequest request = new QueryRequest();
        request.setStart(TEST_TIME);
        request.setEnd(TEST_TIME + 6000);
        SubQuery subQuery = new SubQuery();
        subQuery.setMetric(""sys.cpu.idle"");
        subQuery.setTags(Collections.singletonMap(""tag3"", ""value3""));
        subQuery.setDownsample(Optional.of(""1s-max""));
        request.addQuery(subQuery);
        List<QueryResponse> response = query(baseUrl + ""/api/query"", request);
        assertEquals(1, response.size());
        Map<String,String> tags = response.get(0).getTags();
        assertEquals(1, tags.size());
        assertTrue(tags.containsKey(""tag3""));
        assertTrue(tags.get(""tag3"").equals(""value3""));
        Map<String,Object> dps = response.get(0).getDps();
        assertEquals(2, dps.size());
        Iterator<Entry<String,Object>> entries = dps.entrySet().iterator();
        Entry<String,Object> entry = entries.next();
        assertEquals(Long.toString((TEST_TIME / 1000)), entry.getKey());
        assertEquals(1.0, entry.getValue());
        entry = entries.next();
        assertEquals(Long.toString((TEST_TIME / 1000) + 1), entry.getKey());
        assertEquals(3.0, entry.getValue());
    }",1
"@Test
    public void testQueryWithTagWildcard() throws Exception {
        // @formatter:off
        put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2 rack=r1"",
            ""sys.cpu.user "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 rack=r2"",
            ""sys.cpu.idle "" + (TEST_TIME + 2) + "" 1.0 tag3=value3 tag4=value4 rack=r1"",
            ""sys.cpu.idle "" + (TEST_TIME + 1000) + "" 3.0 tag3=value3 tag4=value4 rack=r2"");
        // @formatter:on
        dataStore.flush();
        dataStoreCache.flushCaches(-1);
        // Latency in TestConfiguration is 2s, wait for it
        sleepUninterruptibly(TestConfiguration.WAIT_SECONDS, TimeUnit.SECONDS);
        QueryRequest request = new QueryRequest();
        request.setStart(TEST_TIME);
        request.setEnd(TEST_TIME + 6000);
        SubQuery subQuery = new SubQuery();
        subQuery.setMetric(""sys.cpu.idle"");
        subQuery.setTags(Collections.singletonMap(""rack"", ""r.*""));
        subQuery.setDownsample(Optional.of(""1s-max""));
        request.addQuery(subQuery);

        List<QueryResponse> response = query(baseUrl + ""/api/query"", request);
        assertEquals(2, response.size());

        AtomicInteger rack1Count = new AtomicInteger(0);
        AtomicInteger rack2Count = new AtomicInteger(0);
        response.forEach(r -> {
            Map<String,String> tags = r.getTags();
            Map<String,Object> dps = r.getDps();
            assertEquals(1, tags.size());
            assertEquals(1, dps.size());
            assertTrue(tags.containsKey(""rack""));
            Value value = parseDps(dps);
            switch (tags.get(""rack"")) {
                case ""r2"":
                    assertEquals((Long) ((TEST_TIME / 1000L) + 1L), value.getTimestamp());
                    assertEquals(3.0D, value.getMeasure(), 0.0);
                    rack2Count.incrementAndGet();
                    break;
                case ""r1"":
                    assertEquals((Long) (TEST_TIME / 1000L), value.getTimestamp());
                    assertEquals(1.0D, value.getMeasure(), 0.0);
                    rack1Count.incrementAndGet();
                    break;
                default:
                    assertTrue(""Found invalid rack number: "" + tags.get(""rack""), false);
                    break;
            }",1
"@Test
    public void testHSTSRequestGet() throws Exception {
        String secureMe = baseHttpsUrl + ""/secure-me"";
        URL url = new URL(secureMe);
        HttpsURLConnection con = getUrlConnection(url);
        int responseCode = con.getResponseCode();
        assertEquals(404, responseCode);
        assertEquals(""max-age="" + httpProperties.getStrictTransportMaxAge(), con.getHeaderField(StrictTransportHandler.HSTS_HEADER_NAME));
    }",1
"@Test
    public void testPutMultiple() throws Exception {

        try (Socket sock = new Socket(serverProperties.getIp(), serverProperties.getTcpPort());
                PrintWriter writer = new PrintWriter(sock.getOutputStream(), true)) {
            // @formatter:off
            writer.write(""put sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2\n""
                       + ""put sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4\n"");
            writer.flush();
            while (2 != tcpRequests.getCount()) {
                Thread.sleep(5);
            }",1
"@Test
    public void testPersistenceWithVisibility() throws Exception {
        put(""sys.cpu.user "" + TEST_TIME + "" 1.0 tag1=value1 tag2=value2"", ""sys.cpu.idle "" + (TEST_TIME + 1) + "" 1.0 tag3=value3 tag4=value4 viz=(a|b)"",
                        ""sys.cpu.idle "" + (TEST_TIME + 2) + "" 1.0 tag3=value3 tag4=value4 viz=(c&b)"");
        sleepUninterruptibly(TestConfiguration.WAIT_SECONDS, TimeUnit.SECONDS);
        accumuloClient.securityOperations().changeUserAuthorizations(""root"", new Authorizations(""a"", ""b"", ""c""));

        int count = 0;
        for (final Map.Entry<Key,Value> entry : accumuloClient.createScanner(""timely.metrics"", Authorizations.EMPTY)) {
            log.debug(""Entry: "" + entry);
            final double value = ByteBuffer.wrap(entry.getValue().get()).getDouble();
            assertEquals(1.0, value, 1e-9);
            count++;
        }",1
"@Test
    public void testPutMultipleBinary() throws Exception {

        FlatBufferBuilder builder = new FlatBufferBuilder(1);

        int[] metric = new int[2];
        Map<String,String> t = new HashMap<>();
        t.put(""tag1"", ""value1"");
        t.put(""tag2"", ""value2"");
        metric[0] = createMetric(builder, ""sys.cpu.user"", TEST_TIME, 1.0D, t);
        t = new HashMap<>();
        t.put(""tag3"", ""value3"");
        t.put(""tag4"", ""value4"");
        metric[1] = createMetric(builder, ""sys.cpu.idle"", TEST_TIME + 1, 1.0D, t);

        int metricVector = timely.api.flatbuffer.Metrics.createMetricsVector(builder, metric);

        timely.api.flatbuffer.Metrics.startMetrics(builder);
        timely.api.flatbuffer.Metrics.addMetrics(builder, metricVector);
        int metrics = timely.api.flatbuffer.Metrics.endMetrics(builder);
        timely.api.flatbuffer.Metrics.finishMetricsBuffer(builder, metrics);

        ByteBuffer binary = builder.dataBuffer();
        byte[] data = new byte[binary.remaining()];
        binary.get(data, 0, binary.remaining());
        log.debug(""Sending {}",1
"@Test
  public void testGetDeletableFiles() throws IOException {
    // 1. Create a file
    Path file = new Path(root, ""testIsFileDeletableWithNoHFileRefs"");
    fs.createNewFile(file);
    // 2. Assert file is successfully created
    assertTrue(""Test file not created!"", fs.exists(file));
    BackupHFileCleaner cleaner = new BackupHFileCleaner();
    cleaner.setConf(conf);
    cleaner.setCheckForFullyBackedUpTables(false);
    List<FileStatus> stats = new ArrayList<>();
    // Prime the cleaner
    cleaner.getDeletableFiles(stats);
    // 3. Assert that file as is should be deletable
    FileStatus stat = fs.getFileStatus(file);
    stats.add(stat);
    Iterable<FileStatus> deletable = cleaner.getDeletableFiles(stats);
    boolean found = false;
    for (FileStatus stat1 : deletable) {
      if (stat.equals(stat1)) {
        found = true;
      }",1
"@Test
  public void testStartBackupExclusiveOperation() {

    long sleepTime = 2000;
    Runnable r = new Runnable() {
      @Override
      public void run() {
        try {
          backupManager.startBackupSession();
          boolean result = startTimes.compareAndSet(0, 0, EnvironmentEdgeManager.currentTime());
          if (!result) {
            result = startTimes.compareAndSet(1, 0, EnvironmentEdgeManager.currentTime());
            if (!result) {
              throw new IOException(""PANIC! Unreachable code"");
            }",1
"@Test
  public void testBackupHistory() throws Exception {
    int n = 10;
    List<BackupInfo> list = createBackupInfoList(n);

    // Load data
    for (BackupInfo bc : list) {
      // Make sure we set right status
      bc.setState(BackupState.COMPLETE);
      table.updateBackupInfo(bc);
    }",1
"@Test
  public void testBackupDelete() throws Exception {
    try (BackupSystemTable table = new BackupSystemTable(conn)) {
      int n = 10;
      List<BackupInfo> list = createBackupInfoList(n);

      // Load data
      for (BackupInfo bc : list) {
        // Make sure we set right status
        bc.setState(BackupState.COMPLETE);
        table.updateBackupInfo(bc);
      }",1
"@Test
  public void testBackupSetAddNotExists() throws IOException {
    try (BackupSystemTable table = new BackupSystemTable(conn)) {

      String[] tables = new String[] { ""table1"", ""table2"", ""table3"" }",1
"@Test
  public void testBackupSetList() throws IOException {
    try (BackupSystemTable table = new BackupSystemTable(conn)) {

      String[] tables = new String[] { ""table1"", ""table2"", ""table3"", ""table4"" }",1
"@Test
  public void testBackupSetRemoveSomeNotExists() throws IOException {
    try (BackupSystemTable table = new BackupSystemTable(conn)) {

      String[] tables = new String[] { ""table1"", ""table2"", ""table3"", ""table4"" }",1
"@Test
  public void testIncrementalBackupTableSet() throws IOException {
    TreeSet<TableName> tables1 = new TreeSet<>();

    tables1.add(TableName.valueOf(""t1""));
    tables1.add(TableName.valueOf(""t2""));
    tables1.add(TableName.valueOf(""t3""));

    TreeSet<TableName> tables2 = new TreeSet<>();

    tables2.add(TableName.valueOf(""t3""));
    tables2.add(TableName.valueOf(""t4""));
    tables2.add(TableName.valueOf(""t5""));

    table.addIncrementalBackupTableSet(tables1, ""root"");

    try (BackupSystemTable systemTable = new BackupSystemTable(conn)) {
      TreeSet<TableName> res1 =
        (TreeSet<TableName>) systemTable.getIncrementalBackupTableSet(""root"");
      assertTrue(tables1.size() == res1.size());
      Iterator<TableName> desc1 = tables1.descendingIterator();
      Iterator<TableName> desc2 = res1.descendingIterator();
      while (desc1.hasNext()) {
        assertEquals(desc1.next(), desc2.next());
      }",1
"@Test
  public void testOperationTimeout() throws Exception {
    // set retry number to 100 to make sure that this test only be affected by operation timeout
    TEST_UTIL.getConfiguration().setInt(HConstants.HBASE_CLIENT_RETRIES_NUMBER, 100);
    TEST_UTIL.getConfiguration().set(CoprocessorHost.MASTER_COPROCESSOR_CONF_KEY,
      TestOperationTimeoutCoprocessor.class.getName());
    TEST_UTIL.startMiniCluster(2);
    ASYNC_CONN = ConnectionFactory.createAsyncConnection(TEST_UTIL.getConfiguration()).get();

    try {
      getAdminBuilder.get()
        .setOperationTimeout(DEFAULT_OPERATION_TIMEOUT / 2, TimeUnit.MILLISECONDS).build()
        .getNamespaceDescriptor(DEFAULT_NAMESPACE_NAME_STR).get();
      fail(""We expect an exception here"");
    }",1
"@Test
  public void testCheckAndMutateWithTimeRange() throws Exception {
    AsyncTable<?> table = getTable.get();
    final long ts = EnvironmentEdgeManager.currentTime() / 2;
    Put put = new Put(row);
    put.addColumn(FAMILY, QUALIFIER, ts, VALUE);

    CheckAndMutateResult result =
      table.checkAndMutate(CheckAndMutate.newBuilder(row).ifNotExists(FAMILY, QUALIFIER).build(put))
        .get();
    assertTrue(result.isSuccess());
    assertNull(result.getResult());

    result = table.checkAndMutate(CheckAndMutate.newBuilder(row).ifEquals(FAMILY, QUALIFIER, VALUE)
      .timeRange(TimeRange.at(ts + 10000)).build(put)).get();
    assertFalse(result.isSuccess());
    assertNull(result.getResult());

    result = table.checkAndMutate(CheckAndMutate.newBuilder(row).ifEquals(FAMILY, QUALIFIER, VALUE)
      .timeRange(TimeRange.at(ts)).build(put)).get();
    assertTrue(result.isSuccess());
    assertNull(result.getResult());

    RowMutations rm = new RowMutations(row).add((Mutation) put);

    result = table.checkAndMutate(CheckAndMutate.newBuilder(row).ifEquals(FAMILY, QUALIFIER, VALUE)
      .timeRange(TimeRange.at(ts + 10000)).build(rm)).get();
    assertFalse(result.isSuccess());
    assertNull(result.getResult());

    result = table.checkAndMutate(CheckAndMutate.newBuilder(row).ifEquals(FAMILY, QUALIFIER, VALUE)
      .timeRange(TimeRange.at(ts)).build(rm)).get();
    assertTrue(result.isSuccess());
    assertNull(result.getResult());

    Delete delete = new Delete(row).addColumn(FAMILY, QUALIFIER);

    result = table.checkAndMutate(CheckAndMutate.newBuilder(row).ifEquals(FAMILY, QUALIFIER, VALUE)
      .timeRange(TimeRange.at(ts + 10000)).build(delete)).get();
    assertFalse(result.isSuccess());
    assertNull(result.getResult());

    result = table.checkAndMutate(CheckAndMutate.newBuilder(row).ifEquals(FAMILY, QUALIFIER, VALUE)
      .timeRange(TimeRange.at(ts)).build(delete)).get();
    assertTrue(result.isSuccess());
    assertNull(result.getResult());
  }",1
"@Test
  public void testSimpleMultiple() throws Exception {
    AsyncTable<?> table = getTable.get();
    int count = 100;
    CountDownLatch putLatch = new CountDownLatch(count);
    IntStream.range(0, count).forEach(
      i -> table.put(new Put(concat(row, i)).addColumn(FAMILY, QUALIFIER, concat(VALUE, i)))
        .thenAccept(x -> putLatch.countDown()));
    putLatch.await();
    BlockingQueue<Boolean> existsResp = new ArrayBlockingQueue<>(count);
    IntStream.range(0, count)
      .forEach(i -> table.exists(new Get(concat(row, i)).addColumn(FAMILY, QUALIFIER))
        .thenAccept(x -> existsResp.add(x)));
    for (int i = 0; i < count; i++) {
      assertTrue(existsResp.take());
    }",1
"@Test
  public void testDeleteAttributes() {
    Delete del = new Delete(new byte[] { 'r' }",1
"@Test
  public void test() throws IOException {
    assertSame(ScanResultCache.EMPTY_RESULT_ARRAY,
      resultCache.addAndGet(ScanResultCache.EMPTY_RESULT_ARRAY, false));
    assertSame(ScanResultCache.EMPTY_RESULT_ARRAY,
      resultCache.addAndGet(ScanResultCache.EMPTY_RESULT_ARRAY, true));

    ExtendedCell[] cells1 = createCells(CF, 1, 10);
    ExtendedCell[] cells2 = createCells(CF, 2, 10);
    ExtendedCell[] cells3 = createCells(CF, 3, 10);
    assertEquals(0, resultCache.addAndGet(
      new Result[] { Result.create(Arrays.copyOf(cells1, 3), null, false, true) }",1
"@Test
  public void testAddGetRemoveConfiguration() {
    ColumnFamilyDescriptorBuilder builder =
      ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(""foo""));
    String key = ""Some"";
    String value = ""value"";
    builder.setConfiguration(key, value);
    assertEquals(value, builder.build().getConfigurationValue(key));
    builder.removeConfiguration(key);
    assertEquals(null, builder.build().getConfigurationValue(key));
  }",1
"@Test
  public void testSetTimeToLive() throws HBaseException {
    String ttl;
    ColumnFamilyDescriptorBuilder builder =
      ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(""foo""));

    ttl = ""50000"";
    builder.setTimeToLive(ttl);
    Assert.assertEquals(50000, builder.build().getTimeToLive());

    ttl = ""50000 seconds"";
    builder.setTimeToLive(ttl);
    Assert.assertEquals(50000, builder.build().getTimeToLive());

    ttl = """";
    builder.setTimeToLive(ttl);
    Assert.assertEquals(0, builder.build().getTimeToLive());

    ttl = ""FOREVER"";
    builder.setTimeToLive(ttl);
    Assert.assertEquals(HConstants.FOREVER, builder.build().getTimeToLive());

    ttl = ""1 HOUR 10 minutes 1 second"";
    builder.setTimeToLive(ttl);
    Assert.assertEquals(4201, builder.build().getTimeToLive());

    ttl = ""500 Days 23 HOURS"";
    builder.setTimeToLive(ttl);
    Assert.assertEquals(43282800, builder.build().getTimeToLive());

    ttl = ""43282800 SECONDS (500 Days 23 hours)"";
    builder.setTimeToLive(ttl);
    Assert.assertEquals(43282800, builder.build().getTimeToLive());
  }",1
"@Test
  public void testIncrementInstance() {
    final long expected = 13;
    Increment inc = new Increment(new byte[] { 'r' }",1
"@Test
  public void testPreserveMetaCacheOnException() throws Exception {
    ((FakeRSRpcServices) badRS.getRSRpcServices())
      .setExceptionInjector(new RoundRobinExceptionInjector());
    setupConnection(1);
    try (Table table = conn.getTable(TABLE_NAME)) {
      byte[] row = Bytes.toBytes(""row1"");

      Put put = new Put(row);
      put.addColumn(FAMILY, QUALIFIER, Bytes.toBytes(10));
      Get get = new Get(row);
      Append append = new Append(row);
      append.addColumn(FAMILY, QUALIFIER, Bytes.toBytes(11));
      Increment increment = new Increment(row);
      increment.addColumn(FAMILY, QUALIFIER, 10);
      Delete delete = new Delete(row);
      delete.addColumn(FAMILY, QUALIFIER);
      RowMutations mutations = new RowMutations(row);
      mutations.add(put);
      mutations.add(delete);

      Exception exp;
      boolean success;
      for (int i = 0; i < 50; i++) {
        exp = null;
        success = false;
        try {
          table.put(put);
          // If at least one operation succeeded, we should have cached the region location.
          success = true;
          table.get(get);
          table.append(append);
          table.increment(increment);
          table.delete(delete);
          table.mutateRow(mutations);
        }",1
"@Test
  public void testStaticMetrics() throws IOException {
    final byte[] foo = Bytes.toBytes(""foo"");
    String table = ""TableX"";
    final RegionSpecifier region = RegionSpecifier.newBuilder()
      .setValue(ByteString.copyFromUtf8(table)).setType(RegionSpecifierType.REGION_NAME).build();
    final int loop = 5;

    for (int i = 0; i < loop; i++) {
      METRICS.updateRpc(ClientService.getDescriptor().findMethodByName(""Get""),
        TableName.valueOf(table),
        GetRequest.newBuilder().setRegion(region).setGet(ProtobufUtil.toGet(new Get(foo))).build(),
        MetricsConnection.newCallStats(), null);
      METRICS.updateRpc(ClientService.getDescriptor().findMethodByName(""Scan""),
        TableName.valueOf(table),
        ScanRequest.newBuilder().setRegion(region)
          .setScan(ProtobufUtil.toScan(new Scan(new Get(foo)))).build(),
        MetricsConnection.newCallStats(),
        new RemoteWithExtrasException(""java.io.IOException"", null, false, false));
      METRICS.updateRpc(ClientService.getDescriptor().findMethodByName(""Multi""),
        TableName.valueOf(table),
        MultiRequest.newBuilder()
          .addRegionAction(ClientProtos.RegionAction.newBuilder()
            .addAction(
              ClientProtos.Action.newBuilder().setGet(ProtobufUtil.toGet(new Get(foo))).build())
            .setRegion(region).build())
          .build(),
        MetricsConnection.newCallStats(),
        new CallTimeoutException(""test with CallTimeoutException""));
      METRICS.updateRpc(ClientService.getDescriptor().findMethodByName(""Mutate""),
        TableName.valueOf(table),
        MutateRequest.newBuilder()
          .setMutation(ProtobufUtil.toMutation(MutationType.APPEND, new Append(foo)))
          .setRegion(region).build(),
        MetricsConnection.newCallStats(), null);
      METRICS.updateRpc(ClientService.getDescriptor().findMethodByName(""Mutate""),
        TableName.valueOf(table),
        MutateRequest.newBuilder()
          .setMutation(ProtobufUtil.toMutation(MutationType.DELETE, new Delete(foo)))
          .setRegion(region).build(),
        MetricsConnection.newCallStats(), null);
      METRICS.updateRpc(ClientService.getDescriptor().findMethodByName(""Mutate""),
        TableName.valueOf(table),
        MutateRequest.newBuilder()
          .setMutation(ProtobufUtil.toMutation(MutationType.INCREMENT, new Increment(foo)))
          .setRegion(region).build(),
        MetricsConnection.newCallStats(), null);
      METRICS.updateRpc(ClientService.getDescriptor().findMethodByName(""Mutate""),
        TableName.valueOf(table),
        MutateRequest.newBuilder()
          .setMutation(ProtobufUtil.toMutation(MutationType.PUT, new Put(foo))).setRegion(region)
          .build(),
        MetricsConnection.newCallStats(),
        new CallTimeoutException(""test with CallTimeoutException""));
    }",1
"@Test
  public void testPutCopyConstructor() throws IOException {
    Put origin = new Put(Bytes.toBytes(""ROW-01""));
    origin.setPriority(100);
    byte[] family = Bytes.toBytes(""CF-01"");

    origin.add(CellBuilderFactory.create(CellBuilderType.SHALLOW_COPY).setRow(origin.getRow())
      .setFamily(family).setQualifier(Bytes.toBytes(""q"")).setType(Cell.Type.Put)
      .setValue(Bytes.toBytes(""value"")).build());
    origin.addColumn(family, Bytes.toBytes(""q0""), Bytes.toBytes(""V-01""));
    origin.addColumn(family, Bytes.toBytes(""q1""), 100, Bytes.toBytes(""V-01""));
    Put clone = new Put(origin);
    assertEquals(origin, clone);
    origin.addColumn(family, Bytes.toBytes(""q2""), Bytes.toBytes(""V-02""));

    // They should have different cell lists
    assertNotEquals(origin.getCellList(family), clone.getCellList(family));
  }",1
"@Test
  public void testOperationJSON() throws IOException {
    // produce a Scan Operation
    Scan scan = new Scan().withStartRow(ROW);
    scan.addColumn(FAMILY, QUALIFIER);
    // get its JSON representation, and parse it
    String json = scan.toJSON();
    Type typeOfHashMap = new TypeToken<Map<String, Object>>() {
    }",1
"@Test
  public void testTaskCountChecker() throws InterruptedIOException {
    long heapSizeOfRow = 12345;
    int maxTotalConcurrentTasks = 100;
    int maxConcurrentTasksPerServer = 2;
    int maxConcurrentTasksPerRegion = 1;
    AtomicLong tasksInProgress = new AtomicLong(0);
    Map<ServerName, AtomicInteger> taskCounterPerServer = new HashMap<>();
    Map<byte[], AtomicInteger> taskCounterPerRegion = new TreeMap<>(Bytes.BYTES_COMPARATOR);
    SimpleRequestController.TaskCountChecker checker = new SimpleRequestController.TaskCountChecker(
      maxTotalConcurrentTasks, maxConcurrentTasksPerServer, maxConcurrentTasksPerRegion,
      tasksInProgress, taskCounterPerServer, taskCounterPerRegion);

    // inner state is unchanged.
    for (int i = 0; i != 10; ++i) {
      ReturnCode code = checker.canTakeOperation(LOC1, heapSizeOfRow);
      assertEquals(ReturnCode.INCLUDE, code);
    }",1
"@Test
  public void testWaitForMaximumCurrentTasks() throws Exception {
    final AtomicInteger max = new AtomicInteger(0);
    final CyclicBarrier barrier = new CyclicBarrier(2);
    SimpleRequestController controller = new SimpleRequestController(HBaseConfiguration.create());
    final AtomicLong tasks = controller.tasksInProgress;
    Runnable runnable = () -> {
      try {
        barrier.await();
        controller.waitForMaximumCurrentTasks(max.get(), 123, 1, null);
      }",1
"@Test
  public void testGetMaxFileSize() {
    TableDescriptor desc =
      TableDescriptorBuilder.newBuilder(TableName.valueOf(name.getMethodName())).build();
    assertEquals(-1, desc.getMaxFileSize());
    desc = TableDescriptorBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
      .setMaxFileSize(1111L).build();
    assertEquals(1111L, desc.getMaxFileSize());
  }",1
"@Test
  public void testSetListRemoveCP() throws Exception {
    TableDescriptor desc =
      TableDescriptorBuilder.newBuilder(TableName.valueOf(name.getMethodName())).build();
    // Check that any coprocessor is present.
    assertTrue(desc.getCoprocessorDescriptors().isEmpty());

    // simple CP
    String className1 = ""org.apache.hadoop.hbase.coprocessor.SimpleRegionObserver"";
    String className2 = ""org.apache.hadoop.hbase.coprocessor.SampleRegionWALObserver"";
    // Add the 1 coprocessor and check if present.
    desc = TableDescriptorBuilder.newBuilder(desc).setCoprocessor(className1).build();
    assertTrue(desc.getCoprocessorDescriptors().size() == 1);
    assertTrue(desc.getCoprocessorDescriptors().stream().map(CoprocessorDescriptor::getClassName)
      .anyMatch(name -> name.equals(className1)));
    // Add the 2nd coprocessor and check if present.
    // remove it and check that it is gone
    desc = TableDescriptorBuilder.newBuilder(desc)

      .setCoprocessor(className2).build();
    assertTrue(desc.getCoprocessorDescriptors().size() == 2);
    assertTrue(desc.getCoprocessorDescriptors().stream().map(CoprocessorDescriptor::getClassName)
      .anyMatch(name -> name.equals(className2)));
    // Remove one and check
    desc = TableDescriptorBuilder.newBuilder(desc)

      .removeCoprocessor(className1).build();
    assertTrue(desc.getCoprocessorDescriptors().size() == 1);
    assertFalse(desc.getCoprocessorDescriptors().stream().map(CoprocessorDescriptor::getClassName)
      .anyMatch(name -> name.equals(className1)));
    assertTrue(desc.getCoprocessorDescriptors().stream().map(CoprocessorDescriptor::getClassName)
      .anyMatch(name -> name.equals(className2)));
    // Remove the last and check
    desc = TableDescriptorBuilder.newBuilder(desc)

      .removeCoprocessor(className2).build();
    assertTrue(desc.getCoprocessorDescriptors().isEmpty());
    assertFalse(desc.getCoprocessorDescriptors().stream().map(CoprocessorDescriptor::getClassName)
      .anyMatch(name -> name.equals(className1)));
    assertFalse(desc.getCoprocessorDescriptors().stream().map(CoprocessorDescriptor::getClassName)
      .anyMatch(name -> name.equals(className2)));
  }",1
"@Test
  public void testScannerWithRestoreScanner() throws Exception {
    TableName tableName = TableName.valueOf(""testScanner"");
    String snapshotName = ""testScannerWithRestoreScanner"";
    try {
      createTableAndSnapshot(UTIL, tableName, snapshotName, 50);
      Path restoreDir = UTIL.getDataTestDirOnTestFS(snapshotName);
      Scan scan = new Scan().withStartRow(bbb).withStopRow(yyy); // limit the scan

      Configuration conf = UTIL.getConfiguration();
      Path rootDir = CommonFSUtils.getRootDir(conf);

      TableSnapshotScanner scanner0 =
        new TableSnapshotScanner(conf, restoreDir, snapshotName, scan);
      verifyScanner(scanner0, bbb, yyy);
      scanner0.close();

      // restore snapshot.
      RestoreSnapshotHelper.copySnapshotForScanner(conf, fs, rootDir, restoreDir, snapshotName);

      // scan the snapshot without restoring snapshot
      TableSnapshotScanner scanner =
        new TableSnapshotScanner(conf, rootDir, restoreDir, snapshotName, scan, true);
      verifyScanner(scanner, bbb, yyy);
      scanner.close();

      // check whether the snapshot has been deleted by the close of scanner.
      scanner = new TableSnapshotScanner(conf, rootDir, restoreDir, snapshotName, scan, true);
      verifyScanner(scanner, bbb, yyy);
      scanner.close();

      // restore snapshot again.
      RestoreSnapshotHelper.copySnapshotForScanner(conf, fs, rootDir, restoreDir, snapshotName);

      // check whether the snapshot has been deleted by the close of scanner.
      scanner = new TableSnapshotScanner(conf, rootDir, restoreDir, snapshotName, scan, true);
      verifyScanner(scanner, bbb, yyy);
      scanner.close();
    }",1
"@Test
  public void testOne() throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    CountingOutputStream cos = new CountingOutputStream(baos);
    DataOutputStream dos = new DataOutputStream(cos);
    Codec codec = new CellCodec();
    Codec.Encoder encoder = codec.getEncoder(dos);
    final KeyValue kv =
      new KeyValue(Bytes.toBytes(""r""), Bytes.toBytes(""f""), Bytes.toBytes(""q""), Bytes.toBytes(""v""));
    kv.setSequenceId(Long.MAX_VALUE);
    encoder.write(kv);
    encoder.flush();
    dos.close();
    long offset = cos.getCount();
    CountingInputStream cis = new CountingInputStream(new ByteArrayInputStream(baos.toByteArray()));
    DataInputStream dis = new DataInputStream(cis);
    Codec.Decoder decoder = codec.getDecoder(dis);
    assertTrue(decoder.advance()); // First read should pull in the KV
    // Second read should trip over the end-of-stream marker and return false
    assertFalse(decoder.advance());
    dis.close();
    assertEquals(offset, cis.getCount());
  }",1
"@Test
  public void testOne() throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    CountingOutputStream cos = new CountingOutputStream(baos);
    DataOutputStream dos = new DataOutputStream(cos);
    KeyValueCodec kvc = new KeyValueCodec();
    Codec.Encoder encoder = kvc.getEncoder(dos);
    final KeyValue kv =
      new KeyValue(Bytes.toBytes(""r""), Bytes.toBytes(""f""), Bytes.toBytes(""q""), Bytes.toBytes(""v""));
    final int length = kv.getLength() + Bytes.SIZEOF_INT;
    encoder.write(kv);
    encoder.flush();
    dos.close();
    long offset = cos.getCount();
    assertEquals(length, offset);
    CountingInputStream cis = new CountingInputStream(new ByteArrayInputStream(baos.toByteArray()));
    DataInputStream dis = new DataInputStream(cis);
    Codec.Decoder decoder = kvc.getDecoder(dis);
    assertTrue(decoder.advance()); // First read should pull in the KV
    // Second read should trip over the end-of-stream marker and return false
    assertFalse(decoder.advance());
    dis.close();
    assertEquals(length, cis.getCount());
  }",1
"@Test
  public void testKeyValueWithTag() throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    CountingOutputStream cos = new CountingOutputStream(baos);
    DataOutputStream dos = new DataOutputStream(cos);
    Codec codec = new KeyValueCodecWithTags();
    Codec.Encoder encoder = codec.getEncoder(dos);
    final KeyValue kv1 = new KeyValue(Bytes.toBytes(""r""), Bytes.toBytes(""f""), Bytes.toBytes(""1""),
      HConstants.LATEST_TIMESTAMP, Bytes.toBytes(""1""),
      new Tag[] { new ArrayBackedTag((byte) 1, Bytes.toBytes(""teststring1"")),
        new ArrayBackedTag((byte) 2, Bytes.toBytes(""teststring2"")) }",1
"@Test
  public void testDeregisterOnOutOfScope() {
    Configuration conf = new Configuration();
    ConfigurationManager cm = new ConfigurationManager();

    boolean outOfScopeObserversDeregistered = false;

    // On my machine, I was able to cause a GC after around 5 iterations.
    // If we do not cause a GC in 100k iterations, which is very unlikely,
    // there might be something wrong with the GC.
    for (int i = 0; i < 100000; i++) {
      registerLocalObserver(cm);
      cm.notifyAllObservers(conf);

      // 'Suggest' the system to do a GC. We should be able to cause GC
      // atleast once in the 2000 iterations.
      System.gc();

      // If GC indeed happened, all the observers (which are all out of scope),
      // should have been deregistered.
      if (cm.getNumObservers() <= i) {
        outOfScopeObserversDeregistered = true;
        break;
      }",1
"@Test
  public void testDisableConstraint() throws Exception {
    // create the table
    TableDescriptorBuilder builder = TableDescriptorBuilder.newBuilder(tableName);
    // add a family to the table
    for (byte[] family : new byte[][] { dummy, test }",1
"@Test
  public void testIsUnloaded() throws Exception {
    // create the table
    TableDescriptorBuilder builder = TableDescriptorBuilder.newBuilder(tableName);

    // add a family to the table
    for (byte[] family : new byte[][] { dummy, test }",1
"@Test
  public void testConfigurationPreserved() throws Exception {
    Configuration conf = new Configuration();
    conf.setBoolean(""_ENABLED"", false);
    conf.setLong(""_PRIORITY"", 10);
    TableDescriptorBuilder builder = TableDescriptorBuilder.newBuilder(name.getTableName());
    Constraints.add(builder, AlsoWorks.class, conf);
    Constraints.add(builder, WorksConstraint.class);
    assertFalse(Constraints.enabled(builder.build(), AlsoWorks.class));
    List<? extends Constraint> constraints =
      Constraints.getConstraints(builder.build(), this.getClass().getClassLoader());
    for (Constraint c : constraints) {
      Configuration storedConf = c.getConf();
      if (c instanceof AlsoWorks) {
        assertEquals(10, storedConf.getLong(""_PRIORITY"", -1));
      }",1
"@Test
  public void testNamespaceOperations() throws Exception {
    SingleProcessHBaseCluster cluster = UTIL.getHBaseCluster();
    String testNamespace = ""observed_ns"";
    HMaster master = cluster.getMaster();
    MasterCoprocessorHost host = master.getMasterCoprocessorHost();
    CPMasterObserver cp = host.findCoprocessor(CPMasterObserver.class);

    // create a table
    Admin admin = UTIL.getAdmin();

    admin.listNamespaces();
    assertTrue(""preListNamespaces should have been called"", cp.preListNamespacesCalled);
    assertTrue(""postListNamespaces should have been called"", cp.postListNamespacesCalled);

    admin.createNamespace(NamespaceDescriptor.create(testNamespace).build());
    assertTrue(""Test namespace should be created"", cp.wasCreateNamespaceCalled());

    assertNotNull(admin.getNamespaceDescriptor(testNamespace));
    assertTrue(""Test namespace descriptor should have been called"",
      cp.wasGetNamespaceDescriptorCalled());
    // This test used to do a bunch w/ bypass but bypass of these table and namespace stuff has
    // been removed so the testing code was removed.
  }",1
"@Test
  public void testSnapshotOperations() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    SingleProcessHBaseCluster cluster = UTIL.getHBaseCluster();
    HMaster master = cluster.getMaster();
    MasterCoprocessorHost host = master.getMasterCoprocessorHost();
    CPMasterObserver cp = host.findCoprocessor(CPMasterObserver.class);
    cp.resetStates();

    // create a table
    TableDescriptor tableDescriptor = TableDescriptorBuilder.newBuilder(tableName)
      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(TEST_FAMILY)).build();
    Admin admin = UTIL.getAdmin();

    tableCreationLatch = new CountDownLatch(1);
    admin.createTable(tableDescriptor);
    tableCreationLatch.await();
    tableCreationLatch = new CountDownLatch(1);

    admin.disableTable(tableName);
    assertTrue(admin.isTableDisabled(tableName));

    try {
      // Test snapshot operation
      assertFalse(""Coprocessor should not have been called yet"", cp.wasSnapshotCalled());
      admin.snapshot(TEST_SNAPSHOT, tableName);
      assertTrue(""Coprocessor should have been called on snapshot"", cp.wasSnapshotCalled());

      // Test list operation
      admin.listSnapshots();
      assertTrue(""Coprocessor should have been called on snapshot list"",
        cp.wasListSnapshotCalled());

      // Test clone operation
      admin.cloneSnapshot(TEST_SNAPSHOT, TEST_CLONE);
      assertTrue(""Coprocessor should have been called on snapshot clone"",
        cp.wasCloneSnapshotCalled());
      assertFalse(""Coprocessor restore should not have been called on snapshot clone"",
        cp.wasRestoreSnapshotCalled());
      admin.disableTable(TEST_CLONE);
      assertTrue(admin.isTableDisabled(tableName));
      deleteTable(admin, TEST_CLONE);

      // Test restore operation
      cp.resetStates();
      admin.restoreSnapshot(TEST_SNAPSHOT);
      assertTrue(""Coprocessor should have been called on snapshot restore"",
        cp.wasRestoreSnapshotCalled());
      assertFalse(""Coprocessor clone should not have been called on snapshot restore"",
        cp.wasCloneSnapshotCalled());

      admin.deleteSnapshot(TEST_SNAPSHOT);
      assertTrue(""Coprocessor should have been called on snapshot delete"",
        cp.wasDeleteSnapshotCalled());
    }",1
"@Test
  public void testTableNamesEnumeration() throws Exception {
    SingleProcessHBaseCluster cluster = UTIL.getHBaseCluster();

    HMaster master = cluster.getMaster();
    MasterCoprocessorHost host = master.getMasterCoprocessorHost();
    CPMasterObserver cp = host.findCoprocessor(CPMasterObserver.class);
    cp.resetStates();

    master.getMasterRpcServices().getTableNames(null, GetTableNamesRequest.newBuilder().build());
    assertTrue(""Coprocessor should be called on table names request"", cp.wasGetTableNamesCalled());
  }",1
"@Test
  public void testConstrainedPlacement() throws Exception {
    List<ServerName> servers = Lists.newArrayList();
    servers.add(ServerName.valueOf(""foo"" + 1 + "":1234"", -1));
    servers.add(ServerName.valueOf(""foo"" + 2 + "":1234"", -1));
    servers.add(ServerName.valueOf(""foo"" + 15 + "":1234"", -1));
    FavoredNodeAssignmentHelper helper = new FavoredNodeAssignmentHelper(servers, rackManager);
    helper.initialize();
    assertTrue(helper.canPlaceFavoredNodes());

    List<RegionInfo> regions = new ArrayList<>(20);
    for (int i = 0; i < 20; i++) {
      regions.add(RegionInfoBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
        .setStartKey(Bytes.toBytes(i)).setEndKey(Bytes.toBytes(i + 1)).build());
    }",1
"@Test
  public void testGenMissingFavoredNodeMultiRack() throws IOException {

    ServerName snRack1SN1 = ServerName.valueOf(""foo1:1234"", ServerName.NON_STARTCODE);
    ServerName snRack1SN2 = ServerName.valueOf(""foo2:1234"", ServerName.NON_STARTCODE);
    ServerName snRack2SN1 = ServerName.valueOf(""foo10:1234"", ServerName.NON_STARTCODE);
    ServerName snRack2SN2 = ServerName.valueOf(""foo11:1234"", ServerName.NON_STARTCODE);

    Map<String, Integer> rackToServerCount = new HashMap<>();
    Set<String> rackList = Sets.newHashSet(""rack1"", ""rack2"");
    for (String rack : rackList) {
      rackToServerCount.put(rack, 4);
    }",1
"@Test
  public void testGreaterThanValue() {
    // given
    byte[] val1 = Bytes.toBytes(new BigDecimal(""1000000000000000000000000000000.9999999999999999""));
    byte[] val2 = Bytes.toBytes(new BigDecimal(0));
    byte[] val3 = Bytes.toBytes(new BigDecimal(Double.MIN_VALUE));
    BigDecimal bd = new BigDecimal(Double.MAX_VALUE);
    BigDecimalComparator comparator = new BigDecimalComparator(bd);

    // when
    int comp1 = comparator.compareTo(val1);
    int comp2 = comparator.compareTo(val2);
    int comp3 = comparator.compareTo(val3);

    // then
    Assert.assertEquals(1, comp1);
    Assert.assertEquals(1, comp2);
    Assert.assertEquals(1, comp3);
  }",1
"@Test
  public void testFilterDropping() throws Exception {
    Filter filter = new DependentColumnFilter(FAMILIES[0], QUALIFIER);
    List<Cell> accepted = new ArrayList<>();
    for (Cell val : testVals) {
      if (filter.filterCell(val) == ReturnCode.INCLUDE) {
        accepted.add(val);
      }",1
"@Test
  public void test94FilterRowCompatibility() throws Exception {
    Scan s = new Scan();
    OldTestFilter filter = new OldTestFilter();
    s.setFilter(filter);

    InternalScanner scanner = this.region.getScanner(s);
    ArrayList<Cell> values = new ArrayList<>();
    scanner.next(values);
    assertTrue(""All rows should be filtered out"", values.isEmpty());
  }",1
"@Test
  public void testFirstKeyOnlyFilter() throws IOException {
    Scan s = new Scan();
    s.setFilter(new FirstKeyOnlyFilter());
    // Expected KVs, the first KV from each of the remaining 6 rows
    KeyValue[] kvs = { new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]) }",1
"@Test
  public void testKeyOnlyFilter() throws Exception {

    // KVs in first 6 rows
    KeyValue[] expectedKVs = {
      // testRowOne-0
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowOne-2
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowOne-3
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowTwo-0
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-2
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-3
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]) }",1
"@Test
  public void testLatestVersionFilterWithExplicitColumn() throws Exception {
    // Add multiple versions
    Put p = new Put(ROWS_ONE[0]);
    p.setDurability(Durability.SKIP_WAL);
    p.addColumn(FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]);
    this.region.put(p);
    p = new Put(ROWS_ONE[0]);
    p.setDurability(Durability.SKIP_WAL);
    p.addColumn(FAMILIES[0], QUALIFIERS_ONE[0], VALUES[1]);
    this.region.put(p);
    this.region.flush(true);
    Scan s = new Scan();
    s.setFilter(new FilterBase() {
      @Override
      public ReturnCode filterCell(Cell c) throws IOException {
        return ReturnCode.INCLUDE_AND_NEXT_COL;
      }",1
"@Test
  public void testPageFilter() throws Exception {

    // KVs in first 6 rows
    KeyValue[] expectedKVs = {
      // testRowOne-0
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowOne-2
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowOne-3
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowTwo-0
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-2
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-3
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]) }",1
"@Test
  public void testQualifierFilter() throws IOException {

    // Match two keys (one from each family) in half the rows
    long expectedRows = this.numRows / 2;
    long expectedKeys = 2;
    Filter f = new QualifierFilter(CompareOperator.EQUAL,
      new BinaryComparator(Bytes.toBytes(""testQualifierOne-2"")));
    Scan s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys less than same qualifier
    // Expect only two keys (one from each family) in half the rows
    expectedRows = this.numRows / 2;
    expectedKeys = 2;
    f = new QualifierFilter(CompareOperator.LESS,
      new BinaryComparator(Bytes.toBytes(""testQualifierOne-2"")));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys less than or equal
    // Expect four keys (two from each family) in half the rows
    expectedRows = this.numRows / 2;
    expectedKeys = 4;
    f = new QualifierFilter(CompareOperator.LESS_OR_EQUAL,
      new BinaryComparator(Bytes.toBytes(""testQualifierOne-2"")));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys not equal
    // Expect four keys (two from each family)
    // Only look in first group of rows
    expectedRows = this.numRows / 2;
    expectedKeys = 4;
    f = new QualifierFilter(CompareOperator.NOT_EQUAL,
      new BinaryComparator(Bytes.toBytes(""testQualifierOne-2"")));
    s =
      new Scan().withStartRow(HConstants.EMPTY_START_ROW).withStopRow(Bytes.toBytes(""testRowTwo""));
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys greater or equal
    // Expect four keys (two from each family)
    // Only look in first group of rows
    expectedRows = this.numRows / 2;
    expectedKeys = 4;
    f = new QualifierFilter(CompareOperator.GREATER_OR_EQUAL,
      new BinaryComparator(Bytes.toBytes(""testQualifierOne-2"")));
    s =
      new Scan().withStartRow(HConstants.EMPTY_START_ROW).withStopRow(Bytes.toBytes(""testRowTwo""));
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys greater
    // Expect two keys (one from each family)
    // Only look in first group of rows
    expectedRows = this.numRows / 2;
    expectedKeys = 2;
    f = new QualifierFilter(CompareOperator.GREATER,
      new BinaryComparator(Bytes.toBytes(""testQualifierOne-2"")));
    s =
      new Scan().withStartRow(HConstants.EMPTY_START_ROW).withStopRow(Bytes.toBytes(""testRowTwo""));
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys not equal to
    // Look across rows and fully validate the keys and ordering
    // Expect varied numbers of keys, 4 per row in group one, 6 per row in group two
    f = new QualifierFilter(CompareOperator.NOT_EQUAL, new BinaryComparator(QUALIFIERS_ONE[2]));
    s = new Scan();
    s.setFilter(f);

    KeyValue[] kvs = {
      // testRowOne-0
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowOne-2
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[2], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowOne-3
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowTwo-0
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-2
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-3
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]), }",1
"@Test
  public void testRowFilter() throws IOException {

    // Match a single row, all keys
    long expectedRows = 1;
    long expectedKeys = this.colsPerRow;
    Filter f =
      new RowFilter(CompareOperator.EQUAL, new BinaryComparator(Bytes.toBytes(""testRowOne-2"")));
    Scan s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match a two rows, one from each group, using regex
    expectedRows = 2;
    expectedKeys = this.colsPerRow;
    f = new RowFilter(CompareOperator.EQUAL, new RegexStringComparator(""testRow.+-2""));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match rows less than
    // Expect all keys in one row
    expectedRows = 1;
    expectedKeys = this.colsPerRow;
    f = new RowFilter(CompareOperator.LESS, new BinaryComparator(Bytes.toBytes(""testRowOne-2"")));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match rows less than or equal
    // Expect all keys in two rows
    expectedRows = 2;
    expectedKeys = this.colsPerRow;
    f = new RowFilter(CompareOperator.LESS_OR_EQUAL,
      new BinaryComparator(Bytes.toBytes(""testRowOne-2"")));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match rows not equal
    // Expect all keys in all but one row
    expectedRows = this.numRows - 1;
    expectedKeys = this.colsPerRow;
    f =
      new RowFilter(CompareOperator.NOT_EQUAL, new BinaryComparator(Bytes.toBytes(""testRowOne-2"")));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys greater or equal
    // Expect all keys in all but one row
    expectedRows = this.numRows - 1;
    expectedKeys = this.colsPerRow;
    f = new RowFilter(CompareOperator.GREATER_OR_EQUAL,
      new BinaryComparator(Bytes.toBytes(""testRowOne-2"")));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match keys greater
    // Expect all keys in all but two rows
    expectedRows = this.numRows - 2;
    expectedKeys = this.colsPerRow;
    f = new RowFilter(CompareOperator.GREATER, new BinaryComparator(Bytes.toBytes(""testRowOne-2"")));
    s = new Scan();
    s.setFilter(f);
    verifyScanNoEarlyOut(s, expectedRows, expectedKeys);

    // Match rows not equal to testRowTwo-2
    // Look across rows and fully validate the keys and ordering
    // Should see all keys in all rows but testRowTwo-2
    f =
      new RowFilter(CompareOperator.NOT_EQUAL, new BinaryComparator(Bytes.toBytes(""testRowOne-2"")));
    s = new Scan();
    s.setFilter(f);

    KeyValue[] kvs = {
      // testRowOne-0
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[0], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowOne-3
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[0], QUALIFIERS_ONE[3], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[0], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[2], VALUES[0]),
      new KeyValue(ROWS_ONE[3], FAMILIES[1], QUALIFIERS_ONE[3], VALUES[0]),
      // testRowTwo-0
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-2
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-3
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]), }",1
"@Test
  public void testSkipFilter() throws IOException {

    // Test for qualifier regex: ""testQualifierOne-2""
    // Should only get rows from second group, and all keys
    Filter f = new SkipFilter(new QualifierFilter(CompareOperator.NOT_EQUAL,
      new BinaryComparator(Bytes.toBytes(""testQualifierOne-2""))));
    Scan s = new Scan();
    s.setFilter(f);

    KeyValue[] kvs = {
      // testRowTwo-0
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[0], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-2
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[2], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]),
      // testRowTwo-3
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[0], QUALIFIERS_TWO[3], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[0], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[2], VALUES[1]),
      new KeyValue(ROWS_TWO[3], FAMILIES[1], QUALIFIERS_TWO[3], VALUES[1]), }",1
"@Test
  public void testConstruction() {
    FirstKeyOnlyFilter f1 = new FirstKeyOnlyFilter();
    FirstKeyOnlyFilter f2 = new FirstKeyOnlyFilter();
    f1.setReversed(true);
    f2.setReversed(false);

    try {
      FilterList ff = new FilterList(f1, f2);
      fail(""The IllegalArgumentException should be thrown"");
    }",1
"@Test
  public void testKeyOnlyFilterTransformCell() throws IOException {
    Cell c;
    KeyValue kv1 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""cf""), Bytes.toBytes(""column1""),
      1, Bytes.toBytes(""value1""));
    KeyValue kv2 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""cf""), Bytes.toBytes(""column1""),
      2, Bytes.toBytes(""value2""));

    Filter filter1 = new SingleColumnValueFilter(Bytes.toBytes(""cf""), Bytes.toBytes(""column1""),
      CompareOperator.EQUAL, Bytes.toBytes(""value1""));
    Filter filter2 = new SingleColumnValueFilter(Bytes.toBytes(""cf""), Bytes.toBytes(""column1""),
      CompareOperator.EQUAL, Bytes.toBytes(""value2""));
    FilterList internalFilterList = new FilterList(Operator.MUST_PASS_ONE, filter1, filter2);

    FilterList keyOnlyFilterFirst =
      new FilterList(Operator.MUST_PASS_ALL, new KeyOnlyFilter(), internalFilterList);

    assertEquals(ReturnCode.INCLUDE, keyOnlyFilterFirst.filterCell(kv1));
    c = keyOnlyFilterFirst.transformCell(kv1);
    assertEquals(0, c.getValueLength());
    assertEquals(ReturnCode.INCLUDE, keyOnlyFilterFirst.filterCell(kv2));
    c = keyOnlyFilterFirst.transformCell(kv2);
    assertEquals(0, c.getValueLength());

    internalFilterList.reset();
    FilterList keyOnlyFilterLast =
      new FilterList(Operator.MUST_PASS_ALL, new KeyOnlyFilter(), internalFilterList);
    assertEquals(ReturnCode.INCLUDE, keyOnlyFilterLast.filterCell(kv1));
    c = keyOnlyFilterLast.transformCell(kv1);
    assertEquals(0, c.getValueLength());
    assertEquals(ReturnCode.INCLUDE, keyOnlyFilterLast.filterCell(kv2));
    c = keyOnlyFilterLast.transformCell(kv2);
    assertEquals(0, c.getValueLength());
  }",1
"@Test
  public void testMPONEWithSeekNextUsingHint() throws Exception {
    byte[] col = Bytes.toBytes(""c"");
    FilterList filterList =
      new FilterList(Operator.MUST_PASS_ONE, new ColumnPaginationFilter(1, col));

    KeyValue kv1 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam""), Bytes.toBytes(""a""), 1,
      Bytes.toBytes(""value""));
    KeyValue kv2 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam""), Bytes.toBytes(""b""), 2,
      Bytes.toBytes(""value""));
    KeyValue kv3 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam""), Bytes.toBytes(""c""), 3,
      Bytes.toBytes(""value""));
    KeyValue kv4 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam""), Bytes.toBytes(""c""), 4,
      Bytes.toBytes(""value""));

    assertEquals(ReturnCode.SEEK_NEXT_USING_HINT, filterList.filterCell(kv1));
    assertEquals(ReturnCode.SEEK_NEXT_USING_HINT, filterList.filterCell(kv2));
    assertEquals(ReturnCode.INCLUDE_AND_NEXT_COL, filterList.filterCell(kv3));
    assertEquals(ReturnCode.NEXT_COL, filterList.filterCell(kv4));
  }",1
"@Test
  public void testReversedFilterListWithOR() throws IOException {
    byte[] r22 = Bytes.toBytes(""Row22"");
    byte[] r2 = Bytes.toBytes(""Row2"");
    byte[] r1 = Bytes.toBytes(""Row1"");

    FilterList filterList = new FilterList(FilterList.Operator.MUST_PASS_ONE);
    filterList.setReversed(true);
    PrefixFilter prefixFilter = new PrefixFilter(r2);
    prefixFilter.setReversed(true);
    filterList.addFilter(prefixFilter);
    filterList.filterRowKey(KeyValueUtil.createFirstOnRow(r22));
    assertEquals(ReturnCode.INCLUDE, filterList.filterCell(new KeyValue(r22, r22, r22)));
    assertEquals(ReturnCode.INCLUDE, filterList.filterCell(new KeyValue(r2, r2, r2)));

    filterList.reset();
    filterList.filterRowKey(KeyValueUtil.createFirstOnRow(r1));
    assertEquals(ReturnCode.SKIP, filterList.filterCell(new KeyValue(r1, r1, r1)));

    filterList = new FilterList(FilterList.Operator.MUST_PASS_ONE);
    filterList.setReversed(true);
    AlwaysNextColFilter alwaysNextColFilter = new AlwaysNextColFilter();
    alwaysNextColFilter.setReversed(true);
    prefixFilter = new PrefixFilter(r2);
    prefixFilter.setReversed(true);
    filterList.addFilter(alwaysNextColFilter);
    filterList.addFilter(prefixFilter);
    filterList.filterRowKey(KeyValueUtil.createFirstOnRow(r22));
    assertEquals(ReturnCode.INCLUDE, filterList.filterCell(new KeyValue(r22, r22, r22)));
    assertEquals(ReturnCode.INCLUDE, filterList.filterCell(new KeyValue(r2, r2, r2)));

    filterList.reset();
    filterList.filterRowKey(KeyValueUtil.createFirstOnRow(r1));
    assertEquals(ReturnCode.NEXT_COL, filterList.filterCell(new KeyValue(r1, r1, r1)));
  }",1
"@Test
  public void testRowCountFilter() throws IOException {
    KeyValue kv1 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam1""), Bytes.toBytes(""a""), 1,
      Bytes.toBytes(""value""));
    KeyValue kv2 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam2""), Bytes.toBytes(""a""), 2,
      Bytes.toBytes(""value""));
    MockNextRowFilter mockNextRowFilter = new MockNextRowFilter();
    FilterList filter = new FilterList(Operator.MUST_PASS_ONE, mockNextRowFilter);
    filter.filterCell(kv1);
    filter.filterCell(kv2);
    assertEquals(2, mockNextRowFilter.getHitCount());
  }",1
"@Test
  public void testShouldPassCurrentCellToFilter() throws IOException {
    KeyValue kv1 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam""), Bytes.toBytes(""a""), 1,
      Bytes.toBytes(""value""));
    KeyValue kv2 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam""), Bytes.toBytes(""a""), 2,
      Bytes.toBytes(""value""));
    KeyValue kv3 = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""fam""), Bytes.toBytes(""b""), 3,
      Bytes.toBytes(""value""));
    KeyValue kv4 = new KeyValue(Bytes.toBytes(""row1""), Bytes.toBytes(""fam""), Bytes.toBytes(""c""), 4,
      Bytes.toBytes(""value""));

    MockFilter mockFilter = new MockFilter(ReturnCode.NEXT_COL);
    FilterList filter = new FilterList(Operator.MUST_PASS_ONE, mockFilter);

    filter.filterCell(kv1);
    assertTrue(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv2);
    assertFalse(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv3);
    assertTrue(mockFilter.didCellPassToTheFilter);

    mockFilter = new MockFilter(ReturnCode.INCLUDE_AND_NEXT_COL);
    filter = new FilterList(Operator.MUST_PASS_ONE, mockFilter);

    filter.filterCell(kv1);
    assertTrue(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv2);
    assertFalse(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv3);
    assertTrue(mockFilter.didCellPassToTheFilter);

    mockFilter = new MockFilter(ReturnCode.NEXT_ROW);
    filter = new FilterList(Operator.MUST_PASS_ONE, mockFilter);
    filter.filterCell(kv1);
    assertTrue(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv2);
    assertFalse(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv3);
    assertFalse(mockFilter.didCellPassToTheFilter);

    filter.reset();
    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv4);
    assertTrue(mockFilter.didCellPassToTheFilter);

    mockFilter = new MockFilter(ReturnCode.INCLUDE_AND_SEEK_NEXT_ROW);
    filter = new FilterList(Operator.MUST_PASS_ONE, mockFilter);
    filter.filterCell(kv1);
    assertTrue(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv2);
    assertFalse(mockFilter.didCellPassToTheFilter);

    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv3);
    assertFalse(mockFilter.didCellPassToTheFilter);

    filter.reset();
    mockFilter.didCellPassToTheFilter = false;
    filter.filterCell(kv4);
    assertTrue(mockFilter.didCellPassToTheFilter);
  }",1
"@Test
  public void testFilterWrapper() {
    int kv_number = 0;
    int row_number = 0;
    try {
      Scan scan = new Scan();
      List<Filter> fs = new ArrayList<>();

      DependentColumnFilter f1 = new DependentColumnFilter(Bytes.toBytes(""f1""), Bytes.toBytes(""c5""),
        true, CompareOperator.EQUAL, new SubstringComparator(""c5""));
      PageFilter f2 = new PageFilter(2);
      fs.add(f1);
      fs.add(f2);
      FilterList filter = new FilterList(fs);

      scan.setFilter(filter);
      Table table = connection.getTable(name);
      ResultScanner scanner = table.getScanner(scan);

      // row2 (c1-c4) and row3(c1-c4) are returned
      for (Result result : scanner) {
        row_number++;
        for (Cell kv : result.listCells()) {
          LOG.debug(kv_number + "". kv: "" + kv);
          kv_number++;
          assertEquals(""Returned row is not correct"", Bytes.toString(CellUtil.cloneRow(kv)),
            ""row"" + (row_number + 1));
        }",1
"@Test
  public void testSimple() {
    for (int i = 1; i < values.length; i++) {
      for (int j = 0; j < i; j++) {
        LongComparator cp = new LongComparator(values[i]);
        assertEquals(1, cp.compareTo(Bytes.toBytes(values[j])));
        ByteBuffer data_bb = ByteBuffer.wrap(Bytes.toBytes(values[j]));
        assertEquals(1, cp.compareTo(data_bb, 0, data_bb.capacity()));
      }",1
"@Test
  public void testMultipleColumnPrefixFilterWithManyFamilies() throws IOException {
    String family1 = ""Family1"";
    String family2 = ""Family2"";
    TableDescriptorBuilder tableDescriptorBuilder =
      TableDescriptorBuilder.newBuilder(TableName.valueOf(name.getMethodName()));
    ColumnFamilyDescriptor columnFamilyDescriptor =
      ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(family1)).setMaxVersions(3).build();
    tableDescriptorBuilder.setColumnFamily(columnFamilyDescriptor);
    columnFamilyDescriptor =
      ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(family2)).setMaxVersions(3).build();
    tableDescriptorBuilder.setColumnFamily(columnFamilyDescriptor);
    TableDescriptor tableDescriptor = tableDescriptorBuilder.build();
    RegionInfo info = RegionInfoBuilder.newBuilder(tableDescriptor.getTableName()).build();
    HRegion region = HBaseTestingUtil.createRegionAndWAL(info, TEST_UTIL.getDataTestDir(),
      TEST_UTIL.getConfiguration(), tableDescriptor);

    List<String> rows = generateRandomWords(100, ""row"");
    List<String> columns = generateRandomWords(10000, ""column"");
    long maxTimestamp = 3;

    List<Cell> kvList = new ArrayList<>();

    Map<String, List<Cell>> prefixMap = new HashMap<>();

    prefixMap.put(""p"", new ArrayList<>());
    prefixMap.put(""q"", new ArrayList<>());
    prefixMap.put(""s"", new ArrayList<>());

    String valueString = ""ValueString"";

    for (String row : rows) {
      Put p = new Put(Bytes.toBytes(row));
      p.setDurability(Durability.SKIP_WAL);
      for (String column : columns) {
        for (long timestamp = 1; timestamp <= maxTimestamp; timestamp++) {
          double rand = Math.random();
          Cell kv;
          if (rand < 0.5) {
            kv = KeyValueTestUtil.create(row, family1, column, timestamp, valueString);
          }",1
"@Test
  public void testEmptyValue() {
    // given
    byte[] value = new byte[] { 0 }",1
"@Test
  public void testNonNullValue() {
    // given
    byte[] value = new byte[] { 0, 1, 2, 3, 4, 5 }",1
"@Test
  public void testColumnCountGetFilter() throws IOException {
    String filterString = "" ColumnCountGetFilter(4)"";
    ColumnCountGetFilter columnCountGetFilter =
      doTestFilter(filterString, ColumnCountGetFilter.class);
    int limit = columnCountGetFilter.getLimit();
    assertEquals(4, limit);

    filterString = "" ColumnCountGetFilter('abc')"";
    try {
      doTestFilter(filterString, ColumnCountGetFilter.class);
      assertTrue(false);
    }",1
"@Test
  public void testCompoundFilter4() throws IOException {
    String filterString = "" ColumnPrefixFilter ('realtime') OR ""
      + ""FirstKeyOnlyFilter() OR SKIP FamilyFilter(=, 'substring:hihi')"";
    FilterList filterList = doTestFilter(filterString, FilterList.class);
    ArrayList<Filter> filters = (ArrayList<Filter>) filterList.getFilters();

    assertTrue(filters.get(0) instanceof ColumnPrefixFilter);
    assertTrue(filters.get(1) instanceof FirstKeyOnlyFilter);
    assertTrue(filters.get(2) instanceof SkipFilter);

    ColumnPrefixFilter columnPrefixFilter = (ColumnPrefixFilter) filters.get(0);
    FirstKeyOnlyFilter firstKeyOnlyFilter = (FirstKeyOnlyFilter) filters.get(1);
    SkipFilter skipFilter = (SkipFilter) filters.get(2);

    byte[] columnPrefix = columnPrefixFilter.getPrefix();
    assertEquals(""realtime"", new String(columnPrefix, StandardCharsets.UTF_8));

    assertTrue(skipFilter.getFilter() instanceof FamilyFilter);
    FamilyFilter familyFilter = (FamilyFilter) skipFilter.getFilter();

    assertEquals(CompareOperator.EQUAL, familyFilter.getCompareOperator());
    assertTrue(familyFilter.getComparator() instanceof SubstringComparator);
    SubstringComparator substringComparator = (SubstringComparator) familyFilter.getComparator();
    assertEquals(""hihi"", new String(substringComparator.getValue(), StandardCharsets.UTF_8));
  }",1
"@Test
  public void testCompoundFilter5() throws IOException {
    String filterStr = ""(ValueFilter(!=, 'substring:pre'))"";
    ValueFilter valueFilter = doTestFilter(filterStr, ValueFilter.class);
    assertTrue(valueFilter.getComparator() instanceof SubstringComparator);

    filterStr = ""(ValueFilter(>=,'binary:x') AND (ValueFilter(<=,'binary:y')))""
      + "" OR ValueFilter(=,'binary:ab')"";
    filter = f.parseFilterString(filterStr);
    assertTrue(filter instanceof FilterList);
    List<Filter> list = ((FilterList) filter).getFilters();
    assertEquals(2, list.size());
    assertTrue(list.get(0) instanceof FilterList);
    assertTrue(list.get(1) instanceof ValueFilter);
  }",1
"@Test
  public void testInclusiveStopFilter() throws IOException {
    String filterString = ""InclusiveStopFilter ('row 3')"";
    InclusiveStopFilter inclusiveStopFilter = doTestFilter(filterString, InclusiveStopFilter.class);
    byte[] stopRowKey = inclusiveStopFilter.getStopRowKey();
    assertEquals(""row 3"", new String(stopRowKey, StandardCharsets.UTF_8));
  }",1
"@Test
  public void testQualifierFilter() throws IOException {
    String filterString = ""QualifierFilter(=, 'regexstring:pre*')"";
    QualifierFilter qualifierFilter = doTestFilter(filterString, QualifierFilter.class);
    assertEquals(CompareOperator.EQUAL, qualifierFilter.getCompareOperator());
    assertTrue(qualifierFilter.getComparator() instanceof RegexStringComparator);
    RegexStringComparator regexStringComparator =
      (RegexStringComparator) qualifierFilter.getComparator();
    assertEquals(""pre*"", new String(regexStringComparator.getValue(), StandardCharsets.UTF_8));
  }",1
"@Test
  public void testSingleColumnValueExcludeFilter() throws IOException {
    String filterString =
      ""SingleColumnValueExcludeFilter ('family', 'qualifier', <, 'binaryprefix:a')"";
    SingleColumnValueExcludeFilter singleColumnValueExcludeFilter =
      doTestFilter(filterString, SingleColumnValueExcludeFilter.class);
    assertEquals(CompareOperator.LESS, singleColumnValueExcludeFilter.getCompareOperator());
    assertEquals(""family"",
      new String(singleColumnValueExcludeFilter.getFamily(), StandardCharsets.UTF_8));
    assertEquals(""qualifier"",
      new String(singleColumnValueExcludeFilter.getQualifier(), StandardCharsets.UTF_8));
    assertEquals(""a"", new String(singleColumnValueExcludeFilter.getComparator().getValue(),
      StandardCharsets.UTF_8));
    assertFalse(singleColumnValueExcludeFilter.getFilterIfMissing());
    assertTrue(singleColumnValueExcludeFilter.getLatestVersionOnly());

    filterString = ""SingleColumnValueExcludeFilter ""
      + ""('family', 'qualifier', <=, 'binaryprefix:a', true, false)"";
    singleColumnValueExcludeFilter =
      doTestFilter(filterString, SingleColumnValueExcludeFilter.class);
    assertEquals(""family"",
      new String(singleColumnValueExcludeFilter.getFamily(), StandardCharsets.UTF_8));
    assertEquals(""qualifier"",
      new String(singleColumnValueExcludeFilter.getQualifier(), StandardCharsets.UTF_8));
    assertEquals(CompareOperator.LESS_OR_EQUAL,
      singleColumnValueExcludeFilter.getCompareOperator());
    assertTrue(singleColumnValueExcludeFilter.getComparator() instanceof BinaryPrefixComparator);
    BinaryPrefixComparator binaryPrefixComparator =
      (BinaryPrefixComparator) singleColumnValueExcludeFilter.getComparator();
    assertEquals(""a"", new String(binaryPrefixComparator.getValue(), StandardCharsets.UTF_8));
    assertTrue(singleColumnValueExcludeFilter.getFilterIfMissing());
    assertFalse(singleColumnValueExcludeFilter.getLatestVersionOnly());
  }",1
"@Test
  public void testTimestampsFilter() throws IOException {
    String filterString = ""TimestampsFilter(9223372036854775806, 6)"";
    TimestampsFilter timestampsFilter = doTestFilter(filterString, TimestampsFilter.class);
    List<Long> timestamps = timestampsFilter.getTimestamps();
    assertEquals(2, timestamps.size());
    assertEquals(Long.valueOf(6), timestamps.get(0));

    filterString = ""TimestampsFilter()"";
    timestampsFilter = doTestFilter(filterString, TimestampsFilter.class);
    timestamps = timestampsFilter.getTimestamps();
    assertEquals(0, timestamps.size());

    filterString = ""TimestampsFilter(9223372036854775808, 6)"";
    try {
      doTestFilter(filterString, ColumnPaginationFilter.class);
      assertTrue(false);
    }",1
"@Test
  public void testUnescapedQuote2() throws IOException {
    String filterString = ""InclusiveStopFilter ('row''3''')"";
    InclusiveStopFilter inclusiveStopFilter = doTestFilter(filterString, InclusiveStopFilter.class);
    byte[] stopRowKey = inclusiveStopFilter.getStopRowKey();
    assertEquals(""row'3'"", new String(stopRowKey, StandardCharsets.UTF_8));
  }",1
"@Test
  public void testFilterCell() throws Exception {
    Filter filter = new SingleColumnValueExcludeFilter(COLUMN_FAMILY, COLUMN_QUALIFIER,
      CompareOperator.EQUAL, VAL_1);

    // A 'match' situation
    List<Cell> kvs = new ArrayList<>();
    KeyValue c = new KeyValue(ROW, COLUMN_FAMILY, COLUMN_QUALIFIER_2, VAL_1);

    kvs.add(new KeyValue(ROW, COLUMN_FAMILY, COLUMN_QUALIFIER_2, VAL_1));
    kvs.add(new KeyValue(ROW, COLUMN_FAMILY, COLUMN_QUALIFIER, VAL_1));
    kvs.add(new KeyValue(ROW, COLUMN_FAMILY, COLUMN_QUALIFIER_2, VAL_1));

    filter.filterRowCells(kvs);

    assertEquals(""resultSize"", 2, kvs.size());
    assertTrue(""leftKV1"", CellComparatorImpl.COMPARATOR.compare(kvs.get(0), c) == 0);
    assertTrue(""leftKV2"", CellComparatorImpl.COMPARATOR.compare(kvs.get(1), c) == 0);
    assertFalse(""allRemainingWhenMatch"", filter.filterAllRemaining());

    // A 'mismatch' situation
    filter.reset();
    // INCLUDE expected because test column has not yet passed
    c = new KeyValue(ROW, COLUMN_FAMILY, COLUMN_QUALIFIER_2, VAL_1);
    assertTrue(""otherColumn"", filter.filterCell(c) == Filter.ReturnCode.INCLUDE);
    // Test column will pass (wont match), expect NEXT_ROW
    c = new KeyValue(ROW, COLUMN_FAMILY, COLUMN_QUALIFIER, VAL_2);
    assertTrue(""testedMismatch"", filter.filterCell(c) == Filter.ReturnCode.NEXT_ROW);
    // After a mismatch (at least with LatestVersionOnly), subsequent columns are EXCLUDE
    c = new KeyValue(ROW, COLUMN_FAMILY, COLUMN_QUALIFIER_2, VAL_1);
    assertTrue(""otherColumn"", filter.filterCell(c) == Filter.ReturnCode.NEXT_ROW);
  }",1
"@Test
  public void testQuery() throws Exception {
    String result = readOutput(new URL(baseUrl, ""/jmx?qry=java.lang:type=Runtime""));
    LOG.info(""/jmx?qry=java.lang:type=Runtime RESULT: "" + result);
    assertReFind(""\""name\""\\s*:\\s*\""java.lang:type=Runtime\"""", result);
    assertReFind(""\""modelerType\"""", result);

    result = readOutput(new URL(baseUrl, ""/jmx?qry=java.lang:type=Memory""));
    LOG.info(""/jmx?qry=java.lang:type=Memory RESULT: "" + result);
    assertReFind(""\""name\""\\s*:\\s*\""java.lang:type=Memory\"""", result);
    assertReFind(""\""modelerType\"""", result);

    result = readOutput(new URL(baseUrl, ""/jmx""));
    LOG.info(""/jmx RESULT: "" + result);
    assertReFind(""\""name\""\\s*:\\s*\""java.lang:type=Memory\"""", result);

    // test to get an attribute of a mbean
    result = readOutput(new URL(baseUrl, ""/jmx?get=java.lang:type=Memory::HeapMemoryUsage""));
    LOG.info(""/jmx RESULT: "" + result);
    assertReFind(""\""name\""\\s*:\\s*\""java.lang:type=Memory\"""", result);
    assertReFind(""\""committed\""\\s*:"", result);

    // negative test to get an attribute of a mbean
    result = readOutput(new URL(baseUrl, ""/jmx?get=java.lang:type=Memory::""));
    LOG.info(""/jmx RESULT: "" + result);
    assertReFind(""\""ERROR\"""", result);

    // test to get JSONP result
    result = readOutput(new URL(baseUrl, ""/jmx?qry=java.lang:type=Memory&callback=mycallback1""));
    LOG.info(""/jmx?qry=java.lang:type=Memory&callback=mycallback RESULT: "" + result);
    assertReFind(""^mycallback1\\(\\{"", result);
    assertReFind(""\\}",1
"@Test
  public void testBindAddress() throws Exception {
    checkBindAddress(""localhost"", 0, false).stop();
    // hang onto this one for a bit more testing
    HttpServer myServer = checkBindAddress(""localhost"", 0, false);
    HttpServer myServer2 = null;
    try {
      int port = myServer.getConnectorAddress(0).getPort();
      // it's already in use, true = expect a higher port
      myServer2 = checkBindAddress(""localhost"", port, true);
      // try to reuse the port
      port = myServer2.getConnectorAddress(0).getPort();
      myServer2.stop();
      assertNull(myServer2.getConnectorAddress(0)); // not bound
      myServer2.openListeners();
      assertEquals(port, myServer2.getConnectorAddress(0).getPort()); // expect same port
    }",1
"@Test
  public void testHttpMethods() throws Exception {
    // HTTP TRACE method should be disabled for security
    // See https://www.owasp.org/index.php/Cross_Site_Tracing
    URL url = new URL(baseUrl, ""/echo?a=b"");
    HttpURLConnection conn = (HttpURLConnection) url.openConnection();
    conn.setRequestMethod(""TRACE"");
    conn.connect();
    assertEquals(HttpURLConnection.HTTP_FORBIDDEN, conn.getResponseCode());
  }",1
"@Test
  public void testBucketAllocator() throws BucketAllocatorException {
    BucketAllocator mAllocator = cache.getAllocator();
    /*
     * Test the allocator first
     */
    final List<Integer> BLOCKSIZES = Arrays.asList(4 * 1024, 8 * 1024, 64 * 1024, 96 * 1024);

    boolean full = false;
    ArrayList<Pair<Long, Integer>> allocations = new ArrayList<>();
    // Fill the allocated extents by choosing a random blocksize. Continues selecting blocks until
    // the cache is completely filled.
    List<Integer> tmp = new ArrayList<>(BLOCKSIZES);
    while (!full) {
      Integer blockSize = null;
      try {
        blockSize = randFrom(tmp);
        allocations.add(new Pair<>(mAllocator.allocateBlock(blockSize), blockSize));
      }",1
"@Test
  public void testCacheBlockNextBlockMetadataMissing() throws Exception {
    int size = 100;
    int length = HConstants.HFILEBLOCK_HEADER_SIZE + size;
    ByteBuffer buf1 = ByteBuffer.allocate(size), buf2 = ByteBuffer.allocate(size);
    HFileContext meta = new HFileContextBuilder().build();
    ByteBuffAllocator allocator = ByteBuffAllocator.HEAP;
    HFileBlock blockWithNextBlockMetadata = new HFileBlock(BlockType.DATA, size, size, -1,
      ByteBuff.wrap(buf1), HFileBlock.FILL_HEADER, -1, 52, -1, meta, allocator);
    HFileBlock blockWithoutNextBlockMetadata = new HFileBlock(BlockType.DATA, size, size, -1,
      ByteBuff.wrap(buf2), HFileBlock.FILL_HEADER, -1, -1, -1, meta, allocator);

    BlockCacheKey key = new BlockCacheKey(""testCacheBlockNextBlockMetadataMissing"", 0);
    ByteBuffer actualBuffer = ByteBuffer.allocate(length);
    ByteBuffer block1Buffer = ByteBuffer.allocate(length);
    ByteBuffer block2Buffer = ByteBuffer.allocate(length);
    blockWithNextBlockMetadata.serialize(block1Buffer, true);
    blockWithoutNextBlockMetadata.serialize(block2Buffer, true);

    // Add blockWithNextBlockMetadata, expect blockWithNextBlockMetadata back.
    CacheTestUtils.getBlockAndAssertEquals(cache, key, blockWithNextBlockMetadata, actualBuffer,
      block1Buffer);

    waitUntilFlushedToBucket(cache, key);
    assertNotNull(cache.backingMap.get(key));
    assertEquals(1, cache.backingMap.get(key).refCnt());
    assertEquals(1, blockWithNextBlockMetadata.getBufferReadOnly().refCnt());
    assertEquals(1, blockWithoutNextBlockMetadata.getBufferReadOnly().refCnt());

    // Add blockWithoutNextBlockMetada, expect blockWithNextBlockMetadata back.
    CacheTestUtils.getBlockAndAssertEquals(cache, key, blockWithoutNextBlockMetadata, actualBuffer,
      block1Buffer);
    assertEquals(1, blockWithNextBlockMetadata.getBufferReadOnly().refCnt());
    assertEquals(1, blockWithoutNextBlockMetadata.getBufferReadOnly().refCnt());
    assertEquals(1, cache.backingMap.get(key).refCnt());

    // Clear and add blockWithoutNextBlockMetadata
    assertTrue(cache.evictBlock(key));
    assertEquals(1, blockWithNextBlockMetadata.getBufferReadOnly().refCnt());
    assertEquals(1, blockWithoutNextBlockMetadata.getBufferReadOnly().refCnt());

    assertNull(cache.getBlock(key, false, false, false));
    CacheTestUtils.getBlockAndAssertEquals(cache, key, blockWithoutNextBlockMetadata, actualBuffer,
      block2Buffer);

    waitUntilFlushedToBucket(cache, key);
    assertEquals(1, blockWithNextBlockMetadata.getBufferReadOnly().refCnt());
    assertEquals(1, blockWithoutNextBlockMetadata.getBufferReadOnly().refCnt());

    // Add blockWithNextBlockMetadata, expect blockWithNextBlockMetadata to replace.
    CacheTestUtils.getBlockAndAssertEquals(cache, key, blockWithNextBlockMetadata, actualBuffer,
      block1Buffer);

    waitUntilFlushedToBucket(cache, key);
    assertEquals(1, blockWithNextBlockMetadata.getBufferReadOnly().refCnt());
    assertEquals(1, blockWithoutNextBlockMetadata.getBufferReadOnly().refCnt());
  }",1
"@Test
  public void testInvalidAcceptFactorConfig() throws IOException {
    float[] configValues = { -1f, 0.2f, 0.86f, 1.05f }",1
"@Test
  public void testMemoryLeak() throws Exception {
    final BlockCacheKey cacheKey = new BlockCacheKey(""dummy"", 1L);
    cacheAndWaitUntilFlushedToBucket(cache, cacheKey,
      new CacheTestUtils.ByteArrayCacheable(new byte[10]), true);
    long lockId = cache.backingMap.get(cacheKey).offset();
    ReentrantReadWriteLock lock = cache.offsetLock.getLock(lockId);
    lock.writeLock().lock();
    Thread evictThread = new Thread(""evict-block"") {
      @Override
      public void run() {
        cache.evictBlock(cacheKey);
      }",1
"@Test
  public void testRetrieveFromFile() throws Exception {
    Path testDir = createAndGetTestDir();
    String ioEngineName = ""file:"" + testDir + ""/bucket.cache"";
    testRetrievalUtils(testDir, ioEngineName);
    int[] smallBucketSizes = new int[] { 3 * 1024, 5 * 1024 }",1
"@Test
  public void testValidBucketCacheConfigs() throws IOException {
    Configuration conf = HBaseConfiguration.create();
    conf.setFloat(ACCEPT_FACTOR_CONFIG_NAME, 0.9f);
    conf.setFloat(MIN_FACTOR_CONFIG_NAME, 0.5f);
    conf.setFloat(EXTRA_FREE_FACTOR_CONFIG_NAME, 0.5f);
    conf.setFloat(BucketCache.SINGLE_FACTOR_CONFIG_NAME, 0.1f);
    conf.setFloat(BucketCache.MULTI_FACTOR_CONFIG_NAME, 0.7f);
    conf.setFloat(BucketCache.MEMORY_FACTOR_CONFIG_NAME, 0.2f);

    BucketCache cache = new BucketCache(ioEngineName, capacitySize, constructedBlockSize,
      constructedBlockSizes, writeThreads, writerQLen, null, 100, conf);
    assertTrue(cache.waitForCacheInitialization(10000));

    assertEquals(ACCEPT_FACTOR_CONFIG_NAME + "" failed to propagate."", 0.9f,
      cache.getAcceptableFactor(), 0);
    assertEquals(MIN_FACTOR_CONFIG_NAME + "" failed to propagate."", 0.5f, cache.getMinFactor(), 0);
    assertEquals(EXTRA_FREE_FACTOR_CONFIG_NAME + "" failed to propagate."", 0.5f,
      cache.getExtraFreeFactor(), 0);
    assertEquals(BucketCache.SINGLE_FACTOR_CONFIG_NAME + "" failed to propagate."", 0.1f,
      cache.getSingleFactor(), 0);
    assertEquals(BucketCache.MULTI_FACTOR_CONFIG_NAME + "" failed to propagate."", 0.7f,
      cache.getMultiFactor(), 0);
    assertEquals(BucketCache.MEMORY_FACTOR_CONFIG_NAME + "" failed to propagate."", 0.2f,
      cache.getMemoryFactor(), 0);
  }",1
"@Test
  public void testRefreshFileConnection() throws IOException {
    FileChannel[] fileChannels = fileIOEngine.getFileChannels();
    FileChannel fileChannel = fileChannels[0];
    assertNotNull(fileChannel);
    fileChannel.close();
    fileIOEngine.refreshFileConnection(0, new IOException(""Test Exception""));
    FileChannel[] reopenedFileChannels = fileIOEngine.getFileChannels();
    FileChannel reopenedFileChannel = reopenedFileChannels[0];
    assertNotEquals(fileChannel, reopenedFileChannel);
    assertEquals(fileChannels.length, reopenedFileChannels.length);
    for (int i = 1; i < fileChannels.length; i++) {
      assertEquals(fileChannels[i], reopenedFileChannels[i]);
    }",1
"@Test
  public void testTrailerForV2NonPBCompatibility() throws Exception {
    if (version == 2) {
      FixedFileTrailer t = new FixedFileTrailer(version, HFileReaderImpl.MINOR_VERSION_NO_CHECKSUM);
      t.setDataIndexCount(3);
      t.setEntryCount(((long) Integer.MAX_VALUE) + 1);
      t.setLastDataBlockOffset(291);
      t.setNumDataIndexLevels(3);
      t.setComparatorClass(CellComparatorImpl.COMPARATOR.getClass());
      t.setFirstDataBlockOffset(9081723123L); // Completely unrealistic.
      t.setUncompressedDataIndexSize(827398717L); // Something random.
      t.setLoadOnOpenOffset(128);
      t.setMetaIndexCount(7);
      t.setTotalUncompressedBytes(129731987);

      {
        DataOutputStream dos = new DataOutputStream(baos); // Limited scope.
        serializeAsWritable(dos, t);
        dos.flush();
        assertEquals(FixedFileTrailer.getTrailerSize(version), dos.size());
      }",1
"@Test
  public void testCorrupt0LengthHFile() throws IOException {
    Path f = new Path(ROOT_DIR, testName.getMethodName());
    FSDataOutputStream fsos = fs.create(f);
    fsos.close();

    try {
      Reader r = HFile.createReader(fs, f, cacheConf, true, conf);
    }",1
"@Test
  public void testShortMidpointSameQual() {
    ExtendedCell left =
      ExtendedCellBuilderFactory.create(CellBuilderType.DEEP_COPY).setRow(Bytes.toBytes(""a""))
        .setFamily(Bytes.toBytes(""a"")).setQualifier(Bytes.toBytes(""a"")).setTimestamp(11)
        .setType(Type.Maximum.getCode()).setValue(HConstants.EMPTY_BYTE_ARRAY).build();
    ExtendedCell right =
      ExtendedCellBuilderFactory.create(CellBuilderType.DEEP_COPY).setRow(Bytes.toBytes(""a""))
        .setFamily(Bytes.toBytes(""a"")).setQualifier(Bytes.toBytes(""a"")).setTimestamp(9)
        .setType(Type.Maximum.getCode()).setValue(HConstants.EMPTY_BYTE_ARRAY).build();
    ExtendedCell mid = HFileWriterImpl.getMidpoint(CellComparatorImpl.COMPARATOR, left, right);
    assertTrue(
      PrivateCellUtil.compareKeyIgnoresMvcc(CellComparatorImpl.COMPARATOR, left, mid) <= 0);
    assertTrue(
      PrivateCellUtil.compareKeyIgnoresMvcc(CellComparatorImpl.COMPARATOR, mid, right) == 0);
  }",1
"@Test
  public void testGzipCompression() throws IOException {
    // @formatter:off
    String correctTestBlockStr = ""DATABLK*\\x00\\x00\\x00>\\x00\\x00\\x0F\\xA0\\xFF\\xFF\\xFF\\xFF""
      + ""\\xFF\\xFF\\xFF\\xFF""
      + ""\\x0"" + ChecksumType.getDefaultChecksumType().getCode()
      + ""\\x00\\x00@\\x00\\x00\\x00\\x00[""
      // gzip-compressed block: http://www.gzip.org/zlib/rfc-gzip.html
      + ""\\x1F\\x8B""  // gzip magic signature
      + ""\\x08""  // Compression method: 8 = ""deflate""
      + ""\\x00""  // Flags
      + ""\\x00\\x00\\x00\\x00""  // mtime
      + ""\\x00""  // XFL (extra flags)
      // OS (0 = FAT filesystems, 3 = Unix). However, this field
      // sometimes gets set to 0 on Linux and Mac, so we reset it to 3.
      // This appears to be a difference caused by the availability
      // (and use) of the native GZ codec.
      + ""\\x03""
      + ""\\xED\\xC3\\xC1\\x11\\x00 \\x08\\xC00DD\\xDD\\x7Fa""
      + ""\\xD6\\xE8\\xA3\\xB9K\\x84`\\x96Q\\xD3\\xA8\\xDB\\xA8e\\xD4c""
      + ""\\xD46\\xEA5\\xEA3\\xEA7\\xE7\\x00LI\\x5Cs\\xA0\\x0F\\x00\\x00""
      + ""\\x00\\x00\\x00\\x00""; //  4 byte checksum (ignored)
    // @formatter:on
    int correctGzipBlockLength = 95;
    String testBlockStr = createTestBlockStr(GZ, correctGzipBlockLength, false);
    // We ignore the block checksum because createTestBlockStr can change the
    // gzip header after the block is produced
    assertEquals(correctTestBlockStr.substring(0, correctGzipBlockLength - 4),
      testBlockStr.substring(0, correctGzipBlockLength - 4));
  }",1
"@Test
  public void testBlockIndexChunk() throws IOException {
    BlockIndexChunk c = new HFileBlockIndex.BlockIndexChunkImpl();
    HFileIndexBlockEncoder indexBlockEncoder = NoOpIndexBlockEncoder.INSTANCE;
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    int N = 1000;
    int[] numSubEntriesAt = new int[N];
    int numSubEntries = 0;
    for (int i = 0; i < N; ++i) {
      baos.reset();
      DataOutputStream dos = new DataOutputStream(baos);
      indexBlockEncoder.encode(c, false, dos);
      assertEquals(c.getNonRootSize(), dos.size());

      baos.reset();
      dos = new DataOutputStream(baos);
      indexBlockEncoder.encode(c, true, dos);
      assertEquals(c.getRootSize(), dos.size());

      byte[] k = RandomKeyValueUtil.randomOrderedKey(RNG, i);
      numSubEntries += RNG.nextInt(5) + 1;
      keys.add(k);
      c.add(k, getDummyFileOffset(i), getDummyOnDiskSize(i), numSubEntries);
    }",1
"@Test
  public void testMidKeyOnLeafIndexBlockBoundary() throws IOException {
    Path hfilePath = new Path(TEST_UTIL.getDataTestDir(), ""hfile_for_midkey"");
    int maxChunkSize = 512;
    conf.setInt(HFileBlockIndex.MAX_CHUNK_SIZE_KEY, maxChunkSize);
    // should open hfile.block.index.cacheonwrite
    conf.setBoolean(CacheConfig.CACHE_INDEX_BLOCKS_ON_WRITE_KEY, true);
    CacheConfig cacheConf = new CacheConfig(conf, BlockCacheFactory.createBlockCache(conf));
    BlockCache blockCache = cacheConf.getBlockCache().get();
    // Evict all blocks that were cached-on-write by the previous invocation.
    blockCache.evictBlocksByHfileName(hfilePath.getName());
    // Write the HFile
    HFileContext meta = new HFileContextBuilder().withBlockSize(SMALL_BLOCK_SIZE)
      .withCompression(Algorithm.NONE).withDataBlockEncoding(DataBlockEncoding.NONE).build();
    HFile.Writer writer = HFile.getWriterFactory(conf, cacheConf).withPath(fs, hfilePath)
      .withFileContext(meta).create();
    Random rand = new Random(19231737);
    byte[] family = Bytes.toBytes(""f"");
    byte[] qualifier = Bytes.toBytes(""q"");
    int kvNumberToBeWritten = 16;
    // the new generated hfile will contain 2 leaf-index blocks and 16 data blocks,
    // midkey is just on the boundary of the first leaf-index block
    for (int i = 0; i < kvNumberToBeWritten; ++i) {
      byte[] row = RandomKeyValueUtil.randomOrderedFixedLengthKey(rand, i, 30);

      // Key will be interpreted by KeyValue.KEY_COMPARATOR
      KeyValue kv = new KeyValue(row, family, qualifier, EnvironmentEdgeManager.currentTime(),
        RandomKeyValueUtil.randomFixedLengthValue(rand, SMALL_BLOCK_SIZE));
      writer.append(kv);
    }",1
"@Test
  public void testCacheEvictionInMemoryForceMode() throws Exception {
    long maxSize = 100000;
    long blockSize = calculateBlockSize(maxSize, 10);

    LruBlockCache cache =
      new LruBlockCache(maxSize, blockSize, false, (int) Math.ceil(1.2 * maxSize / blockSize),
        LruBlockCache.DEFAULT_LOAD_FACTOR, LruBlockCache.DEFAULT_CONCURRENCY_LEVEL, 0.98f, // min
        0.99f, // acceptable
        0.2f, // single
        0.3f, // multi
        0.5f, // memory
        1.2f, // limit
        true, 16 * 1024 * 1024);

    CachedItem[] singleBlocks = generateFixedBlocks(10, blockSize, ""single"");
    CachedItem[] multiBlocks = generateFixedBlocks(10, blockSize, ""multi"");
    CachedItem[] memoryBlocks = generateFixedBlocks(10, blockSize, ""memory"");

    long expectedCacheSize = cache.heapSize();

    // 0. Add 5 single blocks and 4 multi blocks to make cache full, si:mu:me = 5:4:0
    for (int i = 0; i < 4; i++) {
      // Just add single blocks
      cache.cacheBlock(singleBlocks[i].cacheKey, singleBlocks[i]);
      expectedCacheSize += singleBlocks[i].cacheBlockHeapSize();
      // Add and get multi blocks
      cache.cacheBlock(multiBlocks[i].cacheKey, multiBlocks[i]);
      expectedCacheSize += multiBlocks[i].cacheBlockHeapSize();
      cache.getBlock(multiBlocks[i].cacheKey, true, false, true);
    }",1
"@Test
  public void testCacheEvictionThreePriorities() throws Exception {
    long maxSize = 100000;
    long blockSize = calculateBlockSize(maxSize, 10);

    LruBlockCache cache =
      new LruBlockCache(maxSize, blockSize, false, (int) Math.ceil(1.2 * maxSize / blockSize),
        LruBlockCache.DEFAULT_LOAD_FACTOR, LruBlockCache.DEFAULT_CONCURRENCY_LEVEL, 0.98f, // min
        0.99f, // acceptable
        0.33f, // single
        0.33f, // multi
        0.34f, // memory
        1.2f, // limit
        false, 16 * 1024 * 1024);

    CachedItem[] singleBlocks = generateFixedBlocks(5, blockSize, ""single"");
    CachedItem[] multiBlocks = generateFixedBlocks(5, blockSize, ""multi"");
    CachedItem[] memoryBlocks = generateFixedBlocks(5, blockSize, ""memory"");

    long expectedCacheSize = cache.heapSize();

    // Add 3 blocks from each priority
    for (int i = 0; i < 3; i++) {

      // Just add single blocks
      cache.cacheBlock(singleBlocks[i].cacheKey, singleBlocks[i]);
      expectedCacheSize += singleBlocks[i].cacheBlockHeapSize();

      // Add and get multi blocks
      cache.cacheBlock(multiBlocks[i].cacheKey, multiBlocks[i]);
      expectedCacheSize += multiBlocks[i].cacheBlockHeapSize();
      cache.getBlock(multiBlocks[i].cacheKey, true, false, true);

      // Add memory blocks as such
      cache.cacheBlock(memoryBlocks[i].cacheKey, memoryBlocks[i], true);
      expectedCacheSize += memoryBlocks[i].cacheBlockHeapSize();

    }",1
"@Test
  public void testCacheEvictionTwoPriorities() throws Exception {
    long maxSize = 100000;
    long blockSize = calculateBlockSizeDefault(maxSize, 10);

    LruBlockCache cache = new LruBlockCache(maxSize, blockSize, false);

    CachedItem[] singleBlocks = generateFixedBlocks(5, 10000, ""single"");
    CachedItem[] multiBlocks = generateFixedBlocks(5, 10000, ""multi"");

    long expectedCacheSize = cache.heapSize();

    // Add and get the multi blocks
    for (CachedItem block : multiBlocks) {
      cache.cacheBlock(block.cacheKey, block);
      expectedCacheSize += block.cacheBlockHeapSize();
      assertEquals(cache.getBlock(block.cacheKey, true, false, true), block);
    }",1
"@Test
  public void testWrites() throws Exception {
    ByteBuffAllocator alloc = new ByteBuffAllocator(true, 3, 10, 10 / 6);
    ByteBufferListOutputStream bbos = new ByteBufferListOutputStream(alloc);
    bbos.write(2);// Write a byte
    bbos.writeInt(100);// Write an int
    byte[] b = Bytes.toBytes(""row123"");// 6 bytes
    bbos.write(b);
    assertEquals(2, bbos.allBufs.size());
    // Just use the 3rd BB from pool so that pabos, on request, wont get one
    ByteBuff bb1 = alloc.allocateOneBuffer();
    ByteBuffer bb = ByteBuffer.wrap(Bytes.toBytes(""row123_cf1_q1""));// 13 bytes
    bbos.write(bb, 0, bb.capacity());
    bb1.release();
    bbos.writeInt(123);
    bbos.writeInt(124);
    assertEquals(0, alloc.getFreeBufferCount());
    List<ByteBuffer> allBufs = bbos.getByteBuffers();
    assertEquals(4, allBufs.size());
    assertEquals(4, bbos.allBufs.size());
    ByteBuffer b1 = allBufs.get(0);
    assertEquals(10, b1.remaining());
    assertEquals(2, b1.get());
    assertEquals(100, b1.getInt());
    byte[] bActual = new byte[b.length];
    b1.get(bActual, 0, 5);// 5 bytes in 1st BB
    ByteBuffer b2 = allBufs.get(1);
    assertEquals(10, b2.remaining());
    b2.get(bActual, 5, 1);// Remaining 1 byte in 2nd BB
    assertTrue(Bytes.equals(b, bActual));
    bActual = new byte[bb.capacity()];
    b2.get(bActual, 0, 9);
    ByteBuffer b3 = allBufs.get(2);
    assertEquals(8, b3.remaining());
    b3.get(bActual, 9, 4);
    assertTrue(ByteBufferUtils.equals(bb, 0, bb.capacity(), bActual, 0, bActual.length));
    assertEquals(123, b3.getInt());
    ByteBuffer b4 = allBufs.get(3);
    assertEquals(4, b4.remaining());
    assertEquals(124, b4.getInt());
    bbos.releaseResources();
    assertEquals(3, alloc.getFreeBufferCount());
  }",1
"@Test
  public void testHDFSLinkReadDuringRename() throws Exception {
    HBaseTestingUtil testUtil = new HBaseTestingUtil();
    Configuration conf = testUtil.getConfiguration();
    conf.setInt(""dfs.blocksize"", 1024 * 1024);
    conf.setInt(""dfs.client.read.prefetch.size"", 2 * 1024 * 1024);

    testUtil.startMiniDFSCluster(1);
    MiniDFSCluster cluster = testUtil.getDFSCluster();
    FileSystem fs = cluster.getFileSystem();
    assertEquals(""hdfs"", fs.getUri().getScheme());

    try {
      testLinkReadDuringRename(fs, testUtil.getDefaultRootDirPath());
    }",1
"@Test
  public void testHalfScanAndReseek() throws Exception {
    ResourceLeakDetector.setLevel(ResourceLeakDetector.Level.PARANOID);
    Configuration conf = TEST_UTIL.getConfiguration();
    FileSystem fs = FileSystem.get(conf);
    String root_dir = TEST_UTIL.getDataTestDir().toString();
    Path parentPath = new Path(new Path(root_dir, ""parent""), ""CF"");
    fs.mkdirs(parentPath);
    String tableName = Paths.get(root_dir).getFileName().toString();
    RegionInfo splitAHri = RegionInfoBuilder.newBuilder(TableName.valueOf(tableName)).build();
    Thread.currentThread().sleep(1000);
    RegionInfo splitBHri = RegionInfoBuilder.newBuilder(TableName.valueOf(tableName)).build();
    Path splitAPath = new Path(new Path(root_dir, splitAHri.getRegionNameAsString()), ""CF"");
    Path splitBPath = new Path(new Path(root_dir, splitBHri.getRegionNameAsString()), ""CF"");
    Path filePath = StoreFileWriter.getUniqueFile(fs, parentPath);
    String ioEngineName = ""file:"" + TEST_UTIL.getDataTestDir() + ""/bucketNoRecycler.cache"";
    BucketCache bucketCache = new BucketCache(ioEngineName, 32 * 1024 * 1024, 1024,
      new int[] { 4 * 1024, 8 * 1024, 64 * 1024, 96 * 1024 }",1
"@Test
  public void testNativeSizes() throws IOException {
    Class<?> cl;
    long expected;
    long actual;

    // ArrayList
    cl = ArrayList.class;
    expected = ClassSize.estimateBase(cl, false);
    actual = ClassSize.ARRAYLIST;
    if (expected != actual) {
      ClassSize.estimateBase(cl, true);
      assertEquals(expected, actual);
    }",1
"@Test
  public void testCompressUncompressTagsWithOffheapKeyValue2() throws Exception {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream daos = new ByteBufferWriterDataOutputStream(baos);
    TagCompressionContext context = new TagCompressionContext(LRUDictionary.class, Byte.MAX_VALUE);
    ByteBufferExtendedCell kv1 = (ByteBufferExtendedCell) createOffheapKVWithTags(1);
    int tagsLength1 = kv1.getTagsLength();
    context.compressTags(daos, kv1.getTagsByteBuffer(), kv1.getTagsPosition(), tagsLength1);
    ByteBufferExtendedCell kv2 = (ByteBufferExtendedCell) createOffheapKVWithTags(3);
    int tagsLength2 = kv2.getTagsLength();
    context.compressTags(daos, kv2.getTagsByteBuffer(), kv2.getTagsPosition(), tagsLength2);

    context.clear();

    ByteArrayInputStream bais = new ByteArrayInputStream(baos.getBuffer());
    byte[] dest = new byte[tagsLength1];
    context.uncompressTags(bais, dest, 0, tagsLength1);
    assertTrue(
      Bytes.equals(kv1.getTagsArray(), kv1.getTagsOffset(), tagsLength1, dest, 0, tagsLength1));
    dest = new byte[tagsLength2];
    context.uncompressTags(bais, dest, 0, tagsLength2);
    assertTrue(
      Bytes.equals(kv2.getTagsArray(), kv2.getTagsOffset(), tagsLength2, dest, 0, tagsLength2));
  }",1
"@Test
  public void TestLRUPolicy() {
    // start by filling the dictionary up with byte arrays
    for (int i = 0; i < Short.MAX_VALUE; i++) {
      testee.findEntry(BigInteger.valueOf(i).toByteArray(), 0,
        BigInteger.valueOf(i).toByteArray().length);
    }",1
"@Test
  public void testCallQueueInfo() throws Exception {
    Configuration conf = HBaseConfiguration.create();
    AtomicInteger callExecutionCount = new AtomicInteger(0);

    RpcScheduler scheduler = new MockMasterFifoRpcScheduler(conf, 2, 1);
    scheduler.start();

    int totalCallMethods = 30;
    int unableToDispatch = 0;

    for (int i = totalCallMethods; i > 0; i--) {
      CallRunner task = createMockTask(callExecutionCount, i < 20);
      if (!scheduler.dispatch(task)) {
        unableToDispatch++;
      }",1
"@Test
  public void testNettyRpcServer() throws Exception {
    doTest(name.getTableName());
  }",1
"@Test
  public void testSoftAndHardQueueLimits() throws Exception {

    Configuration schedConf = HBaseConfiguration.create();

    schedConf.setInt(HConstants.REGION_SERVER_HANDLER_COUNT, 0);
    schedConf.setInt(""hbase.ipc.server.max.callqueue.length"", 5);
    schedConf.set(RpcExecutor.CALL_QUEUE_TYPE_CONF_KEY,
      RpcExecutor.CALL_QUEUE_TYPE_DEADLINE_CONF_VALUE);

    PriorityFunction priority = mock(PriorityFunction.class);
    when(priority.getPriority(any(), any(), any())).thenReturn(HConstants.NORMAL_QOS);
    SimpleRpcScheduler scheduler =
      new SimpleRpcScheduler(schedConf, 0, 0, 0, priority, HConstants.QOS_THRESHOLD);
    try {
      scheduler.start();

      CallRunner putCallTask = mock(CallRunner.class);
      ServerCall putCall = mock(ServerCall.class);
      putCall.param =
        RequestConverter.buildMutateRequest(Bytes.toBytes(""abc""), new Put(Bytes.toBytes(""row"")));
      RequestHeader putHead = RequestHeader.newBuilder().setMethodName(""mutate"").build();
      when(putCallTask.getRpcCall()).thenReturn(putCall);
      when(putCall.getHeader()).thenReturn(putHead);

      assertTrue(scheduler.dispatch(putCallTask));

      schedConf.setInt(""hbase.ipc.server.max.callqueue.length"", 0);
      scheduler.onConfigurationChange(schedConf);
      assertFalse(scheduler.dispatch(putCallTask));
      waitUntilQueueEmpty(scheduler);
      schedConf.setInt(""hbase.ipc.server.max.callqueue.length"", 1);
      scheduler.onConfigurationChange(schedConf);
      assertTrue(scheduler.dispatch(putCallTask));
    }",1
"@Test
  public void testMainMethod() throws Exception {
    String[] emptyArgs = { ""-h"" }",1
"@Test
  public void testRenameFamily() throws Exception {
    testRenameFamily(TEST_UTIL.getConfiguration());
  }",1
"@Test
  public void testExcludeAllFromMinorCompaction() throws Exception {
    Configuration conf = util.getConfiguration();
    conf.setInt(""hbase.hstore.compaction.min"", 2);
    generateRandomStartKeys(5);

    util.startMiniCluster();
    try (Connection conn = ConnectionFactory.createConnection(); Admin admin = conn.getAdmin();
      Table table = util.createTable(TABLE_NAMES[0], FAMILIES);
      RegionLocator locator = conn.getRegionLocator(TABLE_NAMES[0])) {
      final FileSystem fs = util.getDFSCluster().getFileSystem();
      assertEquals(""Should start with empty table"", 0, util.countRows(table));

      // deep inspection: get the StoreFile dir
      final Path storePath =
        new Path(CommonFSUtils.getTableDir(CommonFSUtils.getRootDir(conf), TABLE_NAMES[0]),
          new Path(admin.getRegions(TABLE_NAMES[0]).get(0).getEncodedName(),
            Bytes.toString(FAMILIES[0])));
      assertEquals(0, fs.listStatus(storePath).length);

      // Generate two bulk load files
      conf.setBoolean(""hbase.mapreduce.hfileoutputformat.compaction.exclude"", true);

      for (int i = 0; i < 2; i++) {
        Path testDir = util.getDataTestDirOnTestFS(""testExcludeAllFromMinorCompaction_"" + i);
        runIncrementalPELoad(conf,
          Arrays.asList(new HFileOutputFormat2.TableInfo(table.getDescriptor(),
            conn.getRegionLocator(TABLE_NAMES[0]))),
          testDir, false);
        // Perform the actual load
        BulkLoadHFiles.create(conf).bulkLoad(table.getName(), testDir);
      }",1
"@Test
  public void testWritingPEData() throws Exception {
    Configuration conf = util.getConfiguration();
    Path testDir = util.getDataTestDirOnTestFS(""testWritingPEData"");
    FileSystem fs = testDir.getFileSystem(conf);

    // Set down this value or we OOME in eclipse.
    conf.setInt(""mapreduce.task.io.sort.mb"", 20);
    // Write a few files.
    long hregionMaxFilesize = 10 * 1024;
    conf.setLong(HConstants.HREGION_MAX_FILESIZE, hregionMaxFilesize);

    Job job = new Job(conf, ""testWritingPEData"");
    setupRandomGeneratorMapper(job, false);
    // This partitioner doesn't work well for number keys but using it anyways
    // just to demonstrate how to configure it.
    byte[] startKey = new byte[RandomKVGeneratingMapper.KEYLEN_DEFAULT];
    byte[] endKey = new byte[RandomKVGeneratingMapper.KEYLEN_DEFAULT];

    Arrays.fill(startKey, (byte) 0);
    Arrays.fill(endKey, (byte) 0xff);

    job.setPartitionerClass(SimpleTotalOrderPartitioner.class);
    // Set start and end rows for partitioner.
    SimpleTotalOrderPartitioner.setStartKey(job.getConfiguration(), startKey);
    SimpleTotalOrderPartitioner.setEndKey(job.getConfiguration(), endKey);
    job.setReducerClass(CellSortReducer.class);
    job.setOutputFormatClass(HFileOutputFormat2.class);
    job.setNumReduceTasks(4);
    job.getConfiguration().setStrings(""io.serializations"", conf.get(""io.serializations""),
      MutationSerialization.class.getName(), ResultSerialization.class.getName(),
      CellSerialization.class.getName());

    FileOutputFormat.setOutputPath(job, testDir);
    assertTrue(job.waitForCompletion(false));
    FileStatus[] files = fs.listStatus(testDir);
    assertTrue(files.length > 0);

    // check output file num and size.
    for (byte[] family : FAMILIES) {
      long kvCount = 0;
      RemoteIterator<LocatedFileStatus> iterator =
        fs.listFiles(testDir.suffix(""/"" + new String(family)), true);
      while (iterator.hasNext()) {
        LocatedFileStatus keyFileStatus = iterator.next();
        HFile.Reader reader =
          HFile.createReader(fs, keyFileStatus.getPath(), new CacheConfig(conf), true, conf);
        HFileScanner scanner = reader.getScanner(conf, false, false, false);

        kvCount += reader.getEntries();
        scanner.seekTo();
        long perKVSize = scanner.getCell().getSerializedSize();
        assertTrue(""Data size of each file should not be too large."",
          perKVSize * reader.getEntries() <= hregionMaxFilesize);
      }",1
"@Test
  public void testSetInputSetsSnapshotToScans() throws Exception {

    callSetInput();

    Map<String, Collection<Scan>> actual = subject.getSnapshotsToScans(conf);

    // convert to scans we can use .equals on
    Map<String, Collection<ScanWithEquals>> actualWithEquals = toScanWithEquals(actual);
    Map<String, Collection<ScanWithEquals>> expectedWithEquals = toScanWithEquals(snapshotScans);

    assertEquals(expectedWithEquals, actualWithEquals);
  }",1
"@Test
  public void testHashCode_length() {
    TableSplit split1 = new TableSplit(TableName.valueOf(name.getMethodName()),
      Bytes.toBytes(""row-start""), Bytes.toBytes(""row-end""), ""location"", 1984);
    TableSplit split2 = new TableSplit(TableName.valueOf(name.getMethodName()),
      Bytes.toBytes(""row-start""), Bytes.toBytes(""row-end""), ""location"", 1982);

    assertEquals(split1, split2);
    assertTrue(split1.hashCode() == split2.hashCode());
    HashSet<TableSplit> set = new HashSet<>(2);
    set.add(split1);
    set.add(split2);
    assertEquals(1, set.size());
  }",1
"@Test
  public void testMergeTwoRegions() throws Exception {
    final TableName tableName = TableName.valueOf(this.name.getMethodName());
    UTIL.createTable(tableName, new byte[][] { HConstants.CATALOG_FAMILY }",1
"@Test
  public void testInvalidSplitKey() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    RegionInfo[] regions = MasterProcedureTestingUtility.createTable(procExec, tableName, null,
      columnFamilyName1, columnFamilyName2);
    insertData(UTIL, tableName, rowCount, startRowNum, columnFamilyName1, columnFamilyName2);

    assertTrue(""not able to find a splittable region"", regions != null);
    assertTrue(""not able to find a splittable region"", regions.length == 1);

    // collect AM metrics before test
    collectAssignmentManagerMetrics();

    // Split region of the table with null split key
    try {
      long procId1 = procExec.submitProcedure(
        new SplitTableRegionProcedure(procExec.getEnvironment(), regions[0], null));
      ProcedureTestingUtility.waitProcedure(procExec, procId1);
      fail(""unexpected procedure start with invalid split-key"");
    }",1
"@Test
  public void testRecoveryAndDoubleExecution() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    RegionInfo[] regions = MasterProcedureTestingUtility.createTable(procExec, tableName, null,
      columnFamilyName1, columnFamilyName2);
    insertData(UTIL, tableName, rowCount, startRowNum, columnFamilyName1, columnFamilyName2);
    int splitRowNum = startRowNum + rowCount / 2;
    byte[] splitKey = Bytes.toBytes("""" + splitRowNum);

    assertTrue(""not able to find a splittable region"", regions != null);
    assertTrue(""not able to find a splittable region"", regions.length == 1);
    ProcedureTestingUtility.waitNoProcedureRunning(procExec);
    ProcedureTestingUtility.setKillIfHasParent(procExec, false);
    ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);

    // collect AM metrics before test
    collectAssignmentManagerMetrics();

    // Split region of the table
    long procId = procExec.submitProcedure(
      new SplitTableRegionProcedure(procExec.getEnvironment(), regions[0], splitKey));

    // Restart the executor and execute the step twice
    MasterProcedureTestingUtility.testRecoveryAndDoubleExecution(procExec, procId);
    ProcedureTestingUtility.assertProcNotFailed(procExec, procId);

    verify(tableName, splitRowNum);

    assertEquals(splitSubmittedCount + 1, splitProcMetrics.getSubmittedCounter().getCount());
    assertEquals(splitFailedCount, splitProcMetrics.getFailedCounter().getCount());
  }",1
"@Test
  public void testSplitWithoutPONR() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    RegionInfo[] regions = MasterProcedureTestingUtility.createTable(procExec, tableName, null,
      columnFamilyName1, columnFamilyName2);
    insertData(UTIL, tableName, rowCount, startRowNum, columnFamilyName1, columnFamilyName2);
    int splitRowNum = startRowNum + rowCount / 2;
    byte[] splitKey = Bytes.toBytes("""" + splitRowNum);

    assertTrue(""not able to find a splittable region"", regions != null);
    assertTrue(""not able to find a splittable region"", regions.length == 1);
    ProcedureTestingUtility.waitNoProcedureRunning(procExec);
    ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);

    // Split region of the table
    long procId = procExec.submitProcedure(
      new SplitTableRegionProcedure(procExec.getEnvironment(), regions[0], splitKey));

    // Execute until step 7 of split procedure
    // NOTE: the 7 (number after SPLIT_TABLE_REGION_UPDATE_META step)
    MasterProcedureTestingUtility.testRecoveryAndDoubleExecution(procExec, procId, 7, false);

    // Unset Toggle Kill and make ProcExec work correctly
    ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, false);
    MasterProcedureTestingUtility.restartMasterProcedureExecutor(procExec);
    ProcedureTestingUtility.waitProcedure(procExec, procId);

    // Even split failed after step 4, it should still works fine
    verify(tableName, splitRowNum);
  }",1
"@Test
  public void testClusterRegionLocations() {
    // tests whether region locations are handled correctly in Cluster
    List<ServerName> servers = getListOfServerNames(randomServers(10, 10));
    List<RegionInfo> regions = randomRegions(101);
    Map<ServerName, List<RegionInfo>> clusterState = new HashMap<>();

    assignRegions(regions, servers, clusterState);

    // mock block locality for some regions
    RegionHDFSBlockLocationFinder locationFinder = mock(RegionHDFSBlockLocationFinder.class);
    // block locality: region:0 => {server:0}",1
"@Test
  public void testRandomAssignment() throws Exception {
    for (int i = 1; i != 5; ++i) {
      LOG.info(""run testRandomAssignment() with idle servers:"" + i);
      testRandomAssignment(i);
    }",1
"@Test
  public void testRegionAvailability() throws Exception {
    // Create a cluster with a few servers, assign them to specific racks
    // then assign some regions. The tests should check whether moving a
    // replica from one node to a specific other node or rack lowers the
    // availability of the region or not

    List<RegionInfo> list0 = new ArrayList<>();
    List<RegionInfo> list1 = new ArrayList<>();
    List<RegionInfo> list2 = new ArrayList<>();
    // create a region (region1)
    RegionInfo hri1 = RegionInfoBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
      .setStartKey(Bytes.toBytes(""key1"")).setEndKey(Bytes.toBytes(""key2"")).setSplit(false)
      .setRegionId(100).build();
    // create a replica of the region (replica_of_region1)
    RegionInfo hri2 = RegionReplicaUtil.getRegionInfoForReplica(hri1, 1);
    // create a second region (region2)
    RegionInfo hri3 = RegionInfoBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
      .setStartKey(Bytes.toBytes(""key2"")).setEndKey(Bytes.toBytes(""key3"")).setSplit(false)
      .setRegionId(101).build();
    list0.add(hri1); // only region1
    list1.add(hri2); // only replica_of_region1
    list2.add(hri3); // only region2
    Map<ServerName, List<RegionInfo>> clusterState = new LinkedHashMap<>();
    clusterState.put(servers[0], list0); // servers[0] hosts region1
    clusterState.put(servers[1], list1); // servers[1] hosts replica_of_region1
    clusterState.put(servers[2], list2); // servers[2] hosts region2
    // create a cluster with the above clusterState. The way in which the
    // cluster is created (constructor code) would make sure the indices of
    // the servers are in the order in which it is inserted in the clusterState
    // map (linkedhashmap is important). A similar thing applies to the region lists
    BalancerClusterState cluster = new BalancerClusterState(clusterState, null, null, rackManager);
    // check whether a move of region1 from servers[0] to servers[1] would lower
    // the availability of region1
    assertTrue(cluster.wouldLowerAvailability(hri1, servers[1]));
    // check whether a move of region1 from servers[0] to servers[2] would lower
    // the availability of region1
    assertTrue(!cluster.wouldLowerAvailability(hri1, servers[2]));
    // check whether a move of replica_of_region1 from servers[0] to servers[2] would lower
    // the availability of replica_of_region1
    assertTrue(!cluster.wouldLowerAvailability(hri2, servers[2]));
    // check whether a move of region2 from servers[0] to servers[1] would lower
    // the availability of region2
    assertTrue(!cluster.wouldLowerAvailability(hri3, servers[1]));

    // now lets have servers[1] host replica_of_region2
    list1.add(RegionReplicaUtil.getRegionInfoForReplica(hri3, 1));
    // create a new clusterState with the above change
    cluster = new BalancerClusterState(clusterState, null, null, rackManager);
    // now check whether a move of a replica from servers[0] to servers[1] would lower
    // the availability of region2
    assertTrue(cluster.wouldLowerAvailability(hri3, servers[1]));

    // start over again
    clusterState.clear();
    clusterState.put(servers[0], list0); // servers[0], rack1 hosts region1
    clusterState.put(servers[5], list1); // servers[5], rack2 hosts replica_of_region1 and
                                         // replica_of_region2
    clusterState.put(servers[6], list2); // servers[6], rack2 hosts region2
    clusterState.put(servers[10], new ArrayList<>()); // servers[10], rack3 hosts no region
    // create a cluster with the above clusterState
    cluster = new BalancerClusterState(clusterState, null, null, rackManager);
    // check whether a move of region1 from servers[0],rack1 to servers[6],rack2 would
    // lower the availability

    assertTrue(cluster.wouldLowerAvailability(hri1, servers[0]));

    // now create a cluster without the rack manager
    cluster = new BalancerClusterState(clusterState, null, null, null);
    // now repeat check whether a move of region1 from servers[0] to servers[6] would
    // lower the availability
    assertTrue(!cluster.wouldLowerAvailability(hri1, servers[6]));
  }",1
"@Test
  public void testRegionAvailabilityWithRegionMoves() throws Exception {
    List<RegionInfo> list0 = new ArrayList<>();
    List<RegionInfo> list1 = new ArrayList<>();
    List<RegionInfo> list2 = new ArrayList<>();
    // create a region (region1)
    RegionInfo hri1 = RegionInfoBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
      .setStartKey(Bytes.toBytes(""key1"")).setEndKey(Bytes.toBytes(""key2"")).setSplit(false)
      .setRegionId(100).build();
    // create a replica of the region (replica_of_region1)
    RegionInfo hri2 = RegionReplicaUtil.getRegionInfoForReplica(hri1, 1);
    // create a second region (region2)
    RegionInfo hri3 = RegionInfoBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
      .setStartKey(Bytes.toBytes(""key2"")).setEndKey(Bytes.toBytes(""key3"")).setSplit(false)
      .setRegionId(101).build();
    list0.add(hri1); // only region1
    list1.add(hri2); // only replica_of_region1
    list2.add(hri3); // only region2
    Map<ServerName, List<RegionInfo>> clusterState = new LinkedHashMap<>();
    clusterState.put(servers[0], list0); // servers[0] hosts region1
    clusterState.put(servers[1], list1); // servers[1] hosts replica_of_region1
    clusterState.put(servers[2], list2); // servers[2] hosts region2
    // create a cluster with the above clusterState. The way in which the
    // cluster is created (constructor code) would make sure the indices of
    // the servers are in the order in which it is inserted in the clusterState
    // map (linkedhashmap is important).
    BalancerClusterState cluster = new BalancerClusterState(clusterState, null, null, rackManager);
    // check whether moving region1 from servers[1] to servers[2] would lower availability
    assertTrue(!cluster.wouldLowerAvailability(hri1, servers[2]));

    // now move region1 from servers[0] to servers[2]
    cluster.doAction(new MoveRegionAction(0, 0, 2));
    // now repeat check whether moving region1 from servers[1] to servers[2]
    // would lower availability
    assertTrue(cluster.wouldLowerAvailability(hri1, servers[2]));

    // start over again
    clusterState.clear();
    List<RegionInfo> list3 = new ArrayList<>();
    RegionInfo hri4 = RegionReplicaUtil.getRegionInfoForReplica(hri3, 1);
    list3.add(hri4);
    clusterState.put(servers[0], list0); // servers[0], rack1 hosts region1
    clusterState.put(servers[5], list1); // servers[5], rack2 hosts replica_of_region1
    clusterState.put(servers[6], list2); // servers[6], rack2 hosts region2
    clusterState.put(servers[12], list3); // servers[12], rack3 hosts replica_of_region2
    // create a cluster with the above clusterState
    cluster = new BalancerClusterState(clusterState, null, null, rackManager);
    // check whether a move of replica_of_region2 from servers[12],rack3 to servers[0],rack1 would
    // lower the availability
    assertTrue(!cluster.wouldLowerAvailability(hri4, servers[0]));
    // now move region2 from servers[6],rack2 to servers[0],rack1
    cluster.doAction(new MoveRegionAction(2, 2, 0));
    // now repeat check if replica_of_region2 from servers[12],rack3 to servers[0],rack1 would
    // lower the availability
    assertTrue(cluster.wouldLowerAvailability(hri3, servers[0]));
  }",1
"@Test
  public void testBulkAssignment() throws Exception {
    List<RegionInfo> regions = randomRegions(25);
    Map<ServerName, List<RegionInfo>> assignments =
      loadBalancer.roundRobinAssignment(regions, servers);
    // test empty region/servers scenario
    // this should not throw an NPE
    loadBalancer.roundRobinAssignment(regions, Collections.emptyList());
    // test regular scenario
    assertTrue(assignments.keySet().size() == servers.size());
    for (ServerName sn : assignments.keySet()) {
      List<RegionInfo> regionAssigned = assignments.get(sn);
      for (RegionInfo region : regionAssigned) {
        TableName tableName = region.getTable();
        String groupName =
          tableDescs.get(tableName).getRegionServerGroup().orElse(RSGroupInfo.DEFAULT_GROUP);
        assertTrue(StringUtils.isNotEmpty(groupName));
        RSGroupInfo gInfo = getMockedGroupInfoManager().getRSGroup(groupName);
        assertTrue(""Region is not correctly assigned to group servers."",
          gInfo.containsServer(sn.getAddress()));
      }",1
"@Test
  public void testRetainAssignment() throws Exception {
    // Test simple case where all same servers are there
    Map<ServerName, List<RegionInfo>> currentAssignments = mockClusterServers();
    Map<RegionInfo, ServerName> inputForTest = new HashMap<>();
    for (ServerName sn : currentAssignments.keySet()) {
      for (RegionInfo region : currentAssignments.get(sn)) {
        inputForTest.put(region, sn);
      }",1
"@Test
  public void testCPRequestCost() {
    // in order to pass needsBalance judgement
    conf.setFloat(""hbase.master.balancer.stochastic.cpRequestCost"", 10000f);
    loadBalancer.onConfigurationChange(conf);
    // mock cluster State
    Map<ServerName, List<RegionInfo>> clusterState = new HashMap<ServerName, List<RegionInfo>>();
    ServerName serverA = randomServer(3).getServerName();
    ServerName serverB = randomServer(3).getServerName();
    ServerName serverC = randomServer(3).getServerName();
    List<RegionInfo> regionsOnServerA = randomRegions(3);
    List<RegionInfo> regionsOnServerB = randomRegions(3);
    List<RegionInfo> regionsOnServerC = randomRegions(3);
    clusterState.put(serverA, regionsOnServerA);
    clusterState.put(serverB, regionsOnServerB);
    clusterState.put(serverC, regionsOnServerC);
    // mock ClusterMetrics
    Map<ServerName, ServerMetrics> serverMetricsMap = new TreeMap<>();
    serverMetricsMap.put(serverA, mockServerMetricsWithCpRequests(regionsOnServerA, 0));
    serverMetricsMap.put(serverB, mockServerMetricsWithCpRequests(regionsOnServerB, 0));
    serverMetricsMap.put(serverC, mockServerMetricsWithCpRequests(regionsOnServerC, 0));
    ClusterMetrics clusterStatus = mock(ClusterMetrics.class);
    when(clusterStatus.getLiveServerMetrics()).thenReturn(serverMetricsMap);
    loadBalancer.updateClusterMetrics(clusterStatus);

    // CPRequestCostFunction are Rate based, So doing setClusterMetrics again
    // this time, regions on serverA with more cpRequestCount load
    // serverA : 1000,1000,1000
    // serverB : 0,0,0
    // serverC : 0,0,0
    // so should move two regions from serverA to serverB & serverC
    serverMetricsMap = new TreeMap<>();
    serverMetricsMap.put(serverA, mockServerMetricsWithCpRequests(regionsOnServerA, 1000));
    serverMetricsMap.put(serverB, mockServerMetricsWithCpRequests(regionsOnServerB, 0));
    serverMetricsMap.put(serverC, mockServerMetricsWithCpRequests(regionsOnServerC, 0));
    clusterStatus = mock(ClusterMetrics.class);
    when(clusterStatus.getLiveServerMetrics()).thenReturn(serverMetricsMap);
    loadBalancer.updateClusterMetrics(clusterStatus);

    List<RegionPlan> plans =
      loadBalancer.balanceTable(HConstants.ENSEMBLE_TABLE_NAME, clusterState);
    Set<RegionInfo> regionsMoveFromServerA = new HashSet<>();
    Set<ServerName> targetServers = new HashSet<>();
    for (RegionPlan plan : plans) {
      if (plan.getSource().equals(serverA)) {
        regionsMoveFromServerA.add(plan.getRegionInfo());
        targetServers.add(plan.getDestination());
      }",1
"@Test
  public void testMinimumNumberOfThreads() throws Exception {
    Configuration conf = UTIL.getConfiguration();
    String confKey = ""hbase.test.cleaner.delegates"";
    conf.set(confKey, AlwaysDelete.class.getName());
    conf.set(CleanerChore.CHORE_POOL_SIZE, ""2"");
    int numProcs = Runtime.getRuntime().availableProcessors();
    // Sanity
    assertEquals(numProcs, CleanerChore.calculatePoolSize(Integer.toString(numProcs)));
    // The implementation does not allow us to set more threads than we have processors
    assertEquals(numProcs, CleanerChore.calculatePoolSize(Integer.toString(numProcs + 2)));
    // Force us into the branch that is multiplying 0.0 against the number of processors
    assertEquals(1, CleanerChore.calculatePoolSize(""0.0""));
  }",1
"@Test
  public void testStoppedCleanerDoesNotDeleteFiles() throws Exception {
    Stoppable stop = new StoppableImplementation();
    Configuration conf = UTIL.getConfiguration();
    Path testDir = UTIL.getDataTestDir();
    FileSystem fs = UTIL.getTestFileSystem();
    String confKey = ""hbase.test.cleaner.delegates"";
    conf.set(confKey, AlwaysDelete.class.getName());

    AllValidPaths chore =
      new AllValidPaths(""test-file-cleaner"", stop, conf, fs, testDir, confKey, POOL);

    // also create a file in the top level directory
    Path topFile = new Path(testDir, ""topFile"");
    fs.create(topFile).close();
    assertTrue(""Test file didn't get created."", fs.exists(topFile));

    // stop the chore
    stop.stop(""testing stop"");

    // run the chore
    chore.chore();

    // test that the file still exists
    assertTrue(""File got deleted while chore was stopped"", fs.exists(topFile));
  }",1
"@Test
  public void testOnConfigurationChange() throws Exception {
    // constants
    final int ORIGINAL_THROTTLE_POINT = 512 * 1024;
    final int ORIGINAL_QUEUE_INIT_SIZE = 512;
    final int UPDATE_THROTTLE_POINT = 1024;// small enough to change large/small check
    final int UPDATE_QUEUE_INIT_SIZE = 1024;
    final int LARGE_FILE_NUM = 5;
    final int SMALL_FILE_NUM = 20;
    final int LARGE_THREAD_NUM = 2;
    final int SMALL_THREAD_NUM = 4;
    final long THREAD_TIMEOUT_MSEC = 30 * 1000L;
    final long THREAD_CHECK_INTERVAL_MSEC = 500L;

    Configuration conf = UTIL.getConfiguration();
    // no cleaner policies = delete all files
    conf.setStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS, """");
    conf.setInt(HFileCleaner.HFILE_DELETE_THROTTLE_THRESHOLD, ORIGINAL_THROTTLE_POINT);
    conf.setInt(HFileCleaner.LARGE_HFILE_QUEUE_INIT_SIZE, ORIGINAL_QUEUE_INIT_SIZE);
    conf.setInt(HFileCleaner.SMALL_HFILE_QUEUE_INIT_SIZE, ORIGINAL_QUEUE_INIT_SIZE);
    Server server = new DummyServer();
    Path archivedHfileDir =
      new Path(UTIL.getDataTestDirOnTestFS(), HConstants.HFILE_ARCHIVE_DIRECTORY);

    // setup the cleaner
    FileSystem fs = UTIL.getDFSCluster().getFileSystem();
    final HFileCleaner cleaner = new HFileCleaner(1000, server, conf, fs, archivedHfileDir, POOL);
    Assert.assertEquals(ORIGINAL_THROTTLE_POINT, cleaner.getThrottlePoint());
    Assert.assertEquals(ORIGINAL_QUEUE_INIT_SIZE, cleaner.getLargeQueueInitSize());
    Assert.assertEquals(ORIGINAL_QUEUE_INIT_SIZE, cleaner.getSmallQueueInitSize());
    Assert.assertEquals(HFileCleaner.DEFAULT_HFILE_DELETE_THREAD_TIMEOUT_MSEC,
      cleaner.getCleanerThreadTimeoutMsec());
    Assert.assertEquals(HFileCleaner.DEFAULT_HFILE_DELETE_THREAD_CHECK_INTERVAL_MSEC,
      cleaner.getCleanerThreadCheckIntervalMsec());

    // clean up archive directory and create files for testing
    fs.delete(archivedHfileDir, true);
    fs.mkdirs(archivedHfileDir);
    createFilesForTesting(LARGE_FILE_NUM, SMALL_FILE_NUM, fs, archivedHfileDir);

    // call cleaner, run as daemon to test the interrupt-at-middle case
    Thread t = new Thread() {
      @Override
      public void run() {
        cleaner.chore();
      }",1
"@Test
  public void testRemovesEmptyDirectories() throws Exception {
    Configuration conf = UTIL.getConfiguration();
    // no cleaner policies = delete all files
    conf.setStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS, """");
    Server server = new DummyServer();
    Path archivedHfileDir =
      new Path(UTIL.getDataTestDirOnTestFS(), HConstants.HFILE_ARCHIVE_DIRECTORY);

    // setup the cleaner
    FileSystem fs = UTIL.getDFSCluster().getFileSystem();
    HFileCleaner cleaner = new HFileCleaner(1000, server, conf, fs, archivedHfileDir, POOL);

    // make all the directories for archiving files
    Path table = new Path(archivedHfileDir, ""table"");
    Path region = new Path(table, ""regionsomthing"");
    Path family = new Path(region, ""fam"");
    Path file = new Path(family, ""file12345"");
    fs.mkdirs(family);
    if (!fs.exists(family)) throw new RuntimeException(""Couldn't create test family:"" + family);
    fs.create(file).close();
    if (!fs.exists(file)) throw new RuntimeException(""Test file didn't get created:"" + file);

    // run the chore to cleanup the files (and the directories above it)
    cleaner.chore();

    // make sure all the parent directories get removed
    assertFalse(""family directory not removed for empty directory"", fs.exists(family));
    assertFalse(""region directory not removed for empty directory"", fs.exists(region));
    assertFalse(""table directory not removed for empty directory"", fs.exists(table));
    assertTrue(""archive directory"", fs.exists(archivedHfileDir));
  }",1
"@Test
  public void testThreadCleanup() throws Exception {
    Configuration conf = UTIL.getConfiguration();
    conf.setStrings(HFileCleaner.MASTER_HFILE_CLEANER_PLUGINS, """");
    Server server = new DummyServer();
    Path archivedHfileDir =
      new Path(UTIL.getDataTestDirOnTestFS(), HConstants.HFILE_ARCHIVE_DIRECTORY);

    // setup the cleaner
    FileSystem fs = UTIL.getDFSCluster().getFileSystem();
    HFileCleaner cleaner = new HFileCleaner(1000, server, conf, fs, archivedHfileDir, POOL);
    // clean up archive directory
    fs.delete(archivedHfileDir, true);
    fs.mkdirs(archivedHfileDir);
    // create some file to delete
    fs.createNewFile(new Path(archivedHfileDir, ""dfd-dfd""));
    // launch the chore
    cleaner.chore();
    // call cleanup
    cleaner.cleanup();
    // wait awhile for thread to die
    Thread.sleep(100);
    for (Thread thread : cleaner.getCleanerThreads()) {
      Assert.assertFalse(thread.isAlive());
    }",1
"@Test
  public void testTTLCleaner() throws IOException {
    FileSystem fs = UTIL.getDFSCluster().getFileSystem();
    Path root = UTIL.getDataTestDirOnTestFS();
    Path file = new Path(root, ""file"");
    fs.createNewFile(file);
    long createTime = EnvironmentEdgeManager.currentTime();
    assertTrue(""Test file not created!"", fs.exists(file));
    TimeToLiveHFileCleaner cleaner = new TimeToLiveHFileCleaner();
    // update the time info for the file, so the cleaner removes it
    fs.setTimes(file, createTime - 100, -1);
    Configuration conf = UTIL.getConfiguration();
    conf.setLong(TimeToLiveHFileCleaner.TTL_CONF_KEY, 100);
    cleaner.setConf(conf);
    assertTrue(""File not set deletable - check mod time:"" + getFileStats(file, fs)
      + "" with create time:"" + createTime, cleaner.isFileDeletable(fs.getFileStatus(file)));
  }",1
"@Test
  public void testMasterLockAcquireTimeout() throws Exception {
    LockManager.MasterLock lock =
      masterServices.getLockManager().createMasterLock(tableName, LockType.EXCLUSIVE, ""desc"");
    LockManager.MasterLock lock2 =
      masterServices.getLockManager().createMasterLock(tableName, LockType.EXCLUSIVE, ""desc"");
    assertTrue(lock.tryAcquire(2000));
    assertFalse(lock2.tryAcquire(LOCAL_LOCKS_TIMEOUT / 2)); // wait less than other lock's timeout
    assertEquals(null, lock2.getProc());
    lock.release();
    assertTrue(lock2.tryAcquire(2000));
    assertTrue(lock2.getProc().isLocked());
    lock2.release();
  }",1
"@Test
  public void testMasterLockAcquireTimeoutRegionVsTableExclusive() throws Exception {
    LockManager.MasterLock lock =
      masterServices.getLockManager().createMasterLock(tableRegions, ""desc"");
    LockManager.MasterLock lock2 =
      masterServices.getLockManager().createMasterLock(tableName, LockType.EXCLUSIVE, ""desc"");
    assertTrue(lock.tryAcquire(2000));
    assertFalse(lock2.tryAcquire(LOCAL_LOCKS_TIMEOUT / 2)); // wait less than other lock's timeout
    assertEquals(null, lock2.getProc());
    lock.release();
    assertTrue(lock2.tryAcquire(2000));
    assertTrue(lock2.getProc().isLocked());
    lock2.release();
  }",1
"@Test
  public void testMergeOfSmallRegions() {
    final TableName tableName = name.getTableName();
    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 5);
    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 15, 5, 5, 15, 16);
    setupMocksForNormalizer(regionSizes, regionInfos);

    assertThat(normalizer.computePlansForTable(tableDescriptor),
      contains(new MergeNormalizationPlan.Builder().addTarget(regionInfos.get(1), 5)
        .addTarget(regionInfos.get(2), 5).build()));
  }",1
"@Test
  public void testSplitOfLargeRegion() {
    final TableName tableName = name.getTableName();
    final List<RegionInfo> regionInfos = createRegionInfos(tableName, 4);
    final Map<byte[], Integer> regionSizes = createRegionSizesMap(regionInfos, 8, 6, 10, 30);
    setupMocksForNormalizer(regionSizes, regionInfos);

    assertThat(normalizer.computePlansForTable(tableDescriptor),
      contains(new SplitNormalizationPlan(regionInfos.get(3), 30)));
  }",1
"@Test
  public void testCreateNamespaceWithInvalidRegionCount() throws Exception {
    final NamespaceDescriptor nsd =
      NamespaceDescriptor.create(""testCreateNamespaceWithInvalidRegionCount"").build();
    final String nsKey = ""hbase.namespace.quota.maxregions"";
    final String nsValue = ""-1"";
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    nsd.setConfiguration(nsKey, nsValue);

    long procId =
      procExec.submitProcedure(new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));
    // Wait the completion
    ProcedureTestingUtility.waitProcedure(procExec, procId);
    Procedure<?> result = procExec.getResult(procId);
    assertTrue(result.isFailed());
    LOG.debug(""Create namespace failed with exception: "" + result.getException());
    assertTrue(ProcedureTestingUtility.getExceptionCause(result) instanceof ConstraintException);
  }",1
"@Test
  public void testCreateSameNamespaceTwice() throws Exception {
    final NamespaceDescriptor nsd =
      NamespaceDescriptor.create(""testCreateSameNamespaceTwice"").build();
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    long procId1 =
      procExec.submitProcedure(new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));
    // Wait the completion
    ProcedureTestingUtility.waitProcedure(procExec, procId1);
    ProcedureTestingUtility.assertProcNotFailed(procExec, procId1);

    // Create the namespace that exists
    long procId2 =
      procExec.submitProcedure(new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));
    // Wait the completion
    ProcedureTestingUtility.waitProcedure(procExec, procId2);

    // Second create should fail with NamespaceExistException
    Procedure<?> result = procExec.getResult(procId2);
    assertTrue(result.isFailed());
    LOG.debug(""Create namespace failed with exception: "" + result.getException());
    assertTrue(
      ProcedureTestingUtility.getExceptionCause(result) instanceof NamespaceExistException);
  }",1
"@Test
  public void testCreateSystemNamespace() throws Exception {
    final NamespaceDescriptor nsd =
      UTIL.getAdmin().getNamespaceDescriptor(NamespaceDescriptor.SYSTEM_NAMESPACE.getName());
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    long procId =
      procExec.submitProcedure(new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));
    // Wait the completion
    ProcedureTestingUtility.waitProcedure(procExec, procId);
    Procedure<?> result = procExec.getResult(procId);
    assertTrue(result.isFailed());
    LOG.debug(""Create namespace failed with exception: "" + result.getException());
    assertTrue(
      ProcedureTestingUtility.getExceptionCause(result) instanceof NamespaceExistException);
  }",1
"@Test
  public void testRecoveryAndDoubleExecution() throws Exception {
    final NamespaceDescriptor nsd =
      NamespaceDescriptor.create(""testRecoveryAndDoubleExecution"").build();
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    ProcedureTestingUtility.waitNoProcedureRunning(procExec);
    ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);

    // Start the CreateNamespace procedure && kill the executor
    long procId =
      procExec.submitProcedure(new CreateNamespaceProcedure(procExec.getEnvironment(), nsd));

    // Restart the executor and execute the step twice
    MasterProcedureTestingUtility.testRecoveryAndDoubleExecution(procExec, procId);

    // Validate the creation of namespace
    ProcedureTestingUtility.assertProcNotFailed(procExec, procId);
    validateNamespaceCreated(nsd);
  }",1
"@Test
  public void testDisableTable() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    MasterProcedureTestingUtility.createTable(procExec, tableName, null, ""f1"", ""f2"");

    // Disable the table
    long procId = procExec
      .submitProcedure(new DisableTableProcedure(procExec.getEnvironment(), tableName, false));
    // Wait the completion
    ProcedureTestingUtility.waitProcedure(procExec, procId);
    ProcedureTestingUtility.assertProcNotFailed(procExec, procId);
    MasterProcedureTestingUtility.validateTableIsDisabled(getMaster(), tableName);
  }",1
"@Test
  public void testCreateDeleteTableOperationsWithReadLock() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final int nitems = 2;

    final TestTableProcedure dummyProc =
      new TestTableProcedure(100, tableName, TableProcedureInterface.TableOperationType.DELETE);

    for (int i = 1; i <= nitems; ++i) {
      queue.addBack(
        new TestTableProcedure(i, tableName, TableProcedureInterface.TableOperationType.READ));
    }",1
"@Test
  public void testVerifyNamespaceRwLocks() throws Exception {
    String nsName1 = ""ns1"";
    String nsName2 = ""ns2"";
    TableName tableName1 = TableName.valueOf(nsName1, name.getMethodName());
    TableName tableName2 = TableName.valueOf(nsName2, name.getMethodName());
    queue.addBack(
      new TestNamespaceProcedure(1, nsName1, TableProcedureInterface.TableOperationType.EDIT));
    queue.addBack(
      new TestTableProcedure(2, tableName1, TableProcedureInterface.TableOperationType.EDIT));
    queue.addBack(
      new TestTableProcedure(3, tableName2, TableProcedureInterface.TableOperationType.EDIT));
    queue.addBack(
      new TestNamespaceProcedure(4, nsName2, TableProcedureInterface.TableOperationType.EDIT));

    // Fetch the 1st item and take the write lock
    Procedure<?> procNs1 = queue.poll();
    assertEquals(1, procNs1.getProcId());
    assertFalse(queue.waitNamespaceExclusiveLock(procNs1, nsName1));

    // namespace table has higher priority so we still return procedure for it
    Procedure<?> procNs2 = queue.poll();
    assertEquals(4, procNs2.getProcId());
    assertFalse(queue.waitNamespaceExclusiveLock(procNs2, nsName2));
    queue.wakeNamespaceExclusiveLock(procNs2, nsName2);

    // add procNs2 back in the queue
    queue.yield(procNs2);

    // again
    procNs2 = queue.poll();
    assertEquals(4, procNs2.getProcId());
    assertFalse(queue.waitNamespaceExclusiveLock(procNs2, nsName2));

    // ns1 and ns2 are both locked so we get nothing
    assertNull(queue.poll());

    // release the ns1 lock
    queue.wakeNamespaceExclusiveLock(procNs1, nsName1);

    // we are now able to execute table of ns1
    long procId = queue.poll().getProcId();
    assertEquals(2, procId);

    // release ns2
    queue.wakeNamespaceExclusiveLock(procNs2, nsName2);

    // we are now able to execute table of ns2
    procId = queue.poll().getProcId();
    assertEquals(3, procId);
  }",1
"@Test
  public void testVerifyRegionLocks() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final RegionInfo regionA = RegionInfoBuilder.newBuilder(tableName)
      .setStartKey(Bytes.toBytes(""a"")).setEndKey(Bytes.toBytes(""b"")).build();
    final RegionInfo regionB = RegionInfoBuilder.newBuilder(tableName)
      .setStartKey(Bytes.toBytes(""b"")).setEndKey(Bytes.toBytes(""c"")).build();
    final RegionInfo regionC = RegionInfoBuilder.newBuilder(tableName)
      .setStartKey(Bytes.toBytes(""c"")).setEndKey(Bytes.toBytes(""d"")).build();

    queue.addBack(
      new TestTableProcedure(1, tableName, TableProcedureInterface.TableOperationType.EDIT));
    queue.addBack(new TestRegionProcedure(2, tableName,
      TableProcedureInterface.TableOperationType.REGION_MERGE, regionA, regionB));
    queue.addBack(new TestRegionProcedure(3, tableName,
      TableProcedureInterface.TableOperationType.REGION_SPLIT, regionA));
    queue.addBack(new TestRegionProcedure(4, tableName,
      TableProcedureInterface.TableOperationType.REGION_SPLIT, regionB));
    queue.addBack(new TestRegionProcedure(5, tableName,
      TableProcedureInterface.TableOperationType.REGION_UNASSIGN, regionC));

    // Fetch the 1st item and take the write lock
    Procedure<?> proc = queue.poll();
    assertEquals(1, proc.getProcId());
    assertEquals(false, queue.waitTableExclusiveLock(proc, tableName));

    // everything is locked by the table operation
    assertEquals(null, queue.poll(0));

    // release the table lock
    queue.wakeTableExclusiveLock(proc, tableName);

    // Fetch the 2nd item and the the lock on regionA and regionB
    Procedure<?> mergeProc = queue.poll();
    assertEquals(2, mergeProc.getProcId());
    assertEquals(false, queue.waitRegions(mergeProc, tableName, regionA, regionB));

    // Fetch the 3rd item and the try to lock region A which will fail
    // because already locked. this procedure will go in waiting.
    // (this stuff will be explicit until we get rid of the zk-lock)
    Procedure<?> procA = queue.poll();
    assertEquals(3, procA.getProcId());
    assertEquals(true, queue.waitRegions(procA, tableName, regionA));

    // Fetch the 4th item, same story as the 3rd
    Procedure<?> procB = queue.poll();
    assertEquals(4, procB.getProcId());
    assertEquals(true, queue.waitRegions(procB, tableName, regionB));

    // Fetch the 5th item, since it is a non-locked region we are able to execute it
    Procedure<?> procC = queue.poll();
    assertEquals(5, procC.getProcId());
    assertEquals(false, queue.waitRegions(procC, tableName, regionC));

    // 3rd and 4th are in the region suspended queue
    assertEquals(null, queue.poll(0));

    // Release region A-B from merge operation (procId=2)
    queue.wakeRegions(mergeProc, tableName, regionA, regionB);

    // Fetch the 3rd item, now the lock on the region is available
    procA = queue.poll();
    assertEquals(3, procA.getProcId());
    assertEquals(false, queue.waitRegions(procA, tableName, regionA));

    // Fetch the 4th item, now the lock on the region is available
    procB = queue.poll();
    assertEquals(4, procB.getProcId());
    assertEquals(false, queue.waitRegions(procB, tableName, regionB));

    // release the locks on the regions
    queue.wakeRegions(procA, tableName, regionA);
    queue.wakeRegions(procB, tableName, regionB);
    queue.wakeRegions(procC, tableName, regionC);
  }",1
"@Test
  public void testVerifyRwLocks() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    queue.addBack(
      new TestTableProcedure(1, tableName, TableProcedureInterface.TableOperationType.EDIT));
    queue.addBack(
      new TestTableProcedure(2, tableName, TableProcedureInterface.TableOperationType.READ));
    queue.addBack(
      new TestTableProcedure(3, tableName, TableProcedureInterface.TableOperationType.EDIT));

    // Fetch the 1st item and take the write lock
    Procedure<?> proc = queue.poll();
    assertEquals(1, proc.getProcId());
    assertEquals(false, queue.waitTableExclusiveLock(proc, tableName));

    // Fetch the 2nd item and verify that the lock can't be acquired
    assertEquals(null, queue.poll(0));

    // Release the write lock and acquire the read lock
    releaseTableExclusiveLockAndComplete(proc, tableName);

    // Fetch the 2nd item and take the read lock
    Procedure<?> rdProc = queue.poll();
    assertEquals(2, rdProc.getProcId());
    assertEquals(false, queue.waitTableSharedLock(rdProc, tableName));

    // Fetch the 3rd item and verify that the lock can't be acquired
    assertEquals(null, queue.poll(0));

    // release the rdlock of item 2 and take the wrlock for the 3d item
    queue.wakeTableSharedLock(rdProc, tableName);

    queue.addBack(
      new TestTableProcedure(4, tableName, TableProcedureInterface.TableOperationType.READ));
    queue.addBack(
      new TestTableProcedure(5, tableName, TableProcedureInterface.TableOperationType.READ));

    // Fetch the 3rd item and take the write lock
    Procedure<?> wrProc = queue.poll();
    assertEquals(false, queue.waitTableExclusiveLock(wrProc, tableName));

    // Fetch 4th item and verify that the lock can't be acquired
    assertEquals(null, queue.poll(0));

    // Release the write lock and acquire the read lock
    releaseTableExclusiveLockAndComplete(wrProc, tableName);

    // Fetch the 4th item and take the read lock
    rdProc = queue.poll();
    assertEquals(4, rdProc.getProcId());
    assertEquals(false, queue.waitTableSharedLock(rdProc, tableName));

    // Fetch the 4th item and take the read lock
    Procedure<?> rdProc2 = queue.poll();
    assertEquals(5, rdProc2.getProcId());
    assertEquals(false, queue.waitTableSharedLock(rdProc2, tableName));

    // Release 4th and 5th read-lock
    queue.wakeTableSharedLock(rdProc, tableName);
    queue.wakeTableSharedLock(rdProc2, tableName);

    // remove table queue
    assertEquals(0, queue.size());
    assertTrue(""queue should be deleted"", queue.markTableAsDeleted(tableName, wrProc));
  }",1
"@Test
  public void testVerifySubProcRegionLocks() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final RegionInfo regionA = RegionInfoBuilder.newBuilder(tableName)
      .setStartKey(Bytes.toBytes(""a"")).setEndKey(Bytes.toBytes(""b"")).build();
    final RegionInfo regionB = RegionInfoBuilder.newBuilder(tableName)
      .setStartKey(Bytes.toBytes(""b"")).setEndKey(Bytes.toBytes(""c"")).build();
    final RegionInfo regionC = RegionInfoBuilder.newBuilder(tableName)
      .setStartKey(Bytes.toBytes(""c"")).setEndKey(Bytes.toBytes(""d"")).build();

    queue.addBack(
      new TestTableProcedure(1, tableName, TableProcedureInterface.TableOperationType.ENABLE));

    // Fetch the 1st item from the queue, ""the root procedure"" and take the table lock
    Procedure<?> rootProc = queue.poll();
    assertEquals(1, rootProc.getProcId());
    assertEquals(false, queue.waitTableExclusiveLock(rootProc, tableName));
    assertEquals(null, queue.poll(0));

    // Execute the 1st step of the root-proc.
    // we should get 3 sub-proc back, one for each region.
    // (this step is done by the executor/rootProc, we are simulating it)
    Procedure<?>[] subProcs = new Procedure[] {
      new TestRegionProcedure(1, 2, tableName,
        TableProcedureInterface.TableOperationType.REGION_EDIT, regionA),
      new TestRegionProcedure(1, 3, tableName,
        TableProcedureInterface.TableOperationType.REGION_EDIT, regionB),
      new TestRegionProcedure(1, 4, tableName,
        TableProcedureInterface.TableOperationType.REGION_EDIT, regionC), }",1
"@Test
  public void testYieldWithSharedLockHeld() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());

    queue.addBack(
      new TestTableProcedure(1, tableName, TableProcedureInterface.TableOperationType.READ));
    queue.addBack(
      new TestTableProcedure(2, tableName, TableProcedureInterface.TableOperationType.READ));
    queue.addBack(
      new TestTableProcedure(3, tableName, TableProcedureInterface.TableOperationType.EDIT));

    // fetch and acquire the first shared-lock
    Procedure<?> proc1 = queue.poll();
    assertEquals(1, proc1.getProcId());
    assertEquals(false, queue.waitTableSharedLock(proc1, tableName));

    // fetch and acquire the second shared-lock
    Procedure<?> proc2 = queue.poll();
    assertEquals(2, proc2.getProcId());
    assertEquals(false, queue.waitTableSharedLock(proc2, tableName));

    // nothing available, until xlock release
    assertEquals(null, queue.poll(0));

    // put the procs back in the queue
    queue.yield(proc1);
    queue.yield(proc2);

    // fetch from the queue, it should fetch the ones with just added back
    proc1 = queue.poll();
    assertEquals(1, proc1.getProcId());
    proc2 = queue.poll();
    assertEquals(2, proc2.getProcId());

    // release the xlock
    queue.wakeTableSharedLock(proc1, tableName);
    queue.wakeTableSharedLock(proc2, tableName);

    Procedure<?> proc3 = queue.poll();
    assertEquals(3, proc3.getProcId());
  }",1
"@Test
  public void testModifyNamespaceWithInvalidTableCount() throws Exception {
    final NamespaceDescriptor nsd =
      NamespaceDescriptor.create(""testModifyNamespaceWithInvalidTableCount"").build();
    final String nsKey = ""hbase.namespace.quota.maxtables"";
    final String nsValue = ""-1"";
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    createNamespaceForTesting(nsd);

    // Modify
    nsd.setConfiguration(nsKey, nsValue);

    long procId =
      procExec.submitProcedure(new ModifyNamespaceProcedure(procExec.getEnvironment(), nsd));
    // Wait the completion
    ProcedureTestingUtility.waitProcedure(procExec, procId);
    Procedure<?> result = procExec.getResult(procId);
    assertTrue(result.isFailed());
    LOG.debug(""Modify namespace failed with exception: "" + result.getException());
    assertTrue(ProcedureTestingUtility.getExceptionCause(result) instanceof ConstraintException);
  }",1
"@Test
  public void testRecoveryAndDoubleExecutionOffline() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final String cf2 = ""cf2"";
    final String cf3 = ""cf3"";
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    // create the table
    RegionInfo[] regions =
      MasterProcedureTestingUtility.createTable(procExec, tableName, null, ""cf1"", cf3);
    UTIL.getAdmin().disableTable(tableName);

    ProcedureTestingUtility.waitNoProcedureRunning(procExec);
    ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);

    // Modify multiple properties of the table.
    TableDescriptor oldDescriptor = UTIL.getAdmin().getDescriptor(tableName);
    TableDescriptor newDescriptor = TableDescriptorBuilder.newBuilder(oldDescriptor)
      .setCompactionEnabled(!oldDescriptor.isCompactionEnabled())
      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(cf2)).removeColumnFamily(Bytes.toBytes(cf3))
      .setRegionReplication(3).build();

    // Start the Modify procedure && kill the executor
    long procId =
      procExec.submitProcedure(new ModifyTableProcedure(procExec.getEnvironment(), newDescriptor));

    // Restart the executor and execute the step twice
    MasterProcedureTestingUtility.testRecoveryAndDoubleExecution(procExec, procId);

    // Validate descriptor
    TableDescriptor currentDescriptor = UTIL.getAdmin().getDescriptor(tableName);
    assertEquals(newDescriptor.isCompactionEnabled(), currentDescriptor.isCompactionEnabled());
    assertEquals(2, newDescriptor.getColumnFamilyNames().size());

    // cf2 should be added cf3 should be removed
    MasterProcedureTestingUtility.validateTableCreation(UTIL.getHBaseCluster().getMaster(),
      tableName, regions, false, ""cf1"", cf2);
  }",1
"@Test
  public void testRollbackAndDoubleExecutionOffline() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final String familyName = ""cf2"";
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    // create the table
    RegionInfo[] regions =
      MasterProcedureTestingUtility.createTable(procExec, tableName, null, ""cf1"");
    UTIL.getAdmin().disableTable(tableName);

    ProcedureTestingUtility.waitNoProcedureRunning(procExec);
    ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);

    TableDescriptor td = UTIL.getAdmin().getDescriptor(tableName);
    TableDescriptor newTd =
      TableDescriptorBuilder.newBuilder(td).setCompactionEnabled(!td.isCompactionEnabled())
        .setColumnFamily(ColumnFamilyDescriptorBuilder.of(familyName)).setRegionReplication(3)
        .build();

    // Start the Modify procedure && kill the executor
    long procId =
      procExec.submitProcedure(new ModifyTableProcedure(procExec.getEnvironment(), newTd));

    // Restart the executor and rollback the step twice
    int lastStep = 8; // failing before MODIFY_TABLE_UPDATE_TABLE_DESCRIPTOR
    MasterProcedureTestingUtility.testRollbackAndDoubleExecution(procExec, procId, lastStep);

    // cf2 should not be present
    MasterProcedureTestingUtility.validateTableCreation(UTIL.getHBaseCluster().getMaster(),
      tableName, regions, ""cf1"");
  }",1
"@Test
  public void testRecoveryAndDoubleExecution() throws Exception {
    final ProcedureExecutor<MasterProcedureEnv> procExec = getMasterProcedureExecutor();

    ProcedureTestingUtility.setKillAndToggleBeforeStoreUpdate(procExec, true);

    // Start the Restore snapshot procedure && kill the executor
    long procId = procExec.submitProcedure(
      new RestoreSnapshotProcedure(procExec.getEnvironment(), snapshotHTD, snapshot));

    // Restart the executor and execute the step twice
    MasterProcedureTestingUtility.testRecoveryAndDoubleExecution(procExec, procId);

    resetProcExecutorTestingKillFlag();
    validateSnapshotRestore();
  }",1
"@Test
  public void testCorruptedDataManifest() throws IOException {
    SnapshotTestingUtils.SnapshotMock snapshotMock =
      new SnapshotTestingUtils.SnapshotMock(conf, fs, rootDir);
    SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder =
      snapshotMock.createSnapshotV2(SNAPSHOT_NAME_STR, TABLE_NAME_STR);
    builder.addRegionV2();
    // consolidate to generate a data.manifest file
    builder.consolidate();
    builder.corruptDataManifest();

    long period = Long.MAX_VALUE;
    SnapshotFileCache cache = new SnapshotFileCache(conf, period, 10000000,
      ""test-snapshot-file-cache-refresh"", new SnapshotFiles());
    try {
      cache.getSnapshotsInProgress();
    }",1
"@Test
  public void testCorruptedRegionManifest() throws IOException {
    SnapshotTestingUtils.SnapshotMock snapshotMock =
      new SnapshotTestingUtils.SnapshotMock(conf, fs, rootDir);
    SnapshotTestingUtils.SnapshotMock.SnapshotBuilder builder =
      snapshotMock.createSnapshotV2(SNAPSHOT_NAME_STR, TABLE_NAME_STR);
    builder.addRegionV2();
    builder.corruptOneRegionManifest();

    long period = Long.MAX_VALUE;
    SnapshotFileCache cache = new SnapshotFileCache(conf, period, 10000000,
      ""test-snapshot-file-cache-refresh"", new SnapshotFiles());
    try {
      cache.getSnapshotsInProgress();
    }",1
"@Test
  public void testActiveMasterManagerFromZK() throws Exception {
    try (ZKWatcher zk =
      new ZKWatcher(TEST_UTIL.getConfiguration(), ""testActiveMasterManagerFromZK"", null, true)) {
      try {
        ZKUtil.deleteNode(zk, zk.getZNodePaths().masterAddressZNode);
        ZKUtil.deleteNode(zk, zk.getZNodePaths().clusterStateZNode);
      }",1
"@Test
  public void testDuplicateHFileResolution() throws Exception {
    TableDescriptor td = createTableDescriptorForCurrentMethod();

    // Create regions.
    RegionInfo parent =
      createRegionInfo(td.getTableName(), Bytes.toBytes(""aaa""), Bytes.toBytes(""eee""));
    RegionInfo splita =
      createRegionInfo(td.getTableName(), Bytes.toBytes(""aaa""), Bytes.toBytes(""ccc""));
    RegionInfo splitb =
      createRegionInfo(td.getTableName(), Bytes.toBytes(""ccc""), Bytes.toBytes(""eee""));
    // Test that when both daughter regions are in place, that we do not
    // remove the parent.
    Result r = createResult(parent, splita, splitb);
    FileSystem fs = FileSystem.get(HTU.getConfiguration());
    Path rootdir = this.masterServices.getMasterFileSystem().getRootDir();
    // Have to set the root directory since we use it in HFileDisposer to figure out to get to the
    // archive directory. Otherwise, it just seems to pick the first root directory it can find (so
    // the single test passes, but when the full suite is run, things get borked).
    CommonFSUtils.setRootDir(fs.getConf(), rootdir);
    Path tabledir = CommonFSUtils.getTableDir(rootdir, parent.getTable());
    Path storedir =
      HRegionFileSystem.getStoreHomedir(tabledir, parent, td.getColumnFamilies()[0].getName());
    LOG.info(""Old root:"" + rootdir);
    LOG.info(""Old table:"" + tabledir);
    LOG.info(""Old store:"" + storedir);

    Path storeArchive = HFileArchiveUtil.getStoreArchivePath(this.masterServices.getConfiguration(),
      parent, tabledir, td.getColumnFamilies()[0].getName());
    LOG.info(""Old archive:"" + storeArchive);

    // enable archiving, make sure that files get archived
    addMockStoreFiles(2, this.masterServices, storedir);
    // get the current store files for comparison
    FileStatus[] storeFiles = fs.listStatus(storedir);
    // Do the cleaning of the parent
    assertTrue(CatalogJanitor.cleanParent(masterServices, parent, r));
    Path parentDir = new Path(tabledir, parent.getEncodedName());
    ProcedureTestingUtility.waitAllProcedures(masterServices.getMasterProcedureExecutor());
    assertTrue(!fs.exists(parentDir));

    // And now check to make sure that the files have actually been archived
    FileStatus[] archivedStoreFiles = fs.listStatus(storeArchive);
    assertArchiveEqualToOriginal(storeFiles, archivedStoreFiles, fs);

    // now add store files with the same names as before to check backup
    // enable archiving, make sure that files get archived
    addMockStoreFiles(2, this.masterServices, storedir);

    // Do the cleaning of the parent
    assertTrue(CatalogJanitor.cleanParent(masterServices, parent, r));
    // Cleanup procedure runs async. Wait till it done.
    ProcedureTestingUtility.waitAllProcedures(masterServices.getMasterProcedureExecutor());
    assertTrue(!fs.exists(parentDir));

    // and now check to make sure that the files have actually been archived
    archivedStoreFiles = fs.listStatus(storeArchive);
    assertArchiveEqualToOriginal(storeFiles, archivedStoreFiles, fs, true);
  }",1
"@Test
  public void testIsDead() {
    DeadServer ds = new DeadServer();
    ds.putIfAbsent(hostname123);

    ds.putIfAbsent(hostname1234);

    ds.putIfAbsent(hostname12345);

    // Already dead = 127.0.0.1,9090,112321
    // Coming back alive = 127.0.0.1,9090,223341

    final ServerName deadServer = ServerName.valueOf(""127.0.0.1"", 9090, 112321L);
    assertFalse(ds.cleanPreviousInstance(deadServer));
    ds.putIfAbsent(deadServer);
    assertTrue(ds.isDeadServer(deadServer));
    Set<ServerName> deadServerNames = ds.copyServerNames();
    for (ServerName eachDeadServer : deadServerNames) {
      Assert.assertNotNull(ds.getTimeOfDeath(eachDeadServer));
    }",1
"@Test
  public void testEqualsWithNulls() {
    RegionInfo hri = RegionInfoBuilder.newBuilder(TableName.valueOf(name.getMethodName())).build();
    RegionPlan a = new RegionPlan(hri, null, null);
    RegionPlan b = new RegionPlan(hri, null, null);
    assertTrue(a.equals(b));
    a = new RegionPlan(hri, SRC, null);
    b = new RegionPlan(hri, null, null);
    assertFalse(a.equals(b));
    a = new RegionPlan(hri, SRC, null);
    b = new RegionPlan(hri, SRC, null);
    assertTrue(a.equals(b));
    a = new RegionPlan(hri, SRC, null);
    b = new RegionPlan(hri, SRC, DEST);
    assertFalse(a.equals(b));
  }",1
"@Test
  public void testDeadWorker() throws Exception {
    LOG.info(""testDeadWorker"");

    conf.setLong(""hbase.splitlog.max.resubmit"", 0);
    slm = new SplitLogManager(master, conf);
    TaskBatch batch = new TaskBatch();

    String tasknode = submitTaskAndWait(batch, ""foo/1"");
    int version = ZKUtil.checkExists(zkw, tasknode);
    final ServerName worker1 = ServerName.valueOf(""worker1,1,1"");
    SplitLogTask slt = new SplitLogTask.Owned(worker1);
    ZKUtil.setData(zkw, tasknode, slt.toByteArray());
    if (tot_mgr_heartbeat.sum() == 0) {
      waitForCounter(tot_mgr_heartbeat, 0, 1, to / 2);
    }",1
"@Test
  public void testMultipleResubmits() throws Exception {
    LOG.info(""TestMultipleResbmits - no indefinite resubmissions"");
    conf.setInt(""hbase.splitlog.max.resubmit"", 2);
    slm = new SplitLogManager(master, conf);
    TaskBatch batch = new TaskBatch();

    String tasknode = submitTaskAndWait(batch, ""foo/1"");
    int version = ZKUtil.checkExists(zkw, tasknode);
    final ServerName worker1 = ServerName.valueOf(""worker1,1,1"");
    final ServerName worker2 = ServerName.valueOf(""worker2,1,1"");
    final ServerName worker3 = ServerName.valueOf(""worker3,1,1"");
    SplitLogTask slt = new SplitLogTask.Owned(worker1);
    ZKUtil.setData(zkw, tasknode, slt.toByteArray());
    waitForCounter(tot_mgr_heartbeat, 0, 1, to / 2);
    waitForCounter(tot_mgr_resubmit, 0, 1, to + to / 2);
    int version1 = ZKUtil.checkExists(zkw, tasknode);
    assertTrue(version1 > version);
    slt = new SplitLogTask.Owned(worker2);
    ZKUtil.setData(zkw, tasknode, slt.toByteArray());
    waitForCounter(tot_mgr_heartbeat, 1, 2, to / 2);
    waitForCounter(tot_mgr_resubmit, 1, 2, to + to / 2);
    int version2 = ZKUtil.checkExists(zkw, tasknode);
    assertTrue(version2 > version1);
    slt = new SplitLogTask.Owned(worker3);
    ZKUtil.setData(zkw, tasknode, slt.toByteArray());
    waitForCounter(tot_mgr_heartbeat, 2, 3, to / 2);
    waitForCounter(tot_mgr_resubmit_threshold_reached, 0, 1, to + to / 2);
    Thread.sleep(to + to / 2);
    assertEquals(2L, tot_mgr_resubmit.sum() - tot_mgr_resubmit_force.sum());
  }",1
"@Test
  public void testSnapshot() {
    HistogramImpl histogram = new HistogramImpl();
    IntStream.range(0, 100).forEach(histogram::update);

    Snapshot snapshot = histogram.snapshot();

    assertEquals(100, snapshot.getCount());
    assertEquals(49, snapshot.getMedian());
    assertEquals(49, snapshot.getMean());
    assertEquals(0, snapshot.getMin());
    assertEquals(99, snapshot.getMax());
    assertEquals(24, snapshot.get25thPercentile());
    assertEquals(74, snapshot.get75thPercentile());
    assertEquals(89, snapshot.get90thPercentile());
    assertEquals(94, snapshot.get95thPercentile());
    assertEquals(97, snapshot.get98thPercentile());
    assertEquals(98, snapshot.get99thPercentile());
    assertEquals(98, snapshot.get999thPercentile());

    assertEquals(100, snapshot.getCountAtOrBelow(50));

    // check that histogram is reset.
    assertEquals(100, histogram.getCount()); // count does not reset

    // put more data after reset
    IntStream.range(100, 200).forEach(histogram::update);

    assertEquals(200, histogram.getCount());

    snapshot = histogram.snapshot();
    assertEquals(100, snapshot.getCount()); // only 100 more events
    assertEquals(150, snapshot.getMedian());
    assertEquals(149, snapshot.getMean());
    assertEquals(100, snapshot.getMin());
    assertEquals(199, snapshot.getMax());
    assertEquals(125, snapshot.get25thPercentile());
    assertEquals(175, snapshot.get75thPercentile());
    assertEquals(190, snapshot.get90thPercentile());
    assertEquals(195, snapshot.get95thPercentile());
    assertEquals(198, snapshot.get98thPercentile());
    assertEquals(199, snapshot.get99thPercentile());
    assertEquals(199, snapshot.get999thPercentile());

    IntStream.range(500, 1000).forEach(histogram::update);

    snapshot = histogram.snapshot();

    assertEquals(500, snapshot.getCount());
    assertEquals(749, snapshot.getMedian());
    assertEquals(749, snapshot.getMean());
    assertEquals(500, snapshot.getMin());
    assertEquals(999, snapshot.getMax());
    assertEquals(624, snapshot.get25thPercentile());
    assertEquals(874, snapshot.get75thPercentile());
    assertEquals(949, snapshot.get90thPercentile());
    assertEquals(974, snapshot.get95thPercentile());
    assertEquals(989, snapshot.get98thPercentile());
    assertEquals(994, snapshot.get99thPercentile());
    assertEquals(998, snapshot.get999thPercentile());

  }",1
"@Test
  public void testGetMetrics() {
    CounterImpl counter = new CounterImpl();
    registry.register(""mycounter"", counter);
    Gauge gauge = registry.register(""mygauge"", () -> 42L);
    Timer timer = registry.timer(""mytimer"");

    Map<String, Metric> metrics = registry.getMetrics();
    assertEquals(3, metrics.size());

    assertEquals(counter, metrics.get(""mycounter""));
    assertEquals(gauge, metrics.get(""mygauge""));
    assertEquals(timer, metrics.get(""mytimer""));
  }",1
"@Test
  public void testRegisterGauge() {
    registry.register(""mygauge"", new Gauge<Long>() {
      @Override
      public Long getValue() {
        return 42L;
      }",1
"@Test
  public void testCleaner() throws Exception {
    init();

    Path mobDirPath = MobUtils.getMobFamilyPath(TEST_UTIL.getConfiguration(), tableName, family);

    byte[] dummyData = makeDummyData(600);
    long ts = EnvironmentEdgeManager.currentTime() - 3 * secondsOfDay() * 1000; // 3 days before
    putKVAndFlush(table, row1, dummyData, ts);
    LOG.info(""test log to be deleted, tablename is "" + tableName);
    CommonFSUtils.logFileSystemState(TEST_UTIL.getTestFileSystem(),
      TEST_UTIL.getDefaultRootDirPath(), LOG);
    FileStatus[] firstFiles = TEST_UTIL.getTestFileSystem().listStatus(mobDirPath);
    // the first mob file
    assertEquals(""Before cleanup without delay 1"", 1, firstFiles.length);
    String firstFile = firstFiles[0].getPath().getName();

    // 1.5 day before
    ts = (long) (EnvironmentEdgeManager.currentTime() - 1.5 * secondsOfDay() * 1000);
    putKVAndFlush(table, row2, dummyData, ts);
    FileStatus[] secondFiles = TEST_UTIL.getTestFileSystem().listStatus(mobDirPath);
    // now there are 2 mob files
    assertEquals(""Before cleanup without delay 2"", 2, secondFiles.length);
    String f1 = secondFiles[0].getPath().getName();
    String f2 = secondFiles[1].getPath().getName();
    String secondFile = f1.equals(firstFile) ? f2 : f1;

    ts = EnvironmentEdgeManager.currentTime() - 4 * secondsOfDay() * 1000; // 4 days before
    putKVAndFlush(table, row3, dummyData, ts);
    ts = EnvironmentEdgeManager.currentTime() - 4 * secondsOfDay() * 1000; // 4 days before
    putKVAndFlush(table, row3, dummyData, ts);
    FileStatus[] thirdFiles = TEST_UTIL.getTestFileSystem().listStatus(mobDirPath);
    // now there are 4 mob files
    assertEquals(""Before cleanup without delay 3"", 4, thirdFiles.length);

    modifyColumnExpiryDays(2); // ttl = 2, make the first row expired

    // run the cleaner
    String[] args = new String[2];
    args[0] = tableName.getNameAsString();
    args[1] = family;
    ToolRunner.run(TEST_UTIL.getConfiguration(), new ExpiredMobFileCleaner(), args);

    FileStatus[] filesAfterClean = TEST_UTIL.getTestFileSystem().listStatus(mobDirPath);
    String lastFile = filesAfterClean[0].getPath().getName();
    // there are 4 mob files in total, but only 3 need to be cleaned
    assertEquals(""After cleanup without delay 1"", 1, filesAfterClean.length);
    assertEquals(""After cleanup without delay 2"", secondFile, lastFile);
  }",1
"@Test
  public void testReadKeyValue() throws Exception {
    Path testDir = TEST_UTIL.getDataTestDir();
    FileSystem fs = testDir.getFileSystem(conf);
    HFileContext meta = new HFileContextBuilder().withBlockSize(8 * 1024).build();
    StoreFileWriter writer = new StoreFileWriter.Builder(conf, cacheConf, fs).withOutputDir(testDir)
      .withFileContext(meta).build();
    String caseName = testName.getMethodName();
    MobTestUtil.writeStoreFile(writer, caseName);

    StoreFileInfo storeFileInfo =
      StoreFileInfo.createStoreFileInfoForHFile(conf, fs, writer.getPath(), true);
    MobFile mobFile = new MobFile(new HStoreFile(storeFileInfo, BloomType.NONE, cacheConf));
    byte[] family = Bytes.toBytes(caseName);
    byte[] qualify = Bytes.toBytes(caseName);

    // Test the start key
    byte[] startKey = Bytes.toBytes(""aa""); // The start key bytes
    KeyValue expectedKey =
      new KeyValue(startKey, family, qualify, Long.MAX_VALUE, Type.Put, startKey);
    KeyValue seekKey = expectedKey.createKeyOnly(false);
    Cell cell = mobFile.readCell(seekKey, false).getCell();
    MobTestUtil.assertCellEquals(expectedKey, cell);

    // Test the end key
    byte[] endKey = Bytes.toBytes(""zz""); // The end key bytes
    expectedKey = new KeyValue(endKey, family, qualify, Long.MAX_VALUE, Type.Put, endKey);
    seekKey = expectedKey.createKeyOnly(false);
    cell = mobFile.readCell(seekKey, false).getCell();
    MobTestUtil.assertCellEquals(expectedKey, cell);

    // Test the random key
    byte[] randomKey = Bytes.toBytes(MobTestUtil.generateRandomString(2));
    expectedKey = new KeyValue(randomKey, family, qualify, Long.MAX_VALUE, Type.Put, randomKey);
    seekKey = expectedKey.createKeyOnly(false);
    cell = mobFile.readCell(seekKey, false).getCell();
    MobTestUtil.assertCellEquals(expectedKey, cell);

    // Test the key which is less than the start key
    byte[] lowerKey = Bytes.toBytes(""a1""); // Smaller than ""aa""
    expectedKey = new KeyValue(startKey, family, qualify, Long.MAX_VALUE, Type.Put, startKey);
    seekKey = new KeyValue(lowerKey, family, qualify, Long.MAX_VALUE, Type.Put, lowerKey);
    cell = mobFile.readCell(seekKey, false).getCell();
    MobTestUtil.assertCellEquals(expectedKey, cell);

    // Test the key which is more than the end key
    byte[] upperKey = Bytes.toBytes(""z{""); // Bigger than ""zz""
    seekKey = new KeyValue(upperKey, family, qualify, Long.MAX_VALUE, Type.Put, upperKey);
    assertNull(mobFile.readCell(seekKey, false));
  }",1
"@Test
  public void testNonAsciiEncoding() {
    MemoryBoundedLogMessageBuffer buf = new MemoryBoundedLogMessageBuffer(TEN_KB);

    buf.add(JP_TEXT);
    StringWriter sw = new StringWriter();
    buf.dumpTo(new PrintWriter(sw));
    String dump = sw.toString();
    assertTrue(dump.contains(JP_TEXT));
  }",1
"@Test
  public void testTasksGetAbortedOnLeak() throws InterruptedException {
    final TaskMonitor tm = new TaskMonitor(new Configuration());
    assertTrue(""Task monitor should start empty"", tm.getTasks().isEmpty());

    final AtomicBoolean threadSuccess = new AtomicBoolean(false);
    // Make a task in some other thread and leak it
    Thread t = new Thread() {
      @Override
      public void run() {
        MonitoredTask task = tm.createStatus(""Test task"");
        assertEquals(MonitoredTask.State.RUNNING, task.getState());
        threadSuccess.set(true);
      }",1
"@Test
  public void testCloneSnapshot() throws Exception {
    String nsp = prefix + ""_testCloneSnapshot"";
    NamespaceDescriptor nspDesc =
      NamespaceDescriptor.create(nsp).addConfiguration(TableNamespaceManager.KEY_MAX_TABLES, ""2"")
        .addConfiguration(TableNamespaceManager.KEY_MAX_REGIONS, ""20"").build();
    ADMIN.createNamespace(nspDesc);
    assertNotNull(""Namespace descriptor found null."", ADMIN.getNamespaceDescriptor(nsp));
    TableName tableName = TableName.valueOf(nsp + TableName.NAMESPACE_DELIM + ""table1"");
    TableName cloneTableName = TableName.valueOf(nsp + TableName.NAMESPACE_DELIM + ""table2"");

    ColumnFamilyDescriptor columnFamilyDescriptor =
      ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(""fam1"")).build();
    TableDescriptorBuilder tableDescOne = TableDescriptorBuilder.newBuilder(tableName);
    tableDescOne.setColumnFamily(columnFamilyDescriptor);

    ADMIN.createTable(tableDescOne.build(), Bytes.toBytes(""AAA""), Bytes.toBytes(""ZZZ""), 4);
    String snapshot = ""snapshot_testCloneSnapshot"";
    ADMIN.snapshot(snapshot, tableName);
    ADMIN.cloneSnapshot(snapshot, cloneTableName);

    int tableLength;
    try (RegionLocator locator = ADMIN.getConnection().getRegionLocator(tableName)) {
      tableLength = locator.getStartKeys().length;
    }",1
"@Test
  public void testArrayBasedMethods() {
    byte[] b = new byte[15];
    ByteBuffer bb1 = ByteBuffer.wrap(b, 1, 10).slice();
    ByteBuffer bb2 = ByteBuffer.allocate(15);
    ByteBuff mbb1 = new MultiByteBuff(bb1, bb2);
    assertFalse(mbb1.hasArray());
    try {
      mbb1.array();
      fail();
    }",1
"@Test
  public void testMarkAndResetWithMBB() {
    ByteBuffer bb1 = ByteBuffer.allocateDirect(15);
    ByteBuffer bb2 = ByteBuffer.allocateDirect(15);
    bb1.putInt(4);
    long l1 = 45L, l2 = 100L, l3 = 12345L;
    bb1.putLong(l1);
    bb1.putShort((short) 2);
    byte[] b = Bytes.toBytes(l2);
    bb1.put(b, 0, 1);
    bb2.put(b, 1, 7);
    bb2.putLong(l3);
    ByteBuff multi = new MultiByteBuff(bb1, bb2);
    assertEquals(4, multi.getInt());
    assertEquals(l1, multi.getLong());
    multi.mark();
    assertEquals((short) 2, multi.getShort());
    multi.reset();
    assertEquals((short) 2, multi.getShort());
    multi.mark();
    assertEquals(l2, multi.getLong());
    multi.reset();
    assertEquals(l2, multi.getLong());
    multi.mark();
    assertEquals(l3, multi.getLong());
    multi.reset();
    assertEquals(l3, multi.getLong());
    // Try absolute gets with mark and reset
    multi.mark();
    assertEquals(l2, multi.getLong(14));
    multi.reset();
    assertEquals(l3, multi.getLong(22));
    // Just reset to see what happens
    multi.reset();
    assertEquals(l2, multi.getLong(14));
    multi.mark();
    assertEquals(l3, multi.getLong(22));
    multi.reset();
  }",1
"@Test
  public void testPropagateConnectionErrorBackToManager() throws Exception {
    // setup the operation
    member = buildCohortMember();
    ProcedureMember memberSpy = spy(member);

    // setup the commit and the spy
    final ForeignExceptionDispatcher dispatcher = new ForeignExceptionDispatcher();
    ForeignExceptionDispatcher dispSpy = spy(dispatcher);
    Subprocedure commit = new EmptySubprocedure(member, dispatcher);
    Subprocedure spy = spy(commit);
    when(mockBuilder.buildSubprocedure(op, data)).thenReturn(spy);

    // fail during the prepare phase
    doThrow(new ForeignException(""SRC"", ""prepare exception"")).when(spy).acquireBarrier();
    // and throw a connection error when we try to tell the controller about it
    doThrow(new IOException(""Controller is down!"")).when(mockMemberComms).sendMemberAborted(eq(spy),
      any());

    // run the operation
    // build a new operation
    Subprocedure subproc = memberSpy.createSubprocedure(op, data);
    memberSpy.submitSubprocedure(subproc);
    // if the operation doesn't die properly, then this will timeout
    memberSpy.closeAndWait(TIMEOUT);

    // make sure everything ran in order
    InOrder order = inOrder(mockMemberComms, spy, dispSpy);
    // make sure we acquire.
    order.verify(spy).acquireBarrier();
    order.verify(mockMemberComms, never()).sendMemberAcquired(spy);

    // TODO Need to do another refactor to get this to propagate to the coordinator.
    // make sure we pass a remote exception back the controller
    // order.verify(mockMemberComms).sendMemberAborted(eq(spy),
    // any());
    // order.verify(dispSpy).receiveError(anyString(),
    // any(), any());
  }",1
"@Test
  public void testLoad() {
    final int MAX_PROCS = 1000;
    final ProcedureStoreTracker tracker = new ProcedureStoreTracker();
    for (int numProcs = 1; numProcs < MAX_PROCS; ++numProcs) {
      for (int start = 1; start <= numProcs; ++start) {
        assertTrue(tracker.isEmpty());

        LOG.debug(""loading "" + numProcs + "" procs from start="" + start);
        for (int i = start; i <= numProcs; ++i) {
          tracker.setDeleted(i, false);
        }",1
"@Test
  public void testPartialTracker() {
    ProcedureStoreTracker tracker = new ProcedureStoreTracker();
    tracker.setPartialFlag(true);

    // nothing in the tracker, the state is unknown
    assertTrue(tracker.isEmpty());
    assertEquals(ProcedureStoreTracker.DeleteState.MAYBE, tracker.isDeleted(1));
    assertEquals(ProcedureStoreTracker.DeleteState.MAYBE, tracker.isDeleted(579));

    // Mark 1 as deleted, now that is a known state
    tracker.setDeleted(1, true);
    tracker.dump();
    assertEquals(ProcedureStoreTracker.DeleteState.YES, tracker.isDeleted(1));
    assertEquals(ProcedureStoreTracker.DeleteState.MAYBE, tracker.isDeleted(2));
    assertEquals(ProcedureStoreTracker.DeleteState.MAYBE, tracker.isDeleted(579));

    // Mark 579 as non-deleted, now that is a known state
    tracker.setDeleted(579, false);
    assertEquals(ProcedureStoreTracker.DeleteState.YES, tracker.isDeleted(1));
    assertEquals(ProcedureStoreTracker.DeleteState.MAYBE, tracker.isDeleted(2));
    assertEquals(ProcedureStoreTracker.DeleteState.NO, tracker.isDeleted(579));
    assertEquals(ProcedureStoreTracker.DeleteState.MAYBE, tracker.isDeleted(577));
    assertEquals(ProcedureStoreTracker.DeleteState.MAYBE, tracker.isDeleted(580));

    tracker.setDeleted(579, true);
    tracker.setPartialFlag(false);
    assertTrue(tracker.isEmpty());
  }",1
"@Test
  public void testCorruptedEntries() throws Exception {
    // Insert something
    for (int i = 0; i < 100; ++i) {
      procStore.insert(new TestSequentialProcedure(), null);
    }",1
"@Test
  public void testCorruptedProcedures() throws Exception {
    // Insert root-procedures
    TestProcedure[] rootProcs = new TestProcedure[10];
    for (int i = 1; i <= rootProcs.length; i++) {
      rootProcs[i - 1] = new TestProcedure(i, 0);
      procStore.insert(rootProcs[i - 1], null);
      rootProcs[i - 1].addStackId(0);
      procStore.update(rootProcs[i - 1]);
    }",1
"@Test
  public void testCorruptedTrailer() throws Exception {
    // Insert something
    for (int i = 0; i < 100; ++i) {
      procStore.insert(new TestSequentialProcedure(), null);
    }",1
"@Test
  public void testLoad() throws Exception {
    Set<Long> procIds = new HashSet<>();

    // Insert something in the log
    Procedure<?> proc1 = new TestSequentialProcedure();
    procIds.add(proc1.getProcId());
    procStore.insert(proc1, null);

    Procedure<?> proc2 = new TestSequentialProcedure();
    Procedure<?>[] child2 = new Procedure[2];
    child2[0] = new TestSequentialProcedure();
    child2[1] = new TestSequentialProcedure();

    procIds.add(proc2.getProcId());
    procIds.add(child2[0].getProcId());
    procIds.add(child2[1].getProcId());
    procStore.insert(proc2, child2);

    // Verify that everything is there
    verifyProcIdsOnRestart(procIds);

    // Update and delete something
    procStore.update(proc1);
    procStore.update(child2[1]);
    procStore.delete(child2[1].getProcId());
    procIds.remove(child2[1].getProcId());

    // Verify that everything is there
    verifyProcIdsOnRestart(procIds);

    // Remove 4 byte from the trailers
    procStore.stop(false);
    FileStatus[] logs = fs.listStatus(logDir);
    assertEquals(3, logs.length);
    for (int i = 0; i < logs.length; ++i) {
      corruptLog(logs[i], 4);
    }",1
"@Test
  public void testWalCleanerNoHoles() throws Exception {
    final Procedure<?>[] procs = new Procedure[5];
    ArrayList<ProcedureWALFile> logs = null;
    // Insert procedures and roll wal after every insert.
    for (int i = 0; i < procs.length; i++) {
      procs[i] = new TestSequentialProcedure();
      procStore.insert(procs[i], null);
      procStore.rollWriterForTesting();
      logs = procStore.getActiveLogs();
      assertEquals(i + 2, logs.size()); // Extra 1 for current ongoing wal.
    }",1
"@Test
  public void testWalCleanerSequentialClean() throws Exception {
    final Procedure<?>[] procs = new Procedure[5];
    ArrayList<ProcedureWALFile> logs = null;

    // Insert procedures and roll wal after every insert.
    for (int i = 0; i < procs.length; i++) {
      procs[i] = new TestSequentialProcedure();
      procStore.insert(procs[i], null);
      procStore.rollWriterForTesting();
      logs = procStore.getActiveLogs();
      assertEquals(logs.size(), i + 2); // Extra 1 for current ongoing wal.
    }",1
"@Test
  public void testWalCleanerUpdates() throws Exception {
    TestSequentialProcedure p1 = new TestSequentialProcedure();
    TestSequentialProcedure p2 = new TestSequentialProcedure();
    procStore.insert(p1, null);
    procStore.insert(p2, null);
    procStore.rollWriterForTesting();
    ProcedureWALFile firstLog = procStore.getActiveLogs().get(0);
    procStore.update(p1);
    procStore.rollWriterForTesting();
    procStore.update(p2);
    procStore.rollWriterForTesting();
    procStore.removeInactiveLogsForTesting();
    assertFalse(procStore.getActiveLogs().contains(firstLog));
  }",1
"@Test
  public void testWalCleanerWithEmptyRolls() throws Exception {
    final Procedure<?>[] procs = new Procedure[3];
    for (int i = 0; i < procs.length; ++i) {
      procs[i] = new TestSequentialProcedure();
      procStore.insert(procs[i], null);
    }",1
"@Test
  public void testSubmitBatch() throws Exception {
    Procedure[] procs = new Procedure[5];
    for (int i = 0; i < procs.length; ++i) {
      procs[i] = new NoopProcedure<TestProcEnv>();
    }",1
"@Test
  public void testChoreAddAndRemove() throws Exception {
    final int timeoutMSec = 50;
    final int nCountDown = 5;

    // submit the chore and wait for execution
    CountDownLatch latch = new CountDownLatch(nCountDown);
    TestLatchChore chore = new TestLatchChore(timeoutMSec, latch);
    procExecutor.addChore(chore);
    assertTrue(chore.isWaiting());
    latch.await();

    // remove the chore and verify it is no longer executed
    assertTrue(chore.isWaiting());
    procExecutor.removeChore(chore);
    latch = new CountDownLatch(nCountDown);
    chore.setLatch(latch);
    latch.await(timeoutMSec * nCountDown, TimeUnit.MILLISECONDS);
    LOG.info(""chore latch count="" + latch.getCount());
    assertFalse(chore.isWaiting());
    assertTrue(""latchCount="" + latch.getCount(), latch.getCount() > 0);
  }",1
"@Test
  public void testMetricForFailedYiledProcedure() {
    // procedure that yields and fails
    ProcedureMetrics proc = new ProcedureMetrics(false, true);
    long id = ProcedureTestingUtility.submitAndWait(procExecutor, proc);
    assertNotEquals(""ProcId zero!"", 0, id);
    beginCount++;
    failedCount++;
    ProcedureTestingUtility.waitProcedure(procExecutor, proc);
    assertEquals(""beginCount doesn't match!"", beginCount, proc.beginCount);
    assertEquals(""successCount doesn't match!"", successCount, proc.successCount);
    assertEquals(""failedCont doesn't match!"", failedCount, proc.failedCount);
  }",1
"@Test
  public void testDelayedContainerEquals() {
    Object o1 = new Object();
    Object o2 = new Object();
    ZeroDelayContainer<Long> lnull = new ZeroDelayContainer(null);
    ZeroDelayContainer<Long> l10a = new ZeroDelayContainer<>(10L);
    ZeroDelayContainer<Long> l10b = new ZeroDelayContainer(10L);
    ZeroDelayContainer<Long> l15 = new ZeroDelayContainer(15L);
    ZeroDelayContainer<Object> onull = new ZeroDelayContainer<>(null);
    ZeroDelayContainer<Object> o1ca = new ZeroDelayContainer<>(o1);
    ZeroDelayContainer<Object> o1cb = new ZeroDelayContainer<>(o1);
    ZeroDelayContainer<Object> o2c = new ZeroDelayContainer<>(o2);

    ZeroDelayContainer[] items =
      new ZeroDelayContainer[] { lnull, l10a, l10b, l15, onull, o1ca, o1cb, o2c, }",1
"@Test
  public void testDelete() throws IOException {
    MutationProto.Builder mutateBuilder = MutationProto.newBuilder();
    mutateBuilder.setRow(ByteString.copyFromUtf8(""row""));
    mutateBuilder.setMutateType(MutationType.DELETE);
    mutateBuilder.setTimestamp(111111);
    ColumnValue.Builder valueBuilder = ColumnValue.newBuilder();
    valueBuilder.setFamily(ByteString.copyFromUtf8(""f1""));
    QualifierValue.Builder qualifierBuilder = QualifierValue.newBuilder();
    qualifierBuilder.setQualifier(ByteString.copyFromUtf8(""c1""));
    qualifierBuilder.setDeleteType(DeleteType.DELETE_ONE_VERSION);
    qualifierBuilder.setTimestamp(111222);
    valueBuilder.addQualifierValue(qualifierBuilder.build());
    qualifierBuilder.setQualifier(ByteString.copyFromUtf8(""c2""));
    qualifierBuilder.setDeleteType(DeleteType.DELETE_MULTIPLE_VERSIONS);
    qualifierBuilder.setTimestamp(111333);
    valueBuilder.addQualifierValue(qualifierBuilder.build());
    mutateBuilder.addColumnValue(valueBuilder.build());

    MutationProto proto = mutateBuilder.build();
    // default fields
    assertEquals(MutationProto.Durability.USE_DEFAULT, proto.getDurability());

    // set the default value for equal comparison
    mutateBuilder = MutationProto.newBuilder(proto);
    mutateBuilder.setDurability(MutationProto.Durability.USE_DEFAULT);

    Delete delete = ProtobufUtil.toDelete(proto);

    // delete always have empty value,
    // add empty value to the original mutate
    for (ColumnValue.Builder column : mutateBuilder.getColumnValueBuilderList()) {
      for (QualifierValue.Builder qualifier : column.getQualifierValueBuilderList()) {
        qualifier.setValue(ByteString.EMPTY);
      }",1
"@Test
  public void testNonViolatingQuotaCachesPolicyEnforcment() {
    final Map<TableName, SpaceQuotaSnapshot> snapshots = new HashMap<>();
    final TableName tableName = TableName.valueOf(""my_table"");
    snapshots.put(tableName, new SpaceQuotaSnapshot(SpaceQuotaStatus.notInViolation(), 0, 1024));
    final ActivePolicyEnforcement ape =
      new ActivePolicyEnforcement(Collections.emptyMap(), snapshots, rss);
    SpaceViolationPolicyEnforcement policyEnforcement = ape.getPolicyEnforcement(tableName);
    assertTrue(""Found the wrong class: "" + policyEnforcement.getClass(),
      policyEnforcement instanceof DefaultViolationPolicyEnforcement);
    SpaceViolationPolicyEnforcement copy = ape.getPolicyEnforcement(tableName);
    assertTrue(""Expected the instance to be cached"", policyEnforcement == copy);
    Entry<TableName, SpaceViolationPolicyEnforcement> entry =
      ape.getLocallyCachedPolicies().entrySet().iterator().next();
    assertTrue(policyEnforcement == entry.getValue());
  }",1
"@Test
  public void testNoPolicyReturnsNoopEnforcement() {
    ActivePolicyEnforcement ape = new ActivePolicyEnforcement(new HashMap<>(),
      Collections.emptyMap(), mock(RegionServerServices.class));
    SpaceViolationPolicyEnforcement enforcement =
      ape.getPolicyEnforcement(TableName.valueOf(""nonexistent""));
    assertNotNull(enforcement);
    assertTrue(""Expected an instance of MissingSnapshotViolationPolicyEnforcement, but got ""
      + enforcement.getClass(), enforcement instanceof MissingSnapshotViolationPolicyEnforcement);
  }",1
"@Test
  public void testNoQuotaReturnsSingletonPolicyEnforcement() {
    final ActivePolicyEnforcement ape =
      new ActivePolicyEnforcement(Collections.emptyMap(), Collections.emptyMap(), rss);
    final TableName tableName = TableName.valueOf(""my_table"");
    SpaceViolationPolicyEnforcement policyEnforcement = ape.getPolicyEnforcement(tableName);
    // This should be the same exact instance, the singleton
    assertTrue(policyEnforcement == MissingSnapshotViolationPolicyEnforcement.getInstance());
    assertEquals(1, ape.getLocallyCachedPolicies().size());
    Entry<TableName, SpaceViolationPolicyEnforcement> entry =
      ape.getLocallyCachedPolicies().entrySet().iterator().next();
    assertTrue(policyEnforcement == entry.getValue());
  }",1
"@Test
  public void testIgnoreSplitParents() {
    final Configuration conf = getDefaultHBaseConfiguration();
    final HRegionServer rs = mockRegionServer(conf);

    // Three regions with multiple store sizes
    final List<Long> r1Sizes = Arrays.asList(1024L, 2048L);
    final long r1Sum = sum(r1Sizes);
    final List<Long> r2Sizes = Arrays.asList(1024L * 1024L);

    final FileSystemUtilizationChore chore = new FileSystemUtilizationChore(rs);
    doAnswer(new ExpectedRegionSizeSummationAnswer(sum(Arrays.asList(r1Sum)))).when(rs)
      .reportRegionSizesForQuotas(any(RegionSizeStore.class));

    final Region r1 = mockRegionWithSize(r1Sizes);
    final Region r2 = mockSplitParentRegionWithSize(r2Sizes);
    doReturn(Arrays.asList(r1, r2)).when(rs).getRegions();
    chore.chore();
  }",1
"@Test
  public void testNonDefaultConfigurationProperties() {
    final Configuration conf = getDefaultHBaseConfiguration();
    // Override the default values
    final int period = 60 * 10;
    final long delay = 30L;
    final TimeUnit timeUnit = TimeUnit.SECONDS;
    conf.setInt(FileSystemUtilizationChore.FS_UTILIZATION_CHORE_PERIOD_KEY, period);
    conf.setLong(FileSystemUtilizationChore.FS_UTILIZATION_CHORE_DELAY_KEY, delay);
    conf.set(FileSystemUtilizationChore.FS_UTILIZATION_CHORE_TIMEUNIT_KEY, timeUnit.name());

    // Verify that the chore reports these non-default values
    final HRegionServer rs = mockRegionServer(conf);
    final FileSystemUtilizationChore chore = new FileSystemUtilizationChore(rs);
    assertEquals(period, chore.getPeriod());
    assertEquals(delay, chore.getInitialDelay());
    assertEquals(timeUnit, chore.getTimeUnit());
  }",1
"@Test
  public void testNonHFilesAreIgnored() {
    final Configuration conf = getDefaultHBaseConfiguration();
    final HRegionServer rs = mockRegionServer(conf);

    // Region r1 has two store files, one hfile link and one hfile
    final List<Long> r1StoreFileSizes = Arrays.asList(1024L, 2048L);
    final List<Long> r1HFileSizes = Arrays.asList(0L, 2048L);
    final long r1HFileSizeSum = sum(r1HFileSizes);
    // Region r2 has one store file which is a hfile link
    final List<Long> r2StoreFileSizes = Arrays.asList(1024L * 1024L);
    final List<Long> r2HFileSizes = Arrays.asList(0L);
    final long r2HFileSizeSum = sum(r2HFileSizes);

    // We expect that only the hfiles would be counted (hfile links are ignored)
    final FileSystemUtilizationChore chore = new FileSystemUtilizationChore(rs);
    doAnswer(
      new ExpectedRegionSizeSummationAnswer(sum(Arrays.asList(r1HFileSizeSum, r2HFileSizeSum))))
        .when(rs).reportRegionSizesForQuotas(any(RegionSizeStore.class));

    final Region r1 = mockRegionWithHFileLinks(r1StoreFileSizes, r1HFileSizes);
    final Region r2 = mockRegionWithHFileLinks(r2StoreFileSizes, r2HFileSizes);
    doReturn(Arrays.asList(r1, r2)).when(rs).getRegions();
    chore.chore();
  }",1
"@Test
  public void testNoOnlineRegions() {
    // One region with a store size of one.
    final List<Long> regionSizes = Collections.emptyList();
    final Configuration conf = getDefaultHBaseConfiguration();
    final HRegionServer rs = mockRegionServer(conf);
    final FileSystemUtilizationChore chore = new FileSystemUtilizationChore(rs);
    doAnswer(new ExpectedRegionSizeSummationAnswer(sum(regionSizes))).when(rs)
      .reportRegionSizesForQuotas(any(RegionSizeStore.class));

    final Region region = mockRegionWithSize(regionSizes);
    doReturn(Arrays.asList(region)).when(rs).getRegions();
    chore.chore();
  }",1
"@Test
  public void testProcessingLeftoverRegions() {
    final Configuration conf = getDefaultHBaseConfiguration();
    final HRegionServer rs = mockRegionServer(conf);

    // Some leftover regions from a previous chore()
    final List<Long> leftover1Sizes = Arrays.asList(1024L, 4096L);
    final long leftover1Sum = sum(leftover1Sizes);
    final List<Long> leftover2Sizes = Arrays.asList(2048L);
    final long leftover2Sum = sum(leftover2Sizes);

    final Region lr1 = mockRegionWithSize(leftover1Sizes);
    final Region lr2 = mockRegionWithSize(leftover2Sizes);
    final FileSystemUtilizationChore chore = new FileSystemUtilizationChore(rs) {
      @Override
      Iterator<Region> getLeftoverRegions() {
        return Arrays.asList(lr1, lr2).iterator();
      }",1
"@Test
  public void testMergeSpace() throws IOException {
    TableName tn = TableName.valueOf(""foo"");
    QuotaProtos.Quotas quota = QuotaProtos.Quotas.newBuilder().setSpace(SPACE_QUOTA).build();

    GlobalQuotaSettingsImpl settings = new GlobalQuotaSettingsImpl(null, tn, null, null, quota);
    // Switch the violation policy to DISABLE
    GlobalQuotaSettingsImpl merged = settings
      .merge(new SpaceLimitSettings(tn, SPACE_QUOTA.getSoftLimit(), SpaceViolationPolicy.DISABLE));

    QuotaProtos.SpaceQuota mergedSpaceQuota = merged.getSpaceProto();
    assertEquals(SPACE_QUOTA.getSoftLimit(), mergedSpaceQuota.getSoftLimit());
    assertEquals(QuotaProtos.SpaceViolationPolicy.DISABLE, mergedSpaceQuota.getViolationPolicy());
  }",1
"@Test
  public void testNamespaceRPCQuotaRemoved() throws Exception {
    final Connection conn = TEST_UTIL.getConnection();
    final Admin admin = conn.getAdmin();
    final String ns = testName.getMethodName();
    // Drop the ns if it somehow exists
    if (namespaceExists(ns)) {
      admin.deleteNamespace(ns);
    }",1
"@Test
  public void testNamespaceSpaceAndRPCQuotaRemoved() throws Exception {
    final Connection conn = TEST_UTIL.getConnection();
    final Admin admin = conn.getAdmin();
    final String ns = testName.getMethodName();
    // Drop the ns if it somehow exists
    if (namespaceExists(ns)) {
      admin.deleteNamespace(ns);
    }",1
"@Test
  public void testNamespaceSpaceQuotaRemoved() throws Exception {
    final Connection conn = TEST_UTIL.getConnection();
    final Admin admin = conn.getAdmin();
    final String ns = testName.getMethodName();
    // Drop the ns if it somehow exists
    if (namespaceExists(ns)) {
      admin.deleteNamespace(ns);
    }",1
"@Test
  public void testTableSpaceQuotaRemoved() throws Exception {
    final Connection conn = TEST_UTIL.getConnection();
    final Admin admin = conn.getAdmin();
    final TableName tn = TableName.valueOf(testName.getMethodName());
    // Drop the table if it somehow exists
    if (admin.tableExists(tn)) {
      dropTable(admin, tn);
    }",1
"@Test
  public void testSpaceLimitSettings() {
    final TableName tableName = TableName.valueOf(""foo"");
    final long sizeLimit = 1024L * 1024L * 1024L * 75; // 75GB
    final SpaceViolationPolicy violationPolicy = SpaceViolationPolicy.NO_INSERTS;
    QuotaSettings settings =
      QuotaSettingsFactory.limitTableSpace(tableName, sizeLimit, violationPolicy);
    assertNotNull(""QuotaSettings should not be null"", settings);
    assertTrue(""Should be an instance of SpaceLimitSettings"",
      settings instanceof SpaceLimitSettings);
    SpaceLimitSettings spaceLimitSettings = (SpaceLimitSettings) settings;
    SpaceLimitRequest protoRequest = spaceLimitSettings.getProto();
    assertTrue(""Request should have a SpaceQuota"", protoRequest.hasQuota());
    SpaceQuota quota = protoRequest.getQuota();
    assertEquals(sizeLimit, quota.getSoftLimit());
    assertEquals(violationPolicy, ProtobufUtil.toViolationPolicy(quota.getViolationPolicy()));
    assertFalse(""The remove attribute should be false"", quota.getRemove());
  }",1
"@Test
  public void testQuotaStateUpdateGlobalThrottle() {
    final int NUM_GLOBAL_THROTTLE_1 = 3;
    final int NUM_GLOBAL_THROTTLE_2 = 11;
    final long LAST_UPDATE_1 = 10;
    final long LAST_UPDATE_2 = 20;
    final long LAST_UPDATE_3 = 30;

    QuotaState quotaInfo = new QuotaState();
    assertEquals(0, quotaInfo.getLastUpdate());
    assertTrue(quotaInfo.isBypass());

    // Add global throttle
    QuotaState otherQuotaState = new QuotaState(LAST_UPDATE_1);
    otherQuotaState.setQuotas(buildReqNumThrottle(NUM_GLOBAL_THROTTLE_1));
    assertEquals(LAST_UPDATE_1, otherQuotaState.getLastUpdate());
    assertFalse(otherQuotaState.isBypass());

    quotaInfo.update(otherQuotaState);
    assertEquals(LAST_UPDATE_1, quotaInfo.getLastUpdate());
    assertFalse(quotaInfo.isBypass());
    assertThrottleException(quotaInfo.getGlobalLimiter(), NUM_GLOBAL_THROTTLE_1);

    // Update global Throttle
    otherQuotaState = new QuotaState(LAST_UPDATE_2);
    otherQuotaState.setQuotas(buildReqNumThrottle(NUM_GLOBAL_THROTTLE_2));
    assertEquals(LAST_UPDATE_2, otherQuotaState.getLastUpdate());
    assertFalse(otherQuotaState.isBypass());

    quotaInfo.update(otherQuotaState);
    assertEquals(LAST_UPDATE_2, quotaInfo.getLastUpdate());
    assertFalse(quotaInfo.isBypass());
    assertThrottleException(quotaInfo.getGlobalLimiter(),
      NUM_GLOBAL_THROTTLE_2 - NUM_GLOBAL_THROTTLE_1);

    // Remove global throttle
    otherQuotaState = new QuotaState(LAST_UPDATE_3);
    assertEquals(LAST_UPDATE_3, otherQuotaState.getLastUpdate());
    assertTrue(otherQuotaState.isBypass());

    quotaInfo.update(otherQuotaState);
    assertEquals(LAST_UPDATE_3, quotaInfo.getLastUpdate());
    assertTrue(quotaInfo.isBypass());
    assertNoopLimiter(quotaInfo.getGlobalLimiter());
  }",1
"@Test
  public void testQuotaStateUpdateTableThrottle() {
    final TableName tableNameA = TableName.valueOf(name.getMethodName() + ""A"");
    final TableName tableNameB = TableName.valueOf(name.getMethodName() + ""B"");
    final TableName tableNameC = TableName.valueOf(name.getMethodName() + ""C"");
    final int TABLE_A_THROTTLE_1 = 3;
    final int TABLE_A_THROTTLE_2 = 11;
    final int TABLE_B_THROTTLE = 4;
    final int TABLE_C_THROTTLE = 5;
    final long LAST_UPDATE_1 = 10;
    final long LAST_UPDATE_2 = 20;
    final long LAST_UPDATE_3 = 30;

    UserQuotaState quotaInfo = new UserQuotaState();
    assertEquals(0, quotaInfo.getLastUpdate());
    assertTrue(quotaInfo.isBypass());

    // Add A B table limiters
    UserQuotaState otherQuotaState = new UserQuotaState(LAST_UPDATE_1);
    otherQuotaState.setQuotas(tableNameA, buildReqNumThrottle(TABLE_A_THROTTLE_1));
    otherQuotaState.setQuotas(tableNameB, buildReqNumThrottle(TABLE_B_THROTTLE));
    assertEquals(LAST_UPDATE_1, otherQuotaState.getLastUpdate());
    assertFalse(otherQuotaState.isBypass());

    quotaInfo.update(otherQuotaState);
    assertEquals(LAST_UPDATE_1, quotaInfo.getLastUpdate());
    assertFalse(quotaInfo.isBypass());
    assertThrottleException(quotaInfo.getTableLimiter(tableNameA), TABLE_A_THROTTLE_1);
    assertThrottleException(quotaInfo.getTableLimiter(tableNameB), TABLE_B_THROTTLE);
    assertNoopLimiter(quotaInfo.getTableLimiter(tableNameC));

    // Add C, Remove B, Update A table limiters
    otherQuotaState = new UserQuotaState(LAST_UPDATE_2);
    otherQuotaState.setQuotas(tableNameA, buildReqNumThrottle(TABLE_A_THROTTLE_2));
    otherQuotaState.setQuotas(tableNameC, buildReqNumThrottle(TABLE_C_THROTTLE));
    assertEquals(LAST_UPDATE_2, otherQuotaState.getLastUpdate());
    assertFalse(otherQuotaState.isBypass());

    quotaInfo.update(otherQuotaState);
    assertEquals(LAST_UPDATE_2, quotaInfo.getLastUpdate());
    assertFalse(quotaInfo.isBypass());
    assertThrottleException(quotaInfo.getTableLimiter(tableNameA),
      TABLE_A_THROTTLE_2 - TABLE_A_THROTTLE_1);
    assertThrottleException(quotaInfo.getTableLimiter(tableNameC), TABLE_C_THROTTLE);
    assertNoopLimiter(quotaInfo.getTableLimiter(tableNameB));

    // Remove table limiters
    otherQuotaState = new UserQuotaState(LAST_UPDATE_3);
    assertEquals(LAST_UPDATE_3, otherQuotaState.getLastUpdate());
    assertTrue(otherQuotaState.isBypass());

    quotaInfo.update(otherQuotaState);
    assertEquals(LAST_UPDATE_3, quotaInfo.getLastUpdate());
    assertTrue(quotaInfo.isBypass());
    assertNoopLimiter(quotaInfo.getTableLimiter(UNKNOWN_TABLE_NAME));
  }",1
"@Test
  public void testTableThrottleWithBatch() {
    final TableName TABLE_A = TableName.valueOf(""TableA"");
    final int TABLE_A_THROTTLE_1 = 3;
    final long LAST_UPDATE_1 = 10;

    UserQuotaState quotaInfo = new UserQuotaState();
    assertEquals(0, quotaInfo.getLastUpdate());
    assertTrue(quotaInfo.isBypass());

    // Add A table limiters
    UserQuotaState otherQuotaState = new UserQuotaState(LAST_UPDATE_1);
    otherQuotaState.setQuotas(TABLE_A, buildReqNumThrottle(TABLE_A_THROTTLE_1));
    assertEquals(LAST_UPDATE_1, otherQuotaState.getLastUpdate());
    assertFalse(otherQuotaState.isBypass());

    quotaInfo.update(otherQuotaState);
    assertEquals(LAST_UPDATE_1, quotaInfo.getLastUpdate());
    assertFalse(quotaInfo.isBypass());
    QuotaLimiter limiter = quotaInfo.getTableLimiter(TABLE_A);
    try {
      limiter.checkQuota(TABLE_A_THROTTLE_1 + 1, TABLE_A_THROTTLE_1 + 1, 0, 0, 1, 0);
      fail(""Should have thrown RpcThrottlingException"");
    }",1
"@Test
  public void testNamespaceQuotaUtil() throws Exception {
    final String namespace = ""testNamespaceQuotaUtilNS"";

    Quotas quota = Quotas.newBuilder()
      .setThrottle(Throttle.newBuilder()
        .setReqNum(ProtobufUtil.toTimedQuota(1000, TimeUnit.SECONDS, QuotaScope.MACHINE))
        .setWriteNum(ProtobufUtil.toTimedQuota(600, TimeUnit.SECONDS, QuotaScope.MACHINE))
        .setReadSize(ProtobufUtil.toTimedQuota(8192, TimeUnit.SECONDS, QuotaScope.MACHINE)).build())
      .build();

    // Add user quota and verify it
    QuotaUtil.addNamespaceQuota(this.connection, namespace, quota);
    Quotas resQuota = QuotaUtil.getNamespaceQuota(this.connection, namespace);
    assertEquals(quota, resQuota);

    // Remove user quota and verify it
    QuotaUtil.deleteNamespaceQuota(this.connection, namespace);
    resQuota = QuotaUtil.getNamespaceQuota(this.connection, namespace);
    assertEquals(null, resQuota);
  }",1
"@Test
  public void testBucketingFilesToSnapshots() throws Exception {
    // Create a table and set a quota
    TableName tn1 = helper.createTableWithRegions(1);
    admin.setQuota(QuotaSettingsFactory.limitTableSpace(tn1, SpaceQuotaHelperForTests.ONE_GIGABYTE,
      SpaceViolationPolicy.NO_INSERTS));

    // Write some data and flush it
    helper.writeData(tn1, 256L * SpaceQuotaHelperForTests.ONE_KILOBYTE);
    admin.flush(tn1);

    final AtomicReference<Long> lastSeenSize = new AtomicReference<>();
    // Wait for the Master chore to run to see the usage (with a fudge factor)
    TEST_UTIL.waitFor(30_000, new SpaceQuotaSnapshotPredicate(conn, tn1) {
      @Override
      boolean evaluate(SpaceQuotaSnapshot snapshot) throws Exception {
        lastSeenSize.set(snapshot.getUsage());
        return snapshot.getUsage() > 230L * SpaceQuotaHelperForTests.ONE_KILOBYTE;
      }",1
"@Test
  public void testSnapshotsFromNamespaces() throws Exception {
    NamespaceDescriptor ns = NamespaceDescriptor.create(""snapshots_from_namespaces"").build();
    admin.createNamespace(ns);

    TableName tn1 = helper.createTableWithRegions(ns.getName(), 1);
    TableName tn2 = helper.createTableWithRegions(ns.getName(), 1);
    TableName tn3 = helper.createTableWithRegions(1);

    // Set a throttle quota on 'default' namespace
    admin.setQuota(QuotaSettingsFactory.throttleNamespace(tn3.getNamespaceAsString(),
      ThrottleType.WRITE_NUMBER, 100, TimeUnit.SECONDS));
    // Set a user throttle quota
    admin.setQuota(
      QuotaSettingsFactory.throttleUser(""user"", ThrottleType.WRITE_NUMBER, 100, TimeUnit.MINUTES));

    // Set a space quota on the namespace
    admin.setQuota(QuotaSettingsFactory.limitNamespaceSpace(ns.getName(),
      SpaceQuotaHelperForTests.ONE_GIGABYTE, SpaceViolationPolicy.NO_INSERTS));

    // Create snapshots on each table (we didn't write any data, so just skipflush)
    admin.snapshot(new SnapshotDescription(tn1.getQualifierAsString() + ""snapshot"", tn1,
      SnapshotType.SKIPFLUSH));
    admin.snapshot(new SnapshotDescription(tn2.getQualifierAsString() + ""snapshot"", tn2,
      SnapshotType.SKIPFLUSH));
    admin.snapshot(new SnapshotDescription(tn3.getQualifierAsString() + ""snapshot"", tn3,
      SnapshotType.SKIPFLUSH));

    Multimap<TableName, String> mapping = testChore.getSnapshotsToComputeSize();
    assertEquals(2, mapping.size());
    assertEquals(1, mapping.get(tn1).size());
    assertEquals(tn1.getQualifierAsString() + ""snapshot"", mapping.get(tn1).iterator().next());
    assertEquals(1, mapping.get(tn2).size());
    assertEquals(tn2.getQualifierAsString() + ""snapshot"", mapping.get(tn2).iterator().next());

    admin.snapshot(new SnapshotDescription(tn2.getQualifierAsString() + ""snapshot1"", tn2,
      SnapshotType.SKIPFLUSH));
    admin.snapshot(new SnapshotDescription(tn3.getQualifierAsString() + ""snapshot2"", tn3,
      SnapshotType.SKIPFLUSH));

    mapping = testChore.getSnapshotsToComputeSize();
    assertEquals(3, mapping.size());
    assertEquals(1, mapping.get(tn1).size());
    assertEquals(tn1.getQualifierAsString() + ""snapshot"", mapping.get(tn1).iterator().next());
    assertEquals(2, mapping.get(tn2).size());
    assertEquals(new HashSet<String>(Arrays.asList(tn2.getQualifierAsString() + ""snapshot"",
      tn2.getQualifierAsString() + ""snapshot1"")), mapping.get(tn2));
  }",1
"@Test
  public void testSnapshotSize() throws Exception {
    // Create a table and set a quota
    TableName tn1 = helper.createTableWithRegions(5);
    admin.setQuota(QuotaSettingsFactory.limitTableSpace(tn1, SpaceQuotaHelperForTests.ONE_GIGABYTE,
      SpaceViolationPolicy.NO_INSERTS));

    // Write some data and flush it
    helper.writeData(tn1, 256L * SpaceQuotaHelperForTests.ONE_KILOBYTE);
    admin.flush(tn1);

    final long snapshotSize = TEST_UTIL.getMiniHBaseCluster().getRegions(tn1).stream()
      .flatMap(r -> r.getStores().stream()).mapToLong(HStore::getHFilesSize).sum();

    // Wait for the Master chore to run to see the usage (with a fudge factor)
    TEST_UTIL.waitFor(30_000, new SpaceQuotaSnapshotPredicate(conn, tn1) {
      @Override
      boolean evaluate(SpaceQuotaSnapshot snapshot) throws Exception {
        return snapshot.getUsage() == snapshotSize;
      }",1
"@Test
  public void testSanityCheckMinVersion() throws IOException {
    error.expect(DoNotRetryIOException.class);
    error.expectMessage(""MIN_VERSION > 0 is not supported for FIFO compaction"");
    TableName tableName = TableName.valueOf(getClass().getSimpleName() + ""-MinVersion"");
    TableDescriptor desc = TableDescriptorBuilder.newBuilder(tableName)
      .setValue(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY,
        FIFOCompactionPolicy.class.getName())
      .setValue(HConstants.HBASE_REGION_SPLIT_POLICY_KEY, DisabledRegionSplitPolicy.class.getName())
      .setColumnFamily(
        ColumnFamilyDescriptorBuilder.newBuilder(family).setTimeToLive(1).setMinVersions(1).build())
      .build();
    TEST_UTIL.getAdmin().createTable(desc);
  }",1
"@Test
  public void testSingleStripeDropDeletes() throws Exception {
    Configuration conf = HBaseConfiguration.create();
    // Test depends on this not being set to pass. Default breaks test. TODO: Revisit.
    conf.unset(""hbase.hstore.compaction.min.size"");
    StripeCompactionPolicy policy = createPolicy(conf);
    // Verify the deletes can be dropped if there are no L0 files.
    Long[][] stripes = new Long[][] { new Long[] { 3L, 2L, 2L, 2L }",1
"@Test
  public void testMaxVersionMask() {
    NewVersionBehaviorTracker tracker =
      new NewVersionBehaviorTracker(null, comparator, 1, 3, 3, 10000);

    KeyValue keyValue = new KeyValue(row, family, col1, 20000, KeyValue.Type.Put, value);
    keyValue.setTimestamp(20000);
    keyValue.setSequenceId(1000);
    assertEquals(DeleteResult.NOT_DELETED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19999);
    keyValue.setSequenceId(999);
    assertEquals(DeleteResult.NOT_DELETED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19999);
    keyValue.setSequenceId(998);
    assertEquals(DeleteResult.VERSION_MASKED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19998);
    keyValue.setSequenceId(997);
    assertEquals(DeleteResult.NOT_DELETED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19997);
    keyValue.setSequenceId(996);
    assertEquals(DeleteResult.VERSION_MASKED, tracker.isDeleted(keyValue));

    keyValue = new KeyValue(row, family, col2, 20000, KeyValue.Type.Put, value);
    keyValue.setTimestamp(20000);
    keyValue.setSequenceId(1000);
    assertEquals(DeleteResult.NOT_DELETED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19999);
    keyValue.setSequenceId(1002);
    assertEquals(DeleteResult.NOT_DELETED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19999);
    keyValue.setSequenceId(1001);
    assertEquals(DeleteResult.VERSION_MASKED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19998);
    keyValue.setSequenceId(1003);
    assertEquals(DeleteResult.NOT_DELETED, tracker.isDeleted(keyValue));
    keyValue.setTimestamp(19997);
    keyValue.setSequenceId(1004);
    assertEquals(DeleteResult.VERSION_MASKED, tracker.isDeleted(keyValue));
  }",1
"@Test
  public void testVersionsDelete() {
    NewVersionBehaviorTracker tracker =
      new NewVersionBehaviorTracker(null, comparator, 1, 3, 3, 10000);
    KeyValue put = new KeyValue(row, family, col1, 20000, KeyValue.Type.Put, value);
    KeyValue delete = new KeyValue(row, family, col1, 20000, KeyValue.Type.DeleteColumn, value);
    delete.setSequenceId(1000);
    delete.setTimestamp(20000);
    tracker.add(delete);
    put.setSequenceId(1001);
    put.setTimestamp(19999);
    assertEquals(DeleteResult.NOT_DELETED, tracker.isDeleted(put));
    put.setSequenceId(999);
    put.setTimestamp(19998);
    assertEquals(DeleteResult.COLUMN_DELETED, tracker.isDeleted(put));

    delete = new KeyValue(row, family, col2, 20000, KeyValue.Type.DeleteColumn, value);
    delete.setSequenceId(1002);
    delete.setTimestamp(20000);
    tracker.add(delete);
    put = new KeyValue(row, family, col2, 20000, KeyValue.Type.Put, value);
    put.setSequenceId(1001);
    put.setTimestamp(19999);
    assertEquals(DeleteResult.COLUMN_DELETED, tracker.isDeleted(put));
    put.setSequenceId(999);
    put.setTimestamp(19998);
    assertEquals(DeleteResult.COLUMN_DELETED, tracker.isDeleted(put));
  }",1
"@Test
  public void testDeleteKeepDelete() {
    byte[] qualifier = Bytes.toBytes(""qualifier"");
    KeyValue kv = new KeyValue(Bytes.toBytes(""row""), Bytes.toBytes(""f""), qualifier, timestamp,
      KeyValue.Type.Delete);
    sdt.add(kv);
    sdt.isDeleted(kv);
    assertEquals(false, sdt.isEmpty());
  }",1
"@Test
  public void DisabledTestCheckColumnWrongOrder() {
    ScanWildcardColumnTracker tracker =
      new ScanWildcardColumnTracker(0, VERSIONS, Long.MIN_VALUE, CellComparatorImpl.COMPARATOR);

    // Create list of qualifiers
    List<byte[]> qualifiers = new ArrayList<>(2);
    qualifiers.add(Bytes.toBytes(""qualifier2""));
    qualifiers.add(Bytes.toBytes(""qualifier1""));

    try {
      for (byte[] qualifier : qualifiers) {
        ScanQueryMatcher.checkColumn(tracker, qualifier, 0, qualifier.length, 1,
          KeyValue.Type.Put.getCode(), false);
      }",1
"@Test
  public void testMatch_Wildcard() throws IOException {
    // Moving up from the Tracker by using Gets and List<KeyValue> instead
    // of just byte []

    // Expected result
    List<MatchCode> expected = new ArrayList<>(6);
    expected.add(ScanQueryMatcher.MatchCode.INCLUDE);
    expected.add(ScanQueryMatcher.MatchCode.INCLUDE);
    expected.add(ScanQueryMatcher.MatchCode.INCLUDE);
    expected.add(ScanQueryMatcher.MatchCode.INCLUDE);
    expected.add(ScanQueryMatcher.MatchCode.INCLUDE);
    expected.add(ScanQueryMatcher.MatchCode.DONE);

    long now = EnvironmentEdgeManager.currentTime();
    UserScanQueryMatcher qm = UserScanQueryMatcher.create(scan, new ScanInfo(this.conf, fam2, 0, 1,
      ttl, KeepDeletedCells.FALSE, HConstants.DEFAULT_BLOCKSIZE, 0, rowComparator, false), null,
      now - ttl, now, null);

    List<KeyValue> memstore = new ArrayList<>(6);
    memstore.add(new KeyValue(row1, fam2, col1, 1, data));
    memstore.add(new KeyValue(row1, fam2, col2, 1, data));
    memstore.add(new KeyValue(row1, fam2, col3, 1, data));
    memstore.add(new KeyValue(row1, fam2, col4, 1, data));
    memstore.add(new KeyValue(row1, fam2, col5, 1, data));
    memstore.add(new KeyValue(row2, fam1, col1, 1, data));

    List<ScanQueryMatcher.MatchCode> actual = new ArrayList<>(memstore.size());

    KeyValue k = memstore.get(0);
    qm.setToNewRow(k);

    for (KeyValue kv : memstore) {
      actual.add(qm.match(kv));
    }",1
"@Test
  public void testMatchWhenFilterReturnsIncludeAndSeekNextRow() throws IOException {
    List<MatchCode> expected = new ArrayList<>();
    expected.add(ScanQueryMatcher.MatchCode.INCLUDE_AND_SEEK_NEXT_ROW);
    expected.add(ScanQueryMatcher.MatchCode.DONE);

    Scan scanWithFilter = new Scan(scan).setFilter(new AlwaysIncludeAndSeekNextRowFilter());

    long now = EnvironmentEdgeManager.currentTime();

    // scan with column 2,4,5
    UserScanQueryMatcher qm = UserScanQueryMatcher.create(
      scanWithFilter, new ScanInfo(this.conf, fam2, 0, 1, ttl, KeepDeletedCells.FALSE,
        HConstants.DEFAULT_BLOCKSIZE, 0, rowComparator, false),
      get.getFamilyMap().get(fam2), now - ttl, now, null);

    List<KeyValue> memstore = new ArrayList<>();
    // ColumnTracker will return INCLUDE_AND_SEEK_NEXT_COL , and filter will return
    // INCLUDE_AND_SEEK_NEXT_ROW, so final match code will be INCLUDE_AND_SEEK_NEXT_ROW.
    memstore.add(new KeyValue(row1, fam2, col2, 1, data));
    memstore.add(new KeyValue(row2, fam1, col1, data));

    List<ScanQueryMatcher.MatchCode> actual = new ArrayList<>(memstore.size());
    KeyValue k = memstore.get(0);
    qm.setToNewRow(k);

    for (KeyValue kv : memstore) {
      actual.add(qm.match(kv));
    }",1
"@Test
  public void testRewritingClusterIdToPB() throws Exception {
    TEST_UTIL.startMiniZKCluster();
    TEST_UTIL.startMiniDFSCluster(1);
    TEST_UTIL.createRootDir();
    Path rootDir = CommonFSUtils.getRootDir(TEST_UTIL.getConfiguration());
    FileSystem fs = rootDir.getFileSystem(TEST_UTIL.getConfiguration());
    Path filePath = new Path(rootDir, HConstants.CLUSTER_ID_FILE_NAME);
    FSDataOutputStream s = null;
    try {
      s = fs.create(filePath);
      s.writeUTF(HBaseCommonTestingUtil.getRandomUUID().toString());
    }",1
"@Test
  public void testCompaction2Buckets() throws IOException {

    // set memstore to do basic structure flattening, the ""eager"" option is tested in
    // TestCompactingToCellFlatMapMemStore
    MemoryCompactionPolicy compactionType = MemoryCompactionPolicy.BASIC;
    memstore.getConfiguration().set(CompactingMemStore.COMPACTING_MEMSTORE_TYPE_KEY,
      String.valueOf(compactionType));
    memstore.getConfiguration().set(MemStoreCompactionStrategy.COMPACTING_MEMSTORE_THRESHOLD_KEY,
      String.valueOf(1));
    ((MyCompactingMemStore) memstore).initiateType(compactionType, memstore.getConfiguration());
    String[] keys1 = { ""A"", ""A"", ""B"", ""C"" }",1
"@Test
  public void testUpdateToTimeOfOldestEdit() throws Exception {
    try {
      EnvironmentEdgeForMemstoreTest edge = new EnvironmentEdgeForMemstoreTest();
      EnvironmentEdgeManager.injectEdge(edge);
      long t = memstore.timeOfOldestEdit();
      assertEquals(Long.MAX_VALUE, t);

      // test the case that the timeOfOldestEdit is updated after a KV add
      memstore.add(KeyValueTestUtil.create(""r"", ""f"", ""q"", 100, ""v""), null);
      t = memstore.timeOfOldestEdit();
      assertTrue(t == 1234);
      // The method will also assert
      // the value is reset to Long.MAX_VALUE
      t = runSnapshot(memstore, true);

      // test the case that the timeOfOldestEdit is updated after a KV delete
      memstore.add(KeyValueTestUtil.create(""r"", ""f"", ""q"", 100, KeyValue.Type.Delete, ""v""), null);
      t = memstore.timeOfOldestEdit();
      assertTrue(t == 1234);
      t = runSnapshot(memstore, true);

      // test the case that the timeOfOldestEdit is updated after a KV upsert
      List<ExtendedCell> l = new ArrayList<>();
      KeyValue kv1 = KeyValueTestUtil.create(""r"", ""f"", ""q"", 100, ""v"");
      kv1.setSequenceId(100);
      l.add(kv1);
      memstore.upsert(l, 1000, null);
      t = memstore.timeOfOldestEdit();
      assertTrue(t == 1234);
    }",1
"@Test
  public void testCreateKey() {
    byte[] row = Bytes.toBytes(""myRow"");
    byte[] qualifier = Bytes.toBytes(""myQualifier"");
    // Mimic what Storefile.createBloomKeyValue() does
    byte[] rowKey =
      KeyValueUtil.createFirstOnRow(row, 0, row.length, new byte[0], 0, 0, row, 0, 0).getKey();
    byte[] rowColKey = KeyValueUtil
      .createFirstOnRow(row, 0, row.length, new byte[0], 0, 0, qualifier, 0, qualifier.length)
      .getKey();
    KeyValue rowKV = KeyValueUtil.createKeyValueFromKey(rowKey);
    KeyValue rowColKV = KeyValueUtil.createKeyValueFromKey(rowColKey);
    assertEquals(rowKV.getTimestamp(), rowColKV.getTimestamp());
    assertEquals(
      Bytes.toStringBinary(rowKV.getRowArray(), rowKV.getRowOffset(), rowKV.getRowLength()), Bytes
        .toStringBinary(rowColKV.getRowArray(), rowColKV.getRowOffset(), rowColKV.getRowLength()));
    assertEquals(0, rowKV.getQualifierLength());
  }",1
"@Test
  public void testGetWithDeleteColumn() throws IOException {
    byte[] row = Bytes.toBytes(""testrow"");
    byte[] fam = Bytes.toBytes(""testfamily"");
    byte[] qf1 = Bytes.toBytes(""testqualifier"");
    byte[] val = Bytes.toBytes(""testval"");

    long ts1 = System.nanoTime();
    KeyValue put1 = new KeyValue(row, fam, qf1, ts1, val);
    long ts2 = ts1 + 1;
    KeyValue put2 = new KeyValue(row, fam, qf1, ts2, val);
    long ts3 = ts2 + 1;
    KeyValue put3 = new KeyValue(row, fam, qf1, ts3, val);
    memstore.add(put1, null);
    memstore.add(put2, null);
    memstore.add(put3, null);

    assertEquals(3, memstore.getActive().getCellsCount());

    KeyValue del2 = new KeyValue(row, fam, qf1, ts2, KeyValue.Type.DeleteColumn, val);
    memstore.add(del2, null);

    List<Cell> expected = new ArrayList<>();
    expected.add(put3);
    expected.add(del2);
    expected.add(put2);
    expected.add(put1);

    assertEquals(4, memstore.getActive().getCellsCount());
    int i = 0;
    for (Cell cell : memstore.getActive().getCellSet()) {
      assertEquals(expected.get(i++), cell);
    }",1
"@Test
  public void testKeepDeleteInmemstore() {
    byte[] row = Bytes.toBytes(""testrow"");
    byte[] fam = Bytes.toBytes(""testfamily"");
    byte[] qf = Bytes.toBytes(""testqualifier"");
    byte[] val = Bytes.toBytes(""testval"");
    long ts = System.nanoTime();
    memstore.add(new KeyValue(row, fam, qf, ts, val), null);
    KeyValue delete = new KeyValue(row, fam, qf, ts, KeyValue.Type.Delete, val);
    memstore.add(delete, null);
    assertEquals(2, memstore.getActive().getCellsCount());
    assertEquals(delete, memstore.getActive().first());
  }",1
"@Test
  public void testMemstoreDeletesVisibilityWithSameKey() throws IOException {
    final byte[] row = Bytes.toBytes(1);
    final byte[] f = Bytes.toBytes(""family"");
    final byte[] q1 = Bytes.toBytes(""q1"");
    final byte[] q2 = Bytes.toBytes(""q2"");
    final byte[] v1 = Bytes.toBytes(""value1"");
    // INSERT 1: Write both columns val1
    MultiVersionConcurrencyControl.WriteEntry w = mvcc.begin();

    KeyValue kv11 = new KeyValue(row, f, q1, v1);
    kv11.setSequenceId(w.getWriteNumber());
    memstore.add(kv11, null);

    KeyValue kv12 = new KeyValue(row, f, q2, v1);
    kv12.setSequenceId(w.getWriteNumber());
    memstore.add(kv12, null);
    mvcc.completeAndWait(w);

    // BEFORE STARTING INSERT 2, SEE FIRST KVS
    KeyValueScanner s = this.memstore.getScanners(mvcc.getReadPoint()).get(0);
    assertScannerResults(s, new KeyValue[] { kv11, kv12 }",1
"@Test
  public void testReadOwnWritesUnderConcurrency() throws Throwable {
    int NUM_THREADS = 8;

    ReadOwnWritesTester threads[] = new ReadOwnWritesTester[NUM_THREADS];
    AtomicReference<Throwable> caught = new AtomicReference<>();

    for (int i = 0; i < NUM_THREADS; i++) {
      threads[i] = new ReadOwnWritesTester(i, memstore, mvcc, caught);
      threads[i].start();
    }",1
"@Test
  public void testRetainsDeleteFamily() throws IOException {
    // add a put to memstore
    memstore.add(KeyValueTestUtil.create(""row1"", ""fam"", ""a"", 100, ""dont-care""), null);

    // now process a specific delete:
    KeyValue delete =
      KeyValueTestUtil.create(""row1"", ""fam"", ""a"", 100, KeyValue.Type.DeleteFamily, ""dont-care"");
    memstore.add(delete, null);

    assertEquals(2, memstore.getActive().getCellsCount());
    assertEquals(delete, memstore.getActive().first());
  }",1
"@Test
  public void testShouldFlushMeta() throws Exception {
    // write an edit in the META and ensure the shouldFlush (that the periodic memstore
    // flusher invokes) returns true after SYSTEM_CACHE_FLUSH_INTERVAL (even though
    // the MEMSTORE_PERIODIC_FLUSH_INTERVAL is set to a higher value)
    Configuration conf = new Configuration();
    conf.setInt(HRegion.MEMSTORE_PERIODIC_FLUSH_INTERVAL, HRegion.SYSTEM_CACHE_FLUSH_INTERVAL * 10);
    HBaseTestingUtil hbaseUtility = new HBaseTestingUtil(conf);
    Path testDir = hbaseUtility.getDataTestDir();
    EnvironmentEdgeForMemstoreTest edge = new EnvironmentEdgeForMemstoreTest();
    EnvironmentEdgeManager.injectEdge(edge);
    edge.setCurrentTimeMillis(1234);
    WALFactory wFactory = new WALFactory(conf, ""1234"");
    TableDescriptors tds = new FSTableDescriptors(conf);
    FSTableDescriptors.tryUpdateMetaTableDescriptor(conf);
    HRegion meta = HRegion.createHRegion(RegionInfoBuilder.FIRST_META_REGIONINFO, testDir, conf,
      tds.get(TableName.META_TABLE_NAME), wFactory.getWAL(RegionInfoBuilder.FIRST_META_REGIONINFO));
    // parameterized tests add [#] suffix get rid of [ and ].
    TableDescriptor desc = TableDescriptorBuilder
      .newBuilder(TableName.valueOf(name.getMethodName().replaceAll(""[\\[\\]]"", ""_"")))
      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(""foo"")).build();
    RegionInfo hri = RegionInfoBuilder.newBuilder(desc.getTableName())
      .setStartKey(Bytes.toBytes(""row_0200"")).setEndKey(Bytes.toBytes(""row_0300"")).build();
    HRegion r = HRegion.createHRegion(hri, testDir, conf, desc, wFactory.getWAL(hri));
    addRegionToMETA(meta, r);
    edge.setCurrentTimeMillis(1234 + 100);
    StringBuilder sb = new StringBuilder();
    assertTrue(meta.shouldFlush(sb) == false);
    edge.setCurrentTimeMillis(edge.currentTime() + HRegion.SYSTEM_CACHE_FLUSH_INTERVAL + 1);
    assertTrue(meta.shouldFlush(sb) == true);
  }",1
"@Test
  public void testUpdateToTimeOfOldestEdit() throws Exception {
    try {
      EnvironmentEdgeForMemstoreTest edge = new EnvironmentEdgeForMemstoreTest();
      EnvironmentEdgeManager.injectEdge(edge);
      DefaultMemStore memstore = new DefaultMemStore();
      long t = memstore.timeOfOldestEdit();
      assertEquals(Long.MAX_VALUE, t);

      // test the case that the timeOfOldestEdit is updated after a KV add
      memstore.add(KeyValueTestUtil.create(""r"", ""f"", ""q"", 100, ""v""), null);
      t = memstore.timeOfOldestEdit();
      assertTrue(t == 1234);
      // snapshot() will reset timeOfOldestEdit. The method will also assert the
      // value is reset to Long.MAX_VALUE
      t = runSnapshot(memstore);

      // test the case that the timeOfOldestEdit is updated after a KV delete
      memstore.add(KeyValueTestUtil.create(""r"", ""f"", ""q"", 100, KeyValue.Type.Delete, ""v""), null);
      t = memstore.timeOfOldestEdit();
      assertTrue(t == 1234);
      t = runSnapshot(memstore);

      // test the case that the timeOfOldestEdit is updated after a KV upsert
      List<ExtendedCell> l = new ArrayList<>();
      KeyValue kv1 = KeyValueTestUtil.create(""r"", ""f"", ""q"", 100, ""v"");
      kv1.setSequenceId(100);
      l.add(kv1);
      memstore.upsert(l, 1000, null);
      t = memstore.timeOfOldestEdit();
      assertTrue(t == 1234);
    }",1
"@Test
  public void testCustomParts() throws Exception {
    Configuration conf = HBaseConfiguration.create();
    conf.set(DefaultStoreEngine.DEFAULT_COMPACTOR_CLASS_KEY, DummyCompactor.class.getName());
    conf.set(DefaultStoreEngine.DEFAULT_COMPACTION_POLICY_CLASS_KEY,
      DummyCompactionPolicy.class.getName());
    conf.set(DefaultStoreEngine.DEFAULT_STORE_FLUSHER_CLASS_KEY, DummyStoreFlusher.class.getName());
    HRegion mockRegion = Mockito.mock(HRegion.class);
    HStore mockStore = Mockito.mock(HStore.class);
    mockStore.conf = conf;
    Mockito.when(mockStore.getRegionInfo()).thenReturn(RegionInfoBuilder.FIRST_META_REGIONINFO);
    Mockito.when(mockStore.getHRegion()).thenReturn(mockRegion);
    StoreEngine<?, ?, ?, ?> se = StoreEngine.create(mockStore, conf, CellComparatorImpl.COMPARATOR);
    Assert.assertTrue(se instanceof DefaultStoreEngine);
    Assert.assertTrue(se.getCompactionPolicy() instanceof DummyCompactionPolicy);
    Assert.assertTrue(se.getStoreFlusher() instanceof DummyStoreFlusher);
    Assert.assertTrue(se.getCompactor() instanceof DummyCompactor);
  }",1
"@Test
  public void testPluggingInHeapMemoryTuner() throws Exception {
    BlockCacheStub blockCache = new BlockCacheStub((long) (maxHeapSize * 0.4));
    MemstoreFlusherStub memStoreFlusher = new MemstoreFlusherStub((long) (maxHeapSize * 0.4));
    Configuration conf = HBaseConfiguration.create();
    conf.setFloat(HeapMemoryManager.MEMSTORE_SIZE_MAX_RANGE_KEY, 0.78f);
    conf.setFloat(HeapMemoryManager.MEMSTORE_SIZE_MIN_RANGE_KEY, 0.05f);
    conf.setFloat(HeapMemoryManager.BLOCK_CACHE_SIZE_MAX_RANGE_KEY, 0.75f);
    conf.setFloat(HeapMemoryManager.BLOCK_CACHE_SIZE_MIN_RANGE_KEY, 0.02f);
    conf.setLong(HeapMemoryManager.HBASE_RS_HEAP_MEMORY_TUNER_PERIOD, 1000);
    conf.setInt(DefaultHeapMemoryTuner.NUM_PERIODS_TO_IGNORE, 0);
    conf.setClass(HeapMemoryManager.HBASE_RS_HEAP_MEMORY_TUNER_CLASS, CustomHeapMemoryTuner.class,
      HeapMemoryTuner.class);
    // Let the system start with default values for memstore heap and block cache size.
    HeapMemoryManager heapMemoryManager = new HeapMemoryManager(blockCache, memStoreFlusher,
      new RegionServerStub(conf), new RegionServerAccountingStub(conf));
    final ChoreService choreService = new ChoreService(""TEST_SERVER_NAME"");
    heapMemoryManager.start(choreService);
    // Now we wants to be in write mode. Set bigger memstore size from CustomHeapMemoryTuner
    CustomHeapMemoryTuner.memstoreSize = 0.78f;
    CustomHeapMemoryTuner.blockCacheSize = 0.02f;
    // Allow the tuner to run once and do necessary memory up
    waitForTune(memStoreFlusher, memStoreFlusher.memstoreSize);
    assertHeapSpace(0.78f, memStoreFlusher.memstoreSize);// Memstore
    assertHeapSpace(0.02f, blockCache.maxSize);// BlockCache
    // Now we wants to be in read mode. Set bigger memstore size from CustomHeapMemoryTuner
    CustomHeapMemoryTuner.blockCacheSize = 0.75f;
    CustomHeapMemoryTuner.memstoreSize = 0.05f;
    // Allow the tuner to run once and do necessary memory up
    waitForTune(memStoreFlusher, memStoreFlusher.memstoreSize);
    assertHeapSpace(0.75f, blockCache.maxSize);// BlockCache
    assertHeapSpace(0.05f, memStoreFlusher.memstoreSize);// Memstore
  }",1
"@Test
  public void testWhenCombinedHeapSizesFromTunerGoesOutSideMaxLimit() throws Exception {
    BlockCacheStub blockCache = new BlockCacheStub((long) (maxHeapSize * 0.4));
    MemstoreFlusherStub memStoreFlusher = new MemstoreFlusherStub((long) (maxHeapSize * 0.4));
    Configuration conf = HBaseConfiguration.create();
    conf.setFloat(HeapMemoryManager.MEMSTORE_SIZE_MAX_RANGE_KEY, 0.7f);
    conf.setFloat(HeapMemoryManager.MEMSTORE_SIZE_MIN_RANGE_KEY, 0.1f);
    conf.setFloat(HeapMemoryManager.BLOCK_CACHE_SIZE_MAX_RANGE_KEY, 0.7f);
    conf.setFloat(HeapMemoryManager.BLOCK_CACHE_SIZE_MIN_RANGE_KEY, 0.1f);
    conf.setLong(HeapMemoryManager.HBASE_RS_HEAP_MEMORY_TUNER_PERIOD, 1000);
    conf.setInt(DefaultHeapMemoryTuner.NUM_PERIODS_TO_IGNORE, 0);
    conf.setClass(HeapMemoryManager.HBASE_RS_HEAP_MEMORY_TUNER_CLASS, CustomHeapMemoryTuner.class,
      HeapMemoryTuner.class);
    HeapMemoryManager heapMemoryManager = new HeapMemoryManager(blockCache, memStoreFlusher,
      new RegionServerStub(conf), new RegionServerAccountingStub(conf));
    long oldMemstoreSize = memStoreFlusher.memstoreSize;
    long oldBlockCacheSize = blockCache.maxSize;
    final ChoreService choreService = new ChoreService(""TEST_SERVER_NAME"");
    heapMemoryManager.start(choreService);
    CustomHeapMemoryTuner.memstoreSize = 0.7f;
    CustomHeapMemoryTuner.blockCacheSize = 0.3f;
    // Allow the tuner to run once and do necessary memory up
    Thread.sleep(1500);
    assertEquals(oldMemstoreSize, memStoreFlusher.memstoreSize);
    assertEquals(oldBlockCacheSize, blockCache.maxSize);
  }",1
"@Test
  public void testGetFromMemStore() throws IOException {
    final Configuration conf = HBaseConfiguration.create();
    init(name.getMethodName(), conf, false);

    // Put data in memstore
    this.store.add(new KeyValue(row, family, qf1, 1, value), null);
    this.store.add(new KeyValue(row, family, qf2, 1, value), null);
    this.store.add(new KeyValue(row, family, qf3, 1, value), null);
    this.store.add(new KeyValue(row, family, qf4, 1, value), null);
    this.store.add(new KeyValue(row, family, qf5, 1, value), null);
    this.store.add(new KeyValue(row, family, qf6, 1, value), null);

    Scan scan = new Scan(get);
    InternalScanner scanner = (InternalScanner) store.getScanner(scan,
      scan.getFamilyMap().get(store.getColumnFamilyDescriptor().getName()), 0);

    List<Cell> results = new ArrayList<>();
    scanner.next(results);
    Collections.sort(results, CellComparatorImpl.COMPARATOR);
    scanner.close();

    // Compare
    Assert.assertEquals(expected.size(), results.size());
    for (int i = 0; i < results.size(); i++) {
      // Verify the values
      Assert.assertEquals(expected.get(i), results.get(i));
    }",1
"@Test
  public void testMOBStoreEncryption() throws Exception {
    final Configuration conf = TEST_UTIL.getConfiguration();

    conf.set(HConstants.CRYPTO_KEYPROVIDER_CONF_KEY, MockAesKeyProvider.class.getName());
    conf.set(HConstants.CRYPTO_MASTERKEY_NAME_CONF_KEY, ""hbase"");
    byte[] keyBytes = new byte[AES.KEY_LENGTH];
    Bytes.secureRandom(keyBytes);
    String algorithm = conf.get(HConstants.CRYPTO_KEY_ALGORITHM_CONF_KEY, HConstants.CIPHER_AES);
    Key cfKey = new SecretKeySpec(keyBytes, algorithm);

    ColumnFamilyDescriptor cfd = ColumnFamilyDescriptorBuilder.newBuilder(family)
      .setMobEnabled(true).setMobThreshold(100).setMaxVersions(4).setEncryptionType(algorithm)
      .setEncryptionKey(EncryptionUtil.wrapKey(conf,
        conf.get(HConstants.CRYPTO_MASTERKEY_NAME_CONF_KEY, User.getCurrent().getShortName()),
        cfKey))
      .build();
    init(name.getMethodName(), conf, cfd, false);

    this.store.add(new KeyValue(row, family, qf1, 1, value), null);
    this.store.add(new KeyValue(row, family, qf2, 1, value), null);
    this.store.add(new KeyValue(row, family, qf3, 1, value), null);
    flush(1);

    this.store.add(new KeyValue(row, family, qf4, 1, value), null);
    this.store.add(new KeyValue(row, family, qf5, 1, value), null);
    this.store.add(new KeyValue(row, family, qf6, 1, value), null);
    flush(2);

    Collection<HStoreFile> storefiles = this.store.getStorefiles();
    checkMobHFileEncrytption(storefiles);

    // Scan the values
    Scan scan = new Scan(get);
    InternalScanner scanner = (InternalScanner) store.getScanner(scan,
      scan.getFamilyMap().get(store.getColumnFamilyDescriptor().getName()), 0);

    List<Cell> results = new ArrayList<>();
    scanner.next(results);
    Collections.sort(results, CellComparatorImpl.COMPARATOR);
    scanner.close();
    Assert.assertEquals(expected.size(), results.size());
    for (int i = 0; i < results.size(); i++) {
      Assert.assertEquals(expected.get(i), results.get(i));
    }",1
"@Test
  public void testResolve() throws Exception {
    final Configuration conf = HBaseConfiguration.create();
    init(name.getMethodName(), conf, true);
    String targetPathName = MobUtils.formatDate(currentDate);
    Path targetPath = new Path(store.getPath(), targetPathName);
    store.commitFile(mobFilePath, targetPath);
    // resolve
    Cell resultCell1 = store.resolve(seekKey1, false).getCell();
    Cell resultCell2 = store.resolve(seekKey2, false).getCell();
    Cell resultCell3 = store.resolve(seekKey3, false).getCell();
    // compare
    Assert.assertEquals(Bytes.toString(value), Bytes.toString(CellUtil.cloneValue(resultCell1)));
    Assert.assertEquals(Bytes.toString(value), Bytes.toString(CellUtil.cloneValue(resultCell2)));
    Assert.assertEquals(Bytes.toString(value2), Bytes.toString(CellUtil.cloneValue(resultCell3)));
  }",1
"@Test
  public void testAppendWithReadOnlyTable() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    this.region = initHRegion(tableName, method, CONF, true, Bytes.toBytes(""somefamily""));
    boolean exceptionCaught = false;
    Append append = new Append(Bytes.toBytes(""somerow""));
    append.setDurability(Durability.SKIP_WAL);
    append.addColumn(Bytes.toBytes(""somefamily""), Bytes.toBytes(""somequalifier""),
      Bytes.toBytes(""somevalue""));
    try {
      region.append(append);
    }",1
"@Test
  public void testAtomicBatchPut() throws IOException {
    final Put[] puts = new Put[10];
    MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);
    long syncs = prepareRegionForBachPut(puts, source, false);

    // 1. Straight forward case, should succeed
    OperationStatus[] codes = this.region.batchMutate(puts, true);
    assertEquals(10, codes.length);
    for (int i = 0; i < 10; i++) {
      assertEquals(OperationStatusCode.SUCCESS, codes[i].getOperationStatusCode());
    }",1
"@Test
  public void testBatchPut_whileNoRowLocksHeld() throws IOException {
    final Put[] puts = new Put[10];
    MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);
    long syncs = prepareRegionForBachPut(puts, source, false);

    OperationStatus[] codes = this.region.batchMutate(puts);
    assertEquals(10, codes.length);
    for (int i = 0; i < 10; i++) {
      assertEquals(OperationStatusCode.SUCCESS, codes[i].getOperationStatusCode());
    }",1
"@Test
  public void testBatchPutWithTsSlop() throws Exception {
    // add data with a timestamp that is too recent for range. Ensure assert
    CONF.setInt(""hbase.hregion.keyvalue.timestamp.slop.millisecs"", 1000);
    final Put[] puts = new Put[10];
    MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);

    long syncs = prepareRegionForBachPut(puts, source, true);

    OperationStatus[] codes = this.region.batchMutate(puts);
    assertEquals(10, codes.length);
    for (int i = 0; i < 10; i++) {
      assertEquals(OperationStatusCode.SANITY_CHECK_FAILURE, codes[i].getOperationStatusCode());
    }",1
"@Test
  public void testCellTTLs() throws IOException {
    IncrementingEnvironmentEdge edge = new IncrementingEnvironmentEdge();
    EnvironmentEdgeManager.injectEdge(edge);

    final byte[] row = Bytes.toBytes(""testRow"");
    final byte[] q1 = Bytes.toBytes(""q1"");
    final byte[] q2 = Bytes.toBytes(""q2"");
    final byte[] q3 = Bytes.toBytes(""q3"");
    final byte[] q4 = Bytes.toBytes(""q4"");

    // 10 seconds
    TableDescriptor tableDescriptor =
      TableDescriptorBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
        .setColumnFamily(ColumnFamilyDescriptorBuilder.newBuilder(fam1).setTimeToLive(10).build())
        .build();

    Configuration conf = new Configuration(TEST_UTIL.getConfiguration());
    conf.setInt(HFile.FORMAT_VERSION_KEY, HFile.MIN_FORMAT_VERSION_WITH_TAGS);

    region = HBaseTestingUtil.createRegionAndWAL(
      RegionInfoBuilder.newBuilder(tableDescriptor.getTableName()).build(),
      TEST_UTIL.getDataTestDir(), conf, tableDescriptor);
    assertNotNull(region);
    long now = EnvironmentEdgeManager.currentTime();
    // Add a cell that will expire in 5 seconds via cell TTL
    region.put(new Put(row).add(new KeyValue(row, fam1, q1, now, HConstants.EMPTY_BYTE_ARRAY,
      new ArrayBackedTag[] {
        // TTL tags specify ts in milliseconds
        new ArrayBackedTag(TagType.TTL_TAG_TYPE, Bytes.toBytes(5000L)) }",1
"@Test
  public void testCheckAndMutateTimestampsAreMonotonic() throws IOException {
    region = initHRegion(tableName, method, CONF, fam1);
    ManualEnvironmentEdge edge = new ManualEnvironmentEdge();
    EnvironmentEdgeManager.injectEdge(edge);

    edge.setValue(10);
    Put p = new Put(row);
    p.setDurability(Durability.SKIP_WAL);
    p.addColumn(fam1, qual1, qual1);
    region.put(p);

    Result result = region.get(new Get(row));
    Cell c = result.getColumnLatestCell(fam1, qual1);
    assertNotNull(c);
    assertEquals(10L, c.getTimestamp());

    edge.setValue(1); // clock goes back
    p = new Put(row);
    p.setDurability(Durability.SKIP_WAL);
    p.addColumn(fam1, qual1, qual2);
    region.checkAndMutate(row, fam1, qual1, CompareOperator.EQUAL, new BinaryComparator(qual1), p);
    result = region.get(new Get(row));
    c = result.getColumnLatestCell(fam1, qual1);
    assertEquals(10L, c.getTimestamp());

    assertTrue(Bytes.equals(c.getValueArray(), c.getValueOffset(), c.getValueLength(), qual2, 0,
      qual2.length));
  }",1
"@Test
  public void testCloseWithFailingFlush() throws Exception {
    final Configuration conf = HBaseConfiguration.create(CONF);
    final WAL wal = createWALCompatibleWithFaultyFileSystem(method, conf, tableName);
    // Only retry once.
    conf.setInt(""hbase.hstore.flush.retries.number"", 1);
    final User user = User.createUserForTesting(conf, this.method, new String[] { ""foo"" }",1
"@Test
  public void testDelete_CheckTimestampUpdated() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] col1 = Bytes.toBytes(""col1"");
    byte[] col2 = Bytes.toBytes(""col2"");
    byte[] col3 = Bytes.toBytes(""col3"");

    byte[] forUnitTestsOnly = Bytes.toBytes(""ForUnitTestsOnly"");

    // Setting up region
    this.region = initHRegion(tableName, method, CONF, fam1);
    // Building checkerList
    List<Cell> kvs = new ArrayList<>();
    kvs.add(new KeyValue(row1, fam1, col1, null));
    kvs.add(new KeyValue(row1, fam1, col2, null));
    kvs.add(new KeyValue(row1, fam1, col3, null));

    NavigableMap<byte[], List<Cell>> deleteMap = new TreeMap<>(Bytes.BYTES_COMPARATOR);
    deleteMap.put(fam1, kvs);
    region.delete(new Delete(forUnitTestsOnly, HConstants.LATEST_TIMESTAMP, deleteMap));

    // extract the key values out the memstore:
    // This is kinda hacky, but better than nothing...
    long now = EnvironmentEdgeManager.currentTime();
    AbstractMemStore memstore = (AbstractMemStore) region.getStore(fam1).memstore;
    Cell firstCell = memstore.getActive().first();
    assertTrue(firstCell.getTimestamp() <= now);
    now = firstCell.getTimestamp();
    for (Cell cell : memstore.getActive().getCellSet()) {
      assertTrue(cell.getTimestamp() <= now);
      now = cell.getTimestamp();
    }",1
"@Test
  public void testFlushResult() throws IOException {
    byte[] family = Bytes.toBytes(""family"");

    this.region = initHRegion(tableName, method, family);

    // empty memstore, flush doesn't run
    HRegion.FlushResult fr = region.flush(true);
    assertFalse(fr.isFlushSucceeded());
    assertFalse(fr.isCompactionNeeded());

    // Flush enough files to get up to the threshold, doesn't need compactions
    for (int i = 0; i < 2; i++) {
      Put put = new Put(tableName.toBytes()).addColumn(family, family, tableName.toBytes());
      region.put(put);
      fr = region.flush(true);
      assertTrue(fr.isFlushSucceeded());
      assertFalse(fr.isCompactionNeeded());
    }",1
"@Test
  public void testFlushSizeAccounting() throws Exception {
    final Configuration conf = HBaseConfiguration.create(CONF);
    final WAL wal = createWALCompatibleWithFaultyFileSystem(method, conf, tableName);
    // Only retry once.
    conf.setInt(""hbase.hstore.flush.retries.number"", 1);
    final User user = User.createUserForTesting(conf, method, new String[] { ""foo"" }",1
"@Test
  public void testGet_Empty() throws IOException {
    byte[] row = Bytes.toBytes(""row"");
    byte[] fam = Bytes.toBytes(""fam"");

    this.region = initHRegion(tableName, method, CONF, fam);
    Get get = new Get(row);
    get.addFamily(fam);
    Result r = region.get(get);

    assertTrue(r.isEmpty());
  }",1
"@Test
  public void testGet_FamilyChecker() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[] fam2 = Bytes.toBytes(""False"");
    byte[] col1 = Bytes.toBytes(""col1"");

    // Setting up region
    this.region = initHRegion(tableName, method, CONF, fam1);
    Get get = new Get(row1);
    get.addColumn(fam2, col1);

    // Test
    try {
      region.get(get);
      fail(""Expecting DoNotRetryIOException in get but did not get any"");
    }",1
"@Test
  public void testGetScanner_WithNoFamilies() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[] fam2 = Bytes.toBytes(""fam2"");
    byte[] fam3 = Bytes.toBytes(""fam3"");
    byte[] fam4 = Bytes.toBytes(""fam4"");

    byte[][] families = { fam1, fam2, fam3, fam4 }",1
"@Test
  public void testGetScanner_WithRegionClosed() throws IOException {
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[] fam2 = Bytes.toBytes(""fam2"");

    byte[][] families = { fam1, fam2 }",1
"@Test
  public void testGetWhileRegionClose() throws IOException {
    Configuration hc = initSplit();
    int numRows = 100;
    byte[][] families = { fam1, fam2, fam3 }",1
"@Test
  public void testReverseScanner_FromMemStore_SingleCF_FullScan() throws IOException {
    byte[] rowC = Bytes.toBytes(""rowC"");
    byte[] rowA = Bytes.toBytes(""rowA"");
    byte[] rowB = Bytes.toBytes(""rowB"");
    byte[] cf = Bytes.toBytes(""CF"");
    byte[][] families = { cf }",1
"@Test
  public void testReverseScanner_FromMemStoreAndHFiles_MultiCFs1() throws IOException {
    byte[] row0 = Bytes.toBytes(""row0""); // 1 kv
    byte[] row1 = Bytes.toBytes(""row1""); // 2 kv
    byte[] row2 = Bytes.toBytes(""row2""); // 4 kv
    byte[] row3 = Bytes.toBytes(""row3""); // 2 kv
    byte[] row4 = Bytes.toBytes(""row4""); // 5 kv
    byte[] row5 = Bytes.toBytes(""row5""); // 2 kv
    byte[] cf1 = Bytes.toBytes(""CF1"");
    byte[] cf2 = Bytes.toBytes(""CF2"");
    byte[] cf3 = Bytes.toBytes(""CF3"");
    byte[][] families = { cf1, cf2, cf3 }",1
"@Test
  public void testReverseScanner_FromMemStoreAndHFiles_MultiCFs2() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] row2 = Bytes.toBytes(""row2"");
    byte[] row3 = Bytes.toBytes(""row3"");
    byte[] row4 = Bytes.toBytes(""row4"");
    byte[] cf1 = Bytes.toBytes(""CF1"");
    byte[] cf2 = Bytes.toBytes(""CF2"");
    byte[] cf3 = Bytes.toBytes(""CF3"");
    byte[] cf4 = Bytes.toBytes(""CF4"");
    byte[][] families = { cf1, cf2, cf3, cf4 }",1
"@Test
  public void testReverseScanShouldNotScanMemstoreIfReadPtLesser() throws Exception {
    byte[] cf1 = Bytes.toBytes(""CF1"");
    byte[][] families = { cf1 }",1
"@Test
  public void testScanner_DeleteOneFamilyNotAnother() throws IOException {
    byte[] fam1 = Bytes.toBytes(""columnA"");
    byte[] fam2 = Bytes.toBytes(""columnB"");
    this.region = initHRegion(tableName, method, CONF, fam1, fam2);
    byte[] rowA = Bytes.toBytes(""rowA"");
    byte[] rowB = Bytes.toBytes(""rowB"");

    byte[] value = Bytes.toBytes(""value"");

    Delete delete = new Delete(rowA);
    delete.addFamily(fam1);

    region.delete(delete);

    // now create data.
    Put put = new Put(rowA);
    put.addColumn(fam2, null, value);
    region.put(put);

    put = new Put(rowB);
    put.addColumn(fam1, null, value);
    put.addColumn(fam2, null, value);
    region.put(put);

    Scan scan = new Scan();
    scan.addFamily(fam1).addFamily(fam2);
    try (InternalScanner s = region.getScanner(scan)) {
      List<Cell> results = new ArrayList<>();
      s.next(results);
      assertTrue(CellUtil.matchingRows(results.get(0), rowA));

      results.clear();
      s.next(results);
      assertTrue(CellUtil.matchingRows(results.get(0), rowB));
    }",1
"@Test
  public void testScanner_Wildcard_FromMemStore_EnforceVersions() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] qf1 = Bytes.toBytes(""qualifier1"");
    byte[] qf2 = Bytes.toBytes(""qualifier2"");
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[][] families = { fam1 }",1
"@Test
  public void testSequenceId() throws IOException {
    region = initHRegion(tableName, method, CONF, COLUMN_FAMILY_BYTES);
    assertEquals(HConstants.NO_SEQNUM, region.getMaxFlushedSeqId());
    // Weird. This returns 0 if no store files or no edits. Afraid to change it.
    assertEquals(0, (long) region.getMaxStoreSeqId().get(COLUMN_FAMILY_BYTES));
    HBaseTestingUtil.closeRegionAndWAL(this.region);
    assertEquals(HConstants.NO_SEQNUM, region.getMaxFlushedSeqId());
    assertEquals(0, (long) region.getMaxStoreSeqId().get(COLUMN_FAMILY_BYTES));
    HRegion oldRegion = region;
    try {
      // Open region again.
      region = initHRegion(tableName, method, CONF, COLUMN_FAMILY_BYTES);
      byte[] value = Bytes.toBytes(method);
      // Make a random put against our cf.
      Put put = new Put(value);
      put.addColumn(COLUMN_FAMILY_BYTES, null, value);
      region.put(put);
      // No flush yet so init numbers should still be in place.
      assertEquals(HConstants.NO_SEQNUM, region.getMaxFlushedSeqId());
      assertEquals(0, (long) region.getMaxStoreSeqId().get(COLUMN_FAMILY_BYTES));
      region.flush(true);
      long max = region.getMaxFlushedSeqId();
      HBaseTestingUtil.closeRegionAndWAL(this.region);
      assertEquals(max, region.getMaxFlushedSeqId());
      this.region = null;
    }",1
"@Test
  public void testSkipRecoveredEditsReplayTheLastFileIgnored() throws Exception {
    byte[] family = Bytes.toBytes(""family"");
    this.region = initHRegion(tableName, method, CONF, family);
    final WALFactory wals = new WALFactory(CONF, method);
    try {
      Path regiondir = region.getRegionFileSystem().getRegionDir();
      FileSystem fs = region.getRegionFileSystem().getFileSystem();
      byte[] regionName = region.getRegionInfo().getEncodedNameAsBytes();
      byte[][] columns = region.getTableDescriptor().getColumnFamilyNames().toArray(new byte[0][]);

      assertEquals(0, region.getStoreFileList(columns).size());

      Path recoveredEditsDir = WALSplitUtil.getRegionDirRecoveredEditsDir(regiondir);

      long maxSeqId = 1050;
      long minSeqId = 1000;

      for (long i = minSeqId; i <= maxSeqId; i += 10) {
        Path recoveredEdits = new Path(recoveredEditsDir, String.format(""%019d"", i));
        fs.create(recoveredEdits);
        WALProvider.Writer writer = wals.createRecoveredEditsWriter(fs, recoveredEdits);

        long time = System.nanoTime();
        WALEdit edit = null;
        if (i == maxSeqId) {
          edit = WALEdit.createCompaction(region.getRegionInfo(),
            CompactionDescriptor.newBuilder().setTableName(ByteString.copyFrom(tableName.getName()))
              .setFamilyName(ByteString.copyFrom(regionName))
              .setEncodedRegionName(ByteString.copyFrom(regionName))
              .setStoreHomeDirBytes(ByteString.copyFrom(Bytes.toBytes(regiondir.toString())))
              .setRegionName(ByteString.copyFrom(region.getRegionInfo().getRegionName())).build());
        }",1
"@Test
  public void testStatusSettingToAbortIfAnyExceptionDuringRegionInitilization() throws Exception {
    RegionInfo info;
    try {
      FileSystem fs = mock(FileSystem.class);
      when(fs.exists(any())).thenThrow(new IOException());
      TableDescriptorBuilder tableDescriptorBuilder = TableDescriptorBuilder.newBuilder(tableName);
      ColumnFamilyDescriptor columnFamilyDescriptor =
        ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(""cf"")).build();
      tableDescriptorBuilder.setColumnFamily(columnFamilyDescriptor);
      info = RegionInfoBuilder.newBuilder(tableName).build();
      Path path = new Path(dir + ""testStatusSettingToAbortIfAnyExceptionDuringRegionInitilization"");
      region = HRegion.newHRegion(path, null, fs, CONF, info, tableDescriptorBuilder.build(), null);
      // region initialization throws IOException and set task state to ABORTED.
      region.initialize();
      fail(""Region initialization should fail due to IOException"");
    }",1
"@Test
  public void testToShowNPEOnRegionScannerReseek() throws Exception {
    byte[] family = Bytes.toBytes(""family"");
    this.region = initHRegion(tableName, method, CONF, family);

    Put put = new Put(Bytes.toBytes(""r1""));
    put.addColumn(family, Bytes.toBytes(""q1""), Bytes.toBytes(""v1""));
    region.put(put);
    put = new Put(Bytes.toBytes(""r2""));
    put.addColumn(family, Bytes.toBytes(""q1""), Bytes.toBytes(""v1""));
    region.put(put);
    region.flush(true);

    Scan scan = new Scan();
    scan.readVersions(3);
    // open the first scanner
    try (RegionScanner scanner1 = region.getScanner(scan)) {
      LOG.info(""Smallest read point:"" + region.getSmallestReadPoint());

      region.compact(true);

      scanner1.reseek(Bytes.toBytes(""r2""));
      List<Cell> results = new ArrayList<>();
      scanner1.next(results);
      Cell keyValue = results.get(0);
      assertTrue(Bytes.compareTo(CellUtil.cloneRow(keyValue), Bytes.toBytes(""r2"")) == 0);
      scanner1.close();
    }",1
"@Test
  public void testCreateWriter() throws Exception {
    Configuration conf = HBaseConfiguration.create();
    FileSystem fs = FileSystem.get(conf);

    ColumnFamilyDescriptor hcd =
      ColumnFamilyDescriptorBuilder.newBuilder(family).setCompressionType(Compression.Algorithm.GZ)
        .setDataBlockEncoding(DataBlockEncoding.DIFF).build();
    init(name.getMethodName(), conf, hcd);

    // Test createWriter
    StoreFileWriter writer = store.getStoreEngine()
      .createWriter(CreateStoreFileWriterParams.create().maxKeyCount(4)
        .compression(hcd.getCompressionType()).isCompaction(false).includeMVCCReadpoint(true)
        .includesTag(false).shouldDropBehind(false));
    Path path = writer.getPath();
    writer.append(new KeyValue(row, family, qf1, Bytes.toBytes(1)));
    writer.append(new KeyValue(row, family, qf2, Bytes.toBytes(2)));
    writer.append(new KeyValue(row2, family, qf1, Bytes.toBytes(3)));
    writer.append(new KeyValue(row2, family, qf2, Bytes.toBytes(4)));
    writer.close();

    // Verify that compression and encoding settings are respected
    HFile.Reader reader = HFile.createReader(fs, path, new CacheConfig(conf), true, conf);
    assertEquals(hcd.getCompressionType(), reader.getTrailer().getCompressionCodec());
    assertEquals(hcd.getDataBlockEncoding(), reader.getDataBlockEncoding());
    reader.close();
  }",1
"@Test
  public void testReclaimChunkWhenScaning() throws IOException {
    init(""testReclaimChunkWhenScaning"");
    long ts = EnvironmentEdgeManager.currentTime();
    long seqId = 100;
    byte[] value = Bytes.toBytes(""value"");
    // older data whihc shouldn't be ""seen"" by client
    store.add(createCell(qf1, ts, seqId, value), null);
    store.add(createCell(qf2, ts, seqId, value), null);
    store.add(createCell(qf3, ts, seqId, value), null);
    TreeSet<byte[]> quals = new TreeSet<>(Bytes.BYTES_COMPARATOR);
    quals.add(qf1);
    quals.add(qf2);
    quals.add(qf3);
    try (InternalScanner scanner =
      (InternalScanner) store.getScanner(new Scan(new Get(row)), quals, seqId)) {
      List<Cell> results = new MyList<>(size -> {
        switch (size) {
          // 1) we get the first cell (qf1)
          // 2) flush the data to have StoreScanner update inner scanners
          // 3) the chunk will be reclaimed after updaing
          case 1:
            try {
              flushStore(store, id++);
            }",1
"@Test
  public void testRefreshStoreFilesNotChanged() throws IOException {
    init(name.getMethodName());

    assertEquals(0, this.store.getStorefilesCount());

    // add some data, flush
    this.store.add(new KeyValue(row, family, qf1, 1, (byte[]) null), null);
    flush(1);
    // add one more file
    addStoreFile();

    StoreEngine<?, ?, ?, ?> spiedStoreEngine = spy(store.getStoreEngine());

    // call first time after files changed
    spiedStoreEngine.refreshStoreFiles();
    assertEquals(2, this.store.getStorefilesCount());
    verify(spiedStoreEngine, times(1)).replaceStoreFiles(any(), any(), any(), any());

    // call second time
    spiedStoreEngine.refreshStoreFiles();

    // ensure that replaceStoreFiles is not called, i.e, the times does not change, if files are not
    // refreshed,
    verify(spiedStoreEngine, times(1)).replaceStoreFiles(any(), any(), any(), any());
  }",1
"@Test
  public void testSwitchingPreadtoStreamParallelyWithCompactionDischarger() throws Exception {
    Configuration conf = HBaseConfiguration.create();
    conf.set(""hbase.hstore.engine.class"", DummyStoreEngine.class.getName());
    conf.setLong(StoreScanner.STORESCANNER_PREAD_MAX_BYTES, 0);
    // Set the lower threshold to invoke the ""MERGE"" policy
    MyStore store = initMyStore(name.getMethodName(), conf, new MyStoreHook() {
    }",1
"@Test
  public void testBloomFilter() throws Exception {
    conf.setFloat(BloomFilterFactory.IO_STOREFILE_BLOOM_ERROR_RATE, (float) 0.01);
    conf.setBoolean(BloomFilterFactory.IO_STOREFILE_BLOOM_ENABLED, true);

    // write the file
    if (!fs.exists(ROOT_DIR)) {
      fs.mkdirs(ROOT_DIR);
    }",1
"@Test
  public void testEmptyStoreFileRestrictKeyRanges() throws Exception {
    StoreFileReader reader = mock(StoreFileReader.class);
    HStore store = mock(HStore.class);
    byte[] cf = Bytes.toBytes(""ty"");
    ColumnFamilyDescriptor cfd = ColumnFamilyDescriptorBuilder.of(cf);
    when(store.getColumnFamilyDescriptor()).thenReturn(cfd);
    try (StoreFileScanner scanner =
      new StoreFileScanner(reader, mock(HFileScanner.class), false, false, 0, 0, true, false)) {
      Scan scan = new Scan();
      scan.setColumnFamilyTimeRange(cf, 0, 1);
      assertFalse(scanner.shouldUseScanner(scan, store, 0));
    }",1
"@Test
  public void testStoreFileReference() throws Exception {
    final RegionInfo hri =
      RegionInfoBuilder.newBuilder(TableName.valueOf(""testStoreFileReference"")).build();
    HRegionFileSystem regionFs = HRegionFileSystem.createRegionOnFileSystem(conf, fs,
      new Path(testDir, hri.getTable().getNameAsString()), hri);
    HFileContext meta = new HFileContextBuilder().withBlockSize(8 * 1024).build();

    // Make a store file and write data to it.
    StoreFileWriter writer = new StoreFileWriter.Builder(conf, cacheConf, this.fs)
      .withFilePath(regionFs.createTempName()).withFileContext(meta).build();
    writeStoreFile(writer);
    Path hsfPath = regionFs.commitStoreFile(TEST_FAMILY, writer.getPath());
    writer.close();
    StoreFileTracker sft = StoreFileTrackerFactory.create(conf, false,
      StoreContext.getBuilder()
        .withFamilyStoreDirectoryPath(new Path(regionFs.getRegionDir(), TEST_FAMILY))
        .withRegionFileSystem(regionFs).build());
    HStoreFile file = new HStoreFile(this.fs, hsfPath, conf, cacheConf, BloomType.NONE, true, sft);
    file.initReader();
    StoreFileReader r = file.getReader();
    assertNotNull(r);
    StoreFileScanner scanner =
      new StoreFileScanner(r, mock(HFileScanner.class), false, false, 0, 0, false, false);

    // Verify after instantiating scanner refCount is increased
    assertTrue(""Verify file is being referenced"", file.isReferencedInReads());
    scanner.close();
    // Verify after closing scanner refCount is decreased
    assertFalse(""Verify file is not being referenced"", file.isReferencedInReads());
  }",1
"@Test
  public void testSorted() throws IOException {
    // Cases that need to be checked are:
    // 1. The ""smallest"" Cell is in the same scanners as current
    // 2. Current scanner gets empty

    List<Cell> expected =
      Arrays.asList(kv111, kv112, kv113, kv114, kv115, kv121, kv122, kv211, kv212, kv213);

    List<Cell> actual = assertCells(expected, scanners);

    // Check if result is sorted according to Comparator
    for (int i = 0; i < actual.size() - 1; i++) {
      int ret = CellComparatorImpl.COMPARATOR.compare(actual.get(i), actual.get(i + 1));
      assertTrue(ret < 0);
    }",1
"@Test
  public void testRegionWrapperMetrics() {
    MetricsRegion mr = new MetricsRegion(new MetricsRegionWrapperStub(), new Configuration());
    MetricsRegionAggregateSource agg = mr.getSource().getAggregateSource();

    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_storeCount"", 101,
      agg);
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_storeFileCount"",
      102, agg);
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_maxStoreFileAge"",
      2, agg);
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_minStoreFileAge"",
      2, agg);
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_avgStoreFileAge"",
      2, agg);
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_numReferenceFiles"",
      2, agg);
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_memstoreSize"", 103,
      agg);
    HELPER.assertCounter(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_cpRequestCount"",
      108, agg);
    HELPER
      .assertCounter(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_""
        + ""filteredReadRequestCount"", 107, agg);
    HELPER.assertCounter(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001_metric_replicaid"", 0,
      agg);
    mr.close();

    // test region with replica id > 0
    mr = new MetricsRegion(new MetricsRegionWrapperStub(1), new Configuration());
    agg = mr.getSource().getAggregateSource();
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001"" + ""_metric_storeCount"",
      101, agg);
    HELPER.assertGauge(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001""
      + ""_metric_storeFileCount"", 102, agg);
    HELPER.assertGauge(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001"" + ""_metric_memstoreSize"",
      103, agg);
    HELPER.assertCounter(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001""
      + ""_metric_cpRequestCount"", 108, agg);
    HELPER.assertCounter(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001""
      + ""_metric_filteredReadRequestCount"", 107, agg);
    HELPER.assertCounter(
      ""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001"" + ""_metric_replicaid"", 1,
      agg);
    HELPER.assertCounter(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001""
      + ""_metric_compactionsQueuedCount"", 4, agg);
    HELPER.assertCounter(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001""
      + ""_metric_flushesQueuedCount"", 6, agg);
    HELPER.assertCounter(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001""
      + ""_metric_maxCompactionQueueSize"", 4, agg);
    HELPER.assertCounter(""namespace_TestNS_table_MetricsRegionWrapperStub_region_DEADBEEF001""
      + ""_metric_maxFlushQueueSize"", 6, agg);
    mr.close();
  }",1
"@Test
  public void testPauseMonitor() {
    Configuration conf = new Configuration();
    conf.setLong(JvmPauseMonitor.INFO_THRESHOLD_KEY, 1000L);
    conf.setLong(JvmPauseMonitor.WARN_THRESHOLD_KEY, 10000L);
    JvmPauseMonitor monitor = new JvmPauseMonitor(conf, serverSource);
    monitor.updateMetrics(1500, false);
    HELPER.assertCounter(""pauseInfoThresholdExceeded"", 1, serverSource);
    HELPER.assertCounter(""pauseWarnThresholdExceeded"", 0, serverSource);
    HELPER.assertCounter(""pauseTimeWithoutGc_num_ops"", 1, serverSource);
    HELPER.assertCounter(""pauseTimeWithGc_num_ops"", 0, serverSource);
    monitor.updateMetrics(15000, true);
    HELPER.assertCounter(""pauseInfoThresholdExceeded"", 1, serverSource);
    HELPER.assertCounter(""pauseWarnThresholdExceeded"", 1, serverSource);
    HELPER.assertCounter(""pauseTimeWithoutGc_num_ops"", 1, serverSource);
    HELPER.assertCounter(""pauseTimeWithGc_num_ops"", 1, serverSource);
  }",1
"@Test
  public void testMobStoreScanner() throws Exception {
    testGetFromFiles(false);
    testGetFromMemStore(false);
    testGetReferences(false);
    testMobThreshold(false);
    testGetFromArchive(false);
  }",1
"@Test
  public void testBuilder() {
    TableName tn = TableName.valueOf(""test"");
    RegionInfoBuilder builder = RegionInfoBuilder.newBuilder(tn);
    byte[] startKey = Bytes.toBytes(""a"");
    builder.setStartKey(startKey);
    byte[] endKey = Bytes.toBytes(""z"");
    builder.setEndKey(endKey);
    int regionId = 1;
    builder.setRegionId(1);
    int replicaId = 2;
    builder.setReplicaId(replicaId);
    boolean offline = true;
    builder.setOffline(offline);
    boolean isSplit = true;
    builder.setSplit(isSplit);
    RegionInfo ri = builder.build();

    assertEquals(tn, ri.getTable());
    assertArrayEquals(startKey, ri.getStartKey());
    assertArrayEquals(endKey, ri.getEndKey());
    assertEquals(regionId, ri.getRegionId());
    assertEquals(replicaId, ri.getReplicaId());
    assertEquals(offline, ri.isOffline());
    assertEquals(isSplit, ri.isSplit());
  }",1
"@Test
  public void testRegionNameForRegionReplicas() throws Exception {
    final TableName tn = name.getTableName();
    String startKey = ""startkey"";
    final byte[] sk = Bytes.toBytes(startKey);
    String id = ""id"";

    // assert with only the region name without encoding

    // primary, replicaId = 0
    byte[] name = RegionInfo.createRegionName(tn, sk, Bytes.toBytes(id), 0, false);
    String nameStr = Bytes.toString(name);
    assertEquals(tn + "","" + startKey + "","" + id, nameStr);

    // replicaId = 1
    name = RegionInfo.createRegionName(tn, sk, Bytes.toBytes(id), 1, false);
    nameStr = Bytes.toString(name);
    assertEquals(
      tn + "","" + startKey + "","" + id + ""_"" + String.format(RegionInfo.REPLICA_ID_FORMAT, 1),
      nameStr);

    // replicaId = max
    name = RegionInfo.createRegionName(tn, sk, Bytes.toBytes(id), 0xFFFF, false);
    nameStr = Bytes.toString(name);
    assertEquals(
      tn + "","" + startKey + "","" + id + ""_"" + String.format(RegionInfo.REPLICA_ID_FORMAT, 0xFFFF),
      nameStr);
  }",1
"@Test
  public void testPreemptTask() throws Exception {
    LOG.info(""testPreemptTask"");
    SplitLogCounters.resetCounters();
    final ServerName SRV = ServerName.valueOf(""tpt_svr,1,1"");
    final String PATH = ZKSplitLog.getEncodedNodeName(zkw, ""tpt_task"");
    RegionServerServices mockedRS = getRegionServer(SRV);
    SplitLogWorker slw =
      new SplitLogWorker(ds, TEST_UTIL.getConfiguration(), mockedRS, neverEndingTask);
    slw.start();
    try {
      Thread.yield(); // let the worker start
      Thread.sleep(1000);
      waitForCounter(SplitLogCounters.tot_wkr_task_grabing, 0, 1, WAIT_TIME);

      // this time create a task node after starting the splitLogWorker
      zkw.getRecoverableZooKeeper().create(PATH, new SplitLogTask.Unassigned(MANAGER).toByteArray(),
        Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

      waitForCounter(SplitLogCounters.tot_wkr_task_acquired, 0, 1, WAIT_TIME);
      assertEquals(1, slw.getTaskReadySeq());
      byte[] bytes = ZKUtil.getData(zkw, PATH);
      SplitLogTask slt = SplitLogTask.parseFrom(bytes);
      assertTrue(slt.isOwned(SRV));
      slt = new SplitLogTask.Owned(MANAGER);
      ZKUtil.setData(zkw, PATH, slt.toByteArray());
      waitForCounter(SplitLogCounters.tot_wkr_preempt_task, 0, 1, WAIT_TIME);
    }",1
"@Test
  public void testRescan() throws Exception {
    LOG.info(""testRescan"");
    SplitLogCounters.resetCounters();
    final ServerName SRV = ServerName.valueOf(""svr,1,1"");
    RegionServerServices mockedRS = getRegionServer(SRV);
    slw = new SplitLogWorker(ds, TEST_UTIL.getConfiguration(), mockedRS, neverEndingTask);
    slw.start();
    Thread.yield(); // let the worker start
    Thread.sleep(100);

    String task = ZKSplitLog.getEncodedNodeName(zkw, ""task"");
    SplitLogTask slt = new SplitLogTask.Unassigned(MANAGER);
    zkw.getRecoverableZooKeeper().create(task, slt.toByteArray(), Ids.OPEN_ACL_UNSAFE,
      CreateMode.PERSISTENT);

    waitForCounter(SplitLogCounters.tot_wkr_task_acquired, 0, 1, WAIT_TIME);
    // now the worker is busy doing the above task

    // preempt the task, have it owned by another worker
    ZKUtil.setData(zkw, task, slt.toByteArray());
    waitForCounter(SplitLogCounters.tot_wkr_preempt_task, 0, 1, WAIT_TIME);

    // create a RESCAN node
    String rescan = ZKSplitLog.getEncodedNodeName(zkw, ""RESCAN"");
    rescan = zkw.getRecoverableZooKeeper().create(rescan, slt.toByteArray(), Ids.OPEN_ACL_UNSAFE,
      CreateMode.PERSISTENT_SEQUENTIAL);

    waitForCounter(SplitLogCounters.tot_wkr_task_acquired, 1, 2, WAIT_TIME);
    // RESCAN node might not have been processed if the worker became busy
    // with the above task. preempt the task again so that now the RESCAN
    // node is processed
    ZKUtil.setData(zkw, task, slt.toByteArray());
    waitForCounter(SplitLogCounters.tot_wkr_preempt_task, 1, 2, WAIT_TIME);
    waitForCounter(SplitLogCounters.tot_wkr_task_acquired_rescan, 0, 1, WAIT_TIME);

    List<String> nodes = ZKUtil.listChildrenNoWatch(zkw, zkw.getZNodePaths().splitLogZNode);
    LOG.debug(Objects.toString(nodes));
    int num = 0;
    for (String node : nodes) {
      num++;
      if (node.startsWith(""RESCAN"")) {
        String name = ZKSplitLog.getEncodedNodeName(zkw, node);
        String fn = ZKSplitLog.getFileName(name);
        byte[] data =
          ZKUtil.getData(zkw, ZNodePaths.joinZNode(zkw.getZNodePaths().splitLogZNode, fn));
        slt = SplitLogTask.parseFrom(data);
        assertTrue(slt.toString(), slt.isDone(SRV));
      }",1
"@Test
  public void testEqualsWithLink() throws IOException {
    Path origin = new Path(""/origin"");
    Path tmp = TEST_UTIL.getDataTestDir();
    Path mob = new Path(""/mob"");
    Path archive = new Path(""/archive"");
    HFileLink link1 = new HFileLink(new Path(origin, ""f1""), new Path(tmp, ""f1""),
      new Path(mob, ""f1""), new Path(archive, ""f1""));
    HFileLink link2 = new HFileLink(new Path(origin, ""f1""), new Path(tmp, ""f1""),
      new Path(mob, ""f1""), new Path(archive, ""f1""));

    StoreFileInfo info1 =
      new StoreFileInfo(TEST_UTIL.getConfiguration(), TEST_UTIL.getTestFileSystem(), null, link1);
    StoreFileInfo info2 =
      new StoreFileInfo(TEST_UTIL.getConfiguration(), TEST_UTIL.getTestFileSystem(), null, link2);

    assertEquals(info1, info2);
    assertEquals(info1.hashCode(), info2.hashCode());
  }",1
"@Test
  public void testCompactionAndFlushConflict() throws Exception {
    // Add file flush into stripes
    StripeStoreFileManager sfm = createManager();
    assertEquals(0, sfm.getStripeCount());
    HStoreFile sf_i2c = createFile(OPEN_KEY, KEY_C), sf_c2i = createFile(KEY_C, OPEN_KEY);
    sfm.insertNewFiles(al(sf_i2c, sf_c2i));
    assertEquals(2, sfm.getStripeCount());
    // Now try to add conflicting flush - should throw.
    HStoreFile sf_i2d = createFile(OPEN_KEY, KEY_D), sf_d2i = createFile(KEY_D, OPEN_KEY);
    sfm.insertNewFiles(al(sf_i2d, sf_d2i));
    assertEquals(2, sfm.getStripeCount());
    assertEquals(2, sfm.getLevel0Files().size());
    verifyGetAndScanScenario(sfm, KEY_C, KEY_C, sf_i2d, sf_d2i, sf_c2i);
    // Remove these files.
    sfm.addCompactionResults(al(sf_i2d, sf_d2i), al());
    sfm.removeCompactedFiles(al(sf_i2d, sf_d2i));
    assertEquals(0, sfm.getLevel0Files().size());
    // Add another file to stripe; then ""rebalance"" stripes w/o it - the file, which was
    // presumably flushed during compaction, should go to L0.
    HStoreFile sf_i2c_2 = createFile(OPEN_KEY, KEY_C);
    sfm.insertNewFiles(al(sf_i2c_2));
    sfm.addCompactionResults(al(sf_i2c, sf_c2i), al(sf_i2d, sf_d2i));
    sfm.removeCompactedFiles(al(sf_i2c, sf_c2i));
    assertEquals(1, sfm.getLevel0Files().size());
    verifyGetAndScanScenario(sfm, KEY_C, KEY_C, sf_i2d, sf_i2c_2);
  }",1
"@Test
  public void testPreparePutCounter() throws Exception {

    ExecutorService executorService = Executors.newFixedThreadPool(10);

    Configuration conf = new Configuration();
    conf.setInt(PARALLEL_PUT_STORE_THREADS_LIMIT_MIN_COLUMN_COUNT, 0);
    conf.setInt(PARALLEL_PUT_STORE_THREADS_LIMIT, 10);
    conf.setInt(PARALLEL_PREPARE_PUT_STORE_MULTIPLIER, 3);
    Region mockRegion = mock(Region.class);
    StoreHotnessProtector storeHotnessProtector = new StoreHotnessProtector(mockRegion, conf);

    Store mockStore1 = mock(Store.class);
    RegionInfo mockRegionInfo = mock(RegionInfo.class);
    byte[] family = Bytes.toBytes(""testF1"");

    when(mockRegion.getStore(family)).thenReturn(mockStore1);
    when(mockRegion.getRegionInfo()).thenReturn(mockRegionInfo);
    when(mockRegionInfo.getRegionNameAsString()).thenReturn(""test_region_1"");

    when(mockStore1.getCurrentParallelPutCount()).thenReturn(1);
    when(mockStore1.getColumnFamilyName()).thenReturn(""test_Family_1"");

    final Map<byte[], List<Cell>> familyMaps = new HashMap<>();
    familyMaps.put(family, Lists.newArrayList(mock(Cell.class), mock(Cell.class)));

    final AtomicReference<Exception> exception = new AtomicReference<>();

    // PreparePutCounter not access limit

    int threadCount = conf.getInt(PARALLEL_PUT_STORE_THREADS_LIMIT, 10)
      * conf.getInt(PARALLEL_PREPARE_PUT_STORE_MULTIPLIER, 3);
    CountDownLatch countDownLatch = new CountDownLatch(threadCount);

    for (int i = 0; i < threadCount; i++) {
      executorService.execute(() -> {
        try {
          storeHotnessProtector.start(familyMaps);
        }",1
"@Test
  public void testWALComparator() throws Exception {
    AbstractFSWAL<?> wal1 = null;
    AbstractFSWAL<?> walMeta = null;
    try {
      wal1 = newWAL(FS, CommonFSUtils.getWALRootDir(CONF), DIR.toString(),
        HConstants.HREGION_OLDLOGDIR_NAME, CONF, null, true, null, null);
      LOG.debug(""Log obtained is: "" + wal1);
      Comparator<Path> comp = wal1.LOG_NAME_COMPARATOR;
      Path p1 = wal1.computeFilename(11);
      Path p2 = wal1.computeFilename(12);
      // comparing with itself returns 0
      assertTrue(comp.compare(p1, p1) == 0);
      // comparing with different filenum.
      assertTrue(comp.compare(p1, p2) < 0);
      walMeta = newWAL(FS, CommonFSUtils.getWALRootDir(CONF), DIR.toString(),
        HConstants.HREGION_OLDLOGDIR_NAME, CONF, null, true, null,
        AbstractFSWALProvider.META_WAL_PROVIDER_ID);
      Comparator<Path> compMeta = walMeta.LOG_NAME_COMPARATOR;

      Path p1WithMeta = walMeta.computeFilename(11);
      Path p2WithMeta = walMeta.computeFilename(12);
      assertTrue(compMeta.compare(p1WithMeta, p1WithMeta) == 0);
      assertTrue(compMeta.compare(p1WithMeta, p2WithMeta) < 0);
      // mixing meta and non-meta logs gives error
      boolean ex = false;
      try {
        comp.compare(p1WithMeta, p2);
      }",1
"@Test
  public void testWriteEntryCanBeNull() throws IOException {
    String testName = currentTest.getMethodName();
    AbstractFSWAL<?> wal = newWAL(FS, CommonFSUtils.getWALRootDir(CONF), DIR.toString(), testName,
      CONF, null, true, null, null);
    wal.close();
    TableDescriptor td = TableDescriptorBuilder.newBuilder(TableName.valueOf(""table""))
      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(""row"")).build();
    RegionInfo ri = RegionInfoBuilder.newBuilder(td.getTableName()).build();
    MultiVersionConcurrencyControl mvcc = new MultiVersionConcurrencyControl();
    NavigableMap<byte[], Integer> scopes = new TreeMap<>(Bytes.BYTES_COMPARATOR);
    for (byte[] fam : td.getColumnFamilyNames()) {
      scopes.put(fam, 0);
    }",1
"@Test
  public void testAreAllLower() {
    SequenceIdAccounting sida = new SequenceIdAccounting();
    sida.getOrCreateLowestSequenceIds(ENCODED_REGION_NAME);
    Map<byte[], Long> m = new HashMap<>();
    m.put(ENCODED_REGION_NAME, HConstants.NO_SEQNUM);
    assertTrue(sida.areAllLower(m, null));
    long sequenceid = 1;
    sida.update(ENCODED_REGION_NAME, FAMILIES, sequenceid, true);
    sida.update(ENCODED_REGION_NAME, FAMILIES, sequenceid++, true);
    sida.update(ENCODED_REGION_NAME, FAMILIES, sequenceid++, true);
    assertTrue(sida.areAllLower(m, null));
    m.put(ENCODED_REGION_NAME, sequenceid);
    assertFalse(sida.areAllLower(m, null));
    ArrayList<byte[]> regions = new ArrayList<>();
    assertFalse(sida.areAllLower(m, regions));
    assertEquals(1, regions.size());
    assertArrayEquals(ENCODED_REGION_NAME, regions.get(0));
    long lowest = sida.getLowestSequenceId(ENCODED_REGION_NAME);
    assertEquals(""Lowest should be first sequence id inserted"", 1, lowest);
    m.put(ENCODED_REGION_NAME, lowest);
    assertFalse(sida.areAllLower(m, null));
    // Now make sure above works when flushing.
    sida.startCacheFlush(ENCODED_REGION_NAME, FAMILIES);
    assertFalse(sida.areAllLower(m, null));
    m.put(ENCODED_REGION_NAME, HConstants.NO_SEQNUM);
    assertTrue(sida.areAllLower(m, null));
    // Let the flush complete and if we ask if the sequenceid is lower, should be yes since no edits
    sida.completeCacheFlush(ENCODED_REGION_NAME, HConstants.NO_SEQNUM);
    m.put(ENCODED_REGION_NAME, sequenceid);
    assertTrue(sida.areAllLower(m, null));
    // Flush again but add sequenceids while we are flushing.
    sida.update(ENCODED_REGION_NAME, FAMILIES, sequenceid++, true);
    sida.update(ENCODED_REGION_NAME, FAMILIES, sequenceid++, true);
    sida.update(ENCODED_REGION_NAME, FAMILIES, sequenceid++, true);
    lowest = sida.getLowestSequenceId(ENCODED_REGION_NAME);
    m.put(ENCODED_REGION_NAME, lowest);
    assertFalse(sida.areAllLower(m, null));
    sida.startCacheFlush(ENCODED_REGION_NAME, FAMILIES);
    // The cache flush will clear out all sequenceid accounting by region.
    assertEquals(HConstants.NO_SEQNUM, sida.getLowestSequenceId(ENCODED_REGION_NAME));
    sida.completeCacheFlush(ENCODED_REGION_NAME, HConstants.NO_SEQNUM);
    // No new edits have gone in so no sequenceid to work with.
    assertEquals(HConstants.NO_SEQNUM, sida.getLowestSequenceId(ENCODED_REGION_NAME));
    // Make an edit behind all we'll put now into sida.
    m.put(ENCODED_REGION_NAME, sequenceid);
    sida.update(ENCODED_REGION_NAME, FAMILIES, ++sequenceid, true);
    sida.update(ENCODED_REGION_NAME, FAMILIES, ++sequenceid, true);
    sida.update(ENCODED_REGION_NAME, FAMILIES, ++sequenceid, true);
    assertTrue(sida.areAllLower(m, null));
    m.put(ENCODED_REGION_NAME, sequenceid);
    assertFalse(sida.areAllLower(m, null));

    // Test the METAFAMILY is filtered in SequenceIdAccounting.lowestUnflushedSequenceIds
    SequenceIdAccounting meta_sida = new SequenceIdAccounting();
    Map<byte[], Long> meta_m = new HashMap<>();
    meta_sida.getOrCreateLowestSequenceIds(ENCODED_REGION_NAME);
    meta_m.put(ENCODED_REGION_NAME, sequenceid);
    meta_sida.update(ENCODED_REGION_NAME, META_FAMILY_SET, ++sequenceid, true);
    meta_sida.update(ENCODED_REGION_NAME, META_FAMILY_SET, ++sequenceid, true);
    meta_sida.update(ENCODED_REGION_NAME, META_FAMILY_SET, ++sequenceid, true);
    assertTrue(meta_sida.areAllLower(meta_m, null));
    meta_m.put(ENCODED_REGION_NAME, sequenceid);
    assertTrue(meta_sida.areAllLower(meta_m, null));
  }",1
"@Test
  public void testActionListener() throws Exception {
    DummyWALActionsListener observer = new DummyWALActionsListener();
    final WALFactory wals = new WALFactory(conf, ""testActionListener"");
    wals.getWALProvider().addWALActionsListener(observer);
    DummyWALActionsListener laterobserver = new DummyWALActionsListener();
    RegionInfo hri = RegionInfoBuilder.newBuilder(TableName.valueOf(SOME_BYTES))
      .setStartKey(SOME_BYTES).setEndKey(SOME_BYTES).build();
    final WAL wal = wals.getWAL(hri);
    MultiVersionConcurrencyControl mvcc = new MultiVersionConcurrencyControl();
    for (int i = 0; i < 20; i++) {
      byte[] b = Bytes.toBytes(i + """");
      KeyValue kv = new KeyValue(b, b, b);
      WALEdit edit = new WALEdit();
      WALEditInternalHelper.addExtendedCell(edit, kv);
      NavigableMap<byte[], Integer> scopes = new TreeMap<>(Bytes.BYTES_COMPARATOR);
      scopes.put(b, 0);
      long txid = wal.appendData(hri,
        new WALKeyImpl(hri.getEncodedNameAsBytes(), TableName.valueOf(b), 0, mvcc, scopes), edit);
      wal.sync(txid);
      if (i == 10) {
        wal.registerWALActionsListener(laterobserver);
      }",1
"@Test
  public void testBatchSink() throws Exception {
    List<WALEntry> entries = new ArrayList<>(BATCH_SIZE);
    List<ExtendedCell> cells = new ArrayList<>();
    for (int i = 0; i < BATCH_SIZE; i++) {
      entries.add(createEntry(TABLE_NAME1, i, KeyValue.Type.Put, cells));
    }",1
"@Test
  public void testThrottling() {
    LOG.info(""testThrottling"");

    // throttle bandwidth is 100 and 10 bytes/cycle respectively
    ReplicationThrottler throttler1 = new ReplicationThrottler(100);
    ReplicationThrottler throttler2 = new ReplicationThrottler(10);

    long ticks1 = throttler1.getNextSleepInterval(1000);
    long ticks2 = throttler2.getNextSleepInterval(1000);

    // 1. the first push size is 1000, though 1000 bytes exceeds 100/10
    // bandwidthes, but no sleep since it's the first push of current
    // cycle, amortizing occurs when next push arrives
    assertEquals(0, ticks1);
    assertEquals(0, ticks2);

    throttler1.addPushSize(1000);
    throttler2.addPushSize(1000);

    ticks1 = throttler1.getNextSleepInterval(5);
    ticks2 = throttler2.getNextSleepInterval(5);

    // 2. when the second push(5) arrives and throttling(5) is called, the
    // current cyclePushSize is 1000 bytes, this should make throttler1
    // sleep 1000/100 = 10 cycles = 1s and make throttler2 sleep 1000/10
    // = 100 cycles = 10s before the second push occurs -- amortize case
    // after amortizing, both cycleStartTick and cyclePushSize are reset
    //
    // Note: in a slow machine, the sleep interval might be less than ideal ticks.
    // If it is 75% of expected value, its is still acceptable.
    if (ticks1 != 1000 && ticks1 != 999) {
      assertTrue(ticks1 >= 750 && ticks1 <= 1000);
    }",1
"@Test
  public void testInterClusterReplication() throws Exception {
    final String id = ""testInterClusterReplication"";

    List<HRegion> regions = UTIL1.getHBaseCluster().getRegions(tableName);
    int totEdits = 0;

    // Make sure edits are spread across regions because we do region based batching
    // before shipping edits.
    for (HRegion region : regions) {
      RegionInfo hri = region.getRegionInfo();
      byte[] row = hri.getStartKey();
      for (int i = 0; i < 100; i++) {
        if (row.length > 0) {
          Put put = new Put(row);
          put.addColumn(famName, row, row);
          region.put(put);
          totEdits++;
        }",1
"@Test
  public void testMetricsSourceBaseSourcePassThrough() {
    /*
     * The replication MetricsSource wraps a MetricsReplicationTableSourceImpl,
     * MetricsReplicationSourceSourceImpl and a MetricsReplicationGlobalSourceSource, so that
     * metrics get written to both namespaces. Both of those classes wrap a
     * MetricsReplicationSourceImpl that implements BaseSource, which allows for custom JMX metrics.
     * This test checks to make sure the BaseSource decorator logic on MetricsSource actually calls
     * down through the two layers of wrapping to the actual BaseSource.
     */
    String id = ""id"";
    DynamicMetricsRegistry mockRegistry = mock(DynamicMetricsRegistry.class);
    MetricsReplicationSourceImpl singleRms = mock(MetricsReplicationSourceImpl.class);
    when(singleRms.getMetricsRegistry()).thenReturn(mockRegistry);
    MetricsReplicationSourceImpl globalRms = mock(MetricsReplicationSourceImpl.class);
    when(globalRms.getMetricsRegistry()).thenReturn(mockRegistry);

    MetricsReplicationSourceSource singleSourceSource =
      new MetricsReplicationSourceSourceImpl(singleRms, id);
    MetricsReplicationGlobalSourceSource globalSourceSource =
      new MetricsReplicationGlobalSourceSourceImpl(globalRms);
    MetricsReplicationGlobalSourceSource spyglobalSourceSource = spy(globalSourceSource);
    doNothing().when(spyglobalSourceSource).incrFailedRecoveryQueue();

    Map<String, MetricsReplicationTableSource> singleSourceSourceByTable = new HashMap<>();
    MetricsSource source =
      new MetricsSource(id, singleSourceSource, spyglobalSourceSource, singleSourceSourceByTable);

    String gaugeName = ""gauge"";
    String singleGaugeName = ""source.id."" + gaugeName;
    String globalGaugeName = ""source."" + gaugeName;
    long delta = 1;
    String counterName = ""counter"";
    String singleCounterName = ""source.id."" + counterName;
    String globalCounterName = ""source."" + counterName;
    long count = 2;
    source.decGauge(gaugeName, delta);
    source.getMetricsContext();
    source.getMetricsDescription();
    source.getMetricsJmxContext();
    source.getMetricsName();
    source.incCounters(counterName, count);
    source.incGauge(gaugeName, delta);
    source.init();
    source.removeMetric(gaugeName);
    source.setGauge(gaugeName, delta);
    source.updateHistogram(counterName, count);
    source.incrFailedRecoveryQueue();

    verify(singleRms).decGauge(singleGaugeName, delta);
    verify(globalRms).decGauge(globalGaugeName, delta);
    verify(globalRms).getMetricsContext();
    verify(globalRms).getMetricsJmxContext();
    verify(globalRms).getMetricsName();
    verify(singleRms).incCounters(singleCounterName, count);
    verify(globalRms).incCounters(globalCounterName, count);
    verify(singleRms).incGauge(singleGaugeName, delta);
    verify(globalRms).incGauge(globalGaugeName, delta);
    verify(globalRms).init();
    verify(singleRms).removeMetric(singleGaugeName);
    verify(globalRms).removeMetric(globalGaugeName);
    verify(singleRms).setGauge(singleGaugeName, delta);
    verify(globalRms).setGauge(globalGaugeName, delta);
    verify(singleRms).updateHistogram(singleCounterName, count);
    verify(globalRms).updateHistogram(globalCounterName, count);
    verify(spyglobalSourceSource).incrFailedRecoveryQueue();

    // check singleSourceSourceByTable metrics.
    // singleSourceSourceByTable map entry will be created only
    // after calling #setAgeOfLastShippedOpByTable
    boolean containsRandomNewTable =
      source.getSingleSourceSourceByTable().containsKey(""RandomNewTable"");
    Assert.assertEquals(false, containsRandomNewTable);
    source.updateTableLevelMetrics(createWALEntriesWithSize(""RandomNewTable""));
    containsRandomNewTable = source.getSingleSourceSourceByTable().containsKey(""RandomNewTable"");
    Assert.assertEquals(true, containsRandomNewTable);
    MetricsReplicationTableSource msr = source.getSingleSourceSourceByTable().get(""RandomNewTable"");

    // age should be greater than zero we created the entry with time in the past
    Assert.assertTrue(msr.getLastShippedAge() > 0);
    Assert.assertTrue(msr.getShippedBytes() > 0);

  }",1
"@Test
  public void testReplicationStatus() throws Exception {
    // This test wants two RS's up. We only run one generally so add one.
    UTIL1.getMiniHBaseCluster().startRegionServer();
    Waiter.waitFor(UTIL1.getConfiguration(), 30000, new Waiter.Predicate<Exception>() {
      @Override
      public boolean evaluate() throws Exception {
        return UTIL1.getMiniHBaseCluster().getLiveRegionServerThreads().size() > 1;
      }",1
"@Test
  public void testMultiCellGetJSON() throws IOException {
    String row_5_url = ""/"" + TABLE + ""/"" + ROW_1 + ""/"" + COLUMN_1;
    String row_6_url = ""/"" + TABLE + ""/"" + ROW_2 + ""/"" + COLUMN_2;

    StringBuilder path = new StringBuilder();
    path.append(""/"");
    path.append(TABLE);
    path.append(""/multiget/?row="");
    path.append(ROW_1);
    path.append(""&row="");
    path.append(ROW_2);

    if (csrfEnabled) {
      Response response = client.post(row_5_url, Constants.MIMETYPE_BINARY, Bytes.toBytes(VALUE_1));
      assertEquals(400, response.getCode());
    }",1
"@Test
  public void testAccessControlRevokeOnlyFewPermission() throws Throwable {
    TableName tname = TableName.valueOf(""revoke"");
    try {
      TEST_UTIL.createTable(tname, TEST_FAMILY);
      User testUserPerms = User.createUserForTesting(conf, ""revokePerms"", new String[0]);
      Permission.Action[] actions = { Action.READ, Action.WRITE }",1
"@Test
  public void testGetProcedures() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final ProcedureExecutor<MasterProcedureEnv> procExec =
      TEST_UTIL.getHBaseCluster().getMaster().getMasterProcedureExecutor();
    Procedure proc = new TestTableDDLProcedure(procExec.getEnvironment(), tableName);
    proc.setOwner(USER_OWNER);
    procExec.submitProcedure(proc);
    final List<Procedure<MasterProcedureEnv>> procList = procExec.getProcedures();

    AccessTestAction getProceduresAction = new AccessTestAction() {
      @Override
      public Object run() throws Exception {
        ACCESS_CONTROLLER.postGetProcedures(ObserverContextImpl.createAndPrepare(CP_ENV));
        return null;
      }",1
"@Test
  public void testGetUserPermissions() throws Throwable {
    Connection conn = null;
    try {
      conn = ConnectionFactory.createConnection(conf);
      User nSUser1 = User.createUserForTesting(conf, ""nsuser1"", new String[0]);
      User nSUser2 = User.createUserForTesting(conf, ""nsuser2"", new String[0]);
      User nSUser3 = User.createUserForTesting(conf, ""nsuser3"", new String[0]);

      // Global access groups
      User globalGroupUser1 =
        User.createUserForTesting(conf, ""globalGroupUser1"", new String[] { ""group_admin"" }",1
"@Test
  public void testHasPermission() throws Throwable {
    Connection conn = null;
    try {
      conn = ConnectionFactory.createConnection(conf);
      // Create user and set namespace ACL
      User user1 = User.createUserForTesting(conf, ""testHasPermissionUser1"", new String[0]);
      // Grant namespace permission
      grantOnNamespaceUsingAccessControlClient(TEST_UTIL, conn, user1.getShortName(),
        NamespaceDescriptor.DEFAULT_NAMESPACE.getName(), Permission.Action.ADMIN,
        Permission.Action.CREATE, Permission.Action.READ);

      // Create user and set table ACL
      User user2 = User.createUserForTesting(conf, ""testHasPermissionUser2"", new String[0]);
      // Grant namespace permission
      grantOnTableUsingAccessControlClient(TEST_UTIL, conn, user2.getShortName(), TEST_TABLE,
        TEST_FAMILY, TEST_QUALIFIER, Permission.Action.READ, Permission.Action.WRITE);

      // Verify action privilege
      AccessTestAction hasPermissionActionCP = new AccessTestAction() {
        @Override
        public Object run() throws Exception {
          try (Connection conn = ConnectionFactory.createConnection(conf);
            Table acl = conn.getTable(PermissionStorage.ACL_TABLE_NAME)) {
            BlockingRpcChannel service = acl.coprocessorService(TEST_TABLE.getName());
            AccessControlService.BlockingInterface protocol =
              AccessControlService.newBlockingStub(service);
            Permission.Action[] actions = { Permission.Action.READ, Permission.Action.WRITE }",1
"@Test
  public void testPostGrantRevokeAtQualifierLevel() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    final byte[] family1 = Bytes.toBytes(""f1"");
    final byte[] family2 = Bytes.toBytes(""f2"");
    final byte[] qualifier = Bytes.toBytes(""q"");

    // create table
    Admin admin = TEST_UTIL.getAdmin();
    if (admin.tableExists(tableName)) {
      deleteTable(TEST_UTIL, tableName);
    }",1
"@Test
  public void testReadWrite() throws Exception {
    // action for checkAndDelete
    AccessTestAction checkAndDeleteAction = new AccessTestAction() {
      @Override
      public Object run() throws Exception {
        Delete d = new Delete(TEST_ROW);
        d.addFamily(TEST_FAMILY);
        try (Connection conn = ConnectionFactory.createConnection(conf);
          Table t = conn.getTable(TEST_TABLE)) {
          t.checkAndMutate(TEST_ROW, TEST_FAMILY).qualifier(TEST_QUALIFIER)
            .ifEquals(Bytes.toBytes(""test_value"")).thenDelete(d);
        }",1
"@Test
  public void testRemoteLocks() throws Exception {
    String namespace = ""preQueueNs"";
    final TableName tableName = TableName.valueOf(namespace, name.getMethodName());
    RegionInfo[] regionInfos = new RegionInfo[] { RegionInfoBuilder.newBuilder(tableName).build() }",1
"@Test
  public void testUnassign() throws Exception {
    List<HRegionLocation> regions;
    try (RegionLocator locator = systemUserConnection.getRegionLocator(TEST_TABLE)) {
      regions = locator.getAllRegionLocations();
    }",1
"@Test
  public void testPermissionsWatcher() throws Exception {
    Configuration conf = UTIL.getConfiguration();
    User george = User.createUserForTesting(conf, ""george"", new String[] {}",1
"@Test
  public void testKeyWrappingUsingHashAlgDefault() throws Exception {
    testKeyWrapping(DEFAULT_HASH_ALGORITHM);
  }",1
"@Test
  public void testRunAs() throws Exception {
    Configuration conf = HBaseConfiguration.create();
    final User user = User.createUserForTesting(conf, ""testuser"", new String[] { ""foo"" }",1
"@Test
  public void testKeyUpdate() throws Exception {
    // sanity check
    assertTrue(KEY_MASTER.isMaster());
    assertFalse(KEY_SLAVE.isMaster());
    int maxKeyId = 0;

    KEY_MASTER.rollCurrentKey();
    AuthenticationKey key1 = KEY_MASTER.getCurrentKey();
    assertNotNull(key1);
    LOG.debug(""Master current key (key1) {}",1
"@Test
  public void testIncrement() throws IOException {

    MutationProto proto = getIncrementMutation(111111L);
    // default fields
    assertEquals(MutationProto.Durability.USE_DEFAULT, proto.getDurability());

    // set the default value for equal comparison
    MutationProto.Builder mutateBuilder = MutationProto.newBuilder(proto);
    mutateBuilder.setDurability(MutationProto.Durability.USE_DEFAULT);

    Increment increment = ProtobufUtil.toIncrement(proto, null);
    mutateBuilder.setTimestamp(increment.getTimestamp());
    mutateBuilder.setTimeRange(ProtobufUtil.toTimeRange(increment.getTimeRange()));
    assertEquals(mutateBuilder.build(), ProtobufUtil.toMutation(MutationType.INCREMENT, increment));
  }",1
"@Test
  public void testPut() throws IOException {
    MutationProto.Builder mutateBuilder = MutationProto.newBuilder();
    mutateBuilder.setRow(ByteString.copyFromUtf8(""row""));
    mutateBuilder.setMutateType(MutationType.PUT);
    mutateBuilder.setTimestamp(111111);
    ColumnValue.Builder valueBuilder = ColumnValue.newBuilder();
    valueBuilder.setFamily(ByteString.copyFromUtf8(""f1""));
    QualifierValue.Builder qualifierBuilder = QualifierValue.newBuilder();
    qualifierBuilder.setQualifier(ByteString.copyFromUtf8(""c1""));
    qualifierBuilder.setValue(ByteString.copyFromUtf8(""v1""));
    valueBuilder.addQualifierValue(qualifierBuilder.build());
    qualifierBuilder.setQualifier(ByteString.copyFromUtf8(""c2""));
    qualifierBuilder.setValue(ByteString.copyFromUtf8(""v2""));
    qualifierBuilder.setTimestamp(222222);
    valueBuilder.addQualifierValue(qualifierBuilder.build());
    mutateBuilder.addColumnValue(valueBuilder.build());

    MutationProto proto = mutateBuilder.build();
    // default fields
    assertEquals(MutationProto.Durability.USE_DEFAULT, proto.getDurability());

    // set the default value for equal comparison
    mutateBuilder = MutationProto.newBuilder(proto);
    mutateBuilder.setDurability(MutationProto.Durability.USE_DEFAULT);

    Put put = ProtobufUtil.toPut(proto);

    // put value always use the default timestamp if no
    // value level timestamp specified,
    // add the timestamp to the original mutate
    long timestamp = put.getTimestamp();
    for (ColumnValue.Builder column : mutateBuilder.getColumnValueBuilderList()) {
      for (QualifierValue.Builder qualifier : column.getQualifierValueBuilderList()) {
        if (!qualifier.hasTimestamp()) {
          qualifier.setTimestamp(timestamp);
        }",1
"@Test
  public void testToCell() {
    KeyValue kv1 =
      new KeyValue(Bytes.toBytes(""aaa""), Bytes.toBytes(""f1""), Bytes.toBytes(""q1""), new byte[30]);
    KeyValue kv2 =
      new KeyValue(Bytes.toBytes(""bbb""), Bytes.toBytes(""f1""), Bytes.toBytes(""q1""), new byte[30]);
    KeyValue kv3 =
      new KeyValue(Bytes.toBytes(""ccc""), Bytes.toBytes(""f1""), Bytes.toBytes(""q1""), new byte[30]);
    byte[] arr = new byte[kv1.getLength() + kv2.getLength() + kv3.getLength()];
    System.arraycopy(kv1.getBuffer(), kv1.getOffset(), arr, 0, kv1.getLength());
    System.arraycopy(kv2.getBuffer(), kv2.getOffset(), arr, kv1.getLength(), kv2.getLength());
    System.arraycopy(kv3.getBuffer(), kv3.getOffset(), arr, kv1.getLength() + kv2.getLength(),
      kv3.getLength());
    ByteBuffer dbb = ByteBuffer.allocateDirect(arr.length);
    dbb.put(arr);
    ByteBufferKeyValue offheapKV = new ByteBufferKeyValue(dbb, kv1.getLength(), kv2.getLength());
    CellProtos.Cell cell = ProtobufUtil.toCell(offheapKV, false);
    Cell newOffheapKV = ProtobufUtil
      .toCell(ExtendedCellBuilderFactory.create(CellBuilderType.SHALLOW_COPY), cell, false);
    assertTrue(CellComparatorImpl.COMPARATOR.compare(offheapKV, newOffheapKV) == 0);
  }",1
"@Test
  public void testCompleteSnapshotWithNoSnapshotDirectoryFailure() throws Exception {
    Path snapshotDir = new Path(root, HConstants.SNAPSHOT_DIR_NAME);
    Path tmpDir = new Path(snapshotDir, "".tmp"");
    Path workingDir = new Path(tmpDir, ""not_a_snapshot"");
    Configuration conf = new Configuration();
    FileSystem workingFs = workingDir.getFileSystem(conf);
    assertFalse(
      ""Already have working snapshot dir: "" + workingDir + "" but shouldn't. Test file leak?"",
      fs.exists(workingDir));
    SnapshotDescription snapshot = SnapshotDescription.newBuilder().setName(""snapshot"").build();
    Path finishedDir = SnapshotDescriptionUtils.getCompletedSnapshotDir(snapshot, snapshotDir);

    try {
      SnapshotDescriptionUtils.completeSnapshot(finishedDir, workingDir, fs, workingFs, conf);
      fail(""Shouldn't successfully complete move of a non-existent directory."");
    }",1
"@Test
  public void testCompare() {
    Cell cell1 = getOffheapCell(row1, fam1, qual1);
    Cell cell2 = getOffheapCell(row1, fam1, qual2);
    assertTrue(CellComparatorImpl.COMPARATOR.compare(cell1, cell2) < 0);
    Cell cell3 = getOffheapCell(row1, Bytes.toBytes(""wide_family""), qual2);
    assertTrue(CellComparatorImpl.COMPARATOR.compare(cell1, cell3) < 0);
    Cell cell4 = getOffheapCell(row1, Bytes.toBytes(""f""), qual2);
    assertTrue(CellComparatorImpl.COMPARATOR.compare(cell1, cell4) > 0);
    CellComparator comparator = CellComparator.getInstance();
    assertTrue(comparator.compare(cell1, cell2) < 0);
    assertTrue(comparator.compare(cell1, cell3) < 0);
    assertTrue(comparator.compare(cell1, cell4) > 0);
    ByteBuffer buf = ByteBuffer.allocate(row1.length);
    ByteBufferUtils.copyFromArrayToBuffer(buf, row1, 0, row1.length);

    ConcurrentSkipListMap<ByteBufferKeyValue, ByteBufferKeyValue> map =
      new ConcurrentSkipListMap<>(comparator);
    map.put((ByteBufferKeyValue) cell1, (ByteBufferKeyValue) cell1);
    map.put((ByteBufferKeyValue) cell2, (ByteBufferKeyValue) cell2);
    map.put((ByteBufferKeyValue) cell3, (ByteBufferKeyValue) cell3);
    map.put((ByteBufferKeyValue) cell1, (ByteBufferKeyValue) cell1);
    map.put((ByteBufferKeyValue) cell1, (ByteBufferKeyValue) cell4);
    assertEquals(3, map.size());
    assertTrue(map.containsKey(cell1));
    assertTrue(map.containsKey(cell2));
    assertTrue(map.containsKey(cell3));
    assertEquals(cell4, map.get(cell1));
    assertEquals(cell2, map.get(cell2));
    assertEquals(cell3, map.get(cell3));
  }",1
"@Test
  public void testExtendedCellBuilderWithDeepCopy() {
    byte[] row = new byte[] { OLD_DATA }",1
"@Test
  public void testMetaComparisons() throws Exception {
    long now = EnvironmentEdgeManager.currentTime();

    // Meta compares
    Cell aaa = createByteBufferKeyValueFromKeyValue(
      new KeyValue(Bytes.toBytes(""TestScanMultipleVersions,row_0500,1236020145502""), now));
    Cell bbb = createByteBufferKeyValueFromKeyValue(
      new KeyValue(Bytes.toBytes(""TestScanMultipleVersions,,99999999999999""), now));
    CellComparator c = MetaCellComparator.META_COMPARATOR;
    assertTrue(c.compare(bbb, aaa) < 0);

    Cell ccc = createByteBufferKeyValueFromKeyValue(
      new KeyValue(Bytes.toBytes(""TestScanMultipleVersions,,1236023996656""), Bytes.toBytes(""info""),
        Bytes.toBytes(""regioninfo""), 1236024396271L, (byte[]) null));
    assertTrue(c.compare(ccc, bbb) < 0);

    Cell x = createByteBufferKeyValueFromKeyValue(
      new KeyValue(Bytes.toBytes(""TestScanMultipleVersions,row_0500,1236034574162""),
        Bytes.toBytes(""info""), Bytes.toBytes(""""), 9223372036854775807L, (byte[]) null));
    Cell y = createByteBufferKeyValueFromKeyValue(
      new KeyValue(Bytes.toBytes(""TestScanMultipleVersions,row_0500,1236034574162""),
        Bytes.toBytes(""info""), Bytes.toBytes(""regioninfo""), 1236034574912L, (byte[]) null));
    assertTrue(c.compare(x, y) < 0);
  }",1
"@Test
  public void testCloneCellFieldsFromByteBufferedCell() {
    byte[] r = Bytes.toBytes(""row1"");
    byte[] f = Bytes.toBytes(""cf1"");
    byte[] q = Bytes.toBytes(""qual1"");
    byte[] v = Bytes.toBytes(""val1"");
    byte[] tags = Bytes.toBytes(""tag1"");
    KeyValue kv =
      new KeyValue(r, f, q, 0, q.length, 1234L, KeyValue.Type.Put, v, 0, v.length, tags);
    ByteBuffer buffer = ByteBuffer.wrap(kv.getBuffer());
    ExtendedCell bbCell = new ByteBufferKeyValue(buffer, 0, buffer.remaining());
    byte[] rDest = CellUtil.cloneRow(bbCell);
    assertTrue(Bytes.equals(r, rDest));
    byte[] fDest = CellUtil.cloneFamily(bbCell);
    assertTrue(Bytes.equals(f, fDest));
    byte[] qDest = CellUtil.cloneQualifier(bbCell);
    assertTrue(Bytes.equals(q, qDest));
    byte[] vDest = CellUtil.cloneValue(bbCell);
    assertTrue(Bytes.equals(v, vDest));
    byte[] tDest = new byte[tags.length];
    PrivateCellUtil.copyTagsTo(bbCell, tDest, 0);
    assertTrue(Bytes.equals(tags, tDest));
  }",1
"@Test
  public void testMatchingCellFieldsFromByteBufferedCell() {
    byte[] r = Bytes.toBytes(""row1"");
    byte[] f = Bytes.toBytes(""cf1"");
    byte[] q1 = Bytes.toBytes(""qual1"");
    byte[] q2 = Bytes.toBytes(""qual2"");
    byte[] v = Bytes.toBytes(""val1"");
    byte[] tags = Bytes.toBytes(""tag1"");
    KeyValue kv =
      new KeyValue(r, f, q1, 0, q1.length, 1234L, KeyValue.Type.Put, v, 0, v.length, tags);
    ByteBuffer buffer = ByteBuffer.wrap(kv.getBuffer());
    Cell bbCell1 = new ByteBufferKeyValue(buffer, 0, buffer.remaining());
    kv = new KeyValue(r, f, q2, 0, q2.length, 1234L, KeyValue.Type.Put, v, 0, v.length, tags);
    buffer = ByteBuffer.wrap(kv.getBuffer());
    Cell bbCell2 = new ByteBufferKeyValue(buffer, 0, buffer.remaining());
    assertTrue(CellUtil.matchingRows(bbCell1, bbCell2));
    assertTrue(CellUtil.matchingRows(kv, bbCell2));
    assertTrue(CellUtil.matchingRows(bbCell1, r));
    assertTrue(CellUtil.matchingFamily(bbCell1, bbCell2));
    assertTrue(CellUtil.matchingFamily(kv, bbCell2));
    assertTrue(CellUtil.matchingFamily(bbCell1, f));
    assertFalse(CellUtil.matchingQualifier(bbCell1, bbCell2));
    assertTrue(CellUtil.matchingQualifier(kv, bbCell2));
    assertTrue(CellUtil.matchingQualifier(bbCell1, q1));
    assertTrue(CellUtil.matchingQualifier(bbCell2, q2));
    assertTrue(CellUtil.matchingValue(bbCell1, bbCell2));
    assertTrue(CellUtil.matchingValue(kv, bbCell2));
    assertTrue(CellUtil.matchingValue(bbCell1, v));
    assertFalse(CellUtil.matchingColumn(bbCell1, bbCell2));
    assertTrue(CellUtil.matchingColumn(kv, bbCell2));
    assertTrue(CellUtil.matchingColumn(bbCell1, f, q1));
    assertTrue(CellUtil.matchingColumn(bbCell2, f, q2));
  }",1
"@Test
  public void testForceTrigger() throws InterruptedException {
    final int period = 100;
    final int delta = period / 10;
    final CountingChore chore = new CountingChore(""countingChore"", period);
    service.scheduleChore(chore);
    Thread.sleep(10 * period + delta);

    assertEquals(""10 periods have elapsed."", 11, chore.getCountOfChoreCalls());

    // Force five runs of the chore to occur, sleeping between triggers to ensure the
    // chore has time to run
    chore.triggerNow();
    Thread.sleep(delta);
    chore.triggerNow();
    Thread.sleep(delta);
    chore.triggerNow();
    Thread.sleep(delta);
    chore.triggerNow();
    Thread.sleep(delta);
    chore.triggerNow();
    Thread.sleep(delta);

    assertEquals(""Trigger was called 5 times after 10 periods."", 16, chore.getCountOfChoreCalls());

    Thread.sleep(10 * period + delta);

    // Be loosey-goosey. It used to be '26' but it was a big flakey relying on timing.
    assertTrue(""Expected at least 16 invocations, instead got "" + chore.getCountOfChoreCalls(),
      chore.getCountOfChoreCalls() > 16);
  }",1
"@Test
  public void testScheduledChoreConstruction() {
    final String NAME = ""chore"";
    final int PERIOD = 100;
    final long VALID_DELAY = 0;
    final long INVALID_DELAY = -100;
    final TimeUnit UNIT = TimeUnit.NANOSECONDS;

    ScheduledChore chore1 =
      new ScheduledChore(NAME, new SampleStopper(), PERIOD, VALID_DELAY, UNIT) {
        @Override
        protected void chore() {
          // DO NOTHING
        }",1
"@Test
  public void testClassFinderFiltersByPathInDirs() throws Exception {
    final String hardcodedThisSubdir = ""hbase-common"";
    final ClassFinder.ResourcePathFilter notExcJarFilter =
      (resourcePath, isJar) -> isJar || !resourcePath.contains(hardcodedThisSubdir);
    String thisPackage = this.getClass().getPackage().getName();
    ClassFinder notThisClassFinder = new ClassFinder(notExcJarFilter, null, null, classLoader);
    Set<Class<?>> notAllClasses = notThisClassFinder.findClasses(thisPackage, false);
    assertFalse(notAllClasses.contains(this.getClass()));
  }",1
"@Test
  public void testClassFinderHandlesNestedPackages() throws Exception {
    final String NESTED = "".nested"";
    final String CLASSNAME1 = name.getMethodName() + ""1"";
    final String CLASSNAME2 = name.getMethodName() + ""2"";
    long counter = testCounter.incrementAndGet();
    FileAndPath c1 = compileTestClass(counter, """", ""c1"");
    FileAndPath c2 = compileTestClass(counter, NESTED, CLASSNAME1);
    FileAndPath c3 = compileTestClass(counter, NESTED, CLASSNAME2);
    packageAndLoadJar(c1, c2);
    packageAndLoadJar(c3);

    ClassFinder allClassesFinder = new ClassFinder(classLoader);
    Set<Class<?>> nestedClasses =
      allClassesFinder.findClasses(makePackageName(NESTED, counter), false);
    assertEquals(2, nestedClasses.size());
    Class<?> nestedClass1 = makeClass(NESTED, CLASSNAME1, counter);
    assertTrue(nestedClasses.contains(nestedClass1));
    Class<?> nestedClass2 = makeClass(NESTED, CLASSNAME2, counter);
    assertTrue(nestedClasses.contains(nestedClass2));
  }",1
"@Test
  public void testLaterConfigsOverrideEarlier() {
    Map<String, String> map1 = new HashMap<>();
    map1.put(""A"", ""2"");
    map1.put(""D"", ""5"");
    Map<String, String> map2 = new HashMap<>();
    String newValueForA = ""3"", newValueForB = ""4"";
    map2.put(""A"", newValueForA);
    map2.put(""B"", newValueForB);

    CompoundConfiguration compoundConf =
      new CompoundConfiguration().addStringMap(map1).add(baseConf);
    assertEquals(""1"", compoundConf.get(""A""));
    assertEquals(""5"", compoundConf.get(""D""));
    compoundConf.addStringMap(map2);
    assertEquals(newValueForA, compoundConf.get(""A""));
    assertEquals(newValueForB, compoundConf.get(""B""));
    assertEquals(""5"", compoundConf.get(""D""));

    int cnt = 0;
    for (Map.Entry<String, String> entry : compoundConf) {
      cnt++;
      if (entry.getKey().equals(""A"")) {
        assertEquals(newValueForA, entry.getValue());
      }",1
"@Test
  public void testWithConfig() {
    Configuration conf = new Configuration();
    conf.set(""B"", ""2b"");
    conf.set(""C"", ""33"");
    conf.set(""D"", ""4"");

    CompoundConfiguration compoundConf = new CompoundConfiguration().add(baseConf).add(conf);
    assertEquals(""1"", compoundConf.get(""A""));
    assertEquals(""2b"", compoundConf.get(""B""));
    assertEquals(33, compoundConf.getInt(""C"", 0));
    assertEquals(""4"", compoundConf.get(""D""));
    assertEquals(4, compoundConf.getInt(""D"", 0));
    assertNull(compoundConf.get(""E""));
    assertEquals(6, compoundConf.getInt(""F"", 6));

    int cnt = 0;
    for (Map.Entry<String, String> entry : compoundConf) {
      cnt++;
      if (entry.getKey().equals(""B"")) {
        assertEquals(""2b"", entry.getValue());
      }",1
"@Test
  public void testWithIbwMap() {
    Map<Bytes, Bytes> map = new HashMap<>();
    map.put(strToIb(""B""), strToIb(""2b""));
    map.put(strToIb(""C""), strToIb(""33""));
    map.put(strToIb(""D""), strToIb(""4""));
    // unlike config, note that IBW Maps can accept null values
    map.put(strToIb(""G""), null);

    CompoundConfiguration compoundConf = new CompoundConfiguration().add(baseConf).addBytesMap(map);
    assertEquals(""1"", compoundConf.get(""A""));
    assertEquals(""2b"", compoundConf.get(""B""));
    assertEquals(33, compoundConf.getInt(""C"", 0));
    assertEquals(""4"", compoundConf.get(""D""));
    assertEquals(4, compoundConf.getInt(""D"", 0));
    assertNull(compoundConf.get(""E""));
    assertEquals(6, compoundConf.getInt(""F"", 6));
    assertNull(compoundConf.get(""G""));

    int cnt = 0;
    for (Map.Entry<String, String> entry : compoundConf) {
      cnt++;
      if (entry.getKey().equals(""B"")) {
        assertEquals(""2b"", entry.getValue());
      }",1
"@Test
  public void testStart() throws Exception {
    JMXConnector connector =
      JMXConnectorFactory.connect(JMXListener.buildJMXServiceURL(CONNECTOR_PORT, CONNECTOR_PORT));

    MBeanServerConnection mb = connector.getMBeanServerConnection();
    String domain = mb.getDefaultDomain();
    Assert.assertTrue(""default domain is not correct"", !domain.isEmpty());
    connector.close();

  }",1
"@Test
  public void testBasics() {
    LOG.info(""LOWKEY: "" + KeyValue.LOWESTKEY.toString());
    String name = ""testBasics"";
    check(Bytes.toBytes(name), Bytes.toBytes(name), Bytes.toBytes(name), 1, Bytes.toBytes(name));
    // Test empty value and empty column -- both should work. (not empty fam)
    check(Bytes.toBytes(name), Bytes.toBytes(name), null, 1, null);
    check(HConstants.EMPTY_BYTE_ARRAY, Bytes.toBytes(name), null, 1, null);
    // empty qual is equivalent to null qual
    assertEquals(new KeyValue(Bytes.toBytes(""rk""), Bytes.toBytes(""fam""), null, 1, (byte[]) null),
      new KeyValue(Bytes.toBytes(""rk""), Bytes.toBytes(""fam""), HConstants.EMPTY_BYTE_ARRAY, 1,
        (byte[]) null));
  }",1
"@Test
  public void testBinaryKeys() {
    Set<KeyValue> set = new TreeSet<>(CellComparatorImpl.COMPARATOR);
    final byte[] fam = Bytes.toBytes(""col"");
    final byte[] qf = Bytes.toBytes(""umn"");
    final byte[] nb = new byte[0];
    KeyValue[] keys = { new KeyValue(Bytes.toBytes(""aaaaa,\u0000\u0000,2""), fam, qf, 2, nb),
      new KeyValue(Bytes.toBytes(""aaaaa,\u0001,3""), fam, qf, 3, nb),
      new KeyValue(Bytes.toBytes(""aaaaa,,1""), fam, qf, 1, nb),
      new KeyValue(Bytes.toBytes(""aaaaa,\u1000,5""), fam, qf, 5, nb),
      new KeyValue(Bytes.toBytes(""aaaaa,a,4""), fam, qf, 4, nb),
      new KeyValue(Bytes.toBytes(""a,a,0""), fam, qf, 0, nb), }",1
"@Test
  public void testColumnCompare_prefix() {
    final byte[] a = Bytes.toBytes(""aaa"");
    byte[] family1 = Bytes.toBytes(""abc"");
    byte[] qualifier1 = Bytes.toBytes(""def"");
    byte[] family2 = Bytes.toBytes(""ab"");
    byte[] qualifier2 = Bytes.toBytes(""def"");

    KeyValue aaa = new KeyValue(a, family1, qualifier1, 0L, KeyValue.Type.Put, a);
    assertFalse(CellUtil.matchingColumn(aaa, family2, qualifier2));
  }",1
"@Test
  public void testKVsWithTags() {
    byte[] row = Bytes.toBytes(""myRow"");
    byte[] cf = Bytes.toBytes(""myCF"");
    byte[] q = Bytes.toBytes(""myQualifier"");
    byte[] value = Bytes.toBytes(""myValue"");
    byte[] metaValue1 = Bytes.toBytes(""metaValue1"");
    byte[] metaValue2 = Bytes.toBytes(""metaValue2"");
    KeyValue kv = new KeyValue(row, cf, q, HConstants.LATEST_TIMESTAMP, value, new Tag[] {
      new ArrayBackedTag((byte) 1, metaValue1), new ArrayBackedTag((byte) 2, metaValue2) }",1
"@Test
  public void testMetaLocationForRegionReplicasIsAddedAtTableCreation() throws IOException {
    long regionId = EnvironmentEdgeManager.currentTime();
    RegionInfo primary = RegionInfoBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
      .setStartKey(HConstants.EMPTY_START_ROW).setEndKey(HConstants.EMPTY_END_ROW).setSplit(false)
      .setRegionId(regionId).setReplicaId(0).build();

    Table meta = MetaTableAccessor.getMetaHTable(connection);
    try {
      List<RegionInfo> regionInfos = Lists.newArrayList(primary);
      MetaTableAccessor.addRegionsToMeta(connection, regionInfos, 3);

      assertEmptyMetaLocation(meta, primary.getRegionName(), 1);
      assertEmptyMetaLocation(meta, primary.getRegionName(), 2);
    }",1
"@Test
  public void testParseOptsMultiPuts() {
    Queue<String> opts = new LinkedList<>();
    String cmdName = ""sequentialWrite"";
    opts.offer(""--multiPut=10"");
    opts.offer(cmdName);
    opts.offer(""64"");
    PerformanceEvaluation.TestOptions options = null;
    try {
      options = PerformanceEvaluation.parseOpts(opts);
      fail(""should fail"");
    }",1
"@Test
  public void testParseOptsWrongThreads() {
    Queue<String> opts = new LinkedList<>();
    String cmdName = ""sequentialWrite"";
    opts.offer(cmdName);
    opts.offer(""qq"");
    try {
      PerformanceEvaluation.parseOpts(opts);
    }",1
"@Test
  public void testSerialization() {
    PerformanceEvaluation.TestOptions options = new PerformanceEvaluation.TestOptions();
    assertFalse(options.isAutoFlush());
    options.setAutoFlush(true);
    Gson gson = GsonUtil.createGson().create();
    String optionsString = gson.toJson(options);
    PerformanceEvaluation.TestOptions optionsDeserialized =
      gson.fromJson(optionsString, PerformanceEvaluation.TestOptions.class);
    assertTrue(optionsDeserialized.isAutoFlush());
  }",1
"@Test
  public void testRegionLoadAggregation() {
    ServerMetrics metrics = ServerMetricsBuilder
      .toServerMetrics(ServerName.valueOf(""localhost,1,1""), createServerLoadProto());
    assertEquals(13,
      metrics.getRegionMetrics().values().stream().mapToInt(v -> v.getStoreCount()).sum());
    assertEquals(114,
      metrics.getRegionMetrics().values().stream().mapToInt(v -> v.getStoreFileCount()).sum());
    assertEquals(129, metrics.getRegionMetrics().values().stream()
      .mapToDouble(v -> v.getUncompressedStoreFileSize().get(Size.Unit.MEGABYTE)).sum(), 0);
    assertEquals(504, metrics.getRegionMetrics().values().stream()
      .mapToDouble(v -> v.getStoreFileRootLevelIndexSize().get(Size.Unit.KILOBYTE)).sum(), 0);
    assertEquals(820, metrics.getRegionMetrics().values().stream()
      .mapToDouble(v -> v.getStoreFileSize().get(Size.Unit.MEGABYTE)).sum(), 0);
    assertEquals(82, metrics.getRegionMetrics().values().stream()
      .mapToDouble(v -> v.getStoreFileIndexSize().get(Size.Unit.KILOBYTE)).sum(), 0);
    assertEquals(((long) Integer.MAX_VALUE) * 2,
      metrics.getRegionMetrics().values().stream().mapToLong(v -> v.getReadRequestCount()).sum());
    assertEquals(100,
      metrics.getRegionMetrics().values().stream().mapToLong(v -> v.getCpRequestCount()).sum());
    assertEquals(300, metrics.getRegionMetrics().values().stream()
      .mapToLong(v -> v.getFilteredReadRequestCount()).sum());
    assertEquals(2, metrics.getRegionMetrics().values().stream()
      .mapToLong(v -> (long) v.getCurrentRegionCachedRatio()).count());
    assertEquals(150, metrics.getRegionMetrics().values().stream()
      .mapToDouble(v -> v.getRegionSizeMB().get(Size.Unit.MEGABYTE)).sum(), 0);
  }",1
"@Test
  public void testMergeLocations() {
    RegionLocations list1, list2;

    // test merge empty lists
    list1 = new RegionLocations();
    list2 = new RegionLocations();

    assertTrue(list1 == list1.mergeLocations(list2));

    // test merge non-empty and empty
    list2 = hrll(hrl(info0, sn0));
    list1 = list1.mergeLocations(list2);
    assertEquals(sn0, list1.getRegionLocation(0).getServerName());

    // test merge empty and non empty
    list1 = hrll();
    list1 = list2.mergeLocations(list1);
    assertEquals(sn0, list1.getRegionLocation(0).getServerName());

    // test merge non intersecting
    list1 = hrll(hrl(info0, sn0), hrl(info1, sn1));
    list2 = hrll(hrl(info2, sn2));
    list1 = list2.mergeLocations(list1);
    assertEquals(sn0, list1.getRegionLocation(0).getServerName());
    assertEquals(sn1, list1.getRegionLocation(1).getServerName());
    assertEquals(2, list1.size()); // the size is taken from the argument list to merge

    // do the other way merge as well
    list1 = hrll(hrl(info0, sn0), hrl(info1, sn1));
    list2 = hrll(hrl(info2, sn2));
    list1 = list1.mergeLocations(list2);
    assertEquals(sn0, list1.getRegionLocation(0).getServerName());
    assertEquals(sn1, list1.getRegionLocation(1).getServerName());
    assertEquals(sn2, list1.getRegionLocation(2).getServerName());

    // test intersecting lists same seqNum
    list1 = hrll(hrl(info0, sn0), hrl(info1, sn1));
    list2 = hrll(hrl(info0, sn2), hrl(info1, sn2), hrl(info9, sn3));
    list1 = list2.mergeLocations(list1); // list1 should override
    assertEquals(2, list1.size());
    assertEquals(sn0, list1.getRegionLocation(0).getServerName());
    assertEquals(sn1, list1.getRegionLocation(1).getServerName());

    // do the other way
    list1 = hrll(hrl(info0, sn0), hrl(info1, sn1));
    list2 = hrll(hrl(info0, sn2), hrl(info1, sn2), hrl(info9, sn3));
    list1 = list1.mergeLocations(list2); // list2 should override
    assertEquals(10, list1.size());
    assertEquals(sn2, list1.getRegionLocation(0).getServerName());
    assertEquals(sn2, list1.getRegionLocation(1).getServerName());
    assertEquals(sn3, list1.getRegionLocation(9).getServerName());

    // test intersecting lists different seqNum
    list1 = hrll(hrl(info0, sn0, 10), hrl(info1, sn1, 10));
    list2 = hrll(hrl(info0, sn2, 11), hrl(info1, sn2, 11), hrl(info9, sn3, 11));
    list1 = list1.mergeLocations(list2); // list2 should override because of seqNum
    assertEquals(10, list1.size());
    assertEquals(sn2, list1.getRegionLocation(0).getServerName());
    assertEquals(sn2, list1.getRegionLocation(1).getServerName());
    assertEquals(sn3, list1.getRegionLocation(9).getServerName());

    // do the other way
    list1 = hrll(hrl(info0, sn0, 10), hrl(info1, sn1, 10));
    list2 = hrll(hrl(info0, sn2, 11), hrl(info1, sn2, 11), hrl(info9, sn3, 11));
    list1 = list1.mergeLocations(list2); // list2 should override
    assertEquals(10, list1.size());
    assertEquals(sn2, list1.getRegionLocation(0).getServerName());
    assertEquals(sn2, list1.getRegionLocation(1).getServerName());
    assertEquals(sn3, list1.getRegionLocation(9).getServerName());
  }",1
"@Test
  public void testUpdateLocation() {
    RegionLocations list;

    // test add to empty list
    list = new RegionLocations();
    list = list.updateLocation(hrl(info0, sn1), false, false);
    assertEquals(sn1, list.getRegionLocation(0).getServerName());

    // test add to non-empty list
    list = list.updateLocation(hrl(info9, sn3, 10), false, false);
    assertEquals(sn3, list.getRegionLocation(9).getServerName());
    assertEquals(10, list.size());
    list = list.updateLocation(hrl(info2, sn2, 10), false, false);
    assertEquals(sn2, list.getRegionLocation(2).getServerName());
    assertEquals(10, list.size());

    // test update greater SeqNum
    list = list.updateLocation(hrl(info2, sn3, 11), false, false);
    assertEquals(sn3, list.getRegionLocation(2).getServerName());
    assertEquals(sn3, list.getRegionLocation(9).getServerName());

    // test update equal SeqNum
    list = list.updateLocation(hrl(info2, sn1, 11), false, false); // should not update
    assertEquals(sn3, list.getRegionLocation(2).getServerName());
    assertEquals(sn3, list.getRegionLocation(9).getServerName());
    list = list.updateLocation(hrl(info2, sn1, 11), true, false); // should update
    assertEquals(sn1, list.getRegionLocation(2).getServerName());
    assertEquals(sn3, list.getRegionLocation(9).getServerName());

    // test force update
    list = list.updateLocation(hrl(info2, sn2, 9), false, true); // should update
    assertEquals(sn2, list.getRegionLocation(2).getServerName());
    assertEquals(sn3, list.getRegionLocation(9).getServerName());
  }",1
"@Test
  public void testCarryForwardTTLTag() throws Exception {
    // No tags so far and the TTL tag must get added to the Tags list
    long ttl = 10 * 1000;
    List<Tag> tags = TagUtil.carryForwardTTLTag(null, ttl);
    assertEquals(1, tags.size());
    Tag ttlTag = tags.get(0);
    assertEquals(TagType.TTL_TAG_TYPE, ttlTag.getType());
    assertEquals(ttl, Tag.getValueAsLong(ttlTag));
    // Already having a TTL tag in the list. So the call must remove the old tag
    long ttl2 = 30 * 1000;
    tags = TagUtil.carryForwardTTLTag(tags, ttl2);
    assertEquals(1, tags.size());
    ttlTag = tags.get(0);
    assertEquals(TagType.TTL_TAG_TYPE, ttlTag.getType());
    assertEquals(ttl2, Tag.getValueAsLong(ttlTag));
  }",1
"@Test
  public void testAppend() throws Exception {
    ThriftHBaseServiceHandler handler = createHandler();
    byte[] rowName = Bytes.toBytes(""testAppend"");
    ByteBuffer table = wrap(tableAname);
    byte[] v1 = Bytes.toBytes(""42"");
    byte[] v2 = Bytes.toBytes(""23"");
    List<TColumnValue> columnValues = new ArrayList<>(1);
    columnValues.add(new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(v1)));
    TPut put = new TPut(wrap(rowName), columnValues);
    put.setColumnValues(columnValues);
    handler.put(table, put);

    List<TColumnValue> appendColumns = new ArrayList<>(1);
    appendColumns.add(new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(v2)));
    TAppend append = new TAppend(wrap(rowName), appendColumns);
    handler.append(table, append);

    TGet get = new TGet(wrap(rowName));
    TResult result = handler.get(table, get);

    assertArrayEquals(rowName, result.getRow());
    assertEquals(1, result.getColumnValuesSize());
    TColumnValue columnValue = result.getColumnValues().get(0);
    assertArrayEquals(Bytes.add(v1, v2), columnValue.getValue());
  }",1
"@Test
  public void testAttribute() throws Exception {
    byte[] rowName = Bytes.toBytes(""testAttribute"");
    byte[] attributeKey = Bytes.toBytes(""attribute1"");
    byte[] attributeValue = Bytes.toBytes(""value1"");
    Map<ByteBuffer, ByteBuffer> attributes = new HashMap<>();
    attributes.put(wrap(attributeKey), wrap(attributeValue));

    TGet tGet = new TGet(wrap(rowName));
    tGet.setAttributes(attributes);
    Get get = getFromThrift(tGet);
    assertArrayEquals(get.getAttribute(""attribute1""), attributeValue);

    List<TColumnValue> columnValues = new ArrayList<>(1);
    columnValues.add(new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(valueAname)));
    TPut tPut = new TPut(wrap(rowName), columnValues);
    tPut.setAttributes(attributes);
    Put put = putFromThrift(tPut);
    assertArrayEquals(put.getAttribute(""attribute1""), attributeValue);

    TScan tScan = new TScan();
    tScan.setAttributes(attributes);
    Scan scan = scanFromThrift(tScan);
    assertArrayEquals(scan.getAttribute(""attribute1""), attributeValue);

    List<TColumnIncrement> incrementColumns = new ArrayList<>(1);
    incrementColumns.add(new TColumnIncrement(wrap(familyAname), wrap(qualifierAname)));
    TIncrement tIncrement = new TIncrement(wrap(rowName), incrementColumns);
    tIncrement.setAttributes(attributes);
    Increment increment = incrementFromThrift(tIncrement);
    assertArrayEquals(increment.getAttribute(""attribute1""), attributeValue);

    TDelete tDelete = new TDelete(wrap(rowName));
    tDelete.setAttributes(attributes);
    Delete delete = deleteFromThrift(tDelete);
    assertArrayEquals(delete.getAttribute(""attribute1""), attributeValue);
  }",1
"@Test
  public void testConsistency() throws Exception {
    byte[] rowName = Bytes.toBytes(""testConsistency"");
    TGet tGet = new TGet(wrap(rowName));
    tGet.setConsistency(TConsistency.STRONG);
    Get get = getFromThrift(tGet);
    assertEquals(Consistency.STRONG, get.getConsistency());

    tGet.setConsistency(TConsistency.TIMELINE);
    tGet.setTargetReplicaId(1);
    get = getFromThrift(tGet);
    assertEquals(Consistency.TIMELINE, get.getConsistency());
    assertEquals(1, get.getReplicaId());

    TScan tScan = new TScan();
    tScan.setConsistency(TConsistency.STRONG);
    Scan scan = scanFromThrift(tScan);
    assertEquals(Consistency.STRONG, scan.getConsistency());

    tScan.setConsistency(TConsistency.TIMELINE);
    tScan.setTargetReplicaId(1);
    scan = scanFromThrift(tScan);
    assertEquals(Consistency.TIMELINE, scan.getConsistency());
    assertEquals(1, scan.getReplicaId());

    TResult tResult = new TResult();
    assertFalse(tResult.isSetStale());
    tResult.setStale(true);
    assertTrue(tResult.isSetStale());
  }",1
"@Test
  public void testDeleteAllTimestamps() throws Exception {
    ThriftHBaseServiceHandler handler = createHandler();
    byte[] rowName = Bytes.toBytes(""testDeleteAllTimestamps"");
    ByteBuffer table = wrap(tableAname);

    List<TColumnValue> columnValues = new ArrayList<>(1);
    TColumnValue columnValueA =
      new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(valueAname));
    columnValueA.setTimestamp(EnvironmentEdgeManager.currentTime() - 10);
    columnValues.add(columnValueA);
    TPut put = new TPut(wrap(rowName), columnValues);

    put.setColumnValues(columnValues);

    handler.put(table, put);
    columnValueA.setTimestamp(EnvironmentEdgeManager.currentTime());
    handler.put(table, put);

    TGet get = new TGet(wrap(rowName));
    get.setMaxVersions(2);
    TResult result = handler.get(table, get);
    assertEquals(2, result.getColumnValuesSize());

    TDelete delete = new TDelete(wrap(rowName));
    List<TColumn> deleteColumns = new ArrayList<>(1);
    TColumn deleteColumn = new TColumn(wrap(familyAname));
    deleteColumn.setQualifier(qualifierAname);
    deleteColumns.add(deleteColumn);
    delete.setColumns(deleteColumns);
    delete.setDeleteType(TDeleteType.DELETE_COLUMNS); // This is the default anyway.

    handler.deleteSingle(table, delete);

    get = new TGet(wrap(rowName));
    result = handler.get(table, get);
    assertNull(result.getRow());
    assertEquals(0, result.getColumnValuesSize());
  }",1
"@Test
  public void testDeleteMultiple() throws Exception {
    ThriftHBaseServiceHandler handler = createHandler();
    ByteBuffer table = wrap(tableAname);
    byte[] rowName1 = Bytes.toBytes(""testDeleteMultiple1"");
    byte[] rowName2 = Bytes.toBytes(""testDeleteMultiple2"");

    List<TColumnValue> columnValues = new ArrayList<>(2);
    columnValues.add(new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(valueAname)));
    columnValues.add(new TColumnValue(wrap(familyBname), wrap(qualifierBname), wrap(valueBname)));
    List<TPut> puts = new ArrayList<>(2);
    puts.add(new TPut(wrap(rowName1), columnValues));
    puts.add(new TPut(wrap(rowName2), columnValues));

    handler.putMultiple(table, puts);

    List<TDelete> deletes = new ArrayList<>(2);
    deletes.add(new TDelete(wrap(rowName1)));
    deletes.add(new TDelete(wrap(rowName2)));

    List<TDelete> deleteResults = handler.deleteMultiple(table, deletes);
    // 0 means they were all successfully applies
    assertEquals(0, deleteResults.size());

    assertFalse(handler.exists(table, new TGet(wrap(rowName1))));
    assertFalse(handler.exists(table, new TGet(wrap(rowName2))));
  }",1
"@Test
  public void testIncrement() throws Exception {
    ThriftHBaseServiceHandler handler = createHandler();
    byte[] rowName = Bytes.toBytes(""testIncrement"");
    ByteBuffer table = wrap(tableAname);

    List<TColumnValue> columnValues = new ArrayList<>(1);
    columnValues
      .add(new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(Bytes.toBytes(1L))));
    TPut put = new TPut(wrap(rowName), columnValues);
    put.setColumnValues(columnValues);
    handler.put(table, put);

    List<TColumnIncrement> incrementColumns = new ArrayList<>(1);
    incrementColumns.add(new TColumnIncrement(wrap(familyAname), wrap(qualifierAname)));
    TIncrement increment = new TIncrement(wrap(rowName), incrementColumns);
    handler.increment(table, increment);

    TGet get = new TGet(wrap(rowName));
    TResult result = handler.get(table, get);

    assertArrayEquals(rowName, result.getRow());
    assertEquals(1, result.getColumnValuesSize());
    TColumnValue columnValue = result.getColumnValues().get(0);
    assertArrayEquals(Bytes.toBytes(2L), columnValue.getValue());
  }",1
"@Test
  public void testMetrics() throws Exception {
    Configuration conf = UTIL.getConfiguration();
    ThriftMetrics metrics = getMetrics(conf);
    ThriftHBaseServiceHandler hbaseHandler = createHandler();
    THBaseService.Iface handler = HbaseHandlerMetricsProxy.newInstance(hbaseHandler, metrics, conf);
    byte[] rowName = Bytes.toBytes(""testMetrics"");
    ByteBuffer table = wrap(tableAname);

    TGet get = new TGet(wrap(rowName));
    assertFalse(handler.exists(table, get));

    List<TColumnValue> columnValues = new ArrayList<>(2);
    columnValues.add(new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(valueAname)));
    columnValues.add(new TColumnValue(wrap(familyBname), wrap(qualifierBname), wrap(valueBname)));
    TPut put = new TPut(wrap(rowName), columnValues);
    put.setColumnValues(columnValues);

    handler.put(table, put);

    assertTrue(handler.exists(table, get));
    metricsHelper.assertCounter(""put_num_ops"", 1, metrics.getSource());
    metricsHelper.assertCounter(""exists_num_ops"", 2, metrics.getSource());
  }",1
"@Test
  public void testMetricsWithException() throws Exception {
    byte[] rowkey = Bytes.toBytes(""row1"");
    byte[] family = Bytes.toBytes(""f"");
    byte[] col = Bytes.toBytes(""c"");
    // create a table which will throw exceptions for requests
    TableName tableName = TableName.valueOf(name.getMethodName());
    TableDescriptor tableDesc = TableDescriptorBuilder.newBuilder(tableName)
      .setCoprocessor(ErrorThrowingGetObserver.class.getName())
      .setColumnFamily(ColumnFamilyDescriptorBuilder.of(family)).build();

    Table table = UTIL.createTable(tableDesc, null);
    table.put(new Put(rowkey).addColumn(family, col, Bytes.toBytes(""val1"")));

    ThriftHBaseServiceHandler hbaseHandler = createHandler();
    ThriftMetrics metrics = getMetrics(UTIL.getConfiguration());
    THBaseService.Iface handler = HbaseHandlerMetricsProxy.newInstance(hbaseHandler, metrics, null);
    ByteBuffer tTableName = wrap(tableName.getName());

    // check metrics increment with a successful get
    long preGetCounter = metricsHelper.checkCounterExists(""get_num_ops"", metrics.getSource())
      ? metricsHelper.getCounter(""get_num_ops"", metrics.getSource())
      : 0;
    TGet tGet = new TGet(wrap(rowkey));
    TResult tResult = handler.get(tTableName, tGet);

    List<TColumnValue> expectedColumnValues =
      Lists.newArrayList(new TColumnValue(wrap(family), wrap(col), wrap(Bytes.toBytes(""val1""))));
    assertArrayEquals(rowkey, tResult.getRow());
    List<TColumnValue> returnedColumnValues = tResult.getColumnValues();
    assertTColumnValuesEqual(expectedColumnValues, returnedColumnValues);

    metricsHelper.assertCounter(""get_num_ops"", preGetCounter + 1, metrics.getSource());

    // check metrics increment when the get throws each exception type
    for (ErrorThrowingGetObserver.ErrorType type : ErrorThrowingGetObserver.ErrorType.values()) {
      testExceptionType(handler, metrics, tTableName, rowkey, type);
    }",1
"@Test
  public void testMutateRow() throws Exception {
    ThriftHBaseServiceHandler handler = createHandler();
    byte[] rowName = Bytes.toBytes(""testMutateRow"");
    ByteBuffer table = wrap(tableAname);

    List<TColumnValue> columnValuesA = new ArrayList<>(1);
    TColumnValue columnValueA =
      new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(valueAname));
    columnValuesA.add(columnValueA);
    TPut putA = new TPut(wrap(rowName), columnValuesA);
    putA.setColumnValues(columnValuesA);

    handler.put(table, putA);

    TGet get = new TGet(wrap(rowName));
    TResult result = handler.get(table, get);
    assertArrayEquals(rowName, result.getRow());
    List<TColumnValue> returnedColumnValues = result.getColumnValues();

    List<TColumnValue> expectedColumnValues = new ArrayList<>(1);
    expectedColumnValues.add(columnValueA);
    assertTColumnValuesEqual(expectedColumnValues, returnedColumnValues);

    List<TColumnValue> columnValuesB = new ArrayList<>(1);
    TColumnValue columnValueB =
      new TColumnValue(wrap(familyAname), wrap(qualifierBname), wrap(valueBname));
    columnValuesB.add(columnValueB);
    TPut putB = new TPut(wrap(rowName), columnValuesB);
    putB.setColumnValues(columnValuesB);

    TDelete delete = new TDelete(wrap(rowName));
    List<TColumn> deleteColumns = new ArrayList<>(1);
    TColumn deleteColumn = new TColumn(wrap(familyAname));
    deleteColumn.setQualifier(qualifierAname);
    deleteColumns.add(deleteColumn);
    delete.setColumns(deleteColumns);

    List<TMutation> mutations = new ArrayList<>(2);
    TMutation mutationA = TMutation.put(putB);
    mutations.add(mutationA);

    TMutation mutationB = TMutation.deleteSingle(delete);
    mutations.add(mutationB);

    TRowMutations tRowMutations = new TRowMutations(wrap(rowName), mutations);
    handler.mutateRow(table, tRowMutations);

    result = handler.get(table, get);
    assertArrayEquals(rowName, result.getRow());
    returnedColumnValues = result.getColumnValues();

    expectedColumnValues = new ArrayList<>(1);
    expectedColumnValues.add(columnValueB);
    assertTColumnValuesEqual(expectedColumnValues, returnedColumnValues);
  }",1
"@Test
  public void testPutTTL() throws Exception {
    ThriftHBaseServiceHandler handler = createHandler();
    byte[] rowName = Bytes.toBytes(""testPutTTL"");
    ByteBuffer table = wrap(tableAname);
    List<TColumnValue> columnValues = new ArrayList<>(1);

    // Add some dummy data
    columnValues
      .add(new TColumnValue(wrap(familyAname), wrap(qualifierAname), wrap(Bytes.toBytes(1L))));

    TPut put = new TPut(wrap(rowName), columnValues);
    put.setColumnValues(columnValues);

    Map<ByteBuffer, ByteBuffer> attributes = new HashMap<>();

    // Time in ms for the kv's to live.
    long ttlTimeMs = 2000L;

    // the _ttl attribute is a number of ms ttl for key values in this put.
    attributes.put(wrap(Bytes.toBytes(""_ttl"")), wrap(Bytes.toBytes(ttlTimeMs)));
    // Attach the attributes
    put.setAttributes(attributes);
    // Send it.
    handler.put(table, put);

    // Now get the data back
    TGet getOne = new TGet(wrap(rowName));
    TResult resultOne = handler.get(table, getOne);

    // It's there.
    assertArrayEquals(rowName, resultOne.getRow());
    assertEquals(1, resultOne.getColumnValuesSize());

    // Sleep 30 seconds just to make 100% sure that the key value should be expired.
    Thread.sleep(ttlTimeMs * 15);

    TGet getTwo = new TGet(wrap(rowName));
    TResult resultTwo = handler.get(table, getTwo);

    // Nothing should be there since it's ttl'd out.
    assertNull(resultTwo.getRow());
    assertEquals(0, resultTwo.getColumnValuesSize());
  }",1
"@Test
  public void testNoSuchClass() throws IOException {
    List<CoprocessorViolation> violations = validateClass(""NoSuchClass"");
    assertEquals(1, violations.size());

    CoprocessorViolation violation = violations.get(0);
    assertEquals(getFullClassName(""NoSuchClass""), violation.getClassName());
    assertEquals(Severity.ERROR, violation.getSeverity());

    String stackTrace = Throwables.getStackTraceAsString(violation.getThrowable());
    assertTrue(stackTrace.contains(""java.lang.ClassNotFoundException: ""
      + ""org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest$NoSuchClass""));
  }",1
"@Test
  public void testEncodedLength() {
    PositionedByteRange buff = new SimplePositionedMutableByteRange(20);
    for (final DataType<String> type : new OrderedString[] { new OrderedString(Order.ASCENDING),
      new OrderedString(Order.DESCENDING) }",1
"@Test
  public void testSkipNonSkippable() {
    PositionedByteRange buff = new SimplePositionedMutableByteRange(12);
    for (Order ord : new Order[] { Order.ASCENDING, Order.DESCENDING }",1
"@Test
  public void testIfWeHaveNewReferenceFilesButOldStoreFiles() throws Exception {
    // this tests that reference files that are new, but have older timestamps for the files
    // they reference still will get compacted.
    TableName tableName = TableName.valueOf(""TestMajorCompactor"");
    TableDescriptor htd = UTILITY.createTableDescriptor(tableName, Bytes.toBytes(FAMILY));
    RegionInfo hri = RegionInfoBuilder.newBuilder(htd.getTableName()).build();
    HRegion region =
      HBaseTestingUtil.createRegionAndWAL(hri, rootRegionDir, UTILITY.getConfiguration(), htd);

    Connection connection = mock(Connection.class);
    // the reference file timestamp is newer
    List<StoreFileInfo> storeFiles = mockStoreFiles(regionStoreDir, 4, 101);
    List<Path> paths = storeFiles.stream().map(StoreFileInfo::getPath).collect(Collectors.toList());
    // the files that are referenced are older, thus we still compact.
    HRegionFileSystem fileSystem = mockFileSystem(region.getRegionInfo(), true, storeFiles, 50);
    MajorCompactionRequest majorCompactionRequest =
      spy(new MajorCompactionRequest(connection, region.getRegionInfo(), Sets.newHashSet(FAMILY)));
    doReturn(paths).when(majorCompactionRequest).getReferenceFilePaths(any(FileSystem.class),
      any(Path.class));
    StoreFileTrackerForTest sft = mockSFT(true, storeFiles);
    doReturn(fileSystem).when(majorCompactionRequest).getFileSystem();
    doReturn(sft).when(majorCompactionRequest).getStoreFileTracker(any(), any());
    doReturn(UTILITY.getConfiguration()).when(connection).getConfiguration();
    Set<String> result =
      majorCompactionRequest.getStoresRequiringCompaction(Sets.newHashSet(""a""), 100);
    assertEquals(FAMILY, Iterables.getOnlyElement(result));
  }",1
"@Test
  public void testAvlTreeIterSeekTo() {
    final int MIN_KEY = 1;
    final int MAX_KEY = 50;

    TestAvlNode root = null;
    for (int i = MIN_KEY; i < MAX_KEY; i += 2) {
      root = AvlTree.insert(root, new TestAvlNode(i));
    }",1
"@Test
  public void testSizing() {
    int bitSize = 8 * 128 * 1024; // 128 KB
    double errorRate = 0.025; // target false positive rate

    // How many keys can we store in a Bloom filter of this size maintaining
    // the given false positive rate, not taking into account that the n
    long maxKeys = BloomFilterUtil.idealMaxKeys(bitSize, errorRate);
    assertEquals(136570, maxKeys);

    // A reverse operation: how many bits would we need to store this many keys
    // and keep the same low false positive rate?
    long bitSize2 = BloomFilterUtil.computeBitSize(maxKeys, errorRate);

    // The bit size comes out a little different due to rounding.
    assertTrue(Math.abs(bitSize2 - bitSize) * 1.0 / bitSize < 1e-5);
  }",1
"@Test
  public void testPollInExecutor() throws InterruptedException {
    final TestObject testObj = new TestObject(0, 0);

    final CyclicBarrier threadsStarted = new CyclicBarrier(2);
    ExecutorService executor = Executors.newFixedThreadPool(2);
    executor.execute(new Runnable() {
      @Override
      public void run() {
        try {
          assertNull(queue.poll(1000, TimeUnit.MILLISECONDS));
          threadsStarted.await();
          assertSame(testObj, queue.poll(1000, TimeUnit.MILLISECONDS));
          assertTrue(queue.isEmpty());
        }",1
"@Test
  public void testByteBufferCreation() throws Exception {
    int capacity = 470 * 1021 * 1023;
    ByteBufferArray array = new ByteBufferArray(capacity, ALLOC);
    assertEquals(118, array.buffers.length);
    for (int i = 0; i < array.buffers.length; i++) {
      assertEquals(ByteBufferArray.DEFAULT_BUFFER_SIZE, array.buffers[i].capacity());
    }",1
"@Test
  public void testByteBufferCreation1() throws Exception {
    long cap = 7 * 1024L * 1024L;
    int bufferSize = ByteBufferArray.getBufferSize(cap), bufferCount = 25;
    ByteBufferArray array = new ByteBufferArray(bufferSize, bufferCount, 16, cap, ALLOC);
    for (int i = 0; i < array.buffers.length; i++) {
      assertEquals(458752, array.buffers[i].capacity());
    }",1
"@Test
  public void testCompareTo() {
    ByteBuffer bb1 = ByteBuffer.allocate(135);
    ByteBuffer bb2 = ByteBuffer.allocate(135);
    byte[] b = new byte[71];
    fillBB(bb1, (byte) 5);
    fillBB(bb2, (byte) 5);
    fillArray(b, (byte) 5);
    assertEquals(0, ByteBufferUtils.compareTo(bb1, 0, bb1.remaining(), bb2, 0, bb2.remaining()));
    assertTrue(ByteBufferUtils.compareTo(bb1, 0, bb1.remaining(), b, 0, b.length) > 0);
    bb2.put(134, (byte) 6);
    assertTrue(ByteBufferUtils.compareTo(bb1, 0, bb1.remaining(), bb2, 0, bb2.remaining()) < 0);
    bb2.put(6, (byte) 4);
    assertTrue(ByteBufferUtils.compareTo(bb1, 0, bb1.remaining(), bb2, 0, bb2.remaining()) > 0);
    // Assert reverse comparing BB and bytearray works.
    ByteBuffer bb3 = ByteBuffer.allocate(135);
    fillBB(bb3, (byte) 0);
    byte[] b3 = new byte[135];
    fillArray(b3, (byte) 1);
    int result = ByteBufferUtils.compareTo(b3, 0, b3.length, bb3, 0, bb3.remaining());
    assertTrue(result > 0);
    result = ByteBufferUtils.compareTo(bb3, 0, bb3.remaining(), b3, 0, b3.length);
    assertTrue(result < 0);
    byte[] b4 = Bytes.toBytes(""123"");
    ByteBuffer bb4 = ByteBuffer.allocate(10 + b4.length);
    for (int i = 10; i < bb4.capacity(); ++i) {
      bb4.put(i, b4[i - 10]);
    }",1
"@Test
  public void testPutInt() {
    testPutInt(0);
    testPutInt(Integer.MAX_VALUE);

    for (int i = 0; i < 3; i++) {
      testPutInt((128 << i) - 1);
    }",1
"@Test
  public void testRelativeCopyFromBuffertoBuffer() {
    ByteBuffer bb1 = ByteBuffer.allocate(135);
    ByteBuffer bb2 = ByteBuffer.allocate(135);
    fillBB(bb1, (byte) 5);
    ByteBufferUtils.copyFromBufferToBuffer(bb1, bb2);
    assertTrue(bb1.position() == bb2.position());
    assertTrue(bb1.limit() == bb2.limit());
    bb1 = ByteBuffer.allocateDirect(135);
    bb2 = ByteBuffer.allocateDirect(135);
    fillBB(bb1, (byte) 5);
    ByteBufferUtils.copyFromBufferToBuffer(bb1, bb2);
    assertTrue(bb1.position() == bb2.position());
    assertTrue(bb1.limit() == bb2.limit());
  }",1
"@Test
  public void testToPrimitiveTypes() {
    ByteBuffer buffer = ByteBuffer.allocate(15);
    long l = 988L;
    int i = 135;
    short s = 7;
    buffer.putLong(l);
    buffer.putShort(s);
    buffer.putInt(i);
    assertEquals(l, ByteBufferUtils.toLong(buffer, 0));
    assertEquals(s, ByteBufferUtils.toShort(buffer, 8));
    assertEquals(i, ByteBufferUtils.toInt(buffer, 10));
  }",1
"@Test
  public void testIncrementBytes() {
    assertTrue(checkTestIncrementBytes(10, 1));
    assertTrue(checkTestIncrementBytes(12, 123435445));
    assertTrue(checkTestIncrementBytes(124634654, 1));
    assertTrue(checkTestIncrementBytes(10005460, 5005645));
    assertTrue(checkTestIncrementBytes(1, -1));
    assertTrue(checkTestIncrementBytes(10, -1));
    assertTrue(checkTestIncrementBytes(10, -5));
    assertTrue(checkTestIncrementBytes(1005435000, -5));
    assertTrue(checkTestIncrementBytes(10, -43657655));
    assertTrue(checkTestIncrementBytes(-1, 1));
    assertTrue(checkTestIncrementBytes(-26, 5034520));
    assertTrue(checkTestIncrementBytes(-10657200, 5));
    assertTrue(checkTestIncrementBytes(-12343250, 45376475));
    assertTrue(checkTestIncrementBytes(-10, -5));
    assertTrue(checkTestIncrementBytes(-12343250, -5));
    assertTrue(checkTestIncrementBytes(-12, -34565445));
    assertTrue(checkTestIncrementBytes(-1546543452, -34565445));
  }",1
"@Test
  public void testAdd() {
    byte[] a = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }",1
"@Test
  public void testBinarySearch() {
    byte[][] arr = { { 1 }",1
"@Test
  public void testFixedSizeString() throws IOException {
    ByteArrayOutputStream baos = new ByteArrayOutputStream();
    DataOutputStream dos = new DataOutputStream(baos);
    Bytes.writeStringFixedSize(dos, ""Hello"", 5);
    Bytes.writeStringFixedSize(dos, ""World"", 18);
    Bytes.writeStringFixedSize(dos, """", 9);

    try {
      // Use a long dash which is three bytes in UTF-8. If encoding happens
      // using ISO-8859-1, this will fail.
      Bytes.writeStringFixedSize(dos, ""Too\u2013Long"", 9);
      fail(""Exception expected"");
    }",1
"@Test
  public void testGetBytesForByteBuffer() {
    byte[] array = { 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 }",1
"@Test
  public void testSplit() {
    byte[] lowest = Bytes.toBytes(""AAA"");
    byte[] middle = Bytes.toBytes(""CCC"");
    byte[] highest = Bytes.toBytes(""EEE"");
    byte[][] parts = Bytes.split(lowest, highest, 1);
    for (byte[] bytes : parts) {
      System.out.println(Bytes.toString(bytes));
    }",1
"@Test
  public void testToInt() {
    int[] ints = { -1, 123, Integer.MIN_VALUE, Integer.MAX_VALUE }",1
"@Test
  public void testToLong() {
    long[] longs = { -1L, 123L, Long.MIN_VALUE, Long.MAX_VALUE }",1
"@Test
  public void testMatchingTail() throws IOException {
    Path rootdir = htu.getDataTestDir();
    final FileSystem fs = rootdir.getFileSystem(conf);
    assertTrue(rootdir.depth() > 1);
    Path partPath = new Path(""a"", ""b"");
    Path fullPath = new Path(rootdir, partPath);
    Path fullyQualifiedPath = fs.makeQualified(fullPath);
    assertFalse(CommonFSUtils.isMatchingTail(fullPath, partPath));
    assertFalse(CommonFSUtils.isMatchingTail(fullPath, partPath.toString()));
    assertTrue(CommonFSUtils.isStartingWithPath(rootdir, fullPath.toString()));
    assertTrue(CommonFSUtils.isStartingWithPath(fullyQualifiedPath, fullPath.toString()));
    assertFalse(CommonFSUtils.isStartingWithPath(rootdir, partPath.toString()));
    assertFalse(CommonFSUtils.isMatchingTail(fullyQualifiedPath, partPath));
    assertTrue(CommonFSUtils.isMatchingTail(fullyQualifiedPath, fullPath));
    assertTrue(CommonFSUtils.isMatchingTail(fullyQualifiedPath, fullPath.toString()));
    assertTrue(CommonFSUtils.isMatchingTail(fullyQualifiedPath, fs.makeQualified(fullPath)));
    assertTrue(CommonFSUtils.isStartingWithPath(rootdir, fullyQualifiedPath.toString()));
    assertFalse(CommonFSUtils.isMatchingTail(fullPath, new Path(""x"")));
    assertFalse(CommonFSUtils.isMatchingTail(new Path(""x""), fullPath));
  }",1
"@Test
  public void testTestCompression() {
    assertTrue(CompressionTest.testCompression(""NONE""));
    assertTrue(CompressionTest.testCompression(""GZ""));

    if (NativeCodeLoader.isNativeCodeLoaded()) {
      // LZO is GPL so not included in hadoop install. You need to do an extra install to pick
      // up the needed support. This article is good on the steps needed to add LZO support:
      // https://stackoverflow.com/questions/23441142/class-com-hadoop-compression-lzo-lzocodec-not-found-for-spark-on-cdh-5
      // Its unlikely at test time that the extras are installed so this test is useless.
      // nativeCodecTest(""LZO"", ""lzo2"", ""com.hadoop.compression.lzo.LzoCodec"");
      nativeCodecTest(""LZ4"", null, ""org.apache.hadoop.io.compress.Lz4Codec"");
      nativeCodecTest(""SNAPPY"", ""snappy"", ""org.apache.hadoop.io.compress.SnappyCodec"");
      nativeCodecTest(""BZIP2"", ""bzip2"", ""org.apache.hadoop.io.compress.BZip2Codec"");
      nativeCodecTest(""ZSTD"", ""zstd"", ""org.apache.hadoop.io.compress.ZStandardCodec"");
    }",1
"@Test
  public void testLoadClassFromAnotherPath() throws Exception {
    ClassLoader parent = TestDynamicClassLoader.class.getClassLoader();
    DynamicClassLoader classLoader = new DynamicClassLoader(conf, parent);

    String className = ""TestLoadClassFromAnotherPath"";
    deleteClass(className);
    try {
      classLoader.loadClass(className);
      fail(""Should not be able to load class "" + className);
    }",1
"@Test
  public void testLoadClassFromLocalPathWithDynamicDirOff() throws Exception {
    conf.setBoolean(""hbase.use.dynamic.jars"", false);
    ClassLoader parent = TestDynamicClassLoader.class.getClassLoader();
    DynamicClassLoader classLoader = new DynamicClassLoader(conf, parent);

    String className = ""TestLoadClassFromLocalPath"";
    deleteClass(className);

    try {
      String folder = TEST_UTIL.getDataTestDir().toString();
      ClassLoaderTestHelper.buildJar(folder, className, null,
        ClassLoaderTestHelper.localDirPath(conf));
      classLoader.loadClass(className);
      fail(""Should not be able to load class "" + className);
    }",1
"@Test
  public void testFormatTableInfoSequenceId() {
    Path p0 = assertWriteAndReadSequenceId(0);
    // Assert p0 has format we expect.
    StringBuilder sb = new StringBuilder();
    for (int i = 0; i < FSTableDescriptors.WIDTH_OF_SEQUENCE_ID; i++) {
      sb.append(""0"");
    }",1
"@Test
  public void testReadingHTDFromFS() throws IOException {
    FileSystem fs = FileSystem.get(UTIL.getConfiguration());
    TableDescriptor htd =
      TableDescriptorBuilder.newBuilder(TableName.valueOf(name.getMethodName())).build();
    FSTableDescriptors fstd = new FSTableDescriptors(fs, testDir);
    fstd.createTableDescriptor(htd);
    TableDescriptor td2 =
      FSTableDescriptors.getTableDescriptorFromFs(fs, testDir, htd.getTableName());
    assertTrue(htd.equals(td2));
  }",1
"@Test
  public void testTableInfoFileStatusComparator() {
    FileStatus bare = new FileStatus(0, false, 0, 0, -1,
      new Path(""/tmp"", FSTableDescriptors.TABLEINFO_FILE_PREFIX));
    FileStatus future = new FileStatus(0, false, 0, 0, -1,
      new Path(""/tmp/tablinfo."" + EnvironmentEdgeManager.currentTime()));
    FileStatus farFuture = new FileStatus(0, false, 0, 0, -1,
      new Path(""/tmp/tablinfo."" + EnvironmentEdgeManager.currentTime() + 1000));
    FileStatus[] alist = { bare, future, farFuture }",1
"@Test
  public void testCopyFilesParallel() throws Exception {
    MiniDFSCluster cluster = htu.startMiniDFSCluster(1);
    cluster.waitActive();
    FileSystem fs = cluster.getFileSystem();
    Path src = new Path(""/src"");
    fs.mkdirs(src);
    for (int i = 0; i < 50; i++) {
      WriteDataToHDFS(fs, new Path(src, String.valueOf(i)), 1024);
    }",1
"@Test
  public void testBuildHashtable() {
    String[] keys = { ""type"", ""name"" }",1
"@Test
  public void testBlobVarLencodedLength() {
    int[][] values = {
      /*
       * decoded length, encoded length ceil((n bytes * 8 bits/input byte) / 7 bits/encoded byte) +
       * 1 header
       */
      { 1, 3 }",1
"@Test
  public void testNumericIntRealCompatibility() {
    for (Order ord : new Order[] { Order.ASCENDING, Order.DESCENDING }",1
"@Test
  public void testString() {
    String[] vals = { ""foo"", ""baaaar"", ""bazz"" }",1
"@Test
  public void testBeginEndMarker() {
    RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);
    sc.add(new SimpleRange(Bytes.toBytes(""""), Bytes.toBytes(""A"")));
    sc.add(new SimpleRange(Bytes.toBytes(""A""), Bytes.toBytes(""B"")));
    sc.add(new SimpleRange(Bytes.toBytes(""B""), Bytes.toBytes("""")));

    Multimap<byte[], SimpleRange> regions = sc.calcCoverage();
    LOG.info(""Special cases -- empty"");
    String res = dump(sc.getSplits(), regions);
    checkDepths(sc.getSplits(), regions, 1, 1, 1, 0);
    assertEquals("":\t[, A]\t\n"" + ""A:\t[A, B]\t\n"" + ""B:\t[B, ]\t\n"" + ""null:\t\n"", res);
  }",1
"@Test
  public void testSplitCalculatorCeil() {
    SimpleRange a = new SimpleRange(Bytes.toBytes(""A""), Bytes.toBytes(""C""));
    SimpleRange b = new SimpleRange(Bytes.toBytes(""B""), Bytes.toBytes(""C""));
    RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);
    sc.add(a);
    sc.add(b);

    Multimap<byte[], SimpleRange> regions = sc.calcCoverage();
    LOG.info(""AC and BC overlap in the end"");
    String res = dump(sc.getSplits(), regions);
    checkDepths(sc.getSplits(), regions, 1, 2, 0);
    assertEquals(""A:\t[A, C]\t\n"" + ""B:\t[A, C]\t[B, C]\t\n"" + ""C:\t\n"", res);
  }",1
"@Test
  public void testSplitCalculatorDegenerateEdge() {
    SimpleRange a = new SimpleRange(Bytes.toBytes(""A""), Bytes.toBytes(""A""));
    RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);
    sc.add(a);

    Multimap<byte[], SimpleRange> regions = sc.calcCoverage();
    LOG.info(""Single empty edge"");
    String res = dump(sc.getSplits(), regions);
    checkDepths(sc.getSplits(), regions, 1);
    assertEquals(""A:\t[A, A]\t\n"", res);
  }",1
"@Test
  public void testSplitCalculatorEq() {
    SimpleRange a = new SimpleRange(Bytes.toBytes(""A""), Bytes.toBytes(""C""));
    SimpleRange b = new SimpleRange(Bytes.toBytes(""A""), Bytes.toBytes(""C""));

    LOG.info(a.tiebreaker + "" - "" + b.tiebreaker);
    RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);
    sc.add(a);
    sc.add(b);

    Multimap<byte[], SimpleRange> regions = sc.calcCoverage();
    LOG.info(""AC and AC overlap completely"");
    String res = dump(sc.getSplits(), regions);
    checkDepths(sc.getSplits(), regions, 2, 0);
    assertEquals(""A:\t[A, C]\t[A, C]\t\n"" + ""C:\t\n"", res);
  }",1
"@Test
  public void testSplitCalculatorSingleEdge() {
    SimpleRange a = new SimpleRange(Bytes.toBytes(""A""), Bytes.toBytes(""B""));
    RegionSplitCalculator<SimpleRange> sc = new RegionSplitCalculator<>(cmp);
    sc.add(a);

    Multimap<byte[], SimpleRange> regions = sc.calcCoverage();
    LOG.info(""Single edge"");
    String res = dump(sc.getSplits(), regions);
    checkDepths(sc.getSplits(), regions, 1, 0);
    assertEquals(""A:\t[A, B]\t\n"" + ""B:\t\n"", res);
  }",1
"@Test
  public void unitTestHexStringSplit() {
    HexStringSplit splitter = new HexStringSplit();
    // Check splitting while starting from scratch

    byte[][] twoRegionsSplits = splitter.split(2);
    assertEquals(1, twoRegionsSplits.length);
    assertArrayEquals(Bytes.toBytes(""80000000""), twoRegionsSplits[0]);

    byte[][] threeRegionsSplits = splitter.split(3);
    assertEquals(2, threeRegionsSplits.length);
    byte[] expectedSplit0 = Bytes.toBytes(""55555555"");
    assertArrayEquals(expectedSplit0, threeRegionsSplits[0]);
    byte[] expectedSplit1 = Bytes.toBytes(""aaaaaaaa"");
    assertArrayEquals(expectedSplit1, threeRegionsSplits[1]);

    // Check splitting existing regions that have start and end points
    byte[] splitPoint = splitter.split(Bytes.toBytes(""10000000""), Bytes.toBytes(""30000000""));
    assertArrayEquals(Bytes.toBytes(""20000000""), splitPoint);

    byte[] lastRow = Bytes.toBytes(""ffffffff"");
    assertArrayEquals(lastRow, splitter.lastRow());
    byte[] firstRow = Bytes.toBytes(""00000000"");
    assertArrayEquals(firstRow, splitter.firstRow());

    // Halfway between 00... and 20... should be 10...
    splitPoint = splitter.split(firstRow, Bytes.toBytes(""20000000""));
    assertArrayEquals(Bytes.toBytes(""10000000""), splitPoint);

    // Halfway between df... and ff... should be ef....
    splitPoint = splitter.split(Bytes.toBytes(""dfffffff""), lastRow);
    assertArrayEquals(Bytes.toBytes(""efffffff""), splitPoint);

    // Check splitting region with multiple mappers per region
    byte[][] splits =
      splitter.split(Bytes.toBytes(""00000000""), Bytes.toBytes(""30000000""), 3, false);
    assertEquals(2, splits.length);
    assertArrayEquals(Bytes.toBytes(""10000000""), splits[0]);
    assertArrayEquals(Bytes.toBytes(""20000000""), splits[1]);

    splits = splitter.split(Bytes.toBytes(""00000000""), Bytes.toBytes(""20000000""), 2, true);
    assertEquals(3, splits.length);
    assertArrayEquals(Bytes.toBytes(""10000000""), splits[1]);
  }",1
"@Test
  public void testBasics() throws InterruptedException {
    int maxAttempts = 10;
    RetryCounterFactory factory = new RetryCounterFactory(maxAttempts, 10, 1000);
    RetryCounter retryCounter = factory.create();
    while (retryCounter.shouldRetry()) {
      LOG.info(""Attempt={}",1
"@Test
  public void testOfferInStealQueueFromShouldUnblock() throws InterruptedException {
    final AtomicInteger taken = new AtomicInteger();
    Thread consumer = new Thread() {
      @Override
      public void run() {
        try {
          Integer n = stealJobQueue.take();
          taken.set(n);
        }",1
"@Test
  public void testWeakReference() throws Exception {
    Object obj1 = pool.get(""a"");
    int hash1 = System.identityHashCode(obj1);

    System.gc();
    System.gc();
    System.gc();

    Thread.sleep(10);
    // Sleep a while because references newly becoming stale
    // may still remain when calling the {@code purge}",1
"@Test
  public void setMembershipDedups() throws IOException {
    Configuration localConf = new Configuration(conf);
    localConf.set(WALFactory.WAL_PROVIDER, FSHLogProvider.class.getName());
    WALFactory wals = new WALFactory(localConf, currentTest.getMethodName());
    try {
      final Set<WAL> seen = new HashSet<>(1);
      assertTrue(""first attempt to add WAL from default provider should work."",
        seen.add(wals.getWAL(null)));
      for (int i = 0; i < 1000; i++) {
        assertFalse(
          ""default wal provider is only supposed to return a single wal, which should ""
            + ""compare as .equals itself."",
          seen.add(wals.getWAL(RegionInfoBuilder
            .newBuilder(TableName.valueOf(""Table-"" + ThreadLocalRandom.current().nextInt()))
            .build())));
      }",1
"@Test
  public void testSplit() throws IOException {
    final TableName tableName = TableName.valueOf(currentTest.getMethodName());
    final byte[] rowName = tableName.getName();
    final MultiVersionConcurrencyControl mvcc = new MultiVersionConcurrencyControl(1);
    final int howmany = 3;
    RegionInfo[] infos = new RegionInfo[3];
    Path tableDataDir = CommonFSUtils.getTableDir(hbaseDir, tableName);
    fs.mkdirs(tableDataDir);
    Path tabledir = CommonFSUtils.getWALTableDir(conf, tableName);
    fs.mkdirs(tabledir);
    for (int i = 0; i < howmany; i++) {
      infos[i] = RegionInfoBuilder.newBuilder(tableName).setStartKey(Bytes.toBytes("""" + i))
        .setEndKey(Bytes.toBytes("""" + (i + 1))).build();
      fs.mkdirs(new Path(tabledir, infos[i].getEncodedName()));
      fs.mkdirs(new Path(tableDataDir, infos[i].getEncodedName()));
      LOG.info(""allo "" + new Path(tabledir, infos[i].getEncodedName()).toString());
    }",1
"@Test
  public void testMakeZKProps() {
    Configuration conf = new Configuration(TEST_UTIL.getConfiguration());
    conf.set(HConstants.ZOOKEEPER_DATA_DIR, this.dataDir.toString());
    Properties properties = ZKConfig.makeZKProps(conf);
    assertEquals(dataDir.toString(), (String) properties.get(""dataDir""));
    assertEquals(Integer.valueOf(PORT_NO), Integer.valueOf(properties.getProperty(""clientPort"")));
    assertEquals(""127.0.0.1:2888:3888"", properties.get(""server.0""));
    assertNull(properties.get(""server.1""));

    String oldValue = conf.get(HConstants.ZOOKEEPER_QUORUM);
    conf.set(HConstants.ZOOKEEPER_QUORUM, ""a.foo.bar,b.foo.bar,c.foo.bar"");
    properties = ZKConfig.makeZKProps(conf);
    assertEquals(dataDir.toString(), properties.get(""dataDir""));
    assertEquals(Integer.valueOf(PORT_NO), Integer.valueOf(properties.getProperty(""clientPort"")));
    assertEquals(""a.foo.bar:2888:3888"", properties.get(""server.0""));
    assertEquals(""b.foo.bar:2888:3888"", properties.get(""server.1""));
    assertEquals(""c.foo.bar:2888:3888"", properties.get(""server.2""));
    assertNull(properties.get(""server.3""));
    conf.set(HConstants.ZOOKEEPER_QUORUM, oldValue);
  }",1
"@Test
  public void testSetDataVersionMismatchInLoop() throws Exception {
    String znode = ""/hbase/splitWAL/9af7cfc9b15910a0b3d714bf40a3248f"";
    Configuration conf = TEST_UTIL.getConfiguration();
    ZKWatcher zkw = new ZKWatcher(conf, ""testSetDataVersionMismatchInLoop"", abortable, true);
    String ensemble = ZKConfig.getZKQuorumServersString(conf);
    RecoverableZooKeeper rzk = RecoverableZooKeeper.connect(conf, ensemble, zkw, null, null);
    rzk.create(znode, new byte[0], Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);
    rzk.setData(znode, Bytes.toBytes(""OPENING""), 0);
    Field zkField = RecoverableZooKeeper.class.getDeclaredField(""zk"");
    zkField.setAccessible(true);
    int timeout = conf.getInt(HConstants.ZK_SESSION_TIMEOUT, HConstants.DEFAULT_ZK_SESSION_TIMEOUT);
    ZookeeperStub zkStub = new ZookeeperStub(ensemble, timeout, zkw);
    zkStub.setThrowExceptionInNumOperations(1);
    zkField.set(rzk, zkStub);
    byte[] opened = Bytes.toBytes(""OPENED"");
    rzk.setData(znode, opened, 1);
    byte[] data = rzk.getData(znode, false, new Stat());
    assertTrue(Bytes.equals(opened, data));
  }",1
"@Test
  public void testHostPortParse() {
    ZKMainServer parser = new ZKMainServer();
    Configuration c = HBaseConfiguration.create();
    assertEquals(""127.0.0.1:"" + c.get(HConstants.ZOOKEEPER_CLIENT_PORT), parser.parse(c));
    final String port = ""1234"";
    c.set(HConstants.ZOOKEEPER_CLIENT_PORT, port);
    c.set(""hbase.zookeeper.quorum"", ""example.com"");
    assertEquals(""example.com:"" + port, parser.parse(c));
    c.set(""hbase.zookeeper.quorum"", ""example1.com,example2.com,example3.com"");
    String ensemble = parser.parse(c);
    assertTrue(port, ensemble.matches(""(example[1-3]\\.com:1234,){2}",1
"@Test
  public void testCleanZNode() throws Exception {
    ZKWatcher zkw = new ZKWatcher(TEST_UTIL.getConfiguration(), ""testNodeTracker"",
      new TestZKNodeTracker.StubAbortable());

    final ServerName sn = ServerName.valueOf(""127.0.0.1:52"", 45L);

    ZKUtil.createAndFailSilent(zkw, TEST_UTIL.getConfiguration()
      .get(HConstants.ZOOKEEPER_ZNODE_PARENT, HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT));

    final String nodeName = zkw.getZNodePaths().masterAddressZNode;

    // Check that we manage the case when there is no data
    ZKUtil.createAndFailSilent(zkw, nodeName);
    MasterAddressTracker.deleteIfEquals(zkw, sn.toString());
    assertNotNull(ZKUtil.getData(zkw, nodeName));

    // Check that we don't delete if we're not supposed to
    ZKUtil.setData(zkw, nodeName, MasterAddressTracker.toByteArray(sn, 0));
    MasterAddressTracker.deleteIfEquals(zkw, ServerName.valueOf(""127.0.0.2:52"", 45L).toString());
    assertNotNull(ZKUtil.getData(zkw, nodeName));

    // Check that we delete when we're supposed to
    ZKUtil.setData(zkw, nodeName, MasterAddressTracker.toByteArray(sn, 0));
    MasterAddressTracker.deleteIfEquals(zkw, sn.toString());
    assertNull(ZKUtil.getData(zkw, nodeName));

    // Check that we support the case when the znode does not exist
    MasterAddressTracker.deleteIfEquals(zkw, sn.toString()); // must not throw an exception
  }",1
"@Test
  public void testNodeTracker() throws Exception {
    Abortable abortable = new StubAbortable();
    ZKWatcher zk = new ZKWatcher(TEST_UTIL.getConfiguration(), ""testNodeTracker"", abortable);
    ZKUtil.createAndFailSilent(zk, zk.getZNodePaths().baseZNode);

    final String node = ZNodePaths.joinZNode(zk.getZNodePaths().baseZNode,
      Long.toString(ThreadLocalRandom.current().nextLong()));

    final byte[] dataOne = Bytes.toBytes(""dataOne"");
    final byte[] dataTwo = Bytes.toBytes(""dataTwo"");

    // Start a ZKNT with no node currently available
    TestTracker localTracker = new TestTracker(zk, node, abortable);
    localTracker.start();
    zk.registerListener(localTracker);

    // Make sure we don't have a node
    assertNull(localTracker.getData(false));

    // Spin up a thread with another ZKNT and have it block
    WaitToGetDataThread thread = new WaitToGetDataThread(zk, node);
    thread.start();

    // Verify the thread doesn't have a node
    assertFalse(thread.hasData);

    // Now, start a new ZKNT with the node already available
    TestTracker secondTracker = new TestTracker(zk, node, null);
    secondTracker.start();
    zk.registerListener(secondTracker);

    // Put up an additional zk listener so we know when zk event is done
    TestingZKListener zkListener = new TestingZKListener(zk, node);
    zk.registerListener(zkListener);
    assertEquals(0, zkListener.createdLock.availablePermits());

    // Create a completely separate zk connection for test triggers and avoid
    // any weird watcher interactions from the test
    final ZooKeeper zkconn = ZooKeeperHelper.getConnectedZooKeeper(
      ZKConfig.getZKQuorumServersString(TEST_UTIL.getConfiguration()), 60000);

    // Add the node with data one
    zkconn.create(node, dataOne, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

    // Wait for the zk event to be processed
    zkListener.waitForCreation();
    thread.join();

    // Both trackers should have the node available with data one
    assertNotNull(localTracker.getData(false));
    assertNotNull(localTracker.blockUntilAvailable());
    assertTrue(Bytes.equals(localTracker.getData(false), dataOne));
    assertTrue(thread.hasData);
    assertTrue(Bytes.equals(thread.tracker.getData(false), dataOne));
    LOG.info(""Successfully got data one"");

    // Make sure it's available and with the expected data
    assertNotNull(secondTracker.getData(false));
    assertNotNull(secondTracker.blockUntilAvailable());
    assertTrue(Bytes.equals(secondTracker.getData(false), dataOne));
    LOG.info(""Successfully got data one with the second tracker"");

    // Drop the node
    zkconn.delete(node, -1);
    zkListener.waitForDeletion();

    // Create a new thread but with the existing thread's tracker to wait
    TestTracker threadTracker = thread.tracker;
    thread = new WaitToGetDataThread(threadTracker);
    thread.start();

    // Verify other guys don't have data
    assertFalse(thread.hasData);
    assertNull(secondTracker.getData(false));
    assertNull(localTracker.getData(false));
    LOG.info(""Successfully made unavailable"");

    // Create with second data
    zkconn.create(node, dataTwo, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);

    // Wait for the zk event to be processed
    zkListener.waitForCreation();
    thread.join();

    // All trackers should have the node available with data two
    assertNotNull(localTracker.getData(false));
    assertNotNull(localTracker.blockUntilAvailable());
    assertTrue(Bytes.equals(localTracker.getData(false), dataTwo));
    assertNotNull(secondTracker.getData(false));
    assertNotNull(secondTracker.blockUntilAvailable());
    assertTrue(Bytes.equals(secondTracker.getData(false), dataTwo));
    assertTrue(thread.hasData);
    assertTrue(Bytes.equals(thread.tracker.getData(false), dataTwo));
    LOG.info(""Successfully got data two on all trackers and threads"");

    // Change the data back to data one
    zkconn.setData(node, dataOne, -1);

    // Wait for zk event to be processed
    zkListener.waitForDataChange();

    // All trackers should have the node available with data one
    assertNotNull(localTracker.getData(false));
    assertNotNull(localTracker.blockUntilAvailable());
    assertTrue(Bytes.equals(localTracker.getData(false), dataOne));
    assertNotNull(secondTracker.getData(false));
    assertNotNull(secondTracker.blockUntilAvailable());
    assertTrue(Bytes.equals(secondTracker.getData(false), dataOne));
    assertTrue(thread.hasData);
    assertTrue(Bytes.equals(thread.tracker.getData(false), dataOne));
    LOG.info(""Successfully got data one following a data change on all trackers and threads"");
  }",1
"@Test
  public void testSetDataWithVersion() throws Exception {
    ZKUtil.createWithParents(ZKW, ""/s1/s2/s3"");
    int v0 = getZNodeDataVersion(""/s1/s2/s3"");
    assertEquals(0, v0);

    ZKUtil.setData(ZKW, ""/s1/s2/s3"", Bytes.toBytes(12L));
    int v1 = getZNodeDataVersion(""/s1/s2/s3"");
    assertEquals(1, v1);

    ZKUtil.multiOrSequential(ZKW,
      ImmutableList.of(ZKUtilOp.setData(""/s1/s2/s3"", Bytes.toBytes(13L), v1)), false);
    int v2 = getZNodeDataVersion(""/s1/s2/s3"");
    assertEquals(2, v2);
  }",1
"@Test
  public void testNamespaceExists() throws Exception {
    final String NONEXISTENT_NAMESPACE = ""xyzpdq_nonexistent"";
    final String EXISTING_NAMESPACE = ""pdqxyz_myExistingNamespace"";
    boolean exists;
    Admin admin = TEST_UTIL.getAdmin();

    exists = HelloHBase.namespaceExists(admin, NONEXISTENT_NAMESPACE);
    assertEquals(""#namespaceExists failed: found nonexistent namespace."", false, exists);

    admin.createNamespace(NamespaceDescriptor.create(EXISTING_NAMESPACE).build());
    exists = HelloHBase.namespaceExists(admin, EXISTING_NAMESPACE);
    assertEquals(""#namespaceExists failed: did NOT find existing namespace."", true, exists);
    admin.deleteNamespace(EXISTING_NAMESPACE);
  }",1
"@Test
  public void testDeleteRow() throws IOException {
    Admin admin = TEST_UTIL.getAdmin();
    admin.createNamespace(NamespaceDescriptor.create(HelloHBase.MY_NAMESPACE_NAME).build());
    Table table = TEST_UTIL.createTable(HelloHBase.MY_TABLE_NAME, HelloHBase.MY_COLUMN_FAMILY_NAME);

    table.put(new Put(HelloHBase.MY_ROW_ID).addColumn(HelloHBase.MY_COLUMN_FAMILY_NAME,
      HelloHBase.MY_FIRST_COLUMN_QUALIFIER, Bytes.toBytes(""xyz"")));
    HelloHBase.deleteRow(table);
    Result row = table.get(new Get(HelloHBase.MY_ROW_ID));
    assertEquals(""#deleteRow failed to delete row."", true, row.isEmpty());

    TEST_UTIL.deleteTable(HelloHBase.MY_TABLE_NAME);
    admin.deleteNamespace(HelloHBase.MY_NAMESPACE_NAME);
  }",1
"@Test
  public void testNamespaceExists() throws Exception {
    final String NONEXISTENT_NAMESPACE = ""xyzpdq_nonexistent"";
    final String EXISTING_NAMESPACE = ""pdqxyz_myExistingNamespace"";
    boolean exists;
    Admin admin = TEST_UTIL.getAdmin();

    exists = HelloHBase.namespaceExists(admin, NONEXISTENT_NAMESPACE);
    assertEquals(""#namespaceExists failed: found nonexistent namespace."", false, exists);

    admin.createNamespace(NamespaceDescriptor.create(EXISTING_NAMESPACE).build());
    exists = HelloHBase.namespaceExists(admin, EXISTING_NAMESPACE);
    assertEquals(""#namespaceExists failed: did NOT find existing namespace."", true, exists);
    admin.deleteNamespace(EXISTING_NAMESPACE);
  }",1
"@Test
	public void testOptionSetDefinition() throws Exception {
		final Object ls = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/ls.xml""));
		System.out.println(ls);
		final Object uniq = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/uniq.xml""));
		System.out.println(uniq);
		final Object cut = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/cut.xml""));
		System.out.println(cut);
		final Object sort = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/sort.xml""));
		System.out.println(sort);
	}",1
"@Test
	public void testOnlyEvenLines() {
		final LineOperation op = new LineOperation() {
			int count = 0;
			@Override
			public void operate(ExecutionContext context, Line input, LineProcessor output) {
				if (count % 2 == 0) {
					output.processLine(input);
				}",1
"@Test
    public void testGrepFileThenDelete() throws IOException {
        //given
        final String[] lines = {""Hello"", ""World"", ""These are 3 lines""}",1
"@Test
    public void testGrepWholeLine(){
        final String lineRegex = ""the cistern .* the dishwasher hot-rinsing, and the kettle being"";
        final String actualLine = ""the cistern refilling, the dishwasher hot-rinsing, and the kettle being"";

        final File testFile = new File(outputDir.getPath() + ""/commuting.txt"" );
        assertEquals(actualLine, Unix4j.use(contextFactory).grep(Grep.Options.wholeLine, lineRegex, testFile).toStringResult());
    }",1
"@Test
	public void testCompareUS() {
		final String[] lMonths = {""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July"", ""August"", ""September"", ""October"", ""November"", ""December""}",1
"@Test
	public void findStartAndEndTrimNewlineChars() {
		final String s = ""\n\r\n\r  hello \r\r\n\n"";
		Assert.assertEquals(3, StringUtil.findStartTrimNewlineChars(s));
		Assert.assertEquals(s.length() - 3, StringUtil.findEndTrimNewlineChars(s));
		for (int i = 0; i < s.length(); i++) {
			final int expected = i <= 3 ? 3 : i < s.length() - 3 ? i : s.length();
			Assert.assertEquals(expected, StringUtil.findStartTrimNewlineChars(s, i));
		}",1
"@Test
	public void testFixedLengthWithIntValue() {
		final boolean[] left = {true, true, false, false, false}",1
"@Test
	public void testFixedLengthWithStringValueAndFiller() {
		final boolean[] left = {true, true, false, false, false}",1
"@Test
	public void testSplitLines() {
		final String[] input = {
				""hello\nworld"",	
				""hello\r\nworld"", 
				""hello\n\r\r\nworld"",
				""hello\n\r\r\nworld\n"",
				""hello\n\r\r\nworld\n\n"",
			}",1
"@Test
    public void testCancelObservable() throws InterruptedException {
        System.out.println(""testCancelObservable"");
        for (int i = 0; i < 50; i++) {
            // System.out.println(i);
            long n = 5000L;
            File pageFile = new File(""target/cancelObs"" + i + "".obj"");
            pageFile.delete();
            byte[] bytes = new byte[40];
            Observable.just(bytes) //
                    .repeat(n) //
                    .to(com.github.davidmoten.rx2.observable.Transformers //
                            .onBackpressureBufferToFile() //
                            .fileFactory(Callables.constant(pageFile)) //
                            .pageSizeBytes(20000000) //
                            .serializerBytes()) //
                    .take(5) //
                    .count() //
                    .test() //
                    .awaitDone(500L, TimeUnit.SECONDS) //
                    .assertNoErrors() //
                    .assertComplete() //
                    .assertValue((long) 5);
            long t = TimeUnit.SECONDS.toMillis(5);
            while (t > 0 && pageFile.exists()) {
                long waitMs = 10;
                TimeUnit.MILLISECONDS.sleep(waitMs);
                t -= waitMs;
            }",1
"@Test
    public void testVeryManyByteArrays() {
        long n = N;
        byte[] bytes = new byte[40];
        new Random().nextBytes(bytes);
        long t = System.currentTimeMillis();
        Flowables.repeat(bytes, n) //
                .compose(onBackpressureBufferToFile() //
                        .pageSizeBytes(20000000) //
                        .serializerBytes()) //
                .count() //
                .test() //
                .awaitDone(500L, TimeUnit.SECONDS) //
                .assertNoErrors() //
                .assertComplete() //
                .assertValue((long) n);
        t = (System.currentTimeMillis() - t);
        DecimalFormat df = new DecimalFormat(""0.000"");
        System.out.println(""byte arrays async rate = "" + df.format((1000.0 * bytes.length * n / 1024.0 / 1024.0 / t))
                + ""MB/s, "" + ""msgs/sec = "" + df.format(n * 1000.0 / t));
    }",1
"@Test
    public void testVeryManyByteArraysObservableSource() {
        long n = N;
        byte[] bytes = new byte[40];
        new Random().nextBytes(bytes);
        long t = System.currentTimeMillis();
        Observable.just(bytes) //
                .repeat(n) //
                .to(onBackpressureBufferToFileObservable() //
                        .pageSizeBytes(20000000) //
                        .serializerBytes()) //
                .count() //
                .test() //
                .awaitDone(500L, TimeUnit.SECONDS) //
                .assertNoErrors() //
                .assertComplete() //
                .assertValue((long) n);
        t = (System.currentTimeMillis() - t);
        DecimalFormat df = new DecimalFormat(""0.000"");
        System.out
                .println(""byte arrays async rate obs = "" + df.format((1000.0 * bytes.length * n / 1024.0 / 1024.0 / t))
                        + ""MB/s, "" + ""msgs/sec = "" + df.format(n * 1000.0 / t));
    }",1
"@Test
    public void testDataSerializer() {
        // Demonstrates DataSerializer usage
        DataSerializer<Integer> ds = new DataSerializer<Integer>() {

            @Override
            public void serialize(Integer t, DataOutput out) throws IOException {
                out.writeInt(t);
            }",1
"@Test
    public void testUnzipExtractSpecificFile() {
        List<String> list = Bytes.unzip(new File(""src/test/resources/test.zip"")).filter(new Predicate<ZippedEntry>() {

            @Override
            public boolean test(ZippedEntry entry) {
                return entry.getName().equals(""document2.txt"");
            }",1
"@Test
    public void testUnsubscribe() {
        AtomicBoolean unsubA = new AtomicBoolean(false);
        AtomicBoolean unsubB = new AtomicBoolean(false);
        Flowable<Integer> a = Flowable.just(1, 2, 5, 7, 6, 8).doOnCancel(Actions.setToTrue(unsubA));
        Flowable<Integer> b = Flowable.just(3, 4, 5, 6, 7).doOnCancel(Actions.setToTrue(unsubB));
        final List<Integer> list = new ArrayList<Integer>();
        final AtomicBoolean terminal = new AtomicBoolean();
        matchThem(a, b) //
                .doOnTerminate(Actions.setToTrue(terminal)) //
                .doOnNext(Consumers.println()) //
                .subscribe(new Subscriber<Integer>() {

                    private Subscription s;

                    @Override
                    public void onSubscribe(Subscription s) {
                        this.s = s;
                        s.request(Long.MAX_VALUE);
                    }",1
"@Test
    public void testOnNextThrowsWithBurstSourceThatTerminatesWithError() {
        List<Throwable> list = new CopyOnWriteArrayList<Throwable>();
        try {
            RxJavaPlugins.setErrorHandler(Consumers.addTo(list));
            FlowableTransformer<Integer, Integer> sm = StateMachine2.builder() //
                    .initialState("""") //
                    .transition(new Transition2<String, Integer, Integer>() {

                        @Override
                        public String apply(String state, Integer value, Emitter<Integer> emitter) {
                            throw new ThrowingException();
                        }",1
"@Test
    public void testExponentialBackoff() {
        Exception ex = new IllegalArgumentException(""boo"");
        TestSubscriber<Integer> ts = TestSubscriber.create();
        final AtomicInteger logCalls = new AtomicInteger();
        Consumer<ErrorAndDuration> log = new Consumer<ErrorAndDuration>() {

            @Override
            public void accept(ErrorAndDuration e) {
                System.out.println(""WARN: "" + e.throwable().getMessage());
                System.out.println(""waiting for "" + e.durationMs() + ""ms"");
                logCalls.incrementAndGet();
            }",1
"@Test
    public void testRetryWhenMultipleRetriesWorkOnSingleDelay() {
        AtomicInteger count = new AtomicInteger();
        TestSubscriber<Object> ts = TestSubscriber.create();
        Exception exception = new Exception(""boo"");
        Flowable.error(exception) //
                .doOnSubscribe(Consumers.increment(count)) //
                .retryWhen(RetryWhen //
                        .delay(1, TimeUnit.MILLISECONDS) //
                        .scheduler(Schedulers.trampoline()) //
                        .maxRetries(10).build()) //
                .subscribe(ts);
        ts.assertTerminated();
        assertFalse(ts.errors().isEmpty());
        assertEquals(exception, ts.errors().get(0));
        assertEquals(11, count.get());
    }",1
"@Test
    public void testRetryWhenSpecificExceptionAllowedUsePredicateReturnsTrue() {
        Exception ex = new IllegalArgumentException(""boo"");
        TestSubscriber<Integer> ts = TestSubscriber.create();
        TestScheduler scheduler = new TestScheduler();
        Predicate<Throwable> predicate = new Predicate<Throwable>() {
            @Override
            public boolean test(Throwable t) {
                return t instanceof IllegalArgumentException;
            }",1
"@Test
    public void testRetryWhenSpecificExceptionFailsBecauseIsNotInstanceOf() {
        Exception ex = new IllegalArgumentException(""boo"");
        TestSubscriber<Integer> ts = TestSubscriber.create();
        TestScheduler scheduler = new TestScheduler();
        Flowable.just(1, 2)
                // force error after 3 emissions
                .concatWith(Flowable.<Integer>error(ex))
                // retry with backoff
                .retryWhen(RetryWhen.maxRetries(2).action(log).exponentialBackoff(1, TimeUnit.MINUTES)
                        .scheduler(scheduler).retryWhenInstanceOf(SQLException.class).build())
                // go
                .subscribe(ts);
        ts.assertValues(1, 2);
        ts.assertError(ex);
    }",1
"@Test
    public void testWithCallSite() {
        Scheduler s = SchedulerHelper.withThreadIdFromCallSite(Schedulers.trampoline());
        final StringBuilder b = new StringBuilder();
        String main = Thread.currentThread().getName();
        s.createWorker().schedule(new Runnable() {

            @Override
            public void run() {
                b.append(Thread.currentThread().getName());
            }",1
"@Test
    public void testWithId() {
        Scheduler s = SchedulerHelper.withThreadId(Schedulers.trampoline(), ""boo"");
        final StringBuilder b = new StringBuilder();
        String main = Thread.currentThread().getName();
        s.createWorker().schedule(new Runnable() {

            @Override
            public void run() {
                b.append(Thread.currentThread().getName());
            }",1
"@Test
    public void testDrawWithNullInfo() {
        try {
            DefaultTableXYDataset<String> dataset = new DefaultTableXYDataset<>();

            XYSeries<String> s1 = new XYSeries<>(""Series 1"", true, false);
            s1.add(5.0, 5.0);
            s1.add(10.0, 15.5);
            s1.add(15.0, 9.5);
            s1.add(20.0, 7.5);
            dataset.addSeries(s1);

            XYSeries<String> s2 = new XYSeries<>(""Series 2"", true, false);
            s2.add(5.0, 5.0);
            s2.add(10.0, 15.5);
            s2.add(15.0, 9.5);
            s2.add(20.0, 3.5);
            dataset.addSeries(s2);
            XYPlot<String> plot = new XYPlot<>(dataset,
                    new NumberAxis(""X""), new NumberAxis(""Y""),
                    new XYLineAndShapeRenderer());
            plot.addAnnotation(new XYBoxAnnotation(10.0, 12.0, 3.0, 4.0,
                    new BasicStroke(1.2f), Color.RED, Color.BLUE));
            JFreeChart chart = new JFreeChart(plot);
            /* BufferedImage image = */ chart.createBufferedImage(300, 200,
                    null);
        }",1
"@Test
    public void testEquals() {
        XYBoxAnnotation a1 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0,
                new BasicStroke(1.2f), Color.RED, Color.BLUE);
        XYBoxAnnotation a2 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0,
                new BasicStroke(1.2f), Color.RED, Color.BLUE);
        assertEquals(a1, a2);
        assertEquals(a2, a1);

        // x0
        a1 = new XYBoxAnnotation(2.0, 2.0, 3.0, 4.0, new BasicStroke(1.2f),
                Color.RED, Color.BLUE);
        assertNotEquals(a1, a2);
        a2 = new XYBoxAnnotation(2.0, 2.0, 3.0, 4.0, new BasicStroke(1.2f),
                Color.RED, Color.BLUE);
        assertEquals(a1, a2);

        // stroke
        a1 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0, new BasicStroke(2.3f),
                Color.RED, Color.BLUE);
        assertNotEquals(a1, a2);
        a2 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0, new BasicStroke(2.3f),
                Color.RED, Color.BLUE);
        assertEquals(a1, a2);

        GradientPaint gp1a = new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.RED);
        GradientPaint gp1b = new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.RED);
        GradientPaint gp2a = new GradientPaint(5.0f, 6.0f, Color.pink,
                7.0f, 8.0f, Color.WHITE);
        GradientPaint gp2b = new GradientPaint(5.0f, 6.0f, Color.pink,
                7.0f, 8.0f, Color.WHITE);

        // outlinePaint
        a1 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0, new BasicStroke(2.3f),
                gp1a, Color.BLUE);
        assertNotEquals(a1, a2);
        a2 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0, new BasicStroke(2.3f),
                gp1b, Color.BLUE);
        assertEquals(a1, a2);

        // fillPaint
        a1 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0, new BasicStroke(2.3f),
                gp1a, gp2a);
        assertNotEquals(a1, a2);
        a2 = new XYBoxAnnotation(1.0, 2.0, 3.0, 4.0, new BasicStroke(2.3f),
                gp1b, gp2b);
        assertEquals(a1, a2);
    }",1
"@Test
    public void testEquals() {
        XYDrawableAnnotation a1 = new XYDrawableAnnotation(10.0, 20.0, 100.0,
                200.0, new TestDrawable());
        XYDrawableAnnotation a2 = new XYDrawableAnnotation(10.0, 20.0, 100.0,
                200.0, new TestDrawable());
        assertEquals(a1, a2);

        a1 = new XYDrawableAnnotation(11.0, 20.0, 100.0, 200.0,
                new TestDrawable());
        assertNotEquals(a1, a2);
        a2 = new XYDrawableAnnotation(11.0, 20.0, 100.0, 200.0,
                new TestDrawable());
        assertEquals(a1, a2);

        a1 = new XYDrawableAnnotation(11.0, 22.0, 100.0, 200.0,
                new TestDrawable());
        assertNotEquals(a1, a2);
        a2 = new XYDrawableAnnotation(11.0, 22.0, 100.0, 200.0,
                new TestDrawable());
        assertEquals(a1, a2);

        a1 = new XYDrawableAnnotation(11.0, 22.0, 101.0, 200.0,
                new TestDrawable());
        assertNotEquals(a1, a2);
        a2 = new XYDrawableAnnotation(11.0, 22.0, 101.0, 200.0,
                new TestDrawable());
        assertEquals(a1, a2);

        a1 = new XYDrawableAnnotation(11.0, 22.0, 101.0, 202.0,
                new TestDrawable());
        assertNotEquals(a1, a2);
        a2 = new XYDrawableAnnotation(11.0, 22.0, 101.0, 202.0,
                new TestDrawable());
        assertEquals(a1, a2);

        a1 = new XYDrawableAnnotation(11.0, 22.0, 101.0, 202.0, 2.0,
                new TestDrawable());
        assertNotEquals(a1, a2);
        a2 = new XYDrawableAnnotation(11.0, 22.0, 101.0, 202.0, 2.0,
                new TestDrawable());
        assertEquals(a1, a2);
    }",1
"@Test
    public void testHashCode() {
        XYPointerAnnotation a1 = new XYPointerAnnotation(""Label"", 10.0, 20.0,
                Math.PI);
        XYPointerAnnotation a2 = new XYPointerAnnotation(""Label"", 10.0, 20.0,
                Math.PI);
        assertEquals(a1, a2);
        int h1 = a1.hashCode();
        int h2 = a2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        Stroke stroke1 = new BasicStroke(2.0f);
        XYPolygonAnnotation a1 = new XYPolygonAnnotation(new double[] {1.0,
                2.0, 3.0, 4.0, 5.0, 6.0}",1
"@Test
    public void testEquals() {
        Stroke stroke1 = new BasicStroke(2.0f);
        Stroke stroke2 = new BasicStroke(2.5f);
        XYPolygonAnnotation a1 = new XYPolygonAnnotation(new double[] {1.0,
                2.0, 3.0, 4.0, 5.0, 6.0}",1
"@Test
    public void testEquals() {

        XYShapeAnnotation a1 = new XYShapeAnnotation(
                new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                new BasicStroke(1.2f), Color.RED, Color.BLUE);
        XYShapeAnnotation a2 = new XYShapeAnnotation(
                new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                new BasicStroke(1.2f), Color.RED, Color.BLUE);
        assertEquals(a1, a2);
        assertEquals(a2, a1);

        // shape
        a1 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(1.2f), Color.RED, Color.BLUE);
        assertNotEquals(a1, a2);
        a2 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(1.2f), Color.RED, Color.BLUE);
        assertEquals(a1, a2);

        // stroke
        a1 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.3f), Color.RED, Color.BLUE);
        assertNotEquals(a1, a2);
        a2 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.3f), Color.RED, Color.BLUE);
        assertEquals(a1, a2);

        GradientPaint gp1a = new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.RED);
        GradientPaint gp1b = new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.RED);
        GradientPaint gp2a = new GradientPaint(5.0f, 6.0f, Color.pink,
                7.0f, 8.0f, Color.WHITE);
        GradientPaint gp2b = new GradientPaint(5.0f, 6.0f, Color.pink,
                7.0f, 8.0f, Color.WHITE);

        // outlinePaint
        a1 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.3f), gp1a, Color.BLUE);
        assertNotEquals(a1, a2);
        a2 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.3f), gp1b, Color.BLUE);
        assertEquals(a1, a2);

        // fillPaint
        a1 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.3f), gp1a, gp2a);
        assertNotEquals(a1, a2);
        a2 = new XYShapeAnnotation(
                new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.3f), gp1b, gp2b);
        assertEquals(a1, a2);
    }",1
"@Test
    public void testEquals() {
        TextTitle t = new TextTitle(""Title"");
        XYTitleAnnotation a1 = new XYTitleAnnotation(1.0, 2.0, t);
        XYTitleAnnotation a2 = new XYTitleAnnotation(1.0, 2.0, t);
        assertEquals(a1, a2);
        
        a1 = new XYTitleAnnotation(1.1, 2.0, t);
        assertNotEquals(a1, a2);
        a2 = new XYTitleAnnotation(1.1, 2.0, t);
        assertEquals(a1, a2);

        a1 = new XYTitleAnnotation(1.1, 2.2, t);
        assertNotEquals(a1, a2);
        a2 = new XYTitleAnnotation(1.1, 2.2, t);
        assertEquals(a1, a2);
        
        TextTitle t2 = new TextTitle(""Title 2"");
        a1 = new XYTitleAnnotation(1.1, 2.2, t2);
        assertNotEquals(a1, a2);
        a2 = new XYTitleAnnotation(1.1, 2.2, t2);
        assertEquals(a1, a2);
    }",1
"@Test
    public void testSerialization() {
        TextTitle t = new TextTitle(""Title"");
        XYTitleAnnotation a1 = new XYTitleAnnotation(1.0, 2.0, t);
        XYTitleAnnotation a2 = TestUtils.serialised(a1);
        assertEquals(a1, a2);
    }",1
"@Test
    public void testPreviousStandardDateDayB() {
        MyDateAxis axis = new MyDateAxis(""Day"");
        Day apr12007 = new Day(1, 4, 2007);
        Day apr22007 = new Day(2, 4, 2007);

        // five dates to check...
        Date d0 = new Date(apr12007.getFirstMillisecond());
        Date d1 = new Date(apr12007.getFirstMillisecond() + 500L);
        Date d2 = new Date(apr12007.getMiddleMillisecond());
        Date d3 = new Date(apr12007.getMiddleMillisecond() + 500L);
        Date d4 = new Date(apr12007.getLastMillisecond());

        Date end = new Date(apr22007.getLastMillisecond());

        DateTickUnit unit = new DateTickUnit(DateTickUnitType.DAY, 7);
        axis.setTickUnit(unit);

        // START: check d0 and d1
        axis.setTickMarkPosition(DateTickMarkPosition.START);

        axis.setRange(d0, end);
        Date psd = axis.previousStandardDate(d0, unit);
        Date nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d0.getTime());
        assertTrue(nsd.getTime() >= d0.getTime());

        axis.setRange(d1, end);
        psd = axis.previousStandardDate(d1, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d1.getTime());
        assertTrue(nsd.getTime() >= d1.getTime());

        // MIDDLE: check d1, d2 and d3
        axis.setTickMarkPosition(DateTickMarkPosition.MIDDLE);

        axis.setRange(d1, end);
        psd = axis.previousStandardDate(d1, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d1.getTime());
        assertTrue(nsd.getTime() >= d1.getTime());

        axis.setRange(d2, end);
        psd = axis.previousStandardDate(d2, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d2.getTime());
        assertTrue(nsd.getTime() >= d2.getTime());

        axis.setRange(d3, end);
        psd = axis.previousStandardDate(d3, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d3.getTime());
        assertTrue(nsd.getTime() >= d3.getTime());

        // END: check d3 and d4
        axis.setTickMarkPosition(DateTickMarkPosition.END);

        axis.setRange(d3, end);
        psd = axis.previousStandardDate(d3, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d3.getTime());
        assertTrue(nsd.getTime() >= d3.getTime());

        axis.setRange(d4, end);
        psd = axis.previousStandardDate(d4, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d4.getTime());
        assertTrue(nsd.getTime() >= d4.getTime());
    }",1
"@Test
    public void testPreviousStandardDateMillisecondA() {
        MyDateAxis axis = new MyDateAxis(""Millisecond"");
        Millisecond m0 = new Millisecond(458, 58, 31, 12, 1, 4, 2007);
        Millisecond m1 = new Millisecond(459, 58, 31, 12, 1, 4, 2007);

        Date d0 = new Date(m0.getFirstMillisecond());
        Date end = new Date(m1.getLastMillisecond());

        DateTickUnit unit = new DateTickUnit(DateTickUnitType.MILLISECOND, 1);
        axis.setTickUnit(unit);

        // START: check d0
        axis.setTickMarkPosition(DateTickMarkPosition.START);

        axis.setRange(d0, end);
        Date psd = axis.previousStandardDate(d0, unit);
        Date nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d0.getTime());
        assertTrue(nsd.getTime() >= d0.getTime());

        // MIDDLE: check d0
        axis.setTickMarkPosition(DateTickMarkPosition.MIDDLE);

        axis.setRange(d0, end);
        psd = axis.previousStandardDate(d0, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d0.getTime());
        assertTrue(nsd.getTime() >= d0.getTime());

        // END: check d0
        axis.setTickMarkPosition(DateTickMarkPosition.END);

        axis.setRange(d0, end);
        psd = axis.previousStandardDate(d0, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d0.getTime());
        assertTrue(nsd.getTime() >= d0.getTime());
    }",1
"@Test
    public void testPreviousStandardDateMonthA() {
        MyDateAxis axis = new MyDateAxis(""Month"");
        Month nov2006 = new Month(11, 2006);
        Month dec2006 = new Month(12, 2006);

        // five dates to check...
        Date d0 = new Date(nov2006.getFirstMillisecond());
        Date d1 = new Date(nov2006.getFirstMillisecond() + 500L);
        Date d2 = new Date(nov2006.getMiddleMillisecond());
        Date d3 = new Date(nov2006.getMiddleMillisecond() + 500L);
        Date d4 = new Date(nov2006.getLastMillisecond());

        Date end = new Date(dec2006.getLastMillisecond());

        DateTickUnit unit = new DateTickUnit(DateTickUnitType.MONTH, 1);
        axis.setTickUnit(unit);

        // START: check d0 and d1
        axis.setTickMarkPosition(DateTickMarkPosition.START);

        axis.setRange(d0, end);
        Date psd = axis.previousStandardDate(d0, unit);
        Date nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d0.getTime());
        assertTrue(nsd.getTime() >= d0.getTime());

        axis.setRange(d1, end);
        psd = axis.previousStandardDate(d1, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d1.getTime());
        assertTrue(nsd.getTime() >= d1.getTime());

        // MIDDLE: check d1, d2 and d3
        axis.setTickMarkPosition(DateTickMarkPosition.MIDDLE);

        axis.setRange(d1, end);
        psd = axis.previousStandardDate(d1, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d1.getTime());
        assertTrue(nsd.getTime() >= d1.getTime());

        axis.setRange(d2, end);
        psd = axis.previousStandardDate(d2, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d2.getTime());
        assertTrue(nsd.getTime() >= d2.getTime());

        axis.setRange(d3, end);
        psd = axis.previousStandardDate(d3, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d3.getTime());
        assertTrue(nsd.getTime() >= d3.getTime());

        // END: check d3 and d4
        axis.setTickMarkPosition(DateTickMarkPosition.END);

        axis.setRange(d3, end);
        psd = axis.previousStandardDate(d3, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d3.getTime());
        assertTrue(nsd.getTime() >= d3.getTime());

        axis.setRange(d4, end);
        psd = axis.previousStandardDate(d4, unit);
        nsd = unit.addToDate(psd, TimeZone.getDefault());
        assertTrue(psd.getTime() < d4.getTime());
        assertTrue(nsd.getTime() >= d4.getTime());
    }",1
"@Test
    public void testHashCode() {
        Date d1 = new Date(0L);
        String l1 = ""Label 1"";
        TextAnchor ta1 = TextAnchor.CENTER;

        DateTick t1 = new DateTick(d1, l1, ta1, ta1, Math.PI / 2.0);
        DateTick t2 = new DateTick(d1, l1, ta1, ta1, Math.PI / 2.0);
        assertEquals(t1, t2);
        int h1 = t1.hashCode();
        int h2 = t2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testSerialization() {
        ExtendedCategoryAxis a1 = new ExtendedCategoryAxis(""Test"");
        a1.setSubLabelPaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f,
                4.0f, Color.BLUE));
        ExtendedCategoryAxis a2 = TestUtils.serialised(a1);
        assertEquals(a1, a2);
    }",1
"@Test
    public void testTranslateJava2DToValue() {
        LogAxis axis = new LogAxis();
        axis.setRange(50.0, 100.0);
        Rectangle2D dataArea = new Rectangle2D.Double(10.0, 50.0, 400.0, 300.0);
        double y1 = axis.java2DToValue(75.0, dataArea, RectangleEdge.LEFT);
        assertEquals(94.3874312681693, y1, EPSILON);
        double y2 = axis.java2DToValue(75.0, dataArea, RectangleEdge.RIGHT);
        assertEquals(94.3874312681693, y2, EPSILON);
        double x1 = axis.java2DToValue(75.0, dataArea, RectangleEdge.TOP);
        assertEquals(55.961246381405, x1, EPSILON);
        double x2 = axis.java2DToValue(75.0, dataArea, RectangleEdge.BOTTOM);
        assertEquals(55.961246381405, x2, EPSILON);
        axis.setInverted(true);
        double y3 = axis.java2DToValue(75.0, dataArea, RectangleEdge.LEFT);
        assertEquals(52.9731547179647, y3, EPSILON);
        double y4 = axis.java2DToValue(75.0, dataArea, RectangleEdge.RIGHT);
        assertEquals(52.9731547179647, y4, EPSILON);
        double x3 = axis.java2DToValue(75.0, dataArea, RectangleEdge.TOP);
        assertEquals(89.3475453695651, x3, EPSILON);
        double x4 = axis.java2DToValue(75.0, dataArea, RectangleEdge.BOTTOM);
        assertEquals(89.3475453695651, x4, EPSILON);
    }",1
"@Test
    public void testEquals() {
        MonthDateFormat mf1 = new MonthDateFormat();
        MonthDateFormat mf2 = new MonthDateFormat();
        assertEquals(mf1, mf2);
        assertEquals(mf2, mf1);

        boolean[] showYear1 = new boolean [12];
        showYear1[0] = true;
        boolean[] showYear2 = new boolean [12];
        showYear1[1] = true;

        // time zone
        mf1 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.US, 1,
            showYear1, new SimpleDateFormat(""yy""));
        assertNotEquals(mf1, mf2);
        mf2 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.US, 1,
            showYear1, new SimpleDateFormat(""yy""));
        assertEquals(mf1, mf2);

        // locale
        mf1 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 1,
            showYear1, new SimpleDateFormat(""yy""));
        assertNotEquals(mf1, mf2);
        mf2 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 1,
            showYear1, new SimpleDateFormat(""yy""));
        assertEquals(mf1, mf2);

        // chars
        mf1 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 2,
            showYear1, new SimpleDateFormat(""yy""));
        assertNotEquals(mf1, mf2);
        mf2 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 2,
            showYear1, new SimpleDateFormat(""yy""));
        assertEquals(mf1, mf2);

        // showYear[]
        mf1 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 2,
            showYear2, new SimpleDateFormat(""yy""));
        assertNotEquals(mf1, mf2);
        mf2 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 2,
            showYear2, new SimpleDateFormat(""yy""));
        assertEquals(mf1, mf2);

        // yearFormatter
        mf1 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 2,
            showYear2, new SimpleDateFormat(""yyyy""));
        assertNotEquals(mf1, mf2);
        mf2 = new MonthDateFormat(TimeZone.getTimeZone(""PST""), Locale.FRANCE, 2,
            showYear2, new SimpleDateFormat(""yyyy""));
        assertEquals(mf1, mf2);

    }",1
"@Test
    public void testAutoRange2() {
        DefaultCategoryDataset<String,String> dataset = new DefaultCategoryDataset<>();
        dataset.setValue(100.0, ""Row 1"", ""Column 1"");
        dataset.setValue(200.0, ""Row 1"", ""Column 2"");
        JFreeChart chart = ChartFactory.createLineChart(""Test"", ""Categories"",
                ""Value"", dataset, PlotOrientation.VERTICAL, false, false,
                false);
        CategoryPlot<?, ?> plot = (CategoryPlot) chart.getPlot();
        NumberAxis axis = (NumberAxis) plot.getRangeAxis();
        axis.setAutoRangeIncludesZero(false);
        assertEquals(axis.getLowerBound(), 95.0, EPSILON);
        assertEquals(axis.getUpperBound(), 205.0, EPSILON);
    }",1
"@Test
    public void testAutoRange4() {
        DefaultCategoryDataset<String,String> dataset = new DefaultCategoryDataset<>();
        dataset.setValue(100.0, ""Row 1"", ""Column 1"");
        dataset.setValue(200.0, ""Row 1"", ""Column 2"");
        JFreeChart chart = ChartFactory.createBarChart(""Test"", ""Categories"",
                ""Value"", dataset, PlotOrientation.VERTICAL, false, false,
                false);
        @SuppressWarnings(""unchecked"")
        CategoryPlot<String, String> plot = (CategoryPlot) chart.getPlot(); 
        NumberAxis axis = (NumberAxis) plot.getRangeAxis();
        axis.setAutoRangeIncludesZero(false);
        BarRenderer br = (BarRenderer) plot.getRenderer();
        br.setIncludeBaseInRange(false);
        assertEquals(95.0, axis.getLowerBound(), EPSILON);
        assertEquals(205.0, axis.getUpperBound(), EPSILON);

        br.setIncludeBaseInRange(true);
        assertEquals(0.0, axis.getLowerBound(), EPSILON);
        assertEquals(210.0, axis.getUpperBound(), EPSILON);

        axis.setAutoRangeIncludesZero(true);
        assertEquals(0.0, axis.getLowerBound(), EPSILON);
        assertEquals(210.0, axis.getUpperBound(), EPSILON);

        br.setIncludeBaseInRange(true);
        assertEquals(0.0, axis.getLowerBound(), EPSILON);
        assertEquals(210.0, axis.getUpperBound(), EPSILON);

        // now replacing the dataset should update the axis range...
        DefaultCategoryDataset<String,String> dataset2 = new DefaultCategoryDataset<>();
        dataset2.setValue(900.0, ""Row 1"", ""Column 1"");
        dataset2.setValue(1000.0, ""Row 1"", ""Column 2"");
        plot.setDataset(dataset2);
        assertEquals(0.0, axis.getLowerBound(), EPSILON);
        assertEquals(1050.0, axis.getUpperBound(), EPSILON);

        br.setIncludeBaseInRange(false);
        assertEquals(0.0, axis.getLowerBound(), EPSILON);
        assertEquals(1050.0, axis.getUpperBound(), EPSILON);

        axis.setAutoRangeIncludesZero(false);
        assertEquals(895.0, axis.getLowerBound(), EPSILON);
        assertEquals(1005.0, axis.getUpperBound(), EPSILON);
    }",1
"@Test
    public void testEquals() {
        PeriodAxisLabelInfo info1 = new PeriodAxisLabelInfo(Day.class,
                new SimpleDateFormat(""d""));
        PeriodAxisLabelInfo info2 = new PeriodAxisLabelInfo(Day.class,
                new SimpleDateFormat(""d""));
        assertEquals(info1, info2);
        assertEquals(info2, info1);

        Class c1 = Day.class;
        Class c2 = Month.class;
        DateFormat df1 = new SimpleDateFormat(""d"");
        DateFormat df2 = new SimpleDateFormat(""MMM"");
        RectangleInsets sp1 = new RectangleInsets(1, 1, 1, 1);
        RectangleInsets sp2 = new RectangleInsets(2, 2, 2, 2);
        Font lf1 = new Font(""SansSerif"", Font.PLAIN, 10);
        Font lf2 = new Font(""SansSerif"", Font.BOLD, 9);
        Paint lp1 = Color.BLACK;
        Paint lp2 = Color.BLUE;
        boolean b1 = true;
        boolean b2 = false;
        Stroke s1 = new BasicStroke(0.5f);
        Stroke s2 = new BasicStroke(0.25f);
        Paint dp1 = Color.RED;
        Paint dp2 = Color.GREEN;

        info1 = new PeriodAxisLabelInfo(c2, df1, sp1, lf1, lp1, b1, s1, dp1);
        info2 = new PeriodAxisLabelInfo(c1, df1, sp1, lf1, lp1, b1, s1, dp1);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df1, sp1, lf1, lp1, b1, s1, dp1);
        assertEquals(info1, info2);

        info1 = new PeriodAxisLabelInfo(c2, df2, sp1, lf1, lp1, b1, s1, dp1);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df2, sp1, lf1, lp1, b1, s1, dp1);
        assertEquals(info1, info2);

        info1 = new PeriodAxisLabelInfo(c2, df2, sp2, lf1, lp1, b1, s1, dp1);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df2, sp2, lf1, lp1, b1, s1, dp1);
        assertEquals(info1, info2);

        info1 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp1, b1, s1, dp1);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp1, b1, s1, dp1);
        assertEquals(info1, info2);

        info1 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b1, s1, dp1);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b1, s1, dp1);
        assertEquals(info1, info2);

        info1 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b2, s1, dp1);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b2, s1, dp1);
        assertEquals(info1, info2);

        info1 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b2, s2, dp1);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b2, s2, dp1);
        assertEquals(info1, info2);

        info1 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b2, s2, dp2);
        assertNotEquals(info1, info2);
        info2 = new PeriodAxisLabelInfo(c2, df2, sp2, lf2, lp2, b2, s2, dp2);
        assertEquals(info1, info2);

    }",1
"@Test
    public void test2275695() {
        JFreeChart chart = ChartFactory.createStackedBarChart(""Test"",
                ""Category"", ""Value"", null, PlotOrientation.VERTICAL,
                true, false, false);
        CategoryPlot<?, ?> plot = (CategoryPlot) chart.getPlot();
        plot.setDomainAxis(new SubCategoryAxis(""SubCategoryAxis""));
        try {
            BufferedImage image = new BufferedImage(200 , 100,
                    BufferedImage.TYPE_INT_RGB);
            Graphics2D g2 = image.createGraphics();
            chart.draw(g2, new Rectangle2D.Double(0, 0, 200, 100), null, null);
            g2.dispose();
        }",1
"@Test
    public void testEquals() {
        FlowArrangement f1 = new FlowArrangement(HorizontalAlignment.LEFT,
                VerticalAlignment.TOP, 1.0, 2.0);
        FlowArrangement f2 = new FlowArrangement(HorizontalAlignment.LEFT,
                VerticalAlignment.TOP, 1.0, 2.0);
        assertEquals(f1, f2);
        assertEquals(f2, f1);

        f1 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.TOP, 1.0, 2.0);
        assertNotEquals(f1, f2);
        f2 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.TOP, 1.0, 2.0);
        assertEquals(f1, f2);

        f1 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.BOTTOM, 1.0, 2.0);
        assertNotEquals(f1, f2);
        f2 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.BOTTOM, 1.0, 2.0);
        assertEquals(f1, f2);

        f1 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.BOTTOM, 1.1, 2.0);
        assertNotEquals(f1, f2);
        f2 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.BOTTOM, 1.1, 2.0);
        assertEquals(f1, f2);

        f1 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.BOTTOM, 1.1, 2.2);
        assertNotEquals(f1, f2);
        f2 = new FlowArrangement(HorizontalAlignment.RIGHT,
                VerticalAlignment.BOTTOM, 1.1, 2.2);
        assertEquals(f1, f2);

    }",1
"@Test
    public void testRF() {
        BlockContainer c = createTestContainer1();
        RectangleConstraint constraint = new RectangleConstraint(new Range(40.0,
                60.0), 100.0);
        Size2D s = c.arrange(null, constraint);
        assertEquals(60.0, s.width, EPSILON);
        assertEquals(100.0, s.height, EPSILON);
    }",1
"@Test
    public void testSerialization() {
        GradientPaint gp = new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f, 4.0f,
                Color.BLUE);
        LabelBlock b1 = new LabelBlock(""ABC"", new Font(""Dialog"",
                Font.PLAIN, 12), gp);
        LabelBlock b2 = TestUtils.serialised(b1);
        assertEquals(b1, b2);
    }",1
"@Test
    public void test2502355_restoreAutoDomainBounds() {
        DefaultXYDataset<String> dataset = new DefaultXYDataset<>();
        JFreeChart chart = ChartFactory.createXYLineChart(""TestChart"", ""X"",
                ""Y"", dataset, PlotOrientation.VERTICAL, false, false, false);
        XYPlot<?> plot = (XYPlot<?>) chart.getPlot();
        plot.setDomainAxis(1, new NumberAxis(""X2""));
        ChartPanel panel = new ChartPanel(chart);
        chart.addChangeListener(this);
        this.chartChangeEvents.clear();
        panel.restoreAutoDomainBounds();
        assertEquals(1, this.chartChangeEvents.size());
    }",1
"@Test
    public void test2502355_zoomInDomain() {
        DefaultXYDataset<String> dataset = new DefaultXYDataset<>();
        JFreeChart chart = ChartFactory.createXYLineChart(""TestChart"", ""X"",
                ""Y"", dataset, PlotOrientation.VERTICAL, false, false, false);
        XYPlot<?> plot = (XYPlot<?>) chart.getPlot();
        plot.setDomainAxis(1, new NumberAxis(""X2""));
        ChartPanel panel = new ChartPanel(chart);
        chart.addChangeListener(this);
        this.chartChangeEvents.clear();
        panel.zoomInDomain(1.0, 2.0);
        assertEquals(1, this.chartChangeEvents.size());
    }",1
"@Test
    public void test2502355_zoomOutBoth() {
        DefaultXYDataset<String> dataset = new DefaultXYDataset<>();
        JFreeChart chart = ChartFactory.createXYLineChart(""TestChart"", ""X"",
                ""Y"", dataset, PlotOrientation.VERTICAL, false, false, false);
        ChartPanel panel = new ChartPanel(chart);
        chart.addChangeListener(this);
        this.chartChangeEvents.clear();
        panel.zoomOutBoth(1.0, 2.0);
        assertEquals(1, this.chartChangeEvents.size());
    }",1
"@Test
    public void testGetListeners() {
        ChartPanel p = new ChartPanel(null);
        p.addChartMouseListener(this);
        EventListener[] listeners = p.getListeners(ChartMouseListener.class);
        assertEquals(1, listeners.length);
        assertEquals(this, listeners[0]);
        // try a listener type that isn't registered
        listeners = p.getListeners(CaretListener.class);
        assertEquals(0, listeners.length);
        p.removeChartMouseListener(this);
        listeners = p.getListeners(ChartMouseListener.class);
        assertEquals(0, listeners.length);
        // try a null argument
        assertThrows(NullPointerException.class, () -> p.getListeners(null));
    }",1
"@Test
    public void testEquals() {
        PieSectionEntity<String> e1 = new PieSectionEntity<>(
                new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0), 
                new DefaultPieDataset<String>(), 1, 2, ""Key"", ""ToolTip"", ""URL"");
        PieSectionEntity<String> e2 = new PieSectionEntity<>(
                new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0), 
                new DefaultPieDataset<String>(), 1, 2, ""Key"", ""ToolTip"", ""URL"");
        assertEquals(e1, e2);

        e1.setArea(new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0));
        assertNotEquals(e1, e2);
        e2.setArea(new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0));
        assertEquals(e1, e2);

        e1.setToolTipText(""New ToolTip"");
        assertNotEquals(e1, e2);
        e2.setToolTipText(""New ToolTip"");
        assertEquals(e1, e2);

        e1.setURLText(""New URL"");
        assertNotEquals(e1, e2);
        e2.setURLText(""New URL"");
        assertEquals(e1, e2);

        e1.setDataset(null);
        assertNotEquals(e1, e2);
        e2.setDataset(null);
        assertEquals(e1, e2);

        e1.setPieIndex(99);
        assertNotEquals(e1, e2);
        e2.setPieIndex(99);
        assertEquals(e1, e2);

        e1.setSectionIndex(66);
        assertNotEquals(e1, e2);
        e2.setSectionIndex(66);
        assertEquals(e1, e2);

        e1.setSectionKey(""ABC"");
        assertNotEquals(e1, e2);
        e2.setSectionKey(""ABC"");
        assertEquals(e1, e2);
    }",1
"@Test
    public void testSerialization() {
        PieSectionEntity<String> e1 = new PieSectionEntity<>(
                new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0), 
                new DefaultPieDataset<String>(), 0, 1, ""Key"", ""ToolTip"", ""URL"");
        StandardEntityCollection c1 = new StandardEntityCollection();
        c1.add(e1);
        StandardEntityCollection c2 = TestUtils.serialised(c1);
        assertEquals(c1, c2);
    }",1
"@Test
    public void testSerialization() {
        XYItemEntity e1 = new XYItemEntity(new Rectangle2D.Double(1.0, 2.0,
                3.0, 4.0), new TimeSeriesCollection<String>(), 1, 9, ""ToolTip"", 
                ""URL"");
        XYItemEntity e2 = TestUtils.serialised(e1);
        assertEquals(e1, e2);
    }",1
"@Test
    public void testEquals() {

        // standard test
        BoxAndWhiskerXYToolTipGenerator g1
                = new BoxAndWhiskerXYToolTipGenerator();
        BoxAndWhiskerXYToolTipGenerator g2
                = new BoxAndWhiskerXYToolTipGenerator();
        assertEquals(g1, g2);
        assertEquals(g2, g1);

        // tooltip format
        g1 = new BoxAndWhiskerXYToolTipGenerator(""{0}",1
"@Test
    public void testEquals() {
        StandardPieToolTipGenerator g1 = new StandardPieToolTipGenerator();
        StandardPieToolTipGenerator g2 = new StandardPieToolTipGenerator();
        assertEquals(g1, g2);
        assertEquals(g2, g1);

        g1 = new StandardPieToolTipGenerator(""{0}",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        StandardXYItemLabelGenerator g1 = new StandardXYItemLabelGenerator();
        StandardXYItemLabelGenerator g2 = CloneUtils.clone(g1);
        assertNotSame(g1, g2);
        assertSame(g1.getClass(), g2.getClass());
        assertEquals(g1, g2);

        // check independence
        g1.getXFormat().setMinimumIntegerDigits(2);
        assertNotEquals(g1, g2);
        g2.getXFormat().setMinimumIntegerDigits(2);
        assertEquals(g1, g2);

        g1.getYFormat().setMinimumIntegerDigits(2);
        assertNotEquals(g1, g2);
        g2.getYFormat().setMinimumIntegerDigits(2);
        assertEquals(g1, g2);

        // another test...
        g1 = new StandardXYItemLabelGenerator(""{0}",1
"@Test
    public void testEquals() {

        LegendItem item1 = new LegendItem(""Label"", ""Description"",
                ""ToolTip"", ""URL"", true,
                new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0), true, Color.RED,
                true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0),
                new BasicStroke(2.1f), Color.GREEN);
        LegendItem item2 = new LegendItem(""Label"", ""Description"",
                ""ToolTip"", ""URL"", true,
                new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);
        assertEquals(item2, item1);

        item1 = new LegendItem(""Label2"", ""Description"", ""ToolTip"", ""URL"",
                true, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0), true,
                Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description"", ""ToolTip"", ""URL"",
                true, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", true, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", true, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                true, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.RED, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, true, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.BLUE, new BasicStroke(1.2f),
                true, new Line2D.Double(1.0, 2.0, 3.0, 4.0),
                new BasicStroke(2.1f), Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, false, Color.BLUE, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, false, Color.YELLOW, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, false, Color.YELLOW, new BasicStroke(1.2f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f), true,
                new Line2D.Double(1.0, 2.0, 3.0, 4.0), new BasicStroke(2.1f),
                Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f),
                false, new Line2D.Double(1.0, 2.0, 3.0, 4.0),
                new BasicStroke(2.1f), Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f),
                false, new Line2D.Double(1.0, 2.0, 3.0, 4.0),
                new BasicStroke(2.1f), Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f),
                false, new Line2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.1f), Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f),
                false, new Line2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(2.1f), Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f),
                false, new Line2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(3.3f), Color.GREEN);
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f),
                false, new Line2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(3.3f), Color.GREEN);
        assertEquals(item1, item2);

        item1 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"", ""URL"",
                false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0), false,
                Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f), false,
            new Line2D.Double(4.0, 3.0, 2.0, 1.0), new BasicStroke(3.3f),
            Color.WHITE
        );
        assertNotEquals(item1, item2);
        item2 = new LegendItem(""Label2"", ""Description2"", ""ToolTip"",
                ""URL"", false, new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0),
                false, Color.BLACK, false, Color.YELLOW, new BasicStroke(2.1f),
                false, new Line2D.Double(4.0, 3.0, 2.0, 1.0),
                new BasicStroke(3.3f),
                Color.WHITE);
        assertEquals(item1, item2);

        // fillPaintTransformer
        item1.setFillPaintTransformer(new StandardGradientPaintTransformer(
                GradientPaintTransformType.CENTER_VERTICAL));
        assertNotEquals(item1, item2);
        item2.setFillPaintTransformer(new StandardGradientPaintTransformer(
                GradientPaintTransformType.CENTER_VERTICAL));
        assertEquals(item1, item2);

        // labelFont
        item1.setLabelFont(new Font(""Dialog"", Font.PLAIN, 13));
        assertNotEquals(item1, item2);
        item2.setLabelFont(new Font(""Dialog"", Font.PLAIN, 13));
        assertEquals(item1, item2);

        // labelPaint
        item1.setLabelPaint(Color.RED);
        assertNotEquals(item1, item2);
        item2.setLabelPaint(Color.RED);
        assertEquals(item1, item2);

        // fillPaint
        item1.setFillPaint(new GradientPaint(1.0f, 2.0f, Color.GREEN, 3.0f,
                4.0f, Color.BLUE));
        assertNotEquals(item1, item2);
        item2.setFillPaint(new GradientPaint(1.0f, 2.0f, Color.GREEN, 3.0f,
                4.0f, Color.BLUE));
        assertEquals(item1, item2);

        // outlinePaint
        item1.setOutlinePaint(new GradientPaint(1.1f, 2.2f, Color.GREEN, 3.3f,
                4.4f, Color.BLUE));
        assertNotEquals(item1, item2);
        item2.setOutlinePaint(new GradientPaint(1.1f, 2.2f, Color.GREEN, 3.3f,
                4.4f, Color.BLUE));
        assertEquals(item1, item2);

        // linePaint
        item1.setLinePaint(new GradientPaint(0.1f, 0.2f, Color.GREEN, 0.3f,
                0.4f, Color.BLUE));
        assertNotEquals(item1, item2);
        item2.setLinePaint(new GradientPaint(0.1f, 0.2f, Color.GREEN, 0.3f,
                0.4f, Color.BLUE));
        assertEquals(item1, item2);
    }",1
"@Test
    public void testGetSetKey() {
        CategoryMarker m = new CategoryMarker(""X"");
        m.addChangeListener(this);
        this.lastEvent = null;
        assertEquals(""X"", m.getKey());
        m.setKey(""Y"");
        assertEquals(""Y"", m.getKey());
        assertEquals(m, this.lastEvent.getMarker());

        // check null argument...
        try {
            m.setKey(null);
            fail(""Expected an IllegalArgumentException for null."");
        }",1
"@Test
    public void testAddDomainMarker() {
        CategoryPlot<String, String> plot = new CategoryPlot<>();
        CategoryMarker m = new CategoryMarker(""C1"");
        plot.addDomainMarker(m);
        List<EventListener> listeners = Arrays.asList(m.getListeners(
                MarkerChangeListener.class));
        assertTrue(listeners.contains(plot));
        plot.clearDomainMarkers();
        listeners = Arrays.asList(m.getListeners(MarkerChangeListener.class));
        assertFalse(listeners.contains(plot));
    }",1
"@Test
    public void testAddRangeMarker() {
        CategoryPlot<String, String> plot = new CategoryPlot<>();
        Marker m = new ValueMarker(1.0);
        plot.addRangeMarker(m);
        List<EventListener> listeners = Arrays.asList(m.getListeners(
                MarkerChangeListener.class));
        assertTrue(listeners.contains(plot));
        plot.clearRangeMarkers();
        listeners = Arrays.asList(m.getListeners(MarkerChangeListener.class));
        assertFalse(listeners.contains(plot));
    }",1
"@Test
    public void testEquals_ObjectList4() {
        CategoryPlot<String, String> p1 = new CategoryPlot<>();
        p1.setRangeAxisLocation(AxisLocation.BOTTOM_OR_RIGHT);
        CategoryPlot<String, String> p2 = new CategoryPlot<>();
        p2.setRangeAxisLocation(AxisLocation.BOTTOM_OR_RIGHT);
        assertEquals(p1, p2);
        p2.setRangeAxisLocation(1, AxisLocation.TOP_OR_LEFT);
        assertNotEquals(p1, p2);
    }",1
"@Test
    public void testGetRangeAxisForDataset() {
        CategoryDataset<String, String> dataset = new DefaultCategoryDataset<>();
        CategoryAxis xAxis = new CategoryAxis(""X"");
        NumberAxis yAxis = new NumberAxis(""Y"");
        CategoryItemRenderer renderer = new DefaultCategoryItemRenderer();
        CategoryPlot<String, String> plot = new CategoryPlot<>(dataset, xAxis, 
                yAxis, renderer);
        assertEquals(yAxis, plot.getRangeAxisForDataset(0));

        // should get IllegalArgumentException for negative index
        boolean pass = false;
        try {
            plot.getRangeAxisForDataset(-1);
        }",1
"@Test
    public void testSerialization() {
        DefaultCategoryDataset<String, String> dataset = new DefaultCategoryDataset<>();
        CategoryAxis domainAxis = new CategoryAxis(""Domain"");
        NumberAxis rangeAxis = new NumberAxis(""Range"");
        BarRenderer renderer = new BarRenderer();
        CategoryPlot<String, String> p1 = new CategoryPlot<>(dataset, domainAxis, 
                rangeAxis, renderer);
        p1.setOrientation(PlotOrientation.HORIZONTAL);
        CategoryPlot<String, String> p2 = TestUtils.serialised(p1);
        assertEquals(p1, p2);
    }",1
"@Test
    public void testEquals() {
        ArcDialFrame f1 = new ArcDialFrame();
        ArcDialFrame f2 = new ArcDialFrame();
        assertEquals(f1, f2);

        // background paint
        f1.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertNotEquals(f1, f2);
        f2.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertEquals(f1, f2);

        // foreground paint
        f1.setForegroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertNotEquals(f1, f2);
        f2.setForegroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertEquals(f1, f2);

        // stroke
        f1.setStroke(new BasicStroke(1.1f));
        assertNotEquals(f1, f2);
        f2.setStroke(new BasicStroke(1.1f));
        assertEquals(f1, f2);

        // inner radius
        f1.setInnerRadius(0.11);
        assertNotEquals(f1, f2);
        f2.setInnerRadius(0.11);
        assertEquals(f1, f2);

        // outer radius
        f1.setOuterRadius(0.88);
        assertNotEquals(f1, f2);
        f2.setOuterRadius(0.88);
        assertEquals(f1, f2);

        // startAngle
        f1.setStartAngle(99);
        assertNotEquals(f1, f2);
        f2.setStartAngle(99);
        assertEquals(f1, f2);

        // extent
        f1.setExtent(33);
        assertNotEquals(f1, f2);
        f2.setExtent(33);
        assertEquals(f1, f2);

        // check an inherited attribute
        f1.setVisible(false);
        assertNotEquals(f1, f2);
        f2.setVisible(false);
        assertEquals(f1, f2);
    }",1
"@Test
    public void testHashCode() {
        ArcDialFrame f1 = new ArcDialFrame();
        ArcDialFrame f2 = new ArcDialFrame();
        assertEquals(f1, f2);
        int h1 = f1.hashCode();
        int h2 = f2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testHashCode() {
        DialBackground b1 = new DialBackground(Color.RED);
        DialBackground b2 = new DialBackground(Color.RED);
        assertEquals(b1, b2);
        int h1 = b1.hashCode();
        int h2 = b2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        // test a default instance
        DialCap c1 = new DialCap();
        DialCap c2 = CloneUtils.clone(c1);

        assertNotSame(c1, c2);
        assertSame(c1.getClass(), c2.getClass());
        assertEquals(c1, c2);

        // test a customised instance
        c1 = new DialCap();
        c1.setFillPaint(new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.GREEN));
        c1.setOutlinePaint(new GradientPaint(1.0f, 2.0f, Color.WHITE,
                3.0f, 4.0f, Color.GRAY));
        c1.setOutlineStroke(new BasicStroke(2.0f));
        c2 = (DialCap) c1.clone();
        assertNotSame(c1, c2);
        assertSame(c1.getClass(), c2.getClass());
        assertEquals(c1, c2);

        // check that the listener lists are independent
        MyDialLayerChangeListener l1 = new MyDialLayerChangeListener();
        c1.addChangeListener(l1);
        assertTrue(c1.hasListener(l1));
        assertFalse(c2.hasListener(l1));
    }",1
"@Test
    public void testEquals() {
        DialCap c1 = new DialCap();
        DialCap c2 = new DialCap();
        assertEquals(c1, c2);

        // radius
        c1.setRadius(0.5);
        assertNotEquals(c1, c2);
        c2.setRadius(0.5);
        assertEquals(c1, c2);

        // fill paint
        c1.setFillPaint(new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.GREEN));
        assertNotEquals(c1, c2);
        c2.setFillPaint(new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.GREEN));

        // outline paint
        c1.setOutlinePaint(new GradientPaint(1.0f, 2.0f, Color.WHITE,
                3.0f, 4.0f, Color.GRAY));
        assertNotEquals(c1, c2);
        c2.setOutlinePaint(new GradientPaint(1.0f, 2.0f, Color.WHITE,
                3.0f, 4.0f, Color.GRAY));

        assertEquals(c1, c2);

        // outline stroke
        c1.setOutlineStroke(new BasicStroke(1.1f));
        assertNotEquals(c1, c2);
        c2.setOutlineStroke(new BasicStroke(1.1f));
        assertEquals(c1, c2);

        // check an inherited attribute
        c1.setVisible(false);
        assertNotEquals(c1, c2);
        c2.setVisible(false);
        assertEquals(c1, c2);
    }",1
"@Test
    public void testHashCode() {
        DialCap c1 = new DialCap();
        DialCap c2 = new DialCap();
        assertEquals(c1, c2);
        int h1 = c1.hashCode();
        int h2 = c2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testLayerListener() {
        DialPlot p = new DialPlot();
        DialBackground b1 = new DialBackground(Color.RED);
        p.addLayer(b1);
        p.addChangeListener(this);
        this.lastEvent = null;
        b1.setPaint(Color.BLUE);
        assertNotNull(this.lastEvent);

        DialBackground b2 = new DialBackground(Color.GREEN);
        p.addLayer(b2);
        this.lastEvent = null;
        b1.setPaint(Color.RED);
        assertNotNull(this.lastEvent);
        b2.setPaint(Color.GREEN);
        assertNotNull(this.lastEvent);

        p.removeLayer(b2);
        this.lastEvent = null;
        b2.setPaint(Color.RED);
        assertNull(this.lastEvent);
    }",1
"@Test
    public void testScaleListener() {
        DialPlot p = new DialPlot();
        StandardDialScale s1 = new StandardDialScale();
        p.addScale(0, s1);
        p.addChangeListener(this);
        this.lastEvent = null;
        s1.setStartAngle(22.0);
        assertNotNull(this.lastEvent);

        StandardDialScale s2 = new StandardDialScale();
        p.addScale(0, s2);
        this.lastEvent = null;
        s1.setStartAngle(33.0);
        assertNull(this.lastEvent);
        s2.setStartAngle(33.0);
        assertNotNull(this.lastEvent);
    }",1
"@Test
    public void testHashCode() {
        DialPointer i1 = new DialPointer.Pin(1);
        DialPointer i2 = new DialPointer.Pin(1);
        assertEquals(i1, i2);
        int h1 = i1.hashCode();
        int h2 = i2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testHashCode() {
        StandardDialFrame f1 = new StandardDialFrame();
        StandardDialFrame f2 = new StandardDialFrame();
        assertEquals(f1, f2);
        int h1 = f1.hashCode();
        int h2 = f2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testHashCode() {
        StandardDialScale s1 = new StandardDialScale();
        StandardDialScale s2 = new StandardDialScale();
        assertEquals(s1, s2);
        int h1 = s1.hashCode();
        int h2 = s2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        MeterPlot p1 = new MeterPlot();
        MeterPlot p2 = CloneUtils.clone(p1);
        assertNotSame(p1, p2);
        assertSame(p1.getClass(), p2.getClass());
        assertEquals(p1, p2);

        // the clone and the original share a reference to the SAME dataset
        assertSame(p1.getDataset(), p2.getDataset());

        // try a few checks to ensure that the clone is independent of the
        // original
        p1.getTickLabelFormat().setMinimumIntegerDigits(99);
        assertNotEquals(p1, p2);
        p2.getTickLabelFormat().setMinimumIntegerDigits(99);
        assertEquals(p1, p2);

        p1.addInterval(new MeterInterval(""Test"", new Range(1.234, 5.678)));
        assertNotEquals(p1, p2);
        p2.addInterval(new MeterInterval(""Test"", new Range(1.234, 5.678)));
        assertEquals(p1, p2);

    }",1
"@Test
    public void testEquals() {
        MultiplePiePlot p1 = new MultiplePiePlot();
        MultiplePiePlot p2 = new MultiplePiePlot();
        assertEquals(p1, p2);
        assertEquals(p2, p1);

        p1.setDataExtractOrder(TableOrder.BY_ROW);
        assertNotEquals(p1, p2);
        p2.setDataExtractOrder(TableOrder.BY_ROW);
        assertEquals(p1, p2);

        p1.setLimit(1.23);
        assertNotEquals(p1, p2);
        p2.setLimit(1.23);
        assertEquals(p1, p2);

        p1.setAggregatedItemsKey(""Aggregated Items"");
        assertNotEquals(p1, p2);
        p2.setAggregatedItemsKey(""Aggregated Items"");
        assertEquals(p1, p2);

        p1.setAggregatedItemsPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertNotEquals(p1, p2);
        p2.setAggregatedItemsPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertEquals(p1, p2);

        p1.setPieChart(ChartFactory.createPieChart(""Title"", null, true, true,
                true));
        assertNotEquals(p1, p2);
        p2.setPieChart(ChartFactory.createPieChart(""Title"", null, true, true,
                true));
        assertEquals(p1, p2);

        p1.setLegendItemShape(new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0));
        assertNotEquals(p1, p2);
        p2.setLegendItemShape(new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0));
        assertEquals(p1, p2);
    }",1
"@Test
    public void testBug1126_b() throws CloneNotSupportedException {
        DefaultPieDataset<String> dataset1 = new DefaultPieDataset<>();
        PiePlot plot1 = new PiePlot(dataset1);
        plot1.setSectionOutlinePaint(""A"", Color.RED);
        plot1.setSectionOutlinePaint(""B"", Color.GREEN);
        PiePlot plot2 = CloneUtils.clone(plot1);
        plot2.setSectionOutlinePaint(""A"", Color.BLUE);
        plot2.setSectionOutlinePaint(""B"", Color.YELLOW);
        assertEquals(Color.RED, plot1.getSectionOutlinePaint(""A""));
        assertEquals(Color.GREEN, plot1.getSectionOutlinePaint(""B""));
        assertEquals(Color.BLUE, plot2.getSectionOutlinePaint(""A""));
        assertEquals(Color.YELLOW, plot2.getSectionOutlinePaint(""B""));
    }",1
"@Test
    public void testBug1126_c() throws CloneNotSupportedException {
        DefaultPieDataset<String> dataset1 = new DefaultPieDataset<>();
        PiePlot plot1 = new PiePlot(dataset1);
        plot1.setSectionOutlineStroke(""A"", new BasicStroke(5.0f));
        plot1.setSectionOutlineStroke(""B"", new BasicStroke(6.0f));
        PiePlot plot2 = CloneUtils.clone(plot1);
        plot2.setSectionOutlineStroke(""A"", new BasicStroke(7.0f));
        plot2.setSectionOutlineStroke(""B"", new BasicStroke(8.0f));
        assertEquals(new BasicStroke(5.0f), plot1.getSectionOutlineStroke(""A""));
        assertEquals(new BasicStroke(6.0f), plot1.getSectionOutlineStroke(""B""));
        assertEquals(new BasicStroke(7.0f), plot2.getSectionOutlineStroke(""A""));
        assertEquals(new BasicStroke(8.0f), plot2.getSectionOutlineStroke(""B""));
    }",1
"@Test
    public void testSerialization() {
        PlotOrientation orientation1 = PlotOrientation.HORIZONTAL;
        PlotOrientation orientation2 = TestUtils.serialised(orientation1);
        assertEquals(orientation1, orientation2);
        boolean same = orientation1 == orientation2;
        assertTrue(same);
    }",1
"@Test
    public void testEquals() {
        PiePlot plot1 = new PiePlot();
        PiePlot plot2 = new PiePlot();
        assertEquals(plot1, plot2);
        assertEquals(plot2, plot1);

        // noDataMessage
        plot1.setNoDataMessage(""No data XYZ"");
        assertNotEquals(plot1, plot2);
        plot2.setNoDataMessage(""No data XYZ"");
        assertEquals(plot1, plot2);

        // noDataMessageFont
        plot1.setNoDataMessageFont(new Font(""SansSerif"", Font.PLAIN, 13));
        assertNotEquals(plot1, plot2);
        plot2.setNoDataMessageFont(new Font(""SansSerif"", Font.PLAIN, 13));
        assertEquals(plot1, plot2);

        // noDataMessagePaint
        plot1.setNoDataMessagePaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.BLUE));
        assertNotEquals(plot1, plot2);
        plot2.setNoDataMessagePaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.BLUE));
        assertEquals(plot1, plot2);

        // insets
        plot1.setInsets(new RectangleInsets(1.0, 2.0, 3.0, 4.0));
        assertNotEquals(plot1, plot2);
        plot2.setInsets(new RectangleInsets(1.0, 2.0, 3.0, 4.0));
        assertEquals(plot1, plot2);

        // outlineVisible
        plot1.setOutlineVisible(false);
        assertNotEquals(plot1, plot2);
        plot2.setOutlineVisible(false);
        assertEquals(plot1, plot2);

        // outlineStroke
        BasicStroke s = new BasicStroke(1.23f);
        plot1.setOutlineStroke(s);
        assertNotEquals(plot1, plot2);
        plot2.setOutlineStroke(s);
        assertEquals(plot1, plot2);

        // outlinePaint
        plot1.setOutlinePaint(new GradientPaint(1.0f, 2.0f, Color.YELLOW,
                3.0f, 4.0f, Color.GREEN));
        assertNotEquals(plot1, plot2);
        plot2.setOutlinePaint(new GradientPaint(1.0f, 2.0f, Color.YELLOW,
                3.0f, 4.0f, Color.GREEN));
        assertEquals(plot1, plot2);

        // backgroundPaint
        plot1.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.CYAN,
                3.0f, 4.0f, Color.GREEN));
        assertNotEquals(plot1, plot2);
        plot2.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.CYAN,
                3.0f, 4.0f, Color.GREEN));
        assertEquals(plot1, plot2);

//        // backgroundImage
//        plot1.setBackgroundImage(JFreeChart.INFO.getLogo());
//        assertFalse(plot1.equals(plot2));
//        plot2.setBackgroundImage(JFreeChart.INFO.getLogo());
//        assertTrue(plot1.equals(plot2));

        // backgroundImageAlignment
        plot1.setBackgroundImageAlignment(RectangleAlignment.BOTTOM_RIGHT);
        assertNotEquals(plot1, plot2);
        plot2.setBackgroundImageAlignment(RectangleAlignment.BOTTOM_RIGHT);
        assertEquals(plot1, plot2);

        // backgroundImageAlpha
        plot1.setBackgroundImageAlpha(0.77f);
        assertNotEquals(plot1, plot2);
        plot2.setBackgroundImageAlpha(0.77f);
        assertEquals(plot1, plot2);

        // foregroundAlpha
        plot1.setForegroundAlpha(0.99f);
        assertNotEquals(plot1, plot2);
        plot2.setForegroundAlpha(0.99f);
        assertEquals(plot1, plot2);

        // backgroundAlpha
        plot1.setBackgroundAlpha(0.99f);
        assertNotEquals(plot1, plot2);
        plot2.setBackgroundAlpha(0.99f);
        assertEquals(plot1, plot2);

        // drawingSupplier
        plot1.setDrawingSupplier(new DefaultDrawingSupplier(
                new Paint[] {Color.BLUE}",1
"@Test
    public void testGetLegendItems() {
        XYSeriesCollection<String> d = new XYSeriesCollection<>();
        d.addSeries(new XYSeries<>(""A""));
        d.addSeries(new XYSeries<>(""B""));
        DefaultPolarItemRenderer r = new DefaultPolarItemRenderer();
        PolarPlot plot = new PolarPlot();
        plot.setDataset(d);
        plot.setRenderer(r);
        LegendItemCollection items = plot.getLegendItems();
        assertEquals(2, items.getItemCount());
        LegendItem item1 = items.get(0);
        assertEquals(""A"", item1.getLabel());
        LegendItem item2 = items.get(1);
        assertEquals(""B"", item2.getLabel());
    }",1
"@Test
    public void testGetLegendItems2() {
        XYSeriesCollection<String> d1 = new XYSeriesCollection<>();
        d1.addSeries(new XYSeries<>(""A""));
        d1.addSeries(new XYSeries<>(""B""));
        XYSeriesCollection<String> d2 = new XYSeriesCollection<>();
        d2.addSeries(new XYSeries<>(""C""));
        d2.addSeries(new XYSeries<>(""D""));
        DefaultPolarItemRenderer r = new DefaultPolarItemRenderer();
        PolarPlot plot = new PolarPlot();
        plot.setDataset(d1);
        plot.setDataset(1, d2);
        plot.setRenderer(r);
        plot.setRenderer(1, new DefaultPolarItemRenderer());
        LegendItemCollection items = plot.getLegendItems();
        assertEquals(4, items.getItemCount());
        LegendItem item1 = items.get(0);
        assertEquals(""A"", item1.getLabel());
        LegendItem item2 = items.get(1);
        assertEquals(""B"", item2.getLabel());
        LegendItem item3 = items.get(2);
        assertEquals(""C"", item3.getLabel());
        LegendItem item4 = items.get(3);
        assertEquals(""D"", item4.getLabel());
    }",1
"@Test
    public void testSerialization() {
        PolarPlot p1 = new PolarPlot();
        p1.setAngleGridlinePaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f,
                4.0f, Color.BLUE));
        p1.setAngleLabelPaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f,
                4.0f, Color.BLUE));
        p1.setRadiusGridlinePaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f,
                4.0f, Color.BLUE));
        PolarPlot p2 = TestUtils.serialised(p1);
        assertEquals(p1, p2);
    }",1
"@Test
    public void testTranslateToJava2D_NumberAxis() {
        
        Rectangle2D dataArea = new Rectangle2D.Double(0.0, 0.0, 100.0, 100.0);
        ValueAxis axis = new NumberAxis();
        axis.setRange(0.0, 20.0);

        PolarPlot plot = new PolarPlot(null, axis, null);
        plot.setMargin(0);
        plot.setAngleOffset(0.0);

        Point point = plot.translateToJava2D(0.0, 10.0, axis, dataArea );
        assertEquals(75.0, point.getX(), 0.5);
        assertEquals(50.0, point.getY(), 0.5);

        point = plot.translateToJava2D(90.0, 5.0, axis, dataArea );
        assertEquals(50.0, point.getX(), 0.5);
        assertEquals(62.5, point.getY(), 0.5);

        point = plot.translateToJava2D(45.0, 20.0, axis, dataArea );
        assertEquals(85.0, point.getX(), 0.5);
        assertEquals(85.0, point.getY(), 0.5);

        point = plot.translateToJava2D(135.0, 20.0, axis, dataArea );
        assertEquals(15.0, point.getX(), 0.5);
        assertEquals(85.0, point.getY(), 0.5);

        point = plot.translateToJava2D(225.0, 15.0, axis, dataArea );
        assertEquals(23.0, point.getX(), 0.5);
        assertEquals(23.0, point.getY(), 0.5);

        point = plot.translateToJava2D(315.0, 15.0, axis, dataArea );
        assertEquals(77.0, point.getX(), 0.5);
        assertEquals(23.0, point.getY(), 0.5);
        
        point = plot.translateToJava2D(21.0, 11.5, axis, dataArea );
        assertEquals(77.0, point.getX(), 0.5);
        assertEquals(60.0, point.getY(), 0.5);
        
        point = plot.translateToJava2D(162.0, 7.0, axis, dataArea );
        assertEquals(33.0, point.getX(), 0.5);
        assertEquals(55.0, point.getY(), 0.5);
        
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        RingPlot p1 = new RingPlot(null);
        GradientPaint gp = new GradientPaint(1.0f, 2.0f, Color.YELLOW,
                3.0f, 4.0f, Color.RED);
        p1.setSeparatorPaint(gp);
        RingPlot p2 = CloneUtils.clone(p1);
        assertNotSame(p1, p2);
        assertSame(p1.getClass(), p2.getClass());
        assertEquals(p1, p2);
    }",1
"@Test
    public void testEquals() {

        RingPlot plot1 = new RingPlot(null);
        RingPlot plot2 = new RingPlot(null);
        assertEquals(plot1, plot2);
        assertEquals(plot2, plot1);

        plot1.setCenterTextMode(CenterTextMode.FIXED);
        assertNotEquals(plot1, plot2);
        plot2.setCenterTextMode(CenterTextMode.FIXED);
        assertEquals(plot1, plot2);

        plot1.setCenterText(""ABC"");
        assertNotEquals(plot1, plot2);
        plot2.setCenterText(""ABC"");
        assertEquals(plot1, plot2);
        
        plot1.setCenterTextColor(Color.RED);
        assertNotEquals(plot1, plot2);
        plot2.setCenterTextColor(Color.RED);
        assertEquals(plot1, plot2);
        
        plot1.setCenterTextFont(new Font(Font.SERIF, Font.PLAIN, 7));
        assertNotEquals(plot1, plot2);
        plot2.setCenterTextFont(new Font(Font.SERIF, Font.PLAIN, 7));
        assertEquals(plot1, plot2);

        plot1.setCenterTextFormatter(new DecimalFormat(""0.000""));
        assertNotEquals(plot1, plot2);
        plot2.setCenterTextFormatter(new DecimalFormat(""0.000""));
        assertEquals(plot1, plot2);
        
        // separatorsVisible
        plot1.setSeparatorsVisible(false);
        assertNotEquals(plot1, plot2);
        plot2.setSeparatorsVisible(false);
        assertEquals(plot1, plot2);

        // separatorStroke
        Stroke s = new BasicStroke(1.1f);
        plot1.setSeparatorStroke(s);
        assertNotEquals(plot1, plot2);
        plot2.setSeparatorStroke(s);
        assertEquals(plot1, plot2);

        // separatorPaint
        plot1.setSeparatorPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                2.0f, 1.0f, Color.BLUE));
        assertNotEquals(plot1, plot2);
        plot2.setSeparatorPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                2.0f, 1.0f, Color.BLUE));
        assertEquals(plot1, plot2);

        // innerSeparatorExtension
        plot1.setInnerSeparatorExtension(0.01);
        assertNotEquals(plot1, plot2);
        plot2.setInnerSeparatorExtension(0.01);
        assertEquals(plot1, plot2);

        // outerSeparatorExtension
        plot1.setOuterSeparatorExtension(0.02);
        assertNotEquals(plot1, plot2);
        plot2.setOuterSeparatorExtension(0.02);
        assertEquals(plot1, plot2);

        // sectionDepth
        plot1.setSectionDepth(0.12);
        assertNotEquals(plot1, plot2);
        plot2.setSectionDepth(0.12);
        assertEquals(plot1, plot2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        SpiderWebPlot p1 = new SpiderWebPlot(new DefaultCategoryDataset<String, String>());
        Rectangle2D legendShape = new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0);
        p1.setLegendItemShape(legendShape);
        SpiderWebPlot p2 = CloneUtils.clone(p1);
        assertNotSame(p1, p2);
        assertSame(p1.getClass(), p2.getClass());
        assertEquals(p1, p2);

        // change the legendItemShape
        legendShape.setRect(4.0, 3.0, 2.0, 1.0);
        assertNotEquals(p1, p2);
        p2.setLegendItemShape(legendShape);
        assertEquals(p1, p2);

        // change a series paint
        p1.setSeriesPaint(1, Color.BLACK);
        assertNotEquals(p1, p2);
        p2.setSeriesPaint(1, Color.BLACK);
        assertEquals(p1, p2);

        // change a series outline paint
        p1.setSeriesOutlinePaint(0, Color.RED);
        assertNotEquals(p1, p2);
        p2.setSeriesOutlinePaint(0, Color.RED);
        assertEquals(p1, p2);

        // change a series outline stroke
        p1.setSeriesOutlineStroke(0, new BasicStroke(1.1f));
        assertNotEquals(p1, p2);
        p2.setSeriesOutlineStroke(0, new BasicStroke(1.1f));
        assertEquals(p1, p2);

    }",1
"@Test
    public void testGetLegendItems() {
        DefaultCategoryDataset<String, String> dataset = new DefaultCategoryDataset<>();
        dataset.addValue(35.0, ""S1"", ""C1"");
        dataset.addValue(45.0, ""S1"", ""C2"");
        dataset.addValue(55.0, ""S2"", ""C1"");
        dataset.addValue(15.0, ""S2"", ""C2"");
        SpiderWebPlot plot = new SpiderWebPlot(dataset);
        JFreeChart chart = new JFreeChart(plot);
        LegendItemCollection legendItems = plot.getLegendItems();
        assertEquals(2, legendItems.getItemCount());
        LegendItem item1 = legendItems.get(0);
        assertEquals(""S1"", item1.getLabel());
        assertEquals(""S1"", item1.getSeriesKey());
        assertEquals(0, item1.getSeriesIndex());
        assertEquals(dataset, item1.getDataset());
        assertEquals(0, item1.getDatasetIndex());

        LegendItem item2 = legendItems.get(1);
        assertEquals(""S2"", item2.getLabel());
        assertEquals(""S2"", item2.getSeriesKey());
        assertEquals(1, item2.getSeriesIndex());
        assertEquals(dataset, item2.getDataset());
        assertEquals(0, item2.getDatasetIndex());
    }",1
"@Test
    public void testEquals() {

        Marker m1 = new ValueMarker(45.0);
        Marker m2 = new ValueMarker(45.0);
        assertEquals(m1, m2);
        assertEquals(m2, m1);

        m1.setPaint(new GradientPaint(1.0f, 2.0f, Color.GREEN,
                3.0f, 4.0f, Color.RED));
        assertNotEquals(m1, m2);
        m2.setPaint(new GradientPaint(1.0f, 2.0f, Color.GREEN,
                3.0f, 4.0f, Color.RED));
        assertEquals(m1, m2);

        BasicStroke stroke = new BasicStroke(2.2f);
        m1.setStroke(stroke);
        assertNotEquals(m1, m2);
        m2.setStroke(stroke);
        assertEquals(m1, m2);

        m1.setOutlinePaint(new GradientPaint(4.0f, 3.0f, Color.YELLOW,
                2.0f, 1.0f, Color.WHITE));
        assertNotEquals(m1, m2);
        m2.setOutlinePaint(new GradientPaint(4.0f, 3.0f, Color.YELLOW,
                2.0f, 1.0f, Color.WHITE));
        assertEquals(m1, m2);

        m1.setOutlineStroke(stroke);
        assertNotEquals(m1, m2);
        m2.setOutlineStroke(stroke);
        assertEquals(m1, m2);

        m1.setAlpha(0.1f);
        assertNotEquals(m1, m2);
        m2.setAlpha(0.1f);
        assertEquals(m1, m2);

        m1.setLabel(""New Label"");
        assertNotEquals(m1, m2);
        m2.setLabel(""New Label"");
        assertEquals(m1, m2);

        m1.setLabelFont(new Font(""SansSerif"", Font.PLAIN, 10));
        assertNotEquals(m1, m2);
        m2.setLabelFont(new Font(""SansSerif"", Font.PLAIN, 10));
        assertEquals(m1, m2);

        m1.setLabelPaint(new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.YELLOW));
        assertNotEquals(m1, m2);
        m2.setLabelPaint(new GradientPaint(1.0f, 2.0f, Color.BLUE,
                3.0f, 4.0f, Color.YELLOW));
        assertEquals(m1, m2);

        m1.setLabelAnchor(RectangleAnchor.TOP_RIGHT);
        assertNotEquals(m1, m2);
        m2.setLabelAnchor(RectangleAnchor.TOP_RIGHT);
        assertEquals(m1, m2);

        m1.setLabelTextAnchor(TextAnchor.BASELINE_RIGHT);
        assertNotEquals(m1, m2);
        m2.setLabelTextAnchor(TextAnchor.BASELINE_RIGHT);
        assertEquals(m1, m2);

        m1.setLabelOffset(new RectangleInsets(10.0, 10.0, 10.0, 10.0));
        assertNotEquals(m1, m2);
        m2.setLabelOffset(new RectangleInsets(10.0, 10.0, 10.0, 10.0));
        assertEquals(m1, m2);

        m1.setLabelOffsetType(LengthAdjustmentType.EXPAND);
        assertNotEquals(m1, m2);
        m2.setLabelOffsetType(LengthAdjustmentType.EXPAND);
        assertEquals(m1, m2);

        m1 = new ValueMarker(12.3);
        m2 = new ValueMarker(45.6);
        assertNotEquals(m1, m2);
        m2 = new ValueMarker(12.3);
        assertEquals(m1, m2);

    }",1
"@Test
    public void testAddRangeMarker() {
        XYPlot<String> plot = new XYPlot<>();
        Marker m = new ValueMarker(1.0);
        plot.addRangeMarker(m);
        List<EventListener> listeners = Arrays.asList(m.getListeners(
                MarkerChangeListener.class));
        assertTrue(listeners.contains(plot));
        plot.clearRangeMarkers();
        listeners = Arrays.asList(m.getListeners(MarkerChangeListener.class));
        assertFalse(listeners.contains(plot));
    }",1
"@Test
    public void testAxisIndices() {
        XYDataset<String> dataset = new XYSeriesCollection<>();
        NumberAxis xAxis = new NumberAxis(""X"");
        NumberAxis yAxis = new NumberAxis(""Y"");
        XYItemRenderer renderer = new DefaultXYItemRenderer();
        XYPlot<String> plot = new XYPlot<>(dataset, xAxis, yAxis, renderer);
        assertEquals(xAxis, plot.getDomainAxis(0));        
        assertEquals(yAxis, plot.getRangeAxis(0)); 
        
        NumberAxis xAxis2 = new NumberAxis(""X2"");
        plot.setDomainAxis(99, xAxis2);
        assertEquals(xAxis2, plot.getDomainAxis(99));
        
        NumberAxis yAxis2 = new NumberAxis(""Y2"");
        plot.setRangeAxis(99, yAxis2);
        assertEquals(yAxis2, plot.getRangeAxis(99));
    }",1
"@Test 
    public void testAxisLocationIndices() {
        XYDataset<String> dataset = new XYSeriesCollection<>();
        NumberAxis xAxis = new NumberAxis(""X"");
        NumberAxis yAxis = new NumberAxis(""Y"");
        XYItemRenderer renderer = new DefaultXYItemRenderer();
        XYPlot<String> plot = new XYPlot<>(dataset, xAxis, yAxis, renderer);

        NumberAxis xAxis2 = new NumberAxis(""X2"");
        NumberAxis yAxis2 = new NumberAxis(""Y2"");
        plot.setDomainAxis(99, xAxis2);
        plot.setRangeAxis(99, yAxis2);
        
        plot.setDomainAxisLocation(99, AxisLocation.BOTTOM_OR_RIGHT);
        assertEquals(AxisLocation.BOTTOM_OR_RIGHT, 
                plot.getDomainAxisLocation(99));
        plot.setRangeAxisLocation(99, AxisLocation.BOTTOM_OR_LEFT);
        assertEquals(AxisLocation.BOTTOM_OR_LEFT, 
                plot.getRangeAxisLocation(99));
    }",1
"@Test
    public void testCloning4() throws CloneNotSupportedException {
        XYLineAndShapeRenderer r1 = new XYLineAndShapeRenderer();
        XYPlot<String> p1 = new XYPlot<>(null, new NumberAxis(""Domain Axis""),
                new NumberAxis(""Range Axis""), r1);
        XYPlot<String> p2 = CloneUtils.clone(p1);
        assertNotSame(p1, p2);
        assertSame(p1.getClass(), p2.getClass());
        assertEquals(p1, p2);

        // verify that the plot is listening to the cloned renderer
        XYLineAndShapeRenderer r2 = (XYLineAndShapeRenderer) p2.getRenderer();
        assertTrue(r2.hasListener(p2));
    }",1
"@Test
    public void testCloning_QuadrantOrigin() throws CloneNotSupportedException {
        XYPlot<String> p1 = new XYPlot<>();
        Point2D p = new Point2D.Double(1.2, 3.4);
        p1.setQuadrantOrigin(p);
        XYPlot<String> p2 = CloneUtils.clone(p1);
        assertNotSame(p1, p2);
        assertSame(p1.getClass(), p2.getClass());
        assertEquals(p1, p2);
        assertNotSame(p2.getQuadrantOrigin(), p);
    }",1
"@Test
    public void testCloning_QuadrantPaint() throws CloneNotSupportedException {
        XYPlot<String> p1 = new XYPlot<>();
        p1.setQuadrantPaint(3, new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.BLUE));
        XYPlot<String> p2 = CloneUtils.clone(p1);
        assertNotSame(p1, p2);
        assertSame(p1.getClass(), p2.getClass());
        assertEquals(p1, p2);

        // check for independence
        p1.setQuadrantPaint(1, Color.RED);
        assertNotEquals(p1, p2);
        p2.setQuadrantPaint(1, Color.RED);
        assertEquals(p1, p2);
    }",1
"@Test
    public void testDomainMarkerIndices() {
        XYDataset<String> dataset = new XYSeriesCollection<>();
        NumberAxis xAxis = new NumberAxis(""X"");
        NumberAxis yAxis = new NumberAxis(""Y"");
        XYItemRenderer renderer = new DefaultXYItemRenderer();
        XYPlot<String> plot = new XYPlot<>(dataset, xAxis, yAxis, renderer);
        
        // add a second dataset, plotted against a second x axis
        XYSeriesCollection<String> dataset2 = new XYSeriesCollection<>();
        dataset2.addSeries(new XYSeries<>(""Series in dataset 2""));
        plot.setDataset(99, dataset);    
        NumberAxis xAxis2 = new NumberAxis(""X2"");
        plot.setDomainAxis(1, xAxis2);
        XYLineAndShapeRenderer renderer2 = new XYLineAndShapeRenderer();
        plot.setRenderer(99, renderer2);
        plot.mapDatasetToDomainAxis(99, 1);
        
        ValueMarker xMarker1 = new ValueMarker(123);
        plot.addDomainMarker(99, xMarker1, Layer.FOREGROUND);
        assertTrue(plot.getDomainMarkers(99, Layer.FOREGROUND).contains(
                xMarker1));
    }",1
"@Test
    public void testEquals_ObjectList4() {
        XYPlot<String> p1 = new XYPlot<>();
        p1.setRangeAxisLocation(AxisLocation.BOTTOM_OR_RIGHT);
        XYPlot<String> p2 = new XYPlot<>();
        p2.setRangeAxisLocation(AxisLocation.BOTTOM_OR_RIGHT);
        assertEquals(p1, p2);
        p2.setRangeAxisLocation(1, AxisLocation.TOP_OR_LEFT);
        assertNotEquals(p1, p2);
    }",1
"@Test
    public void testGetDataRange() {
        XYSeriesCollection<String> dataset = new XYSeriesCollection<>();
        NumberAxis xAxis = new NumberAxis(""X"");
        NumberAxis yAxis = new NumberAxis(""Y"");
        XYItemRenderer renderer = new DefaultXYItemRenderer();
        XYPlot<String> plot = new XYPlot<>(dataset, xAxis, yAxis, renderer);
        assertNull(plot.getDataRange(xAxis));
        assertNull(plot.getDataRange(yAxis));
        
        XYSeries<String> s1 = new XYSeries<>(""S1"");
        s1.add(1.0, 2.0);
        dataset.addSeries(s1);
        assertEquals(new Range(1.0, 1.0), plot.getDataRange(xAxis));
        assertEquals(new Range(2.0, 2.0), plot.getDataRange(yAxis));
        
        s1.add(5.0, null);
        assertEquals(new Range(1.0, 5.0), plot.getDataRange(xAxis));
        assertEquals(new Range(2.0, 2.0), plot.getDataRange(yAxis));
        
        s1.add(6.0, Double.NaN);
        assertEquals(new Range(1.0, 6.0), plot.getDataRange(xAxis));
        assertEquals(new Range(2.0, 2.0), plot.getDataRange(yAxis));
    }",1
"@Test
    public void testGetDataRangeWithMultipleDatasets() {
        XYSeriesCollection<String> dataset1 = new XYSeriesCollection<>();
        XYSeriesCollection<String> dataset2 = new XYSeriesCollection<>();
        NumberAxis xAxis = new NumberAxis(""X"");
        NumberAxis yAxis = new NumberAxis(""Y"");
        XYItemRenderer renderer = new DefaultXYItemRenderer();
        XYPlot<String> plot = new XYPlot<>(dataset1, xAxis, yAxis, renderer);
        plot.setDataset(1, dataset2);
        plot.mapDatasetToDomainAxis(1, 0);
        plot.mapDatasetToRangeAxis(1, 0);
        assertNull(plot.getDataRange(xAxis));
        assertNull(plot.getDataRange(yAxis));
        
        XYSeries<String> s1 = new XYSeries<>(""S1"");
        s1.add(1.0, 2.0);
        dataset1.addSeries(s1);
        assertEquals(new Range(1.0, 1.0), plot.getDataRange(xAxis));
        assertEquals(new Range(2.0, 2.0), plot.getDataRange(yAxis));
        
        XYSeries<String> s2 = new XYSeries<>(""S2"");
        s2.add(5.0, 10.0);
        dataset2.addSeries(s2);
        assertEquals(new Range(1.0, 5.0), plot.getDataRange(xAxis));
        assertEquals(new Range(2.0, 10.0), plot.getDataRange(yAxis));
        
        s2.add(6.0, Double.NaN);
        assertEquals(new Range(1.0, 6.0), plot.getDataRange(xAxis));
        assertEquals(new Range(2.0, 10.0), plot.getDataRange(yAxis));
        
        s2.add(Double.NaN, 0.5); 
        assertEquals(new Range(1.0, 6.0), plot.getDataRange(xAxis));
        assertEquals(new Range(2.0, 10.0), plot.getDataRange(yAxis)); // only y-values for items in the x-range        
    }",1
"@Test
    public void testGetDomainAxisForDataset() {
        XYDataset<String> dataset = new XYSeriesCollection<>();
        NumberAxis xAxis = new NumberAxis(""X"");
        NumberAxis yAxis = new NumberAxis(""Y"");
        XYItemRenderer renderer = new DefaultXYItemRenderer();
        XYPlot<String> plot = new XYPlot<>(dataset, xAxis, yAxis, renderer);
        assertEquals(xAxis, plot.getDomainAxisForDataset(0));

        // should get IllegalArgumentException for negative index
        boolean pass = false;
        try {
            plot.getDomainAxisForDataset(-1);
        }",1
"@Test
    public void testGetRendererForDataset() {
        XYDataset<String> d0 = new XYSeriesCollection<>();
        XYDataset<String> d1 = new XYSeriesCollection<>();
        XYDataset<String> d2 = new XYSeriesCollection<>();
        XYDataset<String> d3 = new XYSeriesCollection<>();  // not used by plot
        XYItemRenderer r0 = new XYLineAndShapeRenderer();
        XYItemRenderer r2 = new XYLineAndShapeRenderer();
        XYPlot<String> plot = new XYPlot<>();
        plot.setDataset(0, d0);
        plot.setDataset(1, d1);
        plot.setDataset(2, d2);
        plot.setRenderer(0, r0);
        // no renderer 1
        plot.setRenderer(2, r2);
        assertEquals(r0, plot.getRendererForDataset(d0));
        assertEquals(r0, plot.getRendererForDataset(d1));
        assertEquals(r2, plot.getRendererForDataset(d2));
        assertNull(plot.getRendererForDataset(d3));
        assertNull(plot.getRendererForDataset(null));
    }",1
"@Test
    public void testSerialization1() {
        XYDataset<String> data = new XYSeriesCollection<>();
        NumberAxis domainAxis = new NumberAxis(""Domain"");
        NumberAxis rangeAxis = new NumberAxis(""Range"");
        StandardXYItemRenderer renderer = new StandardXYItemRenderer();
        XYPlot<String> p1 = new XYPlot<>(data, domainAxis, rangeAxis, renderer);
        XYPlot<String> p2 = TestUtils.serialised(p1);
        assertEquals(p1, p2);
    }",1
"@Test
    public void testSerialization4() {

        XYSeriesCollection<String> dataset = new XYSeriesCollection<>();
        JFreeChart chart = ChartFactory.createXYLineChart(""Test Chart"",
                ""Domain Axis"", ""Range Axis"", dataset);
        XYPlot<?> plot = (XYPlot) chart.getPlot();
        plot.addDomainMarker(new ValueMarker(1.0), Layer.FOREGROUND);
        plot.addDomainMarker(new IntervalMarker(2.0, 3.0), Layer.BACKGROUND);
        plot.addRangeMarker(new ValueMarker(4.0), Layer.FOREGROUND);
        plot.addRangeMarker(new IntervalMarker(5.0, 6.0), Layer.BACKGROUND);
        JFreeChart chart2 = TestUtils.serialised(chart);
        assertEquals(chart, chart2);
        try {
            chart2.createBufferedImage(300, 200);
        }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        LineAndShapeRenderer r1 = new LineAndShapeRenderer();
        Rectangle2D baseShape = new Rectangle2D.Double(11.0, 12.0, 13.0, 14.0);
        r1.setDefaultShape(baseShape);
        r1.setDefaultLegendShape(new Rectangle(4, 3, 2, 1));
        r1.setDefaultLegendTextFont(new Font(""Dialog"", Font.PLAIN, 3));
        r1.setDefaultLegendTextPaint(new Color(1, 2, 3));
        r1.setSeriesItemLabelFont(0, new Font(Font.MONOSPACED, Font.BOLD, 13));
        r1.setLegendTextFont(0, new Font(Font.MONOSPACED, Font.BOLD, 14));
        r1.setSeriesPositiveItemLabelPosition(0, new ItemLabelPosition(
                ItemLabelAnchor.CENTER, TextAnchor.TOP_LEFT));
        r1.setSeriesNegativeItemLabelPosition(0, new ItemLabelPosition(
                ItemLabelAnchor.CENTER, TextAnchor.CENTER));
        
        LineAndShapeRenderer r2 = CloneUtils.clone(r1);
        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);

        r1.setSeriesVisible(0, Boolean.FALSE);
        assertNotEquals(r1, r2);
        r2.setSeriesVisible(0, Boolean.FALSE);
        assertEquals(r1, r2);

        r1.setSeriesVisibleInLegend(0, Boolean.FALSE);
        assertNotEquals(r1, r2);
        r2.setSeriesVisibleInLegend(0, Boolean.FALSE);
        assertEquals(r1, r2);

        r1.setSeriesPaint(0, Color.BLACK);
        assertNotEquals(r1, r2);
        r2.setSeriesPaint(0, Color.BLACK);
        assertEquals(r1, r2);

        r1.setSeriesFillPaint(0, Color.YELLOW);
        assertNotEquals(r1, r2);
        r2.setSeriesFillPaint(0, Color.YELLOW);
        assertEquals(r1, r2);

        r1.setSeriesOutlinePaint(0, Color.YELLOW);
        assertNotEquals(r1, r2);
        r2.setSeriesOutlinePaint(0, Color.YELLOW);
        assertEquals(r1, r2);

        r1.setSeriesStroke(0, new BasicStroke(2.2f));
        assertNotEquals(r1, r2);
        r2.setSeriesStroke(0, new BasicStroke(2.2f));
        assertEquals(r1, r2);

        r1.setSeriesOutlineStroke(0, new BasicStroke(2.2f));
        assertNotEquals(r1, r2);
        r2.setSeriesOutlineStroke(0, new BasicStroke(2.2f));
        assertEquals(r1, r2);

        baseShape.setRect(4.0, 3.0, 2.0, 1.0);
        assertNotEquals(r1, r2);
        r2.setDefaultShape(new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0));
        assertEquals(r1, r2);

        r1.setSeriesShape(0, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0));
        assertNotEquals(r1, r2);
        r2.setSeriesShape(0, new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0));
        assertEquals(r1, r2);

        r1.setSeriesItemLabelsVisible(0, Boolean.TRUE);
        assertNotEquals(r1, r2);
        r2.setSeriesItemLabelsVisible(0, Boolean.TRUE);
        assertEquals(r1, r2);

        r1.setSeriesItemLabelPaint(0, Color.RED);
        assertNotEquals(r1, r2);
        r2.setSeriesItemLabelPaint(0, Color.RED);
        assertEquals(r1, r2);
        
        r1.setSeriesPositiveItemLabelPosition(0, new ItemLabelPosition());
        assertNotEquals(r1, r2);
        r2.setSeriesPositiveItemLabelPosition(0, new ItemLabelPosition());
        assertEquals(r1, r2);

        r1.setSeriesNegativeItemLabelPosition(0, new ItemLabelPosition());
        assertNotEquals(r1, r2);
        r2.setSeriesNegativeItemLabelPosition(0, new ItemLabelPosition());
        assertEquals(r1, r2);

        r1.setSeriesCreateEntities(0, Boolean.FALSE);
        assertNotEquals(r1, r2);
        r2.setSeriesCreateEntities(0, Boolean.FALSE);
        assertEquals(r1, r2);

        r1.setLegendShape(0, new Rectangle(9, 7, 3, 4));
        assertNotEquals(r1, r2);
        r2.setLegendShape(0, new Rectangle(9, 7, 3, 4));
        assertEquals(r1, r2);

        r1.setDefaultLegendShape(new Rectangle(3, 4, 1, 5));
        assertNotEquals(r1, r2);
        r2.setDefaultLegendShape(new Rectangle(3, 4, 1, 5));
        assertEquals(r1, r2);

        r1.setLegendTextFont(1, new Font(""Dialog"", Font.PLAIN, 33));
        assertNotEquals(r1, r2);
        r2.setLegendTextFont(1, new Font(""Dialog"", Font.PLAIN, 33));
        assertEquals(r1, r2);

        r1.setDefaultLegendTextFont(new Font(""Dialog"", Font.PLAIN, 11));
        assertNotEquals(r1, r2);
        r2.setDefaultLegendTextFont(new Font(""Dialog"", Font.PLAIN, 11));
        assertEquals(r1, r2);

        r1.setLegendTextPaint(3, Color.RED);
        assertNotEquals(r1, r2);
        r2.setLegendTextPaint(3, Color.RED);
        assertEquals(r1, r2);

        r1.setDefaultLegendTextPaint(Color.GREEN);
        assertNotEquals(r1, r2);
        r2.setDefaultLegendTextPaint(Color.GREEN);
        assertEquals(r1, r2);
    }",1
"@Test
    public void testCloning2() throws CloneNotSupportedException {
        BarRenderer r1 = new BarRenderer();
        r1.setDefaultItemLabelGenerator(new IntervalCategoryItemLabelGenerator());
        BarRenderer r2 = (BarRenderer) r1.clone();

        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);

        r1 = new BarRenderer();
        r1.setSeriesItemLabelGenerator(0,
                new IntervalCategoryItemLabelGenerator());
        r2 = (BarRenderer) r1.clone();
        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);

        r1 = new BarRenderer();
        r1.setDefaultItemLabelGenerator(new IntervalCategoryItemLabelGenerator());
        r2 = (BarRenderer) r1.clone();

        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);
    }",1
"@Test
    public void testCloning_LegendItemLabelGenerator() throws CloneNotSupportedException {
        StandardCategorySeriesLabelGenerator generator
                = new StandardCategorySeriesLabelGenerator(""Series {0}",1
"@Test
    public void testEquals() {
        BarRenderer r1 = new BarRenderer();
        BarRenderer r2 = new BarRenderer();
        assertEquals(r1, r2);
        assertEquals(r2, r1);

        // base value
        r1.setBase(0.123);
        assertNotEquals(r1, r2);
        r2.setBase(0.123);
        assertEquals(r1, r2);

        // itemMargin
        r1.setItemMargin(0.22);
        assertNotEquals(r1, r2);
        r2.setItemMargin(0.22);
        assertEquals(r1, r2);

        // drawBarOutline
        r1.setDrawBarOutline(!r1.isDrawBarOutline());
        assertNotEquals(r1, r2);
        r2.setDrawBarOutline(!r2.isDrawBarOutline());
        assertEquals(r1, r2);

        // maximumBarWidth
        r1.setMaximumBarWidth(0.11);
        assertNotEquals(r1, r2);
        r2.setMaximumBarWidth(0.11);
        assertEquals(r1, r2);

        // minimumBarLength
        r1.setMinimumBarLength(0.04);
        assertNotEquals(r1, r2);
        r2.setMinimumBarLength(0.04);
        assertEquals(r1, r2);

        // gradientPaintTransformer
        r1.setGradientPaintTransformer(new StandardGradientPaintTransformer(
                GradientPaintTransformType.CENTER_VERTICAL));
        assertNotEquals(r1, r2);
        r2.setGradientPaintTransformer(new StandardGradientPaintTransformer(
                GradientPaintTransformType.CENTER_VERTICAL));
        assertEquals(r1, r2);

        // positiveItemLabelPositionFallback
        r1.setPositiveItemLabelPositionFallback(new ItemLabelPosition(
                ItemLabelAnchor.INSIDE1, TextAnchor.CENTER));
        assertNotEquals(r1, r2);
        r2.setPositiveItemLabelPositionFallback(new ItemLabelPosition(
                ItemLabelAnchor.INSIDE1, TextAnchor.CENTER));
        assertEquals(r1, r2);

        // negativeItemLabelPositionFallback
        r1.setNegativeItemLabelPositionFallback(new ItemLabelPosition(
                ItemLabelAnchor.INSIDE1, TextAnchor.CENTER));
        assertNotEquals(r1, r2);
        r2.setNegativeItemLabelPositionFallback(new ItemLabelPosition(
                ItemLabelAnchor.INSIDE1, TextAnchor.CENTER));
        assertEquals(r1, r2);

        // barPainter
        r1.setBarPainter(new GradientBarPainter(0.1, 0.2, 0.3));
        assertNotEquals(r1, r2);
        r2.setBarPainter(new GradientBarPainter(0.1, 0.2, 0.3));
        assertEquals(r1, r2);

        // shadowsVisible
        r1.setShadowVisible(false);
        assertNotEquals(r1, r2);
        r2.setShadowVisible(false);
        assertEquals(r1, r2);

        r1.setShadowPaint(Color.RED);
        assertNotEquals(r1, r2);
        r2.setShadowPaint(Color.RED);
        assertEquals(r1, r2);

        // shadowXOffset
        r1.setShadowXOffset(3.3);
        assertNotEquals(r1, r2);
        r2.setShadowXOffset(3.3);
        assertEquals(r1, r2);

        // shadowYOffset
        r1.setShadowYOffset(3.3);
        assertNotEquals(r1, r2);
        r2.setShadowYOffset(3.3);
        assertEquals(r1, r2);

    }",1
"@Test
    public void testGetLegendItem() {
        DefaultCategoryDataset<String, String> dataset = new DefaultCategoryDataset<>();
        dataset.addValue(21.0, ""R1"", ""C1"");
        BarRenderer r = new BarRenderer();
        CategoryPlot<String, String> plot = new CategoryPlot<>(dataset, 
                new CategoryAxis(""x""), new NumberAxis(""y""), r);
        /*JFreeChart chart =*/ new JFreeChart(plot);
        LegendItem li = r.getLegendItem(0, 0);
        assertNotNull(li);
        r.setSeriesVisibleInLegend(0, Boolean.FALSE);
        li = r.getLegendItem(0, 0);
        assertNull(li);
    }",1
"@Test
    public void testDrawWithNullMean() {
        boolean success;
        try {
            DefaultBoxAndWhiskerCategoryDataset<String, String> dataset
                    = new DefaultBoxAndWhiskerCategoryDataset<>();
            dataset.add(new BoxAndWhiskerItem(null, 2.0, 0.0, 4.0, 0.5, 4.5, 
                    -0.5, 5.5, null), ""S1"", ""C1"");
            CategoryPlot<String, String> plot = new CategoryPlot<>(dataset,
                    new CategoryAxis(""Category""), new NumberAxis(""Value""),
                    new BoxAndWhiskerRenderer());
            ChartRenderingInfo info = new ChartRenderingInfo();
            JFreeChart chart = new JFreeChart(plot);
            /* BufferedImage image = */ chart.createBufferedImage(300, 200,
                    info);
            success = true;
        }",1
"@Test
    public void testDrawWithNullMinOutlier() {
        boolean success;
        try {
            DefaultBoxAndWhiskerCategoryDataset<String, String> dataset
                    = new DefaultBoxAndWhiskerCategoryDataset<>();
            dataset.add(new BoxAndWhiskerItem(1.0, 2.0, 3.0, 4.0, 0.5, 4.5, 
                    null, 5.5, null), ""S1"", ""C1"");
            CategoryPlot<String, String> plot = new CategoryPlot<>(dataset,
                    new CategoryAxis(""Category""), new NumberAxis(""Value""),
                    new BoxAndWhiskerRenderer());
            ChartRenderingInfo info = new ChartRenderingInfo();
            JFreeChart chart = new JFreeChart(plot);
            /* BufferedImage image = */ chart.createBufferedImage(300, 200,
                    info);
            success = true;
        }",1
"@Test
    public void testDrawWithNullMinRegular() {
        boolean success;
        try {
            DefaultBoxAndWhiskerCategoryDataset<String, String> dataset
                    = new DefaultBoxAndWhiskerCategoryDataset<>();
            dataset.add(new BoxAndWhiskerItem(1.0, 2.0, 3.0, 4.0, null, 4.5, 
                    -0.5, 5.5, null), ""S1"", ""C1"");
            CategoryPlot<String, String> plot = new CategoryPlot<>(dataset,
                    new CategoryAxis(""Category""), new NumberAxis(""Value""),
                    new BoxAndWhiskerRenderer());
            ChartRenderingInfo info = new ChartRenderingInfo();
            JFreeChart chart = new JFreeChart(plot);
            /* BufferedImage image = */ chart.createBufferedImage(300, 200,
                    info);
            success = true;
        }",1
"@Test
    public void testGetLegendItem() {
        DefaultBoxAndWhiskerCategoryDataset<String, String> dataset
                = new DefaultBoxAndWhiskerCategoryDataset<>();
        List<Double> values = new ArrayList<>();
        values.add(1.10);
        values.add(1.45);
        values.add(1.33);
        values.add(1.23);
        dataset.add(values, ""R1"", ""C1"");
        BoxAndWhiskerRenderer r = new BoxAndWhiskerRenderer();
        CategoryPlot<String, String> plot = new CategoryPlot<>(dataset, new CategoryAxis(""x""),
                new NumberAxis(""y""), r);
        /*JFreeChart chart =*/ new JFreeChart(plot);
        LegendItem li = r.getLegendItem(0, 0);
        assertNotNull(li);
        r.setSeriesVisibleInLegend(0, Boolean.FALSE);
        li = r.getLegendItem(0, 0);
        assertNull(li);
    }",1
"@Test
    public void testEquals() {
        CategoryStepRenderer r1 = new CategoryStepRenderer(false);
        CategoryStepRenderer r2 = new CategoryStepRenderer(false);
        assertEquals(r1, r2);

        r1 = new CategoryStepRenderer(true);
        assertNotEquals(r1, r2);
        r2 = new CategoryStepRenderer(true);
        assertEquals(r1, r2);
    }",1
"@Test
    public void testEquals() {
        GradientBarPainter p1 = new GradientBarPainter(0.1, 0.2, 0.3);
        GradientBarPainter p2 = new GradientBarPainter(0.1, 0.2, 0.3);
        assertEquals(p1, p2);

        p1 = new GradientBarPainter(0.11, 0.2, 0.3);
        assertNotEquals(p1, p2);
        p2 = new GradientBarPainter(0.11, 0.2, 0.3);
        assertEquals(p1, p2);

        p1 = new GradientBarPainter(0.11, 0.22, 0.3);
        assertNotEquals(p1, p2);
        p2 = new GradientBarPainter(0.11, 0.22, 0.3);
        assertEquals(p1, p2);

        p1 = new GradientBarPainter(0.11, 0.22, 0.33);
        assertNotEquals(p1, p2);
        p2 = new GradientBarPainter(0.11, 0.22, 0.33);
        assertEquals(p1, p2);
    }",1
"@Test
    public void testEquals() {
        IntervalBarRenderer r1 = new IntervalBarRenderer();
        IntervalBarRenderer r2 = new IntervalBarRenderer();
        assertEquals(r1, r2);

        // the renderer should not be equal to a BarRenderer
        BarRenderer br = new BarRenderer();
        assertNotEquals(r1, br);
    }",1
"@Test
    public void testHashcode() {
        IntervalBarRenderer r1 = new IntervalBarRenderer();
        IntervalBarRenderer r2 = new IntervalBarRenderer();
        assertEquals(r1, r2);
        int h1 = r1.hashCode();
        int h2 = r2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testHashcode() {
        LineAndShapeRenderer r1 = new LineAndShapeRenderer();
        LineAndShapeRenderer r2 = new LineAndShapeRenderer();
        assertEquals(r1, r2);
        int h1 = r1.hashCode();
        int h2 = r2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testEquals() {
        MinMaxCategoryRenderer r1 = new MinMaxCategoryRenderer();
        MinMaxCategoryRenderer r2 = new MinMaxCategoryRenderer();
        assertEquals(r1, r2);

        r1.setDrawLines(true);
        assertNotEquals(r1, r2);
        r2.setDrawLines(true);
        assertEquals(r1, r2);

        r1.setGroupPaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f, 4.0f,
                Color.YELLOW));
        assertNotEquals(r1, r2);
        r2.setGroupPaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f, 4.0f,
                Color.YELLOW));
        assertEquals(r1, r2);

        r1.setGroupStroke(new BasicStroke(1.2f));
        assertNotEquals(r1, r2);
        r2.setGroupStroke(new BasicStroke(1.2f));
        assertEquals(r1, r2);
    }",1
"@Test
    public void testHashcode() {
        MinMaxCategoryRenderer r1 = new MinMaxCategoryRenderer();
        MinMaxCategoryRenderer r2 = new MinMaxCategoryRenderer();
        assertEquals(r1, r2);
        int h1 = r1.hashCode();
        int h2 = r2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testFindRangeBounds() {
        ScatterRenderer r = new ScatterRenderer();
        assertNull(r.findRangeBounds(null));

        // an empty dataset should return a null range
        DefaultMultiValueCategoryDataset<String, String> dataset
                = new DefaultMultiValueCategoryDataset<>();
        assertNull(r.findRangeBounds(dataset));

        List<Number> values = Arrays.asList(new Double[] {1.0}",1
"@Test
    public void testEquals() {
        StackedAreaRenderer r1 = new StackedAreaRenderer();
        StackedAreaRenderer r2 = new StackedAreaRenderer();
        assertEquals(r1, r2);

        r1.setRenderAsPercentages(true);
        assertNotEquals(r1, r2);
        r2.setRenderAsPercentages(true);
        assertEquals(r1, r2);
    }",1
"@Test
    public void testFindRangeBounds() {
        StackedAreaRenderer r = new StackedAreaRenderer();
        assertNull(r.findRangeBounds(null));

        // an empty dataset should return a null range
        DefaultCategoryDataset<String, String> dataset = new DefaultCategoryDataset<>();
        assertNull(r.findRangeBounds(dataset));

        dataset.addValue(1.0, ""R1"", ""C1"");
        assertEquals(new Range(0.0, 1.0), r.findRangeBounds(dataset));

        dataset.addValue(-2.0, ""R1"", ""C2"");
        assertEquals(new Range(-2.0, 1.0), r.findRangeBounds(dataset));

        dataset.addValue(null, ""R1"", ""C3"");
        assertEquals(new Range(-2.0, 1.0), r.findRangeBounds(dataset));

        dataset.addValue(2.0, ""R2"", ""C1"");
        assertEquals(new Range(-2.0, 3.0), r.findRangeBounds(dataset));

        dataset.addValue(null, ""R2"", ""C2"");
        assertEquals(new Range(-2.0, 3.0), r.findRangeBounds(dataset));
    }",1
"@Test
    public void testHashCode() {
        StackedBarRenderer r1 = new StackedBarRenderer();
        StackedBarRenderer r2 = new StackedBarRenderer();
        assertEquals(r1, r2);
        int h1 = r1.hashCode();
        int h2 = r2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testHashcode() {
        StandardBarPainter p1 = new StandardBarPainter();
        StandardBarPainter p2 = new StandardBarPainter();
        assertEquals(p1, p2);
        int h1 = p1.hashCode();
        int h2 = p2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testDrawWithNullDeviationHorizontal() {
        try {
            DefaultStatisticalCategoryDataset<String, String> dataset
                    = new DefaultStatisticalCategoryDataset<>();
            dataset.add(1.0, 2.0, ""S1"", ""C1"");
            dataset.add(4.0, null, ""S1"", ""C2"");
            CategoryPlot<String, String> plot = new CategoryPlot<>(dataset,
                    new CategoryAxis(""Category""), new NumberAxis(""Value""),
                    new StatisticalBarRenderer());
            plot.setOrientation(PlotOrientation.HORIZONTAL);
            JFreeChart chart = new JFreeChart(plot);
            /* BufferedImage image = */ chart.createBufferedImage(300, 200,
                    null);
        }",1
"@Test
    public void testDrawWithNullDeviationVertical() {
        try {
            DefaultStatisticalCategoryDataset<String, String> dataset
                    = new DefaultStatisticalCategoryDataset<>();
            dataset.add(1.0, 2.0, ""S1"", ""C1"");
            dataset.add(4.0, null, ""S1"", ""C2"");
            CategoryPlot<String, String> plot = new CategoryPlot<>(dataset,
                    new CategoryAxis(""Category""), new NumberAxis(""Value""),
                    new StatisticalBarRenderer());
            JFreeChart chart = new JFreeChart(plot);
            /* BufferedImage image = */ chart.createBufferedImage(300, 200,
                    null);
        }",1
"@Test
    public void testGetPaint() {
        GrayPaintScale gps = new GrayPaintScale();
        Color c = (Color) gps.getPaint(0.0);
        assertEquals(c, Color.BLACK);
        c = (Color) gps.getPaint(1.0);
        assertEquals(c, Color.WHITE);

        // check lookup values that are outside the bounds - see bug report
        // 1767315
        c = (Color) gps.getPaint(-0.5);
        assertEquals(c, Color.BLACK);
        c = (Color) gps.getPaint(1.5);
        assertEquals(c, Color.WHITE);
    }",1
"@Test
    public void testEquals() {
        LookupPaintScale g1 = new LookupPaintScale();
        LookupPaintScale g2 = new LookupPaintScale();
        assertEquals(g1, g2);
        assertEquals(g2, g1);

        g1 = new LookupPaintScale(1.0, 2.0, Color.RED);
        assertNotEquals(g1, g2);
        g2 = new LookupPaintScale(1.0, 2.0, Color.RED);
        assertEquals(g1, g2);

        g1.add(1.5, new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f, 4.0f,
                Color.BLUE));
        assertNotEquals(g1, g2);
        g2.add(1.5, new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f, 4.0f,
                Color.BLUE));
        assertEquals(g1, g2);
    }",1
"@Test
    public void testFindLiveItemsUpperBound_Descending() {
        var d = new DefaultXYDataset<String>() {
            @Override
            public DomainOrder getDomainOrder() {
                // we're doing this for testing only, and make sure that we
                // only add data in descending order by x-value
                return DomainOrder.DESCENDING;
            }",1
"@Test
    public void testEquals_ObjectList2() {
        XYBarRenderer r1 = new XYBarRenderer();
        r1.setSeriesToolTipGenerator(0, new StandardXYToolTipGenerator());
        XYBarRenderer r2 = new XYBarRenderer();
        r2.setSeriesToolTipGenerator(0, new StandardXYToolTipGenerator());
        assertEquals(r1, r2);
        r2.setSeriesToolTipGenerator(1, new StandardXYToolTipGenerator());
        assertNotEquals(r1, r2);
    }",1
"@Test
    public void testFindRangeBounds() {
        CandlestickRenderer renderer = new CandlestickRenderer();

        OHLCDataItem item1 = new OHLCDataItem(new Date(1L), 2.0, 4.0, 1.0, 3.0,
                100);
        OHLCDataset dataset = new DefaultOHLCDataset(""S1"",
                new OHLCDataItem[] {item1}",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        HighLowRenderer r1 = new HighLowRenderer();
        r1.setCloseTickPaint(Color.GREEN);
        HighLowRenderer r2 = CloneUtils.clone(r1);
        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);
        TestUtils.checkIndependence(r1, r2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        StackedXYAreaRenderer r1 = new StackedXYAreaRenderer();
        StackedXYAreaRenderer r2 = CloneUtils.clone(r1);
        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);
    }",1
"@Test
    public void testFindRangeBounds() {
        TableXYDataset<String> dataset
                = RendererXYPackageUtils.createTestTableXYDataset();
        JFreeChart chart = ChartFactory.createStackedXYAreaChart(
                ""Test Chart"", ""X"", ""Y"", dataset,
                PlotOrientation.VERTICAL, false, false, false);
        XYPlot<?> plot = (XYPlot) chart.getPlot();
        plot.setRenderer(new StackedXYBarRenderer());
        NumberAxis rangeAxis = (NumberAxis) plot.getRangeAxis();
        Range bounds = rangeAxis.getRange();
        assertTrue(bounds.contains(6.0));
        assertTrue(bounds.contains(8.0));
    }",1
"@Test
    public void testNoDisplayedItem() {
        XYSeriesCollection<String> dataset = new XYSeriesCollection<>();
        XYSeries<String> s1 = new XYSeries<>(""S1"");
        s1.add(10.0, 10.0);
        dataset.addSeries(s1);
        JFreeChart chart = ChartFactory.createXYLineChart(""Title"", ""X"", ""Y"",
                dataset, PlotOrientation.VERTICAL, false, true, false);
        XYPlot<?> plot = (XYPlot) chart.getPlot();
        plot.setRenderer(new StandardXYItemRenderer());
        NumberAxis xAxis = (NumberAxis) plot.getDomainAxis();
        xAxis.setRange(0.0, 5.0);
        NumberAxis yAxis = (NumberAxis) plot.getRangeAxis();
        yAxis.setRange(0.0, 5.0);
        BufferedImage image = new BufferedImage(200 , 100,
                BufferedImage.TYPE_INT_RGB);
        Graphics2D g2 = image.createGraphics();
        ChartRenderingInfo info = new ChartRenderingInfo();
        chart.draw(g2, new Rectangle2D.Double(0, 0, 200, 100), null, info);
        g2.dispose();
        EntityCollection ec = info.getEntityCollection();
        assertFalse(TestUtils.containsInstanceOf(ec.getEntities(), XYItemEntity.class));
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        XYAreaRenderer2 r1 = new XYAreaRenderer2();
        Rectangle rect = new Rectangle(1, 2, 3, 4);
        r1.setLegendArea(rect);
        XYAreaRenderer2 r2 = (XYAreaRenderer2) r1.clone();
        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);

        // check independence
        rect.setBounds(99, 99, 99, 99);
        assertNotEquals(r1, r2);
    }",1
"@Test
    public void testGetLegendItemSeriesIndex() {
        XYSeriesCollection<String> d1 = new XYSeriesCollection<>();
        XYSeries<String> s1 = new XYSeries<>(""S1"");
        s1.add(1.0, 1.1);
        XYSeries<String> s2 = new XYSeries<>(""S2"");
        s2.add(1.0, 1.1);
        d1.addSeries(s1);
        d1.addSeries(s2);

        XYSeriesCollection<String> d2 = new XYSeriesCollection<>();
        XYSeries<String> s3 = new XYSeries<>(""S3"");
        s3.add(1.0, 1.1);
        XYSeries<String> s4 = new XYSeries<>(""S4"");
        s4.add(1.0, 1.1);
        XYSeries<String> s5 = new XYSeries<>(""S5"");
        s5.add(1.0, 1.1);
        d2.addSeries(s3);
        d2.addSeries(s4);
        d2.addSeries(s5);

        XYAreaRenderer r = new XYAreaRenderer();
        XYPlot<String> plot = new XYPlot<>(d1, new NumberAxis(""x""),
                new NumberAxis(""y""), r);
        plot.setDataset(1, d2);
        JFreeChart chart = new JFreeChart(plot);
        LegendItem li = r.getLegendItem(1, 2);
        assertEquals(""S5"", li.getLabel());
        assertEquals(1, li.getDatasetIndex());
        assertEquals(2, li.getSeriesIndex());
    }",1
"@Test
    public void testFindRangeBounds() {
        DefaultIntervalXYDataset<String> dataset = new DefaultIntervalXYDataset<>();
        double[] x = {1.0, 2.0, 3.0, 4.0}",1
"@Test
    public void testBug1766646A() {
        XYBlockRenderer r = new XYBlockRenderer();
        Range range = r.findDomainBounds(null);
        assertNull(range);
        DefaultXYZDataset<String> emptyDataset = new DefaultXYZDataset<>();
        range = r.findDomainBounds(emptyDataset);
        assertNull(range);
    }",1
"@Test
    public void testBug1766646B() {
        XYBlockRenderer r = new XYBlockRenderer();
        Range range = r.findRangeBounds(null);
        assertNull(range);
        DefaultXYZDataset<String> emptyDataset = new DefaultXYZDataset<>();
        range = r.findRangeBounds(emptyDataset);
        assertNull(range);
    }",1
"@Test
    public void testEquals() {
        XYBubbleRenderer r1 = new XYBubbleRenderer();
        XYBubbleRenderer r2 = new XYBubbleRenderer();
        assertEquals(r1, r2);

        r1 = new XYBubbleRenderer(XYBubbleRenderer.SCALE_ON_RANGE_AXIS);
        assertNotEquals(r1, r2);
        r2 = new XYBubbleRenderer(XYBubbleRenderer.SCALE_ON_RANGE_AXIS);
        assertEquals(r1, r2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        XYDifferenceRenderer r1 = new XYDifferenceRenderer(Color.RED, Color.BLUE, false);
        XYDifferenceRenderer r2 = CloneUtils.clone(r1);
        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);

        // check independence
        Shape s = r1.getLegendLine();
        if (s instanceof Line2D) {
            Line2D l = (Line2D) s;
            l.setLine(1.0, 2.0, 3.0, 4.0);
            assertNotEquals(r1, r2);
        }",1
"@Test
    public void testEquals() {
        XYDifferenceRenderer r1 = new XYDifferenceRenderer(
                Color.RED, Color.BLUE, false);
        XYDifferenceRenderer r2 = new XYDifferenceRenderer(
                Color.RED, Color.BLUE, false);
        assertEquals(r1, r2);

        // positive paint
        r1.setPositivePaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.BLUE));
        assertNotEquals(r1, r2);
        r2.setPositivePaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.BLUE));
        assertEquals(r1, r2);

        // negative paint
        r1.setNegativePaint(new GradientPaint(1.0f, 2.0f, Color.YELLOW,
                3.0f, 4.0f, Color.BLUE));
        assertNotEquals(r1, r2);
        r2.setNegativePaint(new GradientPaint(1.0f, 2.0f, Color.YELLOW,
                3.0f, 4.0f, Color.BLUE));
        assertEquals(r1, r2);

        // shapesVisible
        r1 = new XYDifferenceRenderer(Color.GREEN, Color.YELLOW, true);
        assertNotEquals(r1, r2);
        r2 = new XYDifferenceRenderer(Color.GREEN, Color.YELLOW, true);
        assertEquals(r1, r2);

        // legendLine
        r1.setLegendLine(new Line2D.Double(1.0, 2.0, 3.0, 4.0));
        assertNotEquals(r1, r2);
        r2.setLegendLine(new Line2D.Double(1.0, 2.0, 3.0, 4.0));
        assertEquals(r1, r2);

        // roundXCoordinates
        r1.setRoundXCoordinates(true);
        assertNotEquals(r1, r2);
        r2.setRoundXCoordinates(true);
        assertEquals(r1, r2);

        assertNotEquals(null, r1);
    }",1
"@Test
    public void testGetLegendItemSeriesIndex() {
        XYSeriesCollection<String> d1 = new XYSeriesCollection<>();
        XYSeries<String> s1 = new XYSeries<>(""S1"");
        s1.add(1.0, 1.1);
        XYSeries<String> s2 = new XYSeries<>(""S2"");
        s2.add(1.0, 1.1);
        d1.addSeries(s1);
        d1.addSeries(s2);

        XYSeriesCollection<String> d2 = new XYSeriesCollection<>();
        XYSeries<String> s3 = new XYSeries<>(""S3"");
        s3.add(1.0, 1.1);
        XYSeries<String> s4 = new XYSeries<>(""S4"");
        s4.add(1.0, 1.1);
        XYSeries<String> s5 = new XYSeries<>(""S5"");
        s5.add(1.0, 1.1);
        d2.addSeries(s3);
        d2.addSeries(s4);
        d2.addSeries(s5);

        XYDotRenderer r = new XYDotRenderer();
        XYPlot<String> plot = new XYPlot<>(d1, new NumberAxis(""x""),
                new NumberAxis(""y""), r);
        plot.setDataset(1, d2);
        /*JFreeChart chart =*/ new JFreeChart(plot);
        LegendItem li = r.getLegendItem(1, 2);
        assertEquals(""S5"", li.getLabel());
        assertEquals(1, li.getDatasetIndex());
        assertEquals(2, li.getSeriesIndex());
    }",1
"@Test
    public void testEquals() {
        XYErrorRenderer r1 = new XYErrorRenderer();
        XYErrorRenderer r2 = new XYErrorRenderer();
        assertEquals(r1, r2);

        // drawXError
        r1.setDrawXError(false);
        assertNotEquals(r1, r2);
        r2.setDrawXError(false);
        assertEquals(r1, r2);

        // drawYError
        r1.setDrawYError(false);
        assertNotEquals(r1, r2);
        r2.setDrawYError(false);
        assertEquals(r1, r2);

        // capLength
        r1.setCapLength(9.0);
        assertNotEquals(r1, r2);
        r2.setCapLength(9.0);
        assertEquals(r1, r2);

        // errorPaint
        r1.setErrorPaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f, 4.0f,
                Color.GREEN));
        assertNotEquals(r1, r2);
        r2.setErrorPaint(new GradientPaint(1.0f, 2.0f, Color.RED, 3.0f, 4.0f,
                Color.GREEN));
        assertEquals(r1, r2);

        // errorStroke
        r1.setErrorStroke(new BasicStroke(1.5f));
        assertNotEquals(r1, r2);
        r2.setErrorStroke(new BasicStroke(1.5f));
        assertEquals(r1, r2);

    }",1
"@Test
    public void testFindRangeBounds() {
        TableXYDataset<String> dataset
                = RendererXYPackageUtils.createTestTableXYDataset();
        JFreeChart chart = ChartFactory.createXYLineChart(
                ""Test Chart"", ""X"", ""Y"", dataset, PlotOrientation.VERTICAL,
                false, false, false);
        XYPlot<?> plot = (XYPlot) chart.getPlot();
        NumberAxis rangeAxis = (NumberAxis) plot.getRangeAxis();
        rangeAxis.setAutoRangeIncludesZero(false);
        Range bounds = rangeAxis.getRange();
        assertFalse(bounds.contains(1.0));
        assertTrue(bounds.contains(2.0));
        assertTrue(bounds.contains(5.0));
        assertFalse(bounds.contains(6.0));
    }",1
"@Test
    public void testEquals() {
        XYShapeRenderer r1 = new XYShapeRenderer();
        XYShapeRenderer r2 = new XYShapeRenderer();
        assertEquals(r1, r2);
        assertEquals(r2, r1);

        r1.setPaintScale(new LookupPaintScale(1.0, 2.0, Color.WHITE));
        assertNotEquals(r1, r2);
        r2.setPaintScale(new LookupPaintScale(1.0, 2.0, Color.WHITE));
        assertEquals(r1, r2);

        r1.setDrawOutlines(true);
        assertNotEquals(r1, r2);
        r2.setDrawOutlines(true);
        assertEquals(r1, r2);

        r1.setUseOutlinePaint(false);
        assertNotEquals(r1, r2);
        r2.setUseOutlinePaint(false);
        assertEquals(r1, r2);

        r1.setUseFillPaint(true);
        assertNotEquals(r1, r2);
        r2.setUseFillPaint(true);
        assertEquals(r1, r2);

        r1.setGuideLinesVisible(true);
        assertNotEquals(r1, r2);
        r2.setGuideLinesVisible(true);
        assertEquals(r1, r2);

        r1.setGuideLinePaint(Color.RED);
        assertNotEquals(r1, r2);
        r2.setGuideLinePaint(Color.RED);
        assertEquals(r1, r2);

    }",1
"@Test
    public void testFindZBounds() {
        XYShapeRenderer r = new XYShapeRenderer();
        assertNull(r.findZBounds(null));

        DefaultXYZDataset<String> dataset = new DefaultXYZDataset<>();
        Range range;

        double[][] data1 = { {1,1,1}",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        Rectangle2D legendShape = new Rectangle2D.Double(1.0, 2.0, 3.0, 4.0);
        XYSplineRenderer r1 = new XYSplineRenderer();
        r1.setLegendLine(legendShape);
        XYSplineRenderer r2 = CloneUtils.clone(r1);
        assertNotSame(r1, r2);
        assertSame(r1.getClass(), r2.getClass());
        assertEquals(r1, r2);
    }",1
"@Test
    public void testHashcode() {
        XYSplineRenderer r1 = new XYSplineRenderer();
        XYSplineRenderer r2 = new XYSplineRenderer();
        assertEquals(r1, r2);
        int h1 = r1.hashCode();
        int h2 = r2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testCloning() {
        CompositeTitle t1 = new CompositeTitle(new BlockContainer());
        t1.getContainer().add(new TextTitle(""T1""));
        t1.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        CompositeTitle t2 = null;
        try {
            t2 = CloneUtils.clone(t1);
        }",1
"@Test
    public void testEquals() {
        CompositeTitle t1 = new CompositeTitle(new BlockContainer());
        CompositeTitle t2 = new CompositeTitle(new BlockContainer());
        assertEquals(t1, t2);
        assertEquals(t2, t1);

        // margin
        t1.setMargin(new RectangleInsets(1.0, 2.0, 3.0, 4.0));
        assertNotEquals(t1, t2);
        t2.setMargin(new RectangleInsets(1.0, 2.0, 3.0, 4.0));
        assertEquals(t1, t2);

        // frame
        t1.setFrame(new BlockBorder(Color.RED));
        assertNotEquals(t1, t2);
        t2.setFrame(new BlockBorder(Color.RED));
        assertEquals(t1, t2);

        // padding
        t1.setPadding(new RectangleInsets(1.0, 2.0, 3.0, 4.0));
        assertNotEquals(t1, t2);
        t2.setPadding(new RectangleInsets(1.0, 2.0, 3.0, 4.0));
        assertEquals(t1, t2);

        // contained titles
        t1.getContainer().add(new TextTitle(""T1""));
        assertNotEquals(t1, t2);
        t2.getContainer().add(new TextTitle(""T1""));
        assertEquals(t1, t2);

        t1.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertNotEquals(t1, t2);
        t2.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.YELLOW));
        assertEquals(t1, t2);

    }",1
"@Test
    public void testSerialization() {
        CompositeTitle t1 = new CompositeTitle(new BlockContainer());
        t1.getContainer().add(new TextTitle(""T1""));
        t1.setBackgroundPaint(new GradientPaint(1.0f, 2.0f, Color.RED,
                3.0f, 4.0f, Color.BLUE));
        CompositeTitle t2 = TestUtils.serialised(t1);
        assertEquals(t1, t2);
    }",1
"@Test
    public void testHashcode() {
        DateTitle t1 = new DateTitle();
        DateTitle t2 = new DateTitle();
        assertEquals(t1, t2);
        int h1 = t1.hashCode();
        int h2 = t2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testEquals() {
        LegendGraphic g1 = new LegendGraphic(new Rectangle2D.Double(1.0, 2.0,
                3.0, 4.0), Color.BLACK);
        LegendGraphic g2 = new LegendGraphic(new Rectangle2D.Double(1.0, 2.0,
                3.0, 4.0), Color.BLACK);
        assertEquals(g1, g2);
        assertEquals(g2, g1);

        // shapeVisible
        g1.setShapeVisible(!g1.isShapeVisible());
        assertNotEquals(g1, g2);
        g2.setShapeVisible(!g2.isShapeVisible());
        assertEquals(g1, g2);

        // shape
        g1.setShape(new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0));
        assertNotEquals(g1, g2);
        g2.setShape(new Rectangle2D.Double(4.0, 3.0, 2.0, 1.0));
        assertEquals(g1, g2);

        // shapeFilled
        g1.setShapeFilled(!g1.isShapeFilled());
        assertNotEquals(g1, g2);
        g2.setShapeFilled(!g2.isShapeFilled());
        assertEquals(g1, g2);

        // fillPaint
        g1.setFillPaint(Color.GREEN);
        assertNotEquals(g1, g2);
        g2.setFillPaint(Color.GREEN);
        assertEquals(g1, g2);

        // shapeOutlineVisible
        g1.setShapeOutlineVisible(!g1.isShapeOutlineVisible());
        assertNotEquals(g1, g2);
        g2.setShapeOutlineVisible(!g2.isShapeOutlineVisible());
        assertEquals(g1, g2);

        // outlinePaint
        g1.setOutlinePaint(Color.GREEN);
        assertNotEquals(g1, g2);
        g2.setOutlinePaint(Color.GREEN);
        assertEquals(g1, g2);

        // outlineStroke
        g1.setOutlineStroke(new BasicStroke(1.23f));
        assertNotEquals(g1, g2);
        g2.setOutlineStroke(new BasicStroke(1.23f));
        assertEquals(g1, g2);

        // shapeAnchor
        g1.setShapeAnchor(RectangleAnchor.BOTTOM_RIGHT);
        assertNotEquals(g1, g2);
        g2.setShapeAnchor(RectangleAnchor.BOTTOM_RIGHT);
        assertEquals(g1, g2);

        // shapeLocation
        g1.setShapeLocation(RectangleAnchor.BOTTOM_RIGHT);
        assertNotEquals(g1, g2);
        g2.setShapeLocation(RectangleAnchor.BOTTOM_RIGHT);
        assertEquals(g1, g2);

        // lineVisible
        g1.setLineVisible(!g1.isLineVisible());
        assertNotEquals(g1, g2);
        g2.setLineVisible(!g2.isLineVisible());
        assertEquals(g1, g2);

        // line
        g1.setLine(new Line2D.Double(1.0, 2.0, 3.0, 4.0));
        assertNotEquals(g1, g2);
        g2.setLine(new Line2D.Double(1.0, 2.0, 3.0, 4.0));
        assertEquals(g1, g2);

        // linePaint
        g1.setLinePaint(Color.GREEN);
        assertNotEquals(g1, g2);
        g2.setLinePaint(Color.GREEN);
        assertEquals(g1, g2);

        // lineStroke
        g1.setLineStroke(new BasicStroke(1.23f));
        assertNotEquals(g1, g2);
        g2.setLineStroke(new BasicStroke(1.23f));
        assertEquals(g1, g2);

        // fillPaintTransformer
        g1.setFillPaintTransformer(new StandardGradientPaintTransformer(
                GradientPaintTransformType.CENTER_HORIZONTAL));
        assertNotEquals(g1, g2);
        g2.setFillPaintTransformer(new StandardGradientPaintTransformer(
                GradientPaintTransformType.CENTER_HORIZONTAL));
        assertEquals(g1, g2);

    }",1
"@Test
    public void testSerialization() {
        Stroke s = new BasicStroke(1.23f);
        LegendGraphic g1 = new LegendGraphic(new Rectangle2D.Double(1.0, 2.0, 
                3.0, 4.0), Color.BLACK);
        g1.setOutlineStroke(s);
        LegendGraphic g2 = TestUtils.serialised(g1);
        assertEquals(g1, g2);
    }",1
"@Test
    public void testHashcode() {
        PaintScaleLegend l1 = new PaintScaleLegend(new GrayPaintScale(),
                new NumberAxis(""X""));
        PaintScaleLegend l2 = new PaintScaleLegend(new GrayPaintScale(),
                new NumberAxis(""X""));
        assertEquals(l1, l2);
        int h1 = l1.hashCode();
        int h2 = l2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testClipLine() {
        Rectangle2D rect = new Rectangle2D.Double(1.0, 1.0, 1.0, 1.0);
        Line2D line = new Line2D.Double();

        assertFalse(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 0.0, 0.0, 0.0, 0.0));

        line.setLine(0.5, 0.5, 0.6, 0.6);
        assertFalse(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 0.5, 0.5, 0.6, 0.6));

        line.setLine(0.5, 0.5, 1.6, 0.6);
        assertFalse(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 0.5, 0.5, 1.6, 0.6));

        line.setLine(0.5, 0.5, 2.6, 0.6);
        assertFalse(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 0.5, 0.5, 2.6, 0.6));

        line.setLine(0.5, 0.5, 0.6, 1.6);
        assertFalse(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 0.5, 0.5, 0.6, 1.6));

        line.setLine(0.5, 0.5, 1.6, 1.6);
        assertTrue(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 1.0, 1.0, 1.6, 1.6));

        line.setLine(0.5, 0.5, 2.6, 1.6);
        assertTrue(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 1.4545454545454546, 1.0, 2.0,
                1.2857142857142858));

        line.setLine(0.5, 0.5, 0.5, 2.6);
        assertFalse(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 0.5, 0.5, 0.5, 2.6));

        line.setLine(0.5, 0.5, 1.5, 2.6);
        assertTrue(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 1.0, 1.55, 1.2142857142857142, 2.0));

        line.setLine(0.5, 0.5, 2.5, 2.6);
        assertTrue(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 1.0, 1.025, 1.9285714285714284, 2.0));

        line.setLine(0.5, 0.5, 1.5, 1.5);
        assertTrue(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 1.0, 1.0, 1.5, 1.5));

        line.setLine(2.5, 1.0, 1.5, 1.5);
        assertTrue(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 2.0, 1.25, 1.5, 1.5));

        line.setLine(1.5, 1.5, 2.5, 1.0);
        assertTrue(LineUtils.clipLine(line, rect));
        assertTrue(lineEquals(line, 1.5, 1.5, 2.0, 1.25));
    }",1
"@Test
    public void testSerialization() {
        DefaultCategoryDataset<String, String> underlying = new DefaultCategoryDataset<>();
        underlying.addValue(1.1, ""R1"", ""C1"");
        underlying.addValue(2.2, ""R1"", ""C2"");
        CategoryToPieDataset d1 = new CategoryToPieDataset(underlying,
                TableOrder.BY_COLUMN, 1);
        CategoryToPieDataset d2 = (CategoryToPieDataset) 
                TestUtils.serialised(d1);
        assertEquals(d1, d2);

        // regular equality for the datasets doesn't check the fields, just
        // the data values...so let's check some more things...
        assertEquals(d1.getUnderlyingDataset(), d2.getUnderlyingDataset());
        assertEquals(d1.getExtractType(), d2.getExtractType());
        assertEquals(d1.getExtractIndex(), d2.getExtractIndex());
    }",1
"@Test
    public void testGetValue() {
        double[] starts_S1 = new double[] {0.1, 0.2, 0.3}",1
"@Test
    public void testGetColumnIndex() {
        DefaultCategoryDataset<String, String> underlying = new DefaultCategoryDataset<>();
        underlying.addValue(1.0, ""R1"", ""C1"");
        underlying.addValue(2.0, ""R1"", ""C2"");
        underlying.addValue(3.0, ""R1"", ""C3"");
        underlying.addValue(4.0, ""R1"", ""C4"");
        SlidingCategoryDataset<String, String> dataset 
                = new SlidingCategoryDataset<>(underlying, 1, 2);
        assertEquals(-1, dataset.getColumnIndex(""C1""));
        assertEquals(0, dataset.getColumnIndex(""C2""));
        assertEquals(1, dataset.getColumnIndex(""C3""));
        assertEquals(-1, dataset.getColumnIndex(""C4""));
    }",1
"@Test
    public void testSerialization() {
        DefaultCategoryDataset<String, String> u1 = new DefaultCategoryDataset<>();
        u1.addValue(1.0, ""R1"", ""C1"");
        u1.addValue(2.0, ""R1"", ""C2"");
        SlidingCategoryDataset<String, String> d1 = new SlidingCategoryDataset<>(u1, 0, 5);
        SlidingCategoryDataset<String, String> d2 = TestUtils.serialised(d1);
        assertEquals(d1, d2);

        // basic check for independence
        u1.addValue(3.0, ""R1"", ""C3"");
        assertNotEquals(d1, d2);
        DefaultCategoryDataset<String, String> u2
                = (DefaultCategoryDataset) d2.getUnderlyingDataset();
        u2.addValue(3.0, ""R1"", ""C3"");
        assertEquals(d1, d2);
    }",1
"@Test
    public void testConstructor1() {
        ComparableObjectSeries<String> s1 = new ComparableObjectSeries<>(""s1"");
        assertEquals(""s1"", s1.getKey());
        assertTrue(s1.getAllowDuplicateXValues());
        assertTrue(s1.getAutoSort());
        assertEquals(0, s1.getItemCount());
        assertEquals(Integer.MAX_VALUE, s1.getMaximumItemCount());

        // try null key
        boolean pass = false;
        try {
            /*s1 = */new ComparableObjectSeries<String>(null);
        }",1
"@Test
    public void testCalculateRowTotal2() {
        DefaultKeyedValues2D<String, String> table = new DefaultKeyedValues2D<>();
        table.addValue(1.0, ""R0"", ""C0"");
        table.addValue(2.0, ""R0"", ""C1"");
        table.addValue(3.0, ""R1"", ""C0"");
        table.addValue(4.0, ""R1"", ""C1"");
        assertEquals(3.0, DataUtils.calculateRowTotal(table, 0,
                new int[] {0, 1}",1
"@Test
    public void testCreateNumberArray2D() {
        double[][] d = new double[2][];
        d[0] = new double[] {1.1, 2.2, 3.3, 4.4}",1
"@Test
    public void testEquals() {
        PolynomialFunction2D f1 = new PolynomialFunction2D(new double[] {1.0,
                2.0}",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        TaskSeries<String> s1 = new TaskSeries<>(""Series"");
        s1.add(new Task(""Task 1"", new Date(0L), new Date(1L)));
        TaskSeriesCollection<String, String> u1 = new TaskSeriesCollection<>();
        u1.add(s1);
        SlidingGanttCategoryDataset d1 = new SlidingGanttCategoryDataset(
                u1, 0, 5);
        SlidingGanttCategoryDataset d2 = CloneUtils.clone(d1);
        assertNotSame(d1, d2);
        assertSame(d1.getClass(), d2.getClass());
        assertEquals(d1, d2);

        // basic check for independence
        s1.add(new Task(""Task 2"", new Date(10L), new Date(11L)));
        assertNotEquals(d1, d2);
        TaskSeriesCollection<String, String> u2
                = (TaskSeriesCollection) d2.getUnderlyingDataset();
        TaskSeries<String> s2 = u2.getSeries(""Series"");
        s2.add(new Task(""Task 2"", new Date(10L), new Date(11L)));
        assertEquals(d1, d2);
    }",1
"@Test
    public void testSerialization() {
        TaskSeries<String> s1 = new TaskSeries<>(""Series"");
        s1.add(new Task(""Task 1"", new Date(0L), new Date(1L)));
        TaskSeriesCollection<String, String> u1 = new TaskSeriesCollection<>();
        u1.add(s1);
        SlidingGanttCategoryDataset d1 = new SlidingGanttCategoryDataset(
                u1, 0, 5);
        SlidingGanttCategoryDataset d2 = TestUtils.serialised(d1);
        assertEquals(d1, d2);

        // basic check for independence
        s1.add(new Task(""Task 2"", new Date(10L), new Date(11L)));
        assertNotEquals(d1, d2);
        TaskSeriesCollection<String, String> u2
                = (TaskSeriesCollection) d2.getUnderlyingDataset();
        TaskSeries<String> s2 = u2.getSeries(""Series"");
        s2.add(new Task(""Task 2"", new Date(10L), new Date(11L)));
        assertEquals(d1, d2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        Task t1 = new Task(""T"", new Date(1), new Date(2));
        Task t2 = CloneUtils.clone(t1);
        assertNotSame(t1, t2);
        assertSame(t1.getClass(), t2.getClass());
        assertEquals(t1, t2);
    }",1
"@Test
    public void test803660() {
        DefaultCategoryDataset<String, String> dataset = new DefaultCategoryDataset<>();
        dataset.addValue(100.0, ""Series 1"", ""Type 1"");
        dataset.addValue(101.1, ""Series 1"", ""Type 2"");
        Number n = DatasetUtils.findMaximumRangeValue(dataset);
        assertTrue(n.doubleValue() > 101.0);
    }",1
"@Test
    public void testBug2849731_2() {
        XYIntervalSeriesCollection<String> d = new XYIntervalSeriesCollection<>();
        XYIntervalSeries<String> s = new XYIntervalSeries<>(""S1"");
        s.add(1.0, Double.NaN, Double.NaN, Double.NaN, 1.5, Double.NaN);
        d.addSeries(s);
        Range r = DatasetUtils.iterateDomainBounds(d);
        assertEquals(1.0, r.getLowerBound(), EPSILON);
        assertEquals(1.0, r.getUpperBound(), EPSILON);

        s.add(1.0, 1.5, Double.NaN, Double.NaN, 1.5, Double.NaN);
        r = DatasetUtils.iterateDomainBounds(d);
        assertEquals(1.0, r.getLowerBound(), EPSILON);
        assertEquals(1.5, r.getUpperBound(), EPSILON);

        s.add(1.0, Double.NaN, 0.5, Double.NaN, 1.5, Double.NaN);
        r = DatasetUtils.iterateDomainBounds(d);
        assertEquals(0.5, r.getLowerBound(), EPSILON);
        assertEquals(1.5, r.getUpperBound(), EPSILON);
    }",1
"@Test
    public void testCumulativeRange_NaN() {
        DefaultCategoryDataset<String, String> dataset = new DefaultCategoryDataset<>();
        dataset.addValue(10.0, ""Series 1"", ""Start"");
        dataset.addValue(15.0, ""Series 1"", ""Delta 1"");
        dataset.addValue(Double.NaN, ""Series 1"", ""Delta 2"");
        Range range = DatasetUtils.findCumulativeRangeBounds(dataset);
        assertEquals(0.0, range.getLowerBound(), EPSILON);
        assertEquals(25.0, range.getUpperBound(), EPSILON);
    }",1
"@Test
    public void testFindDomainBounds3() {
        DefaultIntervalXYDataset<String> dataset = new DefaultIntervalXYDataset<>();
        double[] x1 = new double[] {1.0, 2.0, 3.0}",1
"@Test
    public void testFindMaximumRangeValue() {
        CategoryDataset<String, String> d1 = createCategoryDataset1();
        Number max1 = DatasetUtils.findMaximumRangeValue(d1);
        assertEquals(6.0, max1);

        XYDataset<String> dataset = createXYDataset1();
        Number maximum = DatasetUtils.findMaximumRangeValue(dataset);
        assertEquals(105.0, maximum);
    }",1
"@Test
    public void testFindMaximumStackedRangeValue2() {
        DefaultCategoryDataset<String, String> dataset 
                = new DefaultCategoryDataset<>();
        dataset.addValue(-1.0, ""R1"", ""C1"");
        Number max = DatasetUtils.findMaximumStackedRangeValue(dataset);
        assertEquals(0.0, max.doubleValue(), EPSILON);

        dataset.addValue(-2.0, ""R2"", ""C1"");
        max = DatasetUtils.findMaximumStackedRangeValue(dataset);
        assertEquals(0.0, max.doubleValue(), EPSILON);
    }",1
"@Test
    public void testIterateDomainBounds_NaN2() {
        DefaultIntervalXYDataset<String> dataset = new DefaultIntervalXYDataset<>();
        double[] x1 = new double[] {Double.NaN, 2.0, 3.0}",1
"@Test
    public void testIterateToFindRangeBounds2_XYDataset() {
        List<String> visibleSeriesKeys = new ArrayList<>();
        Range xRange = new Range(0.0, 10.0);

        // empty dataset returns null
        XYSeriesCollection<String> dataset = new XYSeriesCollection<>();
        Range r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertNull(r);

        // add an empty series
        XYSeries<String> s1 = new XYSeries<>(""A"");
        dataset.addSeries(s1);
        visibleSeriesKeys.add(""A"");
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertNull(r);

        // check a null value
        s1.add(1.0, null);
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertNull(r);

        // check a NaN
        s1.add(2.0, Double.NaN);
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertNull(r);

        // check a regular value
        s1.add(3.0, 5.0);
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertEquals(new Range(5.0, 5.0), r);

        // check another regular value
        s1.add(4.0, 6.0);
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertEquals(new Range(5.0, 6.0), r);

        // add a second series
        XYSeries<String> s2 = new XYSeries<>(""B"");
        dataset.addSeries(s2);
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertEquals(new Range(5.0, 6.0), r);
        visibleSeriesKeys.add(""B"");
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertEquals(new Range(5.0, 6.0), r);

        // add a value to the second series
        s2.add(5.0, 15.0);
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertEquals(new Range(5.0, 15.0), r);

        // add a value that isn't in the xRange
        s2.add(15.0, 150.0);
        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, xRange, false);
        assertEquals(new Range(5.0, 15.0), r);

        r = DatasetUtils.iterateToFindRangeBounds(dataset,
                visibleSeriesKeys, new Range(0.0, 20.0), false);
        assertEquals(new Range(5.0, 150.0), r);
    }",1
"@Test
    public void testStackedRangeWithMap() {
        CategoryDataset<String, String> d = createCategoryDataset1();
        KeyToGroupMap<String, String> map = new KeyToGroupMap<>(""G0"");
        map.mapKeyToGroup(""R2"", ""G1"");
        Range r = DatasetUtils.findStackedRangeBounds(d, map);
        assertEquals(0.0, r.getLowerBound(), EPSILON);
        assertEquals(9.0, r.getUpperBound(), EPSILON);
    }",1
"@Test
    public void testSerialization() {
        DefaultKeyedValues2DDataset<String, String> d1 = new DefaultKeyedValues2DDataset<>();
        d1.addValue(234.2, ""Row1"", ""Col1"");
        d1.addValue(null, ""Row1"", ""Col2"");
        d1.addValue(345.9, ""Row2"", ""Col1"");
        d1.addValue(452.7, ""Row2"", ""Col2"");

        DefaultKeyedValues2DDataset<String, String> d2 = TestUtils.serialised(d1);
        assertEquals(d1, d2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        DefaultKeyedValuesDataset<String> d1 = new DefaultKeyedValuesDataset<>();
        d1.setValue(""V1"", 1);
        d1.setValue(""V2"", null);
        d1.setValue(""V3"", 3);
        DefaultKeyedValuesDataset<String> d2 = CloneUtils.clone(d1);
        assertNotSame(d1, d2);
        assertSame(d1.getClass(), d2.getClass());
        assertEquals(d1, d2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        DefaultBoxAndWhiskerXYDataset<String> d1 
                = new DefaultBoxAndWhiskerXYDataset<>(""Series"");
        d1.add(new Date(1L), new BoxAndWhiskerItem(1.0, 2.0, 3.0, 4.0, 5.0,
                6.0, 7.0, 8.0, new ArrayList<>()));
        DefaultBoxAndWhiskerXYDataset<String> d2 = CloneUtils.clone(d1);
        assertNotSame(d1, d2);
        assertSame(d1.getClass(), d2.getClass());
        assertEquals(d1, d2);

        // test independence
        d1.add(new Date(2L), new BoxAndWhiskerItem(1.0, 2.0, 3.0, 4.0, 5.0,
                6.0, 7.0, 8.0, new ArrayList<>()));
        assertNotEquals(d1, d2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        DefaultMultiValueCategoryDataset<String, String> d1
                = new DefaultMultiValueCategoryDataset<>();
        DefaultMultiValueCategoryDataset<String, String> d2 = CloneUtils.clone(d1);
        assertNotSame(d1, d2);
        assertSame(d1.getClass(), d2.getClass());
        assertEquals(d1, d2);

        // try a dataset with some content...
        List<Integer> values = new ArrayList<>();
        values.add(99);
        d1.add(values, ""R1"", ""C1"");
        d2 = CloneUtils.clone(d1);
        assertNotSame(d1, d2);
        assertSame(d1.getClass(), d2.getClass());
        assertEquals(d1, d2);

        // check that the clone doesn't share the same underlying arrays.
        List<Integer> values2 = new ArrayList<>();
        values2.add(111);
        d1.add(values2, ""R2"", ""C2"");
        assertNotEquals(d1, d2);
        d2.add(values2, ""R2"", ""C2"");
        assertEquals(d1, d2);
    }",1
"@Test
    public void test2902842() {
        this.lastEvent = null;
        double[] values = {0.0, 1.0, 2.0, 3.0, 4.0, 5.0}",1
"@Test
    public void testEquals() {
        double[] values = {1.0, 2.0, 3.0, 4.0, 6.0, 12.0, 5.0, 6.3, 4.5}",1
"@Test
    public void testEquals() {
        MeanAndStandardDeviation m1 = new MeanAndStandardDeviation(1.2, 3.4);
        MeanAndStandardDeviation m2 = new MeanAndStandardDeviation(1.2, 3.4);
        assertEquals(m1, m2);
        assertEquals(m2, m1);

        m1 = new MeanAndStandardDeviation(1.0, 3.4);
        assertNotEquals(m1, m2);
        m2 = new MeanAndStandardDeviation(1.0, 3.4);
        assertEquals(m1, m2);

        m1 = new MeanAndStandardDeviation(1.0, 3.0);
        assertNotEquals(m1, m2);
        m2 = new MeanAndStandardDeviation(1.0, 3.0);
        assertEquals(m1, m2);
    }",1
"@Test
    public void testOLSRegression1b() {

        double[][] data = createSampleData1();

        XYSeries<String> series = new XYSeries<>(""Test"");
        for (int i = 0; i < 11; i++) {
            series.add(data[i][0], data[i][1]);
        }",1
"@Test
    public void testPowerRegression1b() {

        double[][] data = createSampleData1();

        XYSeries<String> series = new XYSeries<>(""Test"");
        for (int i = 0; i < 11; i++) {
            series.add(data[i][0], data[i][1]);
        }",1
"@Test
    public void testEquals() {
        SimpleHistogramBin b1 = new SimpleHistogramBin(1.0, 2.0);
        SimpleHistogramBin b2 = new SimpleHistogramBin(1.0, 2.0);
        assertEquals(b1, b2);
        assertEquals(b2, b1);

        b1 = new SimpleHistogramBin(1.1, 2.0, true, true);
        assertNotEquals(b1, b2);
        b2 = new SimpleHistogramBin(1.1, 2.0, true, true);
        assertEquals(b1, b2);

        b1 = new SimpleHistogramBin(1.1, 2.2, true, true);
        assertNotEquals(b1, b2);
        b2 = new SimpleHistogramBin(1.1, 2.2, true, true);
        assertEquals(b1, b2);

        b1 = new SimpleHistogramBin(1.1, 2.2, false, true);
        assertNotEquals(b1, b2);
        b2 = new SimpleHistogramBin(1.1, 2.2, false, true);
        assertEquals(b1, b2);

        b1 = new SimpleHistogramBin(1.1, 2.2, false, false);
        assertNotEquals(b1, b2);
        b2 = new SimpleHistogramBin(1.1, 2.2, false, false);
        assertEquals(b1, b2);

        b1.setItemCount(99);
        assertNotEquals(b1, b2);
        b2.setItemCount(99);
        assertEquals(b1, b2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        SimpleHistogramDataset<String> d1 = new SimpleHistogramDataset<>(""Dataset 1"");
        SimpleHistogramDataset<String> d2 = CloneUtils.clone(d1);
        assertNotSame(d1, d2);
        assertSame(d1.getClass(), d2.getClass());
        assertEquals(d1, d2);

        // check that clone is independent of the original
        d2.addBin(new SimpleHistogramBin(2.0, 3.0));
        d2.addObservation(2.3);
        assertNotEquals(d1, d2);
    }",1
"@Test
    public void testCalculateMean_Collection() {

        // try a null collection
        boolean pass = false;
        try {
            Statistics.calculateMean((Collection) null);
        }",1
"@Test
    public void testImmutable() {
        Date d1 = new Date(10L);
        Date d2 = new Date(20L);
        DateRange r = new DateRange(d1, d2);
        d1.setTime(11L);
        assertEquals(new Date(10L), r.getLowerDate());
        r.getUpperDate().setTime(22L);
        assertEquals(new Date(20L), r.getUpperDate());
    }",1
"@Test
    public void testDateConstructor2() {
        TimeZone zone = TimeZone.getTimeZone(""Europe/Helsinki"");
        Calendar cal = Calendar.getInstance(zone);
        Locale locale = Locale.getDefault();  // locale shouldn't matter here
        Day d1 = new Day(new Date(1078091999999L), zone, locale);
        Day d2 = new Day(new Date(1078092000000L), zone, locale);

        assertEquals(MonthConstants.FEBRUARY, d1.getMonth());
        assertEquals(1078091999999L, d1.getLastMillisecond(cal));

        assertEquals(MonthConstants.MARCH, d2.getMonth());
        assertEquals(1078092000000L, d2.getFirstMillisecond(cal));
    }",1
"@Test
    public void testGetFirstMillisecond() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/London""));
        Day d = new Day(1, 3, 1970);
        assertEquals(5094000000L, d.getFirstMillisecond());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testGetLastMillisecondWithTimeZone() {
        Hour h = new Hour(2, 7, 7, 1950);
        TimeZone zone = TimeZone.getTimeZone(""America/Los_Angeles"");
        Calendar cal = Calendar.getInstance(zone);
        assertEquals(-614959200001L, h.getLastMillisecond(cal));

        // try null calendar
        boolean pass = false;
        try {
            h.getLastMillisecond((Calendar) null);
        }",1
"@Test
    public void testHashcode() {
        Hour h1 = new Hour(7, 9, 10, 1999);
        Hour h2 = new Hour(7, 9, 10, 1999);
        assertEquals(h1, h2);
        int hash1 = h1.hashCode();
        int hash2 = h2.hashCode();
        assertEquals(hash1, hash2);
    }",1
"@Test
    public void testEqualsSelf() {
        Millisecond millisecond = new Millisecond();
        assertEquals(millisecond, millisecond);
    }",1
"@Test
    public void testDateConstructor1() {
        TimeZone zone = TimeZone.getTimeZone(""GMT"");
        Calendar cal = Calendar.getInstance(zone);
        Locale locale = Locale.getDefault(); // locale should not matter here
        Minute m1 = new Minute(new Date(1016729699999L), zone, locale);
        Minute m2 = new Minute(new Date(1016729700000L), zone, locale);

        assertEquals(54, m1.getMinute());
        assertEquals(1016729699999L, m1.getLastMillisecond(cal));

        assertEquals(55, m2.getMinute());
        assertEquals(1016729700000L, m2.getFirstMillisecond(cal));
    }",1
"@Test
    public void testGetFirstMillisecond() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/London""));
        Minute m = new Minute(43, 15, 1, 4, 2006);
        assertEquals(1143902580000L, m.getFirstMillisecond());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testGetStart() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.ITALY);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/Rome""));
        Calendar cal = Calendar.getInstance(Locale.ITALY);
        cal.set(2006, Calendar.JANUARY, 16, 3, 47, 0);
        cal.set(Calendar.MILLISECOND, 0);
        Minute m = new Minute(47, 3, 16, 1, 2006);
        assertEquals(cal.getTime(), m.getStart());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testDateConstructor2() {

        TimeZone zone = TimeZone.getTimeZone(""Pacific/Auckland"");
        Calendar cal = Calendar.getInstance(zone);
        Month m1 = new Month(new Date(951821999999L), zone, Locale.getDefault());
        Month m2 = new Month(new Date(951822000000L), zone, Locale.getDefault());

        assertEquals(MonthConstants.FEBRUARY, m1.getMonth());
        assertEquals(951821999999L, m1.getLastMillisecond(cal));

        assertEquals(MonthConstants.MARCH, m2.getMonth());
        assertEquals(951822000000L, m2.getFirstMillisecond(cal));

    }",1
"@Test
    public void testGetEnd() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.ITALY);
        Calendar cal = Calendar.getInstance(Locale.ITALY);
        cal.set(2006, Calendar.JANUARY, 31, 23, 59, 59);
        cal.set(Calendar.MILLISECOND, 999);
        Month m = new Month(1, 2006);
        assertEquals(cal.getTime(), m.getEnd());
        Locale.setDefault(saved);
    }",1
"@Test
    public void testGetFirstMillisecondWithCalendar() {
        Month m = new Month(1, 2001);
        GregorianCalendar calendar = new GregorianCalendar(Locale.GERMANY);
        calendar.setTimeZone(TimeZone.getTimeZone(""Europe/Frankfurt""));
        assertEquals(978307200000L, m.getFirstMillisecond(calendar));

        // try null calendar
        boolean pass = false;
        try {
            m.getFirstMillisecond((Calendar) null);
        }",1
"@Test
    public void testGetLastMillisecondWithTimeZone() {
        Month m = new Month(2, 1950);
        TimeZone zone = TimeZone.getTimeZone(""America/Los_Angeles"");
        Calendar cal = Calendar.getInstance(zone);
        assertEquals(-626025600001L, m.getLastMillisecond(cal));

        // try null calendar
        boolean pass = false;
        try {
            m.getLastMillisecond((Calendar) null);
        }",1
"@Test
    public void testGetStart() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.ITALY);
        Calendar cal = Calendar.getInstance(Locale.ITALY);
        cal.set(2006, Calendar.MARCH, 1, 0, 0, 0);
        cal.set(Calendar.MILLISECOND, 0);
        Month m = new Month(3, 2006);
        assertEquals(cal.getTime(), m.getStart());
        Locale.setDefault(saved);
    }",1
"@Test
    public void testParseMonth() {
        Month month = null;

        // test 1...
        try {
            month = Month.parseMonth(""1990-01"");
        }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        OHLCSeriesCollection c1 = new OHLCSeriesCollection();
        OHLCSeries<String> s1 = new OHLCSeries<>(""Series"");
        s1.add(new Year(2006), 1.0, 1.1, 1.2, 1.3);
        c1.addSeries(s1);
        OHLCSeriesCollection c2 = CloneUtils.clone(c1);
        assertNotSame(c1, c2);
        assertSame(c1.getClass(), c2.getClass());
        assertEquals(c1, c2);

        // check independence
        c1.setXPosition(TimePeriodAnchor.END);
        assertNotEquals(c1, c2);
    }",1
"@Test
    public void testSerialization() {
        OHLCSeriesCollection c1 = new OHLCSeriesCollection();
        OHLCSeries<String> s1 = new OHLCSeries<>(""Series"");
        s1.add(new Year(2006), 1.0, 1.1, 1.2, 1.3);
        c1.addSeries(s1);
        OHLCSeriesCollection c2 = TestUtils.serialised(c1);
        assertEquals(c1, c2);
    }",1
"@Test
    public void testGetFirstMillisecond() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/London""));
        Quarter q = new Quarter(3, 1970);
        assertEquals(15634800000L, q.getFirstMillisecond());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testGetLastMillisecond() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/London""));
        Quarter q = new Quarter(3, 1970);
        assertEquals(23583599999L, q.getLastMillisecond());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testGetLastMillisecondWithTimeZone() {
        Quarter q = new Quarter(2, 1950);
        TimeZone zone = TimeZone.getTimeZone(""America/Los_Angeles"");
        Calendar cal = Calendar.getInstance(zone);
        assertEquals(-615488400001L, q.getLastMillisecond(cal));

        // try null calendar
        boolean pass = false;
        try {
            q.getLastMillisecond((Calendar) null);
        }",1
"@Test
    public void testHashcode() {
        Quarter q1 = new Quarter(2, 2003);
        Quarter q2 = new Quarter(2, 2003);
        assertEquals(q1, q2);
        int h1 = q1.hashCode();
        int h2 = q2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testDateConstructor2() {
        TimeZone zone = TimeZone.getTimeZone(""America/Chicago"");
        Calendar cal = Calendar.getInstance(zone);
        Locale locale = Locale.getDefault();  // locale shouldn't matter here
        Second s1 = new Second(new Date(1016751358999L), zone, locale);
        Second s2 = new Second(new Date(1016751359000L), zone, locale);

        assertEquals(58, s1.getSecond());
        assertEquals(1016751358999L, s1.getLastMillisecond(cal));

        assertEquals(59, s2.getSecond());
        assertEquals(1016751359000L, s2.getFirstMillisecond(cal));
    }",1
"@Test
    public void testGetLastMillisecond() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/London""));
        Second s = new Second(1, 1, 1, 1, 1, 1970);
        assertEquals(61999L, s.getLastMillisecond());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testHashcode() {
        SimpleTimePeriod s1 = new SimpleTimePeriod(new Date(10L),
                new Date(20L));
        SimpleTimePeriod s2 = new SimpleTimePeriod(new Date(10L),
                new Date(20L));
        assertEquals(s1, s2);
        int h1 = s1.hashCode();
        int h2 = s2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testImmutable() {
        SimpleTimePeriod p1 = new SimpleTimePeriod(new Date(10L),
                new Date(20L));
        SimpleTimePeriod p2 = new SimpleTimePeriod(new Date(10L),
                new Date(20L));
        assertEquals(p1, p2);
        p1.getStart().setTime(11L);
        assertEquals(p1, p2);

        Date d1 = new Date(10L);
        Date d2 = new Date(20L);
        p1 = new SimpleTimePeriod(d1, d2);
        d1.setTime(11L);
        assertEquals(new Date(10L), p1.getStart());
    }",1
"@Test 
    public void testGetDomainBoundsWithInterval() {
        // check empty dataset
        TimePeriodValuesCollection dataset = new TimePeriodValuesCollection();
        Range r = dataset.getDomainBounds(true);
        assertNull(r);
        
        // check dataset with one time period
        TimePeriodValues<String> s1 = new TimePeriodValues<>(""S1"");
        s1.add(new SimpleTimePeriod(1000L, 2000L), 1.0);
        dataset.addSeries(s1);
        r = dataset.getDomainBounds(true);
        assertEquals(1000.0, r.getLowerBound(), EPSILON);
        assertEquals(2000.0, r.getUpperBound(), EPSILON);
        
        // check dataset with two time periods
        s1.add(new SimpleTimePeriod(1500L, 3000L), 2.0);
        r = dataset.getDomainBounds(true);
        assertEquals(1000.0, r.getLowerBound(), EPSILON);
        assertEquals(3000.0, r.getUpperBound(), EPSILON);
        
        // add a third time period
        s1.add(new SimpleTimePeriod(6000L, 7000L), 1.5);
        r = dataset.getDomainBounds(true);
        assertEquals(1000.0, r.getLowerBound(), EPSILON);
        assertEquals(7000.0, r.getUpperBound(), EPSILON);

        // add a fourth time period
        s1.add(new SimpleTimePeriod(4000L, 5000L), 1.4);
        r = dataset.getDomainBounds(true);
        assertEquals(1000.0, r.getLowerBound(), EPSILON);
        assertEquals(7000.0, r.getUpperBound(), EPSILON);    
    }",1
"@Test
    public void testGetRangeBounds() {
        TimeSeriesCollection<String> dataset = new TimeSeriesCollection<>();
        
        // when the dataset contains no series, we expect the range to be null
        assertNull(dataset.getRangeBounds(false));
        assertNull(dataset.getRangeBounds(true));

        // when the dataset contains one or more series, but those series
        // contain no items, we still expect the range to be null
        TimeSeries<String> s1 = new TimeSeries<>(""S1"");
        dataset.addSeries(s1);
        assertNull(dataset.getRangeBounds(false));
        assertNull(dataset.getRangeBounds(true));

        // tests with values
        s1.add(new Year(2012), 1.0);
        assertEquals(new Range(1.0, 1.0), dataset.getRangeBounds(false));
        assertEquals(new Range(1.0, 1.0), dataset.getRangeBounds(true));
        s1.add(new Year(2013), -1.0);
        assertEquals(new Range(-1.0, 1.0), dataset.getRangeBounds(false));
        assertEquals(new Range(-1.0, 1.0), dataset.getRangeBounds(true));
        s1.add(new Year(2014), null);
        assertEquals(new Range(-1.0, 1.0), dataset.getRangeBounds(false));
        assertEquals(new Range(-1.0, 1.0), dataset.getRangeBounds(true));
        
        // adding a second series
        TimeSeries<String> s2 = new TimeSeries<>(""S2"");
        dataset.addSeries(s2);
        assertEquals(new Range(-1.0, 1.0), dataset.getRangeBounds(false));
        assertEquals(new Range(-1.0, 1.0), dataset.getRangeBounds(true));
        
        s2.add(new Year(2014), 5.0);
        assertEquals(new Range(-1.0, 5.0), dataset.getRangeBounds(false));
        assertEquals(new Range(-1.0, 5.0), dataset.getRangeBounds(true));
        
        dataset.removeAllSeries();
        assertNull(dataset.getRangeBounds(false));
        assertNull(dataset.getRangeBounds(true));
        
        s1 = new TimeSeries<>(""s1"");
        s2 = new TimeSeries<>(""s2"");
        dataset.addSeries(s1);
        dataset.addSeries(s2);
        assertNull(dataset.getRangeBounds(false));
        assertNull(dataset.getRangeBounds(true));
        
        s2.add(new Year(2014), 100.0);
        assertEquals(new Range(100.0, 100.0), dataset.getRangeBounds(false));
        assertEquals(new Range(100.0, 100.0), dataset.getRangeBounds(true));
    }",1
"@Test
    public void testIndexOf() {
        TimeSeries<String> s1 = new TimeSeries<>(""S1"");
        TimeSeries<String> s2 = new TimeSeries<>(""S2"");
        TimeSeriesCollection<String> dataset = new TimeSeriesCollection<>();
        assertEquals(-1, dataset.indexOf(s1));
        assertEquals(-1, dataset.indexOf(s2));

        dataset.addSeries(s1);
        assertEquals(0, dataset.indexOf(s1));
        assertEquals(-1, dataset.indexOf(s2));

        dataset.addSeries(s2);
        assertEquals(0, dataset.indexOf(s1));
        assertEquals(1, dataset.indexOf(s2));

        dataset.removeSeries(s1);
        assertEquals(-1, dataset.indexOf(s1));
        assertEquals(0, dataset.indexOf(s2));

        TimeSeries<String> s2b = new TimeSeries<>(""S2"");
        assertEquals(0, dataset.indexOf(s2b));
    }",1
"@Test
    public void testRemoveSeries() {
        TimeSeriesCollection<String> c1 = new TimeSeriesCollection<>();

        TimeSeries<String> s1 = new TimeSeries<>(""Series 1"");
        TimeSeries<String> s2 = new TimeSeries<>(""Series 2"");
        TimeSeries<String> s3 = new TimeSeries<>(""Series 3"");
        TimeSeries<String> s4 = new TimeSeries<>(""Series 4"");

        c1.addSeries(s1);
        c1.addSeries(s2);
        c1.addSeries(s3);
        c1.addSeries(s4);

        c1.removeSeries(s3);

        TimeSeries<String> s = c1.getSeries(2);
        boolean b1 = s.equals(s4);
        assertTrue(b1);
    }",1
"@Test
    public void testBug1498805() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        try {
            TimeZone zone = TimeZone.getTimeZone(""GMT"");
            GregorianCalendar gc = new GregorianCalendar(zone);
            gc.set(2005, Calendar.JANUARY, 1, 12, 0, 0);
            Week w = new Week(gc.getTime(), zone, Locale.UK);
            assertEquals(53, w.getWeek());
            assertEquals(new Year(2004), w.getYear());
        }",1
"@Test
    public void testGetLastMillisecondWithTimeZone() {
        Week w = new Week(2, 1950);
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.US);
        try {
            TimeZone zone = TimeZone.getTimeZone(""America/Los_Angeles"");
            Calendar cal = Calendar.getInstance(zone);
            assertEquals(-629913600001L, w.getLastMillisecond(cal));
        }",1
"@Test
    public void testHashcode() {
        Week w1 = new Week(2, 2003);
        Week w2 = new Week(2, 2003);
        assertEquals(w1, w2);
        int h1 = w1.hashCode();
        int h2 = w2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testGetFirstMillisecond() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/London""));
        Year y = new Year(1970);
        // TODO: Check this result...
        assertEquals(-3600000L, y.getFirstMillisecond());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testGetFirstMillisecondWithCalendar() {
        Year y = new Year(2001);
        GregorianCalendar calendar = new GregorianCalendar(Locale.GERMANY);
        calendar.setTimeZone(TimeZone.getTimeZone(""Europe/Frankfurt""));
        assertEquals(978307200000L, y.getFirstMillisecond(calendar));

        // try null calendar
        boolean pass = false;
        try {
            y.getFirstMillisecond((Calendar) null);
        }",1
"@Test
    public void testGetLastMillisecond() {
        Locale saved = Locale.getDefault();
        Locale.setDefault(Locale.UK);
        TimeZone savedZone = TimeZone.getDefault();
        TimeZone.setDefault(TimeZone.getTimeZone(""Europe/London""));
        Year y = new Year(1970);
        // TODO: Check this result...
        assertEquals(31532399999L, y.getLastMillisecond());
        Locale.setDefault(saved);
        TimeZone.setDefault(savedZone);
    }",1
"@Test
    public void testEquals() {
        DefaultHighLowDataset d1 = new DefaultHighLowDataset(""Series 1"",
                new Date[0], new double[0], new double[0], new double[0],
                new double[0], new double[0]);
        DefaultHighLowDataset d2 = new DefaultHighLowDataset(""Series 1"",
                new Date[0], new double[0], new double[0], new double[0],
                new double[0], new double[0]);
        assertEquals(d1, d2);
        assertEquals(d2, d1);

        d1 = new DefaultHighLowDataset(""Series 2"",
                new Date[0], new double[0], new double[0], new double[0],
                new double[0], new double[0]);
        assertNotEquals(d1, d2);
        d2 = new DefaultHighLowDataset(""Series 2"",
                new Date[0], new double[0], new double[0], new double[0],
                new double[0], new double[0]);
        assertEquals(d1, d2);

        d1 = new DefaultHighLowDataset(""Series 2"",
                new Date[] {new Date(123L)}",1
"@Test
    public void testEquals() {
        DefaultTableXYDataset<String> d1 = new DefaultTableXYDataset<>();
        XYSeries<String> s1 = new XYSeries<>(""Series 1"", true, false);
        s1.add(1.0, 1.1);
        s1.add(2.0, 2.2);
        d1.addSeries(s1);

        DefaultTableXYDataset<String> d2 = new DefaultTableXYDataset<>();
        XYSeries<String> s2 = new XYSeries<>(""Series 1"", true, false);
        s2.add(1.0, 1.1);
        s2.add(2.0, 2.2);
        d2.addSeries(s2);

        assertEquals(d1, d2);
        assertEquals(d2, d1);

        s1.add(3.0, 3.3);
        assertNotEquals(d1, d2);

        s2.add(3.0, 3.3);
        assertEquals(d1, d2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        DefaultXYDataset<String> d1 = new DefaultXYDataset<>();
        DefaultXYDataset<String> d2 = CloneUtils.clone(d1);
        assertNotSame(d1, d2);
        assertSame(d1.getClass(), d2.getClass());
        assertEquals(d1, d2);

        // try a dataset with some content...
        double[] x1 = new double[] {1.0, 2.0, 3.0}",1
"@Test
    public void testSerialization() {
        DefaultXYDataset<String> d1 = new DefaultXYDataset<>();
        DefaultXYDataset<String> d2 = TestUtils.serialised(d1);
        assertEquals(d1, d2);

        // try a dataset with some content...
        double[] x1 = new double[] {1.0, 2.0, 3.0}",1
"@Test
    public void testSerialization() {
        XYSeries<String> s1 = new XYSeries<>(""Series"");
        s1.add(1.2, 3.4);
        XYSeriesCollection<String> c1 = new XYSeriesCollection<>();
        c1.addSeries(s1);
        IntervalXYDelegate d1 = new IntervalXYDelegate(c1);
        IntervalXYDelegate d2 = TestUtils.serialised(d1);
        assertEquals(d1, d2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        MatrixSeries<String> s1 = new MatrixSeries<>(""Series"", 2, 3);
        s1.update(0, 0, 1.1);
        MatrixSeriesCollection<String> c1 = new MatrixSeriesCollection<>();
        c1.addSeries(s1);
        MatrixSeriesCollection<String> c2 = CloneUtils.clone(c1);

        assertNotSame(c1, c2);
        assertSame(c1.getClass(), c2.getClass());
        assertEquals(c1, c2);

        // check independence
        c2.removeAllSeries();
        assertNotEquals(c1, c2);
    }",1
"@Test
    public void testCloning() throws CloneNotSupportedException {
        MatrixSeries<String> m1 = new MatrixSeries<>(""Test"", 8, 3);
        m1.update(0, 0, 11.0);
        m1.update(7, 2, 22.0);
        MatrixSeries<String> m2 = CloneUtils.clone(m1);
        assertNotSame(m1, m2);
        assertSame(m1.getClass(), m2.getClass());
        assertEquals(m1, m2);
    }",1
"@Test
    public void testTableXYDataset() {
        XYSeries<String> series1 = createSeries1();
        XYSeries<String> series2 = createSeries2();

        DefaultTableXYDataset<String> dataset = new DefaultTableXYDataset<>();
        dataset.addSeries(series1);
        dataset.addSeries(series2);

        //  Test that there are 6 X points and some specific values
        assertEquals(6, dataset.getItemCount());
        assertEquals(6, dataset.getX(0, 5).intValue());
        assertNull(dataset.getY(0, 5));
        assertEquals(6, dataset.getX(1, 5).intValue());
        assertEquals(2, dataset.getY(1, 5).intValue());

        // after adding a point to a series, check that there are now 7
        // items in each series
        series2.add(7, 2);
        assertEquals(7, dataset.getItemCount());
        assertNull(dataset.getY(0, 6));
        assertEquals(2, dataset.getY(1, 6).intValue());

        //  Remove series 1
        dataset.removeSeries(series1);
        //  Test that there are still 7 X points
        assertEquals(7, dataset.getItemCount());

        //  Remove series 2 and add new series
        dataset.removeSeries(series2);
        series1 = createSeries1();
        dataset.addSeries(series1);

        //  Test that there are now 4 X points
        assertEquals(4, dataset.getItemCount());
    }",1
"@Test
    public void testEquals() {
        DefaultXYDataset<String> d1 = new DefaultXYDataset<>();
        double[] x1 = new double[] {1.0, 2.0, 3.0}",1
"@Test
    public void testHashcode() {
        XYCoordinate v1 = new XYCoordinate(1.0, 2.0);
        XYCoordinate v2 = new XYCoordinate(1.0, 2.0);
        assertEquals(v1, v2);
        int h1 = v1.hashCode();
        int h2 = v2.hashCode();
        assertEquals(h1, h2);
    }",1
"@Test
    public void testEquals() {
        XYIntervalDataItem item1 = new XYIntervalDataItem(1.0, 0.5, 1.5, 2.0,
                1.9, 2.1);
        XYIntervalDataItem item2 = new XYIntervalDataItem(1.0, 0.5, 1.5, 2.0,
                1.9, 2.1);
        assertEquals(item1, item2);
        assertEquals(item2, item1);

        // x
        item1 = new XYIntervalDataItem(1.1, 0.5, 1.5, 2.0, 1.9, 2.1);
        assertNotEquals(item1, item2);
        item2 = new XYIntervalDataItem(1.1, 0.5, 1.5, 2.0, 1.9, 2.1);
        assertEquals(item1, item2);

        // xLow
        item1 = new XYIntervalDataItem(1.1, 0.55, 1.5, 2.0, 1.9, 2.1);
        assertNotEquals(item1, item2);
        item2 = new XYIntervalDataItem(1.1, 0.55, 1.5, 2.0, 1.9, 2.1);
        assertEquals(item1, item2);

        // xHigh
        item1 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.0, 1.9, 2.1);
        assertNotEquals(item1, item2);
        item2 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.0, 1.9, 2.1);
        assertEquals(item1, item2);

        // y
        item1 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.2, 1.9, 2.1);
        assertNotEquals(item1, item2);
        item2 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.2, 1.9, 2.1);
        assertEquals(item1, item2);

        // yLow
        item1 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.2, 1.99, 2.1);
        assertNotEquals(item1, item2);
        item2 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.2, 1.99, 2.1);
        assertEquals(item1, item2);

        // yHigh
        item1 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.2, 1.99, 2.11);
        assertNotEquals(item1, item2);
        item2 = new XYIntervalDataItem(1.1, 0.55, 1.55, 2.2, 1.99, 2.11);
        assertEquals(item1, item2);
    }",1
"@Test
    public void test1170825() {
        XYIntervalSeries<String> s1 = new XYIntervalSeries<>(""Series1"");
        XYIntervalSeriesCollection<String> dataset = new XYIntervalSeriesCollection<>();
        dataset.addSeries(s1);
        try {
            /* XYSeries s = */ dataset.getSeries(1);
        }",1
"@Test
    public void testAddSeries() {
        XYSeriesCollection<String> c = new XYSeriesCollection<>();
        XYSeries<String> s1 = new XYSeries<>(""s1"");
        c.addSeries(s1);

        // the dataset should prevent the addition of a series with the
        // same name as an existing series in the dataset
        XYSeries<String> s2 = new XYSeries<>(""s1"");
        try {
            c.addSeries(s2);
            fail(""Should have thrown IllegalArgumentException on duplicate key"");
        }",1
"@Test
    public void testGetRangeUpperBound() {
        XYSeriesCollection<String> dataset = new XYSeriesCollection<>();
        
        // when the dataset contains no series, we expect the value range to 
        // be null
        assertTrue(Double.isNaN(dataset.getRangeUpperBound(false)));
        assertTrue(Double.isNaN(dataset.getRangeUpperBound(true)));

        // when the dataset contains one or more series, but those series 
        // contain no items, we expect the value range to be null
        XYSeries<String> series = new XYSeries<>(""S1"");
        dataset.addSeries(series);
        assertTrue(Double.isNaN(dataset.getRangeUpperBound(false)));
        assertTrue(Double.isNaN(dataset.getRangeUpperBound(true)));

        // tests with values
        series.add(1.0, 1.1);
        assertEquals(1.1, dataset.getRangeUpperBound(false), EPSILON);
        assertEquals(1.1, dataset.getRangeUpperBound(true), EPSILON);

        series.add(-1.0, -1.1);
        assertEquals(1.1, dataset.getRangeUpperBound(false), EPSILON);
        assertEquals(1.1, dataset.getRangeUpperBound(true), EPSILON);
        
        series.add(0.0, null);
        assertEquals(1.1, dataset.getRangeUpperBound(false), EPSILON);
        assertEquals(1.1, dataset.getRangeUpperBound(true), EPSILON);
        
        XYSeries<String> s2 = new XYSeries<>(""S2"");
        dataset.addSeries(s2);
        assertEquals(1.1, dataset.getRangeUpperBound(false), EPSILON);
        assertEquals(1.1, dataset.getRangeUpperBound(true), EPSILON);
        
        s2.add(2.0, 5.0);
        assertEquals(5.0, dataset.getRangeUpperBound(false), EPSILON);
        assertEquals(5.0, dataset.getRangeUpperBound(true), EPSILON);
    }",1
"@Test
    public void testGetSeries() {
        XYSeriesCollection<String> c = new XYSeriesCollection<>();
        XYSeries<String> s1 = new XYSeries<>(""s1"");
        c.addSeries(s1);
        assertEquals(""s1"", c.getSeries(0).getKey());

        try {
            c.getSeries(-1);
            fail(""Should have thrown IndexOutOfBoundsException on negative key"");
        }",1
"@Test
    public void testEquals() {
        YInterval i1 = new YInterval(1.0, 0.5, 1.5);
        YInterval i2 = new YInterval(1.0, 0.5, 1.5);
        assertEquals(i1, i2);

        i1 = new YInterval(1.1, 0.5, 1.5);
        assertNotEquals(i1, i2);
        i2 = new YInterval(1.1, 0.5, 1.5);
        assertEquals(i1, i2);

        i1 = new YInterval(1.1, 0.55, 1.5);
        assertNotEquals(i1, i2);
        i2 = new YInterval(1.1, 0.55, 1.5);
        assertEquals(i1, i2);

        i1 = new YInterval(1.1, 0.55, 1.55);
        assertNotEquals(i1, i2);
        i2 = new YInterval(1.1, 0.55, 1.55);
        assertEquals(i1, i2);
    }",1
"@Test
	public void testSecureJs() throws Exception {
		final String js1 = jsSanitizer.secureJs(""while(a > 0)\n\n\n {\n\n\nprint(a);}",1
"@Test
  public void responseType() {
    Type bodyClass = new TypeToken<ListenableFuture<String>>() {}",1
"@Test
  public void rawBodyTypeThrows() {
    Type observableType = new TypeToken<Observable>() {}",1
"@Test
  public void rawResponseTypeThrows() {
    Type observableType = new TypeToken<Observable<Response>>() {}",1
"@Test
  public void rawResultTypeThrows() {
    Type observableType = new TypeToken<Observable<Result>>() {}",1
"@Test
  public void responseTypes() {
    Type oBodyClass = new TypeToken<Observable<String>>() {}",1
"@Test
  public void parameterizedTypes() {
    ParameterizedType one = (ParameterizedType) new TypeToken<List<String>>() {}",1
"@Test
  public void conversionProblemOutgoingSync() throws IOException {
    Retrofit retrofit =
        new Retrofit.Builder()
            .baseUrl(server.url(""/""))
            .addConverterFactory(
                new ToStringConverterFactory() {
                  @Override
                  public Converter<String, RequestBody> requestBodyConverter(
                      Type type,
                      Annotation[] parameterAnnotations,
                      Annotation[] methodAnnotations,
                      Retrofit retrofit) {
                    return value -> {
                      throw new UnsupportedOperationException(""I am broken!"");
                    }",1
"@Test
  public void responseBodyStreams() throws IOException {
    Retrofit retrofit =
        new Retrofit.Builder()
            .baseUrl(server.url(""/""))
            .addConverterFactory(new ToStringConverterFactory())
            .build();
    Service example = retrofit.create(Service.class);

    server.enqueue(
        new MockResponse().setBody(""1234"").setSocketPolicy(DISCONNECT_DURING_RESPONSE_BODY));

    Response<ResponseBody> response = example.getStreamingBody().execute();

    ResponseBody streamedBody = response.body();
    // When streaming we only detect socket problems as the ResponseBody is read.
    try {
      streamedBody.string();
      fail();
    }",1
"@Test
  public void transportProblemSync() {
    Retrofit retrofit =
        new Retrofit.Builder()
            .baseUrl(server.url(""/""))
            .addConverterFactory(new ToStringConverterFactory())
            .build();
    Service example = retrofit.create(Service.class);

    server.enqueue(new MockResponse().setSocketPolicy(SocketPolicy.DISCONNECT_AT_START));

    Call<String> call = example.getString();
    try {
      call.execute();
      fail();
    }",1
"@Test
  public void xmlRequestBody() throws Exception {
    server.enqueue(new MockResponse());

    Call<Void> call = service.postXml(SAMPLE_CONTACT);
    call.execute();

    RecordedRequest request = server.takeRequest();
    assertThat(request.getHeader(""Content-Type"")).isEqualTo(""application/xml; charset=utf-8"");
    assertThat(request.getBody().readUtf8()).isEqualTo(SAMPLE_CONTACT_XML);
  }",1
"@Test
  public void deserializeWrongValue() throws IOException {
    ByteString encoded = ByteString.decodeBase64(""////"");
    server.enqueue(new MockResponse().setBody(new Buffer().write(encoded)));

    Call<?> call = service.get();
    try {
      call.execute();
      fail();
    }",1
"@Test
  public void deferredReturnExecute() throws IOException {
    Call<Integer> counts =
        Calls.defer(
            new Callable<Call<Integer>>() {
              private int count = 0;

              @Override
              public Call<Integer> call() throws Exception {
                return Calls.response(++count);
              }",1
"@Test
  public void responseCancelEnqueue() throws IOException {
    Call<String> taco = Calls.response(Response.success(""Taco""));
    assertFalse(taco.isCanceled());
    taco.cancel();
    assertTrue(taco.isCanceled());

    final AtomicReference<Throwable> failureRef = new AtomicReference<>();
    taco.enqueue(
        new Callback<String>() {
          @Override
          public void onResponse(Call<String> call, Response<String> response) {
            fail();
          }",1
"@Test
  public void errorPercentageIsAccurate() {
    behavior.setErrorPercent(0);
    for (int i = 0; i < 10000; i++) {
      assertThat(behavior.calculateIsError()).isFalse();
    }",1
"@Test
  public void contentTypeAnnotationHeaderOverrides() {
    class Example {
      @POST(""/"") //
      @Headers(""Content-Type: text/not-plain"") //
      Call<ResponseBody> method(@Body RequestBody body) {
        return null;
      }",1
"@Test
  public void contentTypeParameterHeaderOverrides() {
    class Example {
      @POST(""/"") //
      Call<ResponseBody> method(
          @Header(""Content-Type"") String contentType, @Body RequestBody body) {
        return null;
      }",1
"@Test
  public void customMethodWithBody() {
    class Example {
      @HTTP(method = ""CUSTOM2"", path = ""/foo"", hasBody = true)
      Call<ResponseBody> method(@Body RequestBody body) {
        return null;
      }",1
"@Test
  public void fieldParamMapsConvertedToNullShouldError() throws Exception {
    class Example {
      @FormUrlEncoded
      @POST(""/query"")
      Call<ResponseBody> queryPath(@FieldMap Map<String, String> a) {
        return null;
      }",1
"@Test
  public void fieldParamsSkippedIfConvertedToNull() throws Exception {
    class Example {
      @FormUrlEncoded
      @POST(""/query"")
      Call<ResponseBody> queryPath(@Field(""a"") Object a) {
        return null;
      }",1
"@Test
  public void formEncodedFieldPrimitiveArray() {
    class Example {
      @FormUrlEncoded //
      @POST(""/foo"") //
      Call<ResponseBody> method(@Field(""foo"") int[] fields, @Field(""kit"") String kit) {
        return null;
      }",1
"@Test
  public void getWithHeaderMap() {
    class Example {
      @GET(""/search"")
      Call<ResponseBody> method(@HeaderMap Map<String, Object> headers) {
        return null;
      }",1
"@Test
  public void getWithQueryNameParamArray() {
    class Example {
      @GET(""/foo/bar/"") //
      Call<ResponseBody> method(@QueryName Object[] keys) {
        return null;
      }",1
"@Test
  public void getWithQueryNameParamPrimitiveArray() {
    class Example {
      @GET(""/foo/bar/"") //
      Call<ResponseBody> method(@QueryName int[] keys) {
        return null;
      }",1
"@Test
  public void multipartIterableRequiresName() {
    class Example {
      @Multipart //
      @POST(""/foo/bar/"") //
      Call<ResponseBody> method(@Part List<RequestBody> part) {
        return null;
      }",1
"@Test
  public void multipartOkHttpPartForbidsName() {
    class Example {
      @Multipart //
      @POST(""/foo/bar/"") //
      Call<ResponseBody> method(@Part(""name"") MultipartBody.Part part) {
        return null;
      }",1
"@Test
  public void multipartPartMap() throws IOException {
    class Example {
      @Multipart //
      @POST(""/foo/bar/"") //
      Call<ResponseBody> method(@PartMap Map<String, RequestBody> parts) {
        return null;
      }",1
"@Test
  public void multipartPartsShouldBeInOrder() throws IOException {
    class Example {
      @Multipart
      @POST(""/foo"")
      Call<ResponseBody> get(
          @Part(""first"") String data,
          @Part(""second"") String dataTwo,
          @Part(""third"") String dataThree) {
        return null;
      }",1
"@Test
  public void pathParamRequired() {
    class Example {
      @GET(""/foo/bar/{ping}",1
"@Test
  public void postWithUrl() {
    class Example {
      @POST
      Call<ResponseBody> method(@Url String url, @Body RequestBody body) {
        return null;
      }",1
"@Test
  public void argumentCapture() throws Exception {
    AtomicInteger i = new AtomicInteger();

    server.enqueue(new MockResponse().setBody(""a""));
    server.enqueue(new MockResponse().setBody(""b""));

    Retrofit retrofit =
        new Retrofit.Builder()
            .baseUrl(server.url(""/""))
            .addConverterFactory(new ToStringConverterFactory())
            .build();
    MutableParameters mutableParameters = retrofit.create(MutableParameters.class);

    i.set(100);
    Call<String> call1 = mutableParameters.method(i);

    i.set(101);
    Response<String> response1 = call1.execute();

    i.set(102);
    assertEquals(""a"", response1.body());
    assertEquals(""/?i=101"", server.takeRequest().getPath());

    i.set(200);
    Call<String> call2 = call1.clone();

    i.set(201);
    Response<String> response2 = call2.execute();

    i.set(202);
    assertEquals(""b"", response2.body());

    assertEquals(""/?i=201"", server.takeRequest().getPath());
  }",1
"@Test
  public void callAdapterFactoryQueriedCanDelegateTwiceWithoutRecursion() {
    Type type = String.class;
    Annotation[] annotations = new Annotation[0];

    final CallAdapter<?, ?> expectedAdapter =
        new CallAdapter<Object, Object>() {
          @Override
          public Type responseType() {
            throw new AssertionError();
          }",1
"@Test
  public void callbackExecutorUsedForSuccess() throws InterruptedException {
    final CountDownLatch runnableLatch = new CountDownLatch(1);
    final AtomicReference<Runnable> runnableRef = new AtomicReference<>();
    Executor executor =
        command -> {
          runnableRef.set(command);
          runnableLatch.countDown();
        }",1
"@Test
  public void callFactoryClientPropagated() {
    OkHttpClient client = new OkHttpClient();
    Retrofit retrofit =
        new Retrofit.Builder().baseUrl(""http://example.com/"").client(client).build();
    assertThat(retrofit.callFactory()).isSameInstanceAs(client);
  }",1
"@Test
  public void callFactoryReturningNullThrows() throws IOException {
    okhttp3.Call.Factory callFactory = request -> null;
    Retrofit retrofit =
        new Retrofit.Builder().baseUrl(""http://example.com/"").callFactory(callFactory).build();

    server.enqueue(new MockResponse());

    CallMethod service = retrofit.create(CallMethod.class);
    Call<ResponseBody> call = service.getResponseBody();
    try {
      call.execute();
      fail();
    }",1
"@Test
  public void callFactoryUsed() throws IOException {
    final AtomicBoolean called = new AtomicBoolean();
    okhttp3.Call.Factory callFactory =
        request -> {
          called.set(true);
          return new OkHttpClient().newCall(request);
        }",1
"@Test
  public void customCallAdapter() {
    class GreetingCallAdapterFactory extends CallAdapter.Factory {
      @Override
      public @Nullable CallAdapter<Object, String> get(
          Type returnType, Annotation[] annotations, Retrofit retrofit) {
        if (getRawType(returnType) != String.class) {
          return null;
        }",1
"@Test
  public void customCallAdapterMissingThrows() {
    Retrofit retrofit = new Retrofit.Builder().baseUrl(server.url(""/"")).build();
    FutureMethod example = retrofit.create(FutureMethod.class);
    try {
      example.method();
      fail();
    }",1
"@Test
  public void methodAnnotationsPassedToResponseBodyConverter() {
    final AtomicReference<Annotation[]> annotationsRef = new AtomicReference<>();
    class MyConverterFactory extends Converter.Factory {
      @Override
      public Converter<ResponseBody, ?> responseBodyConverter(
          Type type, Annotation[] annotations, Retrofit retrofit) {
        annotationsRef.set(annotations);
        return new ToStringConverterFactory().responseBodyConverter(type, annotations, retrofit);
      }",1
"@Test
  public void requestConverterFactoryNoMatchThrows() {
    Type type = String.class;
    Annotation[] annotations = new Annotation[0];

    NonMatchingConverterFactory nonMatchingFactory = new NonMatchingConverterFactory();

    Retrofit retrofit =
        new Retrofit.Builder()
            .baseUrl(""http://example.com/"")
            .addConverterFactory(nonMatchingFactory)
            .build();

    try {
      retrofit.requestBodyConverter(type, annotations, annotations);
      fail();
    }",1
"@Test
  public void responseConverterFactoryNoMatchThrows() {
    Type type = String.class;
    Annotation[] annotations = new Annotation[0];

    NonMatchingConverterFactory nonMatchingFactory = new NonMatchingConverterFactory();

    Retrofit retrofit =
        new Retrofit.Builder()
            .baseUrl(""http://example.com/"")
            .addConverterFactory(nonMatchingFactory)
            .build();

    try {
      retrofit.responseBodyConverter(type, annotations);
      fail();
    }",1
"@Test
  public void responseTypeCannotBeOkHttpResponse() {
    Retrofit retrofit = new Retrofit.Builder().baseUrl(server.url(""/"")).build();
    CallMethod service = retrofit.create(CallMethod.class);
    try {
      service.badType2();
      fail();
    }",1
"@Test
  public void testRegularAsyncExecution() {

    ProcessEngine processEngine = null;

    try {
      // Deploy
      processEngine = createProcessEngine(true);
      setClockToCurrentTime(processEngine);
      deploy(processEngine, ""AsyncExecutorTest.testRegularAsyncExecution.bpmn20.xml"");

      // Start process instance. Wait for all jobs to be done
      processEngine.getRuntimeService().startProcessInstanceByKey(""asyncExecutor"");

      // Move clock 3 minutes. Nothing should happen
      addSecondsToCurrentTime(processEngine, 180L);
      ProcessEngine processEngineForException = processEngine;
      assertThatExceptionOfType(ActivitiException.class)
        .isThrownBy(() -> waitForAllJobsBeingExecuted(processEngineForException, 500L));
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""The Task"").count()).isEqualTo(1);
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""Task after timer"").count()).isEqualTo(0);
      assertThat(processEngine.getManagementService().createTimerJobQuery().count()).isEqualTo(1);
      assertThat(getAsyncExecutorJobCount(processEngine)).isEqualTo(0);

      // Move clock 3 minutes and 1 second. Triggers the timer
      addSecondsToCurrentTime(processEngine, 181);
      waitForAllJobsBeingExecuted(processEngine);

      // Verify if all is as expected
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""The Task"").count()).isEqualTo(0);
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""Task after timer"").count()).isEqualTo(1);
      assertThat(processEngine.getManagementService().createTimerJobQuery().count()).isEqualTo(0);
      assertThat(processEngine.getManagementService().createJobQuery().count()).isEqualTo(0);

      assertThat(getAsyncExecutorJobCount(processEngine)).isEqualTo(1);
    }",1
"@Test
    public void hasConnectorBeanShouldReturnFalseIfABeanOfDifferentTypeIsFound() {
        //given
        String connectorName = ""connector"";
        DelegateExecution execution = ConnectorRuntimeApiTestHelper.buildExecution(connectorName);
        given(context.containsBean(connectorName)).willReturn(true);
        DelegateExecution nonConnectorBean = mock(DelegateExecution.class);
        given(context.getBean(connectorName)).willReturn(nonConnectorBean);

        //when
        boolean hasConnectorBean = behavior.hasConnectorBean(execution);

        //then
        assertThat(hasConnectorBean).isFalse();
    }",1
"@Test
    public void daylightSaving23HourDay() throws Exception {
        Clock testingClock = new DefaultClockImpl();
        testingClock.setCurrentCalendar(parseCalendar(""20140309-00:00:00"", TimeZone.getTimeZone(""US/Eastern"")));

        DurationHelper dh = new DurationHelper(""R2/2014-03-09T00:00:00/P1D"", testingClock);

        assertThat(dh.getCalendarAfter(testingClock.getCurrentCalendar())).isEqualTo(parseCalendar(""20140310-00:00:00"", TimeZone.getTimeZone(""US/Eastern"")));
    }",1
"@Test
    public void daylightSaving25HourDayEurope() throws Exception {
        Clock testingClock = new DefaultClockImpl();
        testingClock.setCurrentCalendar(parseCalendar(""20131027-00:00:00"", TimeZone.getTimeZone(""Europe/Amsterdam"")));

        DurationHelper dh = new DurationHelper(""R2/2013-10-27T00:00:00/P1D"", testingClock);

        assertThat(dh.getCalendarAfter(testingClock.getCurrentCalendar())).isEqualTo(parseCalendar(""20131028-00:00:00"", TimeZone.getTimeZone(""Europe/Amsterdam"")));
    }",1
"@Test
    public void daylightSavingFall() throws Exception {
        Clock testingClock = new DefaultClockImpl();
        testingClock.setCurrentCalendar(parseCalendar(""20131103-04:45:00"", TimeZone.getTimeZone(""UTC"")));

        DurationHelper dh = new DurationHelper(""R2/2013-11-03T00:45:00-04:00/PT1H"", testingClock);

        assertThat(dh.getCalendarAfter(testingClock.getCurrentCalendar(TimeZone.getTimeZone(""US/Eastern"")))).isEqualTo(parseCalendar(""20131103-05:45:00"", TimeZone.getTimeZone(""UTC"")));

        testingClock.setCurrentCalendar(parseCalendar(""20131103-05:45:00"", TimeZone.getTimeZone(""UTC"")));

        assertThat(dh.getCalendarAfter(testingClock.getCurrentCalendar(TimeZone.getTimeZone(""US/Eastern"")))).isEqualTo(parseCalendar(""20131103-06:45:00"", TimeZone.getTimeZone(""UTC"")));
    }",1
"@Test
    public void daylightSavingFallFirstHour() throws Exception {
        Clock testingClock = new DefaultClockImpl();
        testingClock.setCurrentCalendar(parseCalendar(""20131103-05:45:00"", TimeZone.getTimeZone(""UTC"")));
        Calendar easternTime = testingClock.getCurrentCalendar(TimeZone.getTimeZone(""US/Eastern""));

        DurationHelper dh = new DurationHelper(""R2/2013-11-03T01:45:00-04:00/PT1H"", testingClock);

        assertThat(dh.getCalendarAfter(easternTime)).isEqualTo(parseCalendar(""20131103-06:45:00"", TimeZone.getTimeZone(""UTC"")));
    }",1
"@Test
    public void daylightSavingFallObservedSecondHour() throws Exception {
        Clock testingClock = new DefaultClockImpl();
        testingClock.setCurrentCalendar(parseCalendar(""20131103-00:45:00"", TimeZone.getTimeZone(""US/Eastern"")));

        DurationHelper dh = new DurationHelper(""R2/2013-11-03T00:45:00-04:00/PT2H"", testingClock);
        Calendar expected = parseCalendarWithOffset(""20131103-01:45:00 -05:00"");

        assertThat(expected.compareTo(dh.getCalendarAfter()) == 0).isTrue();
    }",1
"@Test
    public void shouldNotExceedNumber() throws Exception {
        Clock testingClock = new DefaultClockImpl();
        testingClock.setCurrentTime(new Date(0));
        DurationHelper dh = new DurationHelper(""R2/PT10S"", testingClock);

        testingClock.setCurrentTime(new Date(15000));
        assertThat(dh.getDateAfter().getTime()).isEqualTo(20000);

        testingClock.setCurrentTime(new Date(30000));
        assertThat(dh.getDateAfter().getTime()).isEqualTo(30000);
    }",1
"@Test
    public void executeValidationShouldNotRiseErrorsForServiceTasksSettingOnlyTheImplementation() {
        //given
        Process process = new Process();
        ServiceTask serviceTask = new ServiceTask();
        serviceTask.setImplementation(""myImpl"");
        process.addFlowElement(serviceTask);
        BpmnModel bpmnModel = new BpmnModel();
        bpmnModel.addProcess(process);

        //when
        var errors = validator.validate(bpmnModel);

        //then
        assertThat(errors)
                .as(""No error is expected: the default behavior will be used"")
                .isEmpty();
    }",1
"@Test
  public void get_scheduled_by_task_name() {
    Instant now = TimeHelper.truncatedInstantNow();
    final SchedulableTaskInstance<Void> execution1 =
        new SchedulableTaskInstance<>(
            oneTimeTask.instance(""id"" + 1), now.plus(new Random().nextInt(10), ChronoUnit.HOURS));
    taskRepository.createIfNotExists(execution1);
    taskRepository.createIfNotExists(
        new SchedulableTaskInstance<>(
            oneTimeTask.instance(""id"" + 2), now.plus(new Random().nextInt(10), ChronoUnit.HOURS)));
    taskRepository.createIfNotExists(
        new SchedulableTaskInstance<>(
            alternativeOneTimeTask.instance(""id"" + 3),
            now.plus(new Random().nextInt(10), ChronoUnit.HOURS)));

    taskRepository.pick(
        taskRepository.getExecution(execution1.getTaskInstance()).get(), Instant.now());
    assertThat(getScheduledExecutions(all().withPicked(true), oneTimeTask.getName()), hasSize(1));
    assertThat(getScheduledExecutions(all().withPicked(false), oneTimeTask.getName()), hasSize(1));
    assertThat(getScheduledExecutions(all(), oneTimeTask.getName()), hasSize(2));

    assertThat(
        getScheduledExecutions(all().withPicked(false), alternativeOneTimeTask.getName()),
        hasSize(1));
    assertThat(getScheduledExecutions(all().withPicked(false), ""non-existing""), empty());
  }",1
"@Test
  public void reschedule_should_move_execution_in_time() {
    Instant now = TimeHelper.truncatedInstantNow();
    final TaskInstance<Void> instance = oneTimeTask.instance(""id1"");
    taskRepository.createIfNotExists(new SchedulableTaskInstance<>(instance, now));
    List<Execution> due = taskRepository.getDue(now, POLLING_LIMIT);
    assertThat(due, hasSize(1));

    Execution execution = due.get(0);
    final Optional<Execution> pickedExecution = taskRepository.pick(execution, now);
    final Instant nextExecutionTime = now.plus(Duration.ofMinutes(1));
    taskRepository.reschedule(pickedExecution.get(), nextExecutionTime, now, null, 0);

    assertThat(taskRepository.getDue(now, POLLING_LIMIT), hasSize(0));
    assertThat(taskRepository.getDue(nextExecutionTime, POLLING_LIMIT), hasSize(1));

    final Optional<Execution> nextExecution = taskRepository.getExecution(instance);
    assertTrue(nextExecution.isPresent());
    assertThat(nextExecution.get().picked, is(false));
    assertThat(nextExecution.get().pickedBy, nullValue());
    assertThat(nextExecution.get().executionTime, is(nextExecutionTime));
  }",1
"@Test
  public void should_not_be_able_to_pick_execution_that_has_been_rescheduled() {
    Instant now = TimeHelper.truncatedInstantNow();
    final TaskInstance<Void> instance = oneTimeTask.instance(""id1"");
    taskRepository.createIfNotExists(new SchedulableTaskInstance<>(instance, now));

    List<Execution> due = taskRepository.getDue(now, POLLING_LIMIT);
    assertThat(due, hasSize(1));
    final Execution execution = due.get(0);
    final Optional<Execution> pickedExecution = taskRepository.pick(execution, now);
    assertThat(pickedExecution.isPresent(), is(true));
    taskRepository.reschedule(pickedExecution.get(), now.plusSeconds(1), now, null, 0);

    assertThat(taskRepository.pick(pickedExecution.get(), now).isPresent(), is(false));
  }",1
"@Test
  public void scheduler_should_execute_task_when_exactly_due() {
    LOG.info(""scheduler_should_execute_task_when_exactly_due()"");
    OneTimeTask<Void> oneTimeTask = TestTasks.oneTime(""OneTime"", Void.class, handler);
    ManualScheduler scheduler = schedulerFor(oneTimeTask);

    try {
      Instant executionTime = clock.now().plus(ofMinutes(1));
      scheduler.schedule(oneTimeTask.instance(""1""), executionTime);

      scheduler.runAnyDueExecutions();
      assertThat(handler.timesExecuted.get(), is(0));

      clock.set(executionTime);
      scheduler.runAnyDueExecutions();
      assertThat(handler.timesExecuted.get(), is(1));
    }",1
"@Test
  public void scheduler_should_not_execute_canceled_tasks() {
    OneTimeTask<Void> oneTimeTask = TestTasks.oneTime(""OneTime"", Void.class, handler);
    Scheduler scheduler = schedulerFor(oneTimeTask);

    Instant executionTime = clock.now().plus(ofMinutes(1));
    String instanceId = ""1"";
    TaskInstance<Void> oneTimeTaskInstance = oneTimeTask.instance(instanceId);
    scheduler.schedule(oneTimeTaskInstance, executionTime);
    scheduler.cancel(oneTimeTaskInstance);
    scheduler.executeDue();
    assertThat(handler.timesExecuted.get(), is(0));

    clock.set(executionTime);
    scheduler.executeDue();
    assertThat(handler.timesExecuted.get(), is(0));
  }",1
"@Test
    public void testNullFieldInSuperclass() throws Exception {
        Subclass pojo = Subclass.builder().subVal(""two"").build();
        JsonGenerator jgen = mock(JsonGenerator.class);
        SerializerProvider provider = mock(SerializerProvider.class);
        PropertyWriter writer = mock(PropertyWriter.class);

        when(writer.getName()).thenReturn(""baseVal"");

        filter.serializeAsField(pojo, jgen, provider, writer);

        verify(writer, atLeast(1)).getName();
        verifyNoMoreInteractions(writer);
    }",1
"@Test
    public void testNullInSubclass() throws Exception {
        Subclass pojo = Subclass.builder().baseVal(1).build();
        JsonGenerator jgen = mock(JsonGenerator.class);
        SerializerProvider provider = mock(SerializerProvider.class);
        PropertyWriter writer = mock(PropertyWriter.class);

        when(writer.getName()).thenReturn(""subVal"");

        filter.serializeAsField(pojo, jgen, provider, writer);

        verify(writer, atLeast(1)).getName();
        verifyNoMoreInteractions(writer);
    }",1
"@Test
    public void format_rfc3339_zeroMillis() {
        Calendar cal = Calendar.getInstance(TimeZone.getTimeZone(""GMT""));
        cal.set(1985, 3, 12, 23, 20, 50);
        cal.set(Calendar.MILLISECOND, 0);
        Date date = cal.getTime();
        assertEquals(""1985-04-12T23:20:50Z"", HttpDateUtils.format(date));
    }",1
"@Test
    public void abortAll() throws Exception {
        UploadPartRequest request1 = UploadPartRequest.builder().uploadPartNum(1).build();
        final UploadPartResponse response1 = UploadPartResponse.builder().build();

        when(service.uploadPart(request1))
                .thenAnswer(
                        new Answer<UploadPartResponse>() {
                            @Override
                            public UploadPartResponse answer(InvocationOnMock arg0)
                                    throws Throwable {
                                // long enough to abort without starting the task
                                Thread.sleep(10000L);
                                return response1;
                            }",1
"@Test
    public void addParts_allSuccessful_commit() throws Exception {
        String uploadId = ""uploadId"";
        initializeCreateMultipartUpload(uploadId);
        MultipartManifest manifest =
                assembler.newRequest(CONTENT_TYPE, CONTENT_LANGUAGE, CONTENT_ENCODING, OPC_META);

        byte[] bytes = ""abcd"".getBytes();

        File file = File.createTempFile(""unitTest"", "".txt"");
        file.deleteOnExit();
        try (FileOutputStream fos = new FileOutputStream(file)) {
            fos.write(bytes);
        }",1
"@Test
    public void newRequest_andVerifyManifestWithRetryConfiguration() {
        String uploadId = ""uploadId"";

        initializeCreateMultipartUpload(uploadId);

        MultipartManifest manifest =
                assemblerWithRetryConfiguration.newRequest(
                        CONTENT_TYPE, CONTENT_LANGUAGE, CONTENT_ENCODING, OPC_META);
        assertNotNull(manifest);
        assertEquals(uploadId, manifest.getUploadId());

        ArgumentCaptor<CreateMultipartUploadRequest> captor =
                ArgumentCaptor.forClass(CreateMultipartUploadRequest.class);
        verify(service).createMultipartUpload(captor.capture());

        CreateMultipartUploadRequest request = captor.getValue();
        assertEquals(NAMESPACE, request.getNamespaceName());
        assertEquals(BUCKET, request.getBucketName());
        assertEquals(OBJECT, request.getCreateMultipartUploadDetails().getObject());
        assertEquals(CONTENT_TYPE, request.getCreateMultipartUploadDetails().getContentType());
        assertEquals(
                CONTENT_LANGUAGE, request.getCreateMultipartUploadDetails().getContentLanguage());
        assertEquals(
                CONTENT_ENCODING, request.getCreateMultipartUploadDetails().getContentEncoding());
        assertEquals(OPC_META, request.getCreateMultipartUploadDetails().getMetadata());
        assertEquals(mockInvocationCallback, request.getInvocationCallback());
        assertEquals(CACHE_CONTROL, request.getCreateMultipartUploadDetails().getCacheControl());
        assertEquals(
                CONTENT_DISPOSITION,
                request.getCreateMultipartUploadDetails().getContentDisposition());
    }",1
"@Test
    public void resumeUpload_noMatchingUploadId_shouldThrowIllegalArgumentException() {
        thrown.expect(IllegalArgumentException.class);
        thrown.expectMessage(""Could not find existing upload with ID doesNotExist"");

        ArrayList<MultipartUpload> existingUploads = new ArrayList<>();
        existingUploads.add(MultipartUpload.builder().uploadId(""foobar"").build());
        ListMultipartUploadsResponse listResponse1 =
                ListMultipartUploadsResponse.builder()
                        .opcNextPage(""nextPage"")
                        .items(existingUploads)
                        .build();
        ListMultipartUploadsResponse listResponse2 =
                ListMultipartUploadsResponse.builder()
                        .items(new ArrayList<MultipartUpload>())
                        .build();
        when(service.listMultipartUploads(any(ListMultipartUploadsRequest.class)))
                .thenReturn(listResponse1)
                .thenReturn(listResponse2);

        assembler.resumeRequest(""doesNotExist"");
    }",1
"@Test
    public void singleUpload_progressReporter() {
        final UploadConfiguration uploadConfiguration =
                UploadConfiguration.builder().allowMultipartUploads(false).build();
        final UploadManager uploadManager = new UploadManager(objectStorage, uploadConfiguration);

        final AtomicInteger expectedProgressNotificationCount = new AtomicInteger();
        when(objectStorage.putObject(any(PutObjectRequest.class)))
                .then(
                        new Answer<PutObjectResponse>() {
                            @Override
                            public PutObjectResponse answer(InvocationOnMock invocationOnMock)
                                    throws Throwable {
                                final PutObjectRequest putObjectRequest =
                                        invocationOnMock.getArgument(0);
                                final InputStream inputStream = putObjectRequest.getPutObjectBody();
                                byte[] buffer = new byte[READ_BLOCK_SIZE];
                                while (inputStream.read(buffer) != -1) {
                                    expectedProgressNotificationCount.getAndIncrement();
                                }",1
"@Test
    public void upload_singleUpload_enforceMd5() throws Exception {
        UploadConfiguration uploadConfiguration =
                UploadConfiguration.builder().allowMultipartUploads(false).enforceMd5(true).build();
        UploadManager uploadManager = new UploadManager(objectStorage, uploadConfiguration);

        UploadRequest request = createUploadRequest();

        ArgumentCaptor<PutObjectRequest> putRequestCaptor =
                ArgumentCaptor.forClass(PutObjectRequest.class);
        PutObjectResponse putResponse = PutObjectResponse.builder().build();
        when(objectStorage.putObject(putRequestCaptor.capture())).thenReturn(putResponse);

        UploadResponse uploadResponse = uploadManager.upload(request);
        assertNotNull(uploadResponse);
        byte[] buffer = new byte[(int) CONTENT_LENGTH];
        putRequestCaptor.getValue().getPutObjectBody().read(buffer);
        assertEquals(CONTENT, new String(buffer));
        assertEquals(CONTENT_LENGTH, putRequestCaptor.getValue().getContentLength().longValue());
        assertEquals(
                ""U2yw5mJhFHg/U4cBMrrFyw=="",
                putRequestCaptor.getValue().getContentMD5()); // 'a' times content-length
    }",1
"@Test public void deadEventPosting() {
    GhostCatcher catcher = new GhostCatcher();
    bus.register(catcher);

    bus.post(new DeadEvent(this, EVENT));

    List<DeadEvent> events = catcher.getEvents();
    assertEquals(""The explicit DeadEvent should be delivered."",
        1, events.size());
    assertEquals(""The dead event must not be re-wrapped."",
        EVENT, events.get(0).event);
  }",1
"@Test public void polymorphicDistribution() {
    // Three catchers for related types String, Object, and Comparable<?>.
    // String isa Object
    // String isa Comparable<?>
    // Comparable<?> isa Object
    StringCatcher stringCatcher = new StringCatcher();

    final List<Object> objectEvents = new ArrayList<Object>();
    Object objCatcher = new Object() {
      @SuppressWarnings(""unused"")
      @Subscribe public void eat(Object food) {
        objectEvents.add(food);
      }",1
"@Test public void producerUnregisterAllowsReregistering() {
    StringProducer producer1 = new StringProducer();
    StringProducer producer2 = new StringProducer();

    bus.register(producer1);
    bus.unregister(producer1);
    bus.register(producer2);
  }",1
"@Test public void returnValueNotCached() throws Exception {
    Method method = getRecordingMethod();
    EventProducer producer = new EventProducer(this, method);
    producer.produceEvent();
    methodReturnValue = new Object();
    methodCalled = false;
    Object secondReturnValue = producer.produceEvent();

    assertTrue(""Producer must call provided method twice."", methodCalled);
    assertSame(""Producer result must be *exactly* the specified return value on each invocation."",
        secondReturnValue, methodReturnValue);
  }",1
"@Test public void manySourcesOfMany() {
        CartesianIterator<Integer> iter =
            new CartesianIterator<>(
                asList(
                    asList(0, 1, 2, 3, 4).iterator(),
                    asList(5, 6).iterator(),
                    asList(7, 8, 9).iterator(),
                    asList(10, 11, 12).iterator()));

        List<List<Integer>> result = newArrayList(iter);

        assertEquals(
            asList(
                asList(0, 5, 7, 10), asList(1, 5, 7, 10), asList(2, 5, 7, 10), asList(3, 5, 7, 10), asList(4, 5, 7, 10),
                asList(0, 6, 7, 10), asList(1, 6, 7, 10), asList(2, 6, 7, 10), asList(3, 6, 7, 10), asList(4, 6, 7, 10),
                asList(0, 5, 8, 10), asList(1, 5, 8, 10), asList(2, 5, 8, 10), asList(3, 5, 8, 10), asList(4, 5, 8, 10),
                asList(0, 6, 8, 10), asList(1, 6, 8, 10), asList(2, 6, 8, 10), asList(3, 6, 8, 10), asList(4, 6, 8, 10),
                asList(0, 5, 9, 10), asList(1, 5, 9, 10), asList(2, 5, 9, 10), asList(3, 5, 9, 10), asList(4, 5, 9, 10),
                asList(0, 6, 9, 10), asList(1, 6, 9, 10), asList(2, 6, 9, 10), asList(3, 6, 9, 10), asList(4, 6, 9, 10),
                asList(0, 5, 7, 11), asList(1, 5, 7, 11), asList(2, 5, 7, 11), asList(3, 5, 7, 11), asList(4, 5, 7, 11),
                asList(0, 6, 7, 11), asList(1, 6, 7, 11), asList(2, 6, 7, 11), asList(3, 6, 7, 11), asList(4, 6, 7, 11),
                asList(0, 5, 8, 11), asList(1, 5, 8, 11), asList(2, 5, 8, 11), asList(3, 5, 8, 11), asList(4, 5, 8, 11),
                asList(0, 6, 8, 11), asList(1, 6, 8, 11), asList(2, 6, 8, 11), asList(3, 6, 8, 11), asList(4, 6, 8, 11),
                asList(0, 5, 9, 11), asList(1, 5, 9, 11), asList(2, 5, 9, 11), asList(3, 5, 9, 11), asList(4, 5, 9, 11),
                asList(0, 6, 9, 11), asList(1, 6, 9, 11), asList(2, 6, 9, 11), asList(3, 6, 9, 11), asList(4, 6, 9, 11),
                asList(0, 5, 7, 12), asList(1, 5, 7, 12), asList(2, 5, 7, 12), asList(3, 5, 7, 12), asList(4, 5, 7, 12),
                asList(0, 6, 7, 12), asList(1, 6, 7, 12), asList(2, 6, 7, 12), asList(3, 6, 7, 12), asList(4, 6, 7, 12),
                asList(0, 5, 8, 12), asList(1, 5, 8, 12), asList(2, 5, 8, 12), asList(3, 5, 8, 12), asList(4, 5, 8, 12),
                asList(0, 6, 8, 12), asList(1, 6, 8, 12), asList(2, 6, 8, 12), asList(3, 6, 8, 12), asList(4, 6, 8, 12),
                asList(0, 5, 9, 12), asList(1, 5, 9, 12), asList(2, 5, 9, 12), asList(3, 5, 9, 12), asList(4, 5, 9, 12),
                asList(0, 6, 9, 12), asList(1, 6, 9, 12), asList(2, 6, 9, 12), asList(3, 6, 9, 12), asList(4, 6, 9, 12)
            ),
            result);
    }",1
"@Test public void manySourcesOfOne() {
        CartesianIterator<Integer> iter =
            new CartesianIterator<>(
                asList(
                    singletonList(1).iterator(),
                    singletonList(2).iterator(),
                    singletonList(3).iterator(),
                    singletonList(4).iterator()));

        List<List<Integer>> result = newArrayList(iter);

        assertEquals(singletonList(asList(1, 2, 3, 4)), result);
    }",1
"@Test public void oneSourceOfManyAtPositionMid() {
        CartesianIterator<Integer> iter =
            new CartesianIterator<>(
                asList(
                    singletonList(1).iterator(),
                    singletonList(2).iterator(),
                    asList(3, 4, 5).iterator(),
                    singletonList(6).iterator()));

        List<List<Integer>> result = newArrayList(iter);

        assertEquals(
            asList(
                asList(1, 2, 3, 6),
                asList(1, 2, 4, 6),
                asList(1, 2, 5, 6)),
            result);
    }",1
"@Test public void singleSourceIsEmpty() {
        CartesianIterator<Integer> iter =
            new CartesianIterator<>(singletonList(emptyIterator()));

        List<List<Integer>> result = newArrayList(iter);

        assertEquals(0, result.size());
    }",1
"@Test public void inRangeMinOnlyOnBound() {
        assertTrue(inRangeMinOnly.test(-3));
    }",1
"@Test public void inRangeUnbounded() {
        assertTrue(inRangeUnbounded.test(2));
    }",1
"@Test public void leastMagnitudeBothLessThanZero() {
        assertEquals(
            Integer.valueOf(-1),
            Comparables.leastMagnitude(-4, -1, 0));
    }",1
"@Test public void leastMagnitudePositiveMaxOnly() {
        assertEquals(
            Integer.valueOf(0),
            Comparables.leastMagnitude(null, 5, 0));
    }",1
"@Test public void leastMagnitudeStraddlingZero() {
        assertEquals(
            Integer.valueOf(0),
            Comparables.leastMagnitude(-2, 4, 0));
    }",1
"@Test public void whenDiscardRatioExceededEvenWithSomeSuccesses()
        throws Exception {

        PropertyParameterContext parameter =
            new PropertyParameterContext(
                ParameterTypeContext.forParameter(parameter()))
                    .annotate(annotatedElement());

        PropertyParameterGenerationContext gen =
            new PropertyParameterGenerationContext(
                parameter,
                new GeneratorRepository(random).register(new Countdown()),
                new GeometricDistribution(),
                random,
                new TupleParameterSampler(20));

        DiscardRatioExceededException ex =
            assertThrows(
                DiscardRatioExceededException.class,
                () -> {
                    while (gen.attempts() < 100)
                        gen.generate();
                }",1
"@Test public void weakSanityCheckForDistributionOfChooseLongs() {
        boolean[] hits = new boolean[5];
        SourceOfRandomness random = new SourceOfRandomness(new Random(0));

        for (int i = 0; i < 100; i++) {
            int index =
                (int) Ranges.choose(random, 0, (long) hits.length - 1);
            hits[index] = true;
        }",1
"@Test
    public void testQueryExecutionCountWhenScrollingApi() {
        Elasticsearch5SearchIndex searchIndex = (Elasticsearch5SearchIndex) ((GraphWithSearchIndex) graph).getSearchIndex();
        searchIndex.getConfig().getGraphConfiguration().set(GraphConfiguration.SEARCH_INDEX_PROP_PREFIX + ""."" + ElasticsearchSearchIndexConfiguration.QUERY_PAGE_SIZE, 1);

        graph.prepareVertex(""v1"", VISIBILITY_A).save(AUTHORIZATIONS_A);
        graph.prepareVertex(""v2"", VISIBILITY_A).save(AUTHORIZATIONS_A);
        graph.flush();

        long startingNumQueries = getNumQueries();

        QueryResultsIterable<Vertex> vertices = graph.query(AUTHORIZATIONS_A).vertices();
        assertResultsCount(2, vertices);
        assertEquals(startingNumQueries + 4, getNumQueries());

        searchIndex = (Elasticsearch5SearchIndex) ((GraphWithSearchIndex) graph).getSearchIndex();
        searchIndex.getConfig().getGraphConfiguration().set(GraphConfiguration.SEARCH_INDEX_PROP_PREFIX + ""."" + ElasticsearchSearchIndexConfiguration.QUERY_PAGE_SIZE, 2);

        graph.prepareVertex(""v3"", VISIBILITY_A).save(AUTHORIZATIONS_A);
        graph.flush();

        vertices = graph.query(AUTHORIZATIONS_A).vertices();
        assertResultsCount(3, vertices);
        assertEquals(startingNumQueries + 8, getNumQueries());
    }",1
"@Test
    public void testTestClassQuick() {
        TestClass testClass = new TestClass(""value1"", 42);
        QuickKryoVertexiumSerializer serializer = new QuickKryoVertexiumSerializer(graphConfiguration);
        byte[] v = serializer.objectToBytes(testClass);
        assertEquals(testClass, serializer.bytesToObject(v));
    }",1
"@Test
    public void existingFileShouldBeDeletedWhenStreamIsClosed() throws IOException {
        file = File.createTempFile(getClass().getSimpleName(), null);
        file.deleteOnExit();

        AutoDeleteFileInputStream adFileInputStream = new AutoDeleteFileInputStream(file);
        assertTrue(file.exists());

        adFileInputStream.close();
        assertFalse(file.exists());
    }",1
"@Test
    public void currentTimeMillisReturnsEverIncreasingTime() {
        List<Long> times = new ArrayList<>(NUM_ITERATIONS);
        // iterate without sleeping to insure IncreasingTime will encounter duplicate system times.
        for (int i = 0; i < NUM_ITERATIONS; i++) {
            times.add(IncreasingTime.currentTimeMillis());
        }",1
"@Test
    public void testText() throws Exception {


        final AtomicBoolean connected = new AtomicBoolean(false);

        final ServletContainer container = ServletContainer.Factory.newInstance();

        DeploymentUtils.setupServlet(new ServletInfo(""websocket"", WebSocketServlet.class,
                new ImmediateInstanceFactory<Servlet>(new WebSocketServlet(new WebSocketConnectionCallback() {
                    @Override
                    public void onConnect(final WebSocketHttpExchange exchange, final WebSocketChannel channel) {
                        connected.set(true);
                        channel.getReceiveSetter().set(new AbstractReceiveListener() {

                            @Override
                            protected void onFullTextMessage(WebSocketChannel channel, BufferedTextMessage message) throws IOException {
                                final String string = message.getData();
                                if(string.equals(""hello"")) {
                                    WebSockets.sendText(""world"", channel, null);
                                }",1
"@Test
    public void testClientSideIdleTimeout() throws Exception {
        //make a sub class
        CountDownLatch latch = new CountDownLatch(1);
        CloseCountdownEndpoint c = new CloseCountdownEndpoint(latch);

        Session session = deployment.connectToServer(c, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws/chat/Bob""));
        session.setMaxIdleTimeout(100);
        Assert.assertTrue(latch.await(2000, TimeUnit.MILLISECONDS));
        Assert.assertFalse(session.isOpen());

    }",1
"@Test
    public void testEncodingAndDecodingBinary() throws Exception {
        final byte[] payload = ""hello"".getBytes();
        final FutureResult<?> latch = new FutureResult<>();

        WebSocketTestClient client = new WebSocketTestClient(WebSocketVersion.V13, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws/encoding/Stuart""));
        client.connect();
        client.send(new BinaryWebSocketFrame(Unpooled.wrappedBuffer(payload)), new FrameChecker(TextWebSocketFrame.class, ""hello Stuart"".getBytes(), latch));
        latch.getIoFuture().get();
        client.destroy();
    }",1
"@Test
  public void acceptedClientIdAutoGenerated(TestContext context) {

    this.expectedReturnCode = MqttConnectReturnCode.CONNECTION_ACCEPTED;

    try {
      MemoryPersistence persistence = new MemoryPersistence();
      MqttClient client = new MqttClient(String.format(""tcp://%s:%d"", MQTT_SERVER_HOST, MQTT_SERVER_PORT), """", persistence);
      client.connect();
    }",1
"@Test
  public void refusedServerUnavailable(TestContext context) {

    this.expectedReturnCode = MqttConnectReturnCode.CONNECTION_REFUSED_SERVER_UNAVAILABLE;

    try {
      MemoryPersistence persistence = new MemoryPersistence();
      MqttClient client = new MqttClient(String.format(""tcp://%s:%d"", MQTT_SERVER_HOST, MQTT_SERVER_PORT), ""12345"", persistence);
      client.connect();
      context.fail();
    }",1
"@Test
  public void refusedUnacceptableProtocolVersion(TestContext context) {

    this.expectedReturnCode = MqttConnectReturnCode.CONNECTION_REFUSED_UNACCEPTABLE_PROTOCOL_VERSION;

    try {
      MemoryPersistence persistence = new MemoryPersistence();
      MqttConnectOptions options = new MqttConnectOptions();
      // trying the old 3.1
      options.setMqttVersion(MqttConnectOptions.MQTT_VERSION_3_1);
      MqttClient client = new MqttClient(String.format(""tcp://%s:%d"", MQTT_SERVER_HOST, MQTT_SERVER_PORT), ""12345"", persistence);
      client.connect(options);
      context.fail();
    }",1
"@Test
    public void testFieldHasValue() {
        String stringValue = ""value1"";
        Integer intValue = 1;
        long longValue = 2L;
        Float floatValue = 4.7f;
        double doubleValue = 3.5d;
        List<String> listValue = Arrays.asList(""some"", ""list"");
        ImmutableMap<String, String> mapValue = ImmutableMap.of(""some"", ""map"");
        String templateValue = ""{{templateField}",1
"@Test
    public void testFieldNotExists() {
        String field = ""field1"";
        String value = ""value1"";

        InCondition inCondition = new InCondition(field, value);

        Doc doc = createDoc(""field2"", ""value2"");

        assertThat(inCondition.evaluate(doc)).isFalse();
    }",1
"@Test
    public void testInvalidRegex() {
        String field = ""field1"";
        String invalidRegexEscaping = ""Wed\\""+'x';
        assertThatThrownBy(() -> new MatchRegexCondition(field, invalidRegexEscaping, false, false))
                .isInstanceOf(PatternSyntaxException.class)
                .hasMessageContaining(""Illegal hexadecimal escape sequence near index"");

        String invalidRegex = ""[]"";
        assertThatThrownBy(() -> new MatchRegexCondition(field, invalidRegex, false, false))
                .isInstanceOf(PatternSyntaxException.class)
                .hasMessageContaining(""Unclosed character class near index"");
    }",1
"@Test
    public void testGte() {
        String field = ""field1"";
        Long gte = 10l;


        Map<String, Object> config = createConfig(""field"", field,
                ""gte"", gte);
        MathComparatorCondition mathComparatorCondition = new MathComparatorCondition.Factory().create(config, conditionParser);

        Doc doc = createDoc(""field1"", 15l);
        assertThat(mathComparatorCondition.evaluate(doc)).isTrue();

        doc = createDoc(""field1"", 10);
        assertThat(mathComparatorCondition.evaluate(doc)).isTrue();

        doc = createDoc(""field1"", 5l);
        assertThat(mathComparatorCondition.evaluate(doc)).isFalse();
    }",1
"@Test
    public void testGtAndLt() {
        String field = ""field1"";
        Long lt = 20l;
        Long gt = 10l;


        Map<String, Object> config = createConfig(""field"", field,
                ""lt"", lt,
                ""gt"", gt);
        MathComparatorCondition mathComparatorCondition = new MathComparatorCondition.Factory().create(config, conditionParser);

        Doc doc = createDoc(""field1"", 15l);
        assertThat(mathComparatorCondition.evaluate(doc)).isTrue();

        doc = createDoc(""field1"", 10);
        assertThat(mathComparatorCondition.evaluate(doc)).isFalse();

        doc = createDoc(""field1"", 20);
        assertThat(mathComparatorCondition.evaluate(doc)).isFalse();

        doc = createDoc(""field1"", 5l);
        assertThat(mathComparatorCondition.evaluate(doc)).isFalse();

        doc = createDoc(""field1"", 25l);
        assertThat(mathComparatorCondition.evaluate(doc)).isFalse();
    }",1
"@Test
    public void testLte() {
        String field = ""field1"";
        Long lte = 10l;


        Map<String, Object> config = createConfig(""field"", field,
                ""lte"", lte);
        MathComparatorCondition mathComparatorCondition = new MathComparatorCondition.Factory().create(config, conditionParser);

        Doc doc = createDoc(""field1"", 15l);
        assertThat(mathComparatorCondition.evaluate(doc)).isFalse();

        doc = createDoc(""field1"", 10);
        assertThat(mathComparatorCondition.evaluate(doc)).isTrue();

        doc = createDoc(""field1"", 5l);
        assertThat(mathComparatorCondition.evaluate(doc)).isTrue();
    }",1
"@Test
    public void testParseConditionalExecutionStep() {
        List<ExecutionStepDefinition> executionStepDefinitionList = Collections.singletonList(
                new ConditionalExecutionStepDefinition(
                        createAndExistsConditionDefinition(),
                        Collections.singletonList(
                                createAddTagStepDefinition()
                        ),
                        Collections.singletonList(
                                createAddTagStepDefinition()
                        )));

        List<ExecutionStep> executionSteps = executionStepsParser.parse(executionStepDefinitionList);
        assertThat(executionSteps.size()).isEqualTo(1);

        ConditionalExecutionStep conditionalExecutionStep = (ConditionalExecutionStep) executionSteps.get(0);

        assertThat(conditionalExecutionStep.getCondition()).isInstanceOf(AndCondition.class);

        ProcessorExecutionStep onTrueExecutionStep = (ProcessorExecutionStep) conditionalExecutionStep.getOnTrue().get(0);
        assertThat(onTrueExecutionStep.getProcessor()).isInstanceOf(AddTagProcessor.class);

        ProcessorExecutionStep onFalseExecutionStep = (ProcessorExecutionStep) conditionalExecutionStep.getOnFalse().get(0);
        assertThat(onFalseExecutionStep.getProcessor()).isInstanceOf(AddTagProcessor.class);
    }",1
"@Test
    public void testParseOnFailureExecutionStep() {
        List<ExecutionStepDefinition> executionStepDefinitionList = Collections.singletonList(
                createAddTagStepDefinition(Collections.singletonList(
                        createAddTagStepDefinition()
                ))
        );

        List<ExecutionStep> executionSteps = executionStepsParser.parse(executionStepDefinitionList);

        ProcessorExecutionStep processorExecutionStep = (ProcessorExecutionStep) executionSteps.get(0);
        List<ExecutionStep> onFailureExecutionSteps = processorExecutionStep.getOnFailureExecutionSteps().get();

        assertThat(onFailureExecutionSteps.size()).isEqualTo(1);

        ProcessorExecutionStep onFailureExecutionStep = (ProcessorExecutionStep) onFailureExecutionSteps.get(0);
        assertThat(onFailureExecutionStep.getProcessor()).isInstanceOf(AddTagProcessor.class);
    }",1
"@Test
    public void testParseOnSuccessExecutionStep() {
        List<ExecutionStepDefinition> executionStepDefinitionList = Collections.singletonList(
                createAddTagStepDefinition(null, null, Collections.singletonList(createAddTagStepDefinition()))
        );

        List<ExecutionStep> executionSteps = executionStepsParser.parse(executionStepDefinitionList);

        ProcessorExecutionStep processorExecutionStep = (ProcessorExecutionStep) executionSteps.get(0);
        List<ExecutionStep> onSuccessExecutionSteps = processorExecutionStep.getOnSuccessExecutionSteps().get();

        assertThat(onSuccessExecutionSteps.size()).isEqualTo(1);

        ProcessorExecutionStep onSuccessExecutionStep = (ProcessorExecutionStep) onSuccessExecutionSteps.get(0);
        assertThat(onSuccessExecutionStep.getProcessor()).isInstanceOf(AddTagProcessor.class);
    }",1
"@Test
    public void testParseProcessorExecutionStep() {
        List<ExecutionStepDefinition> executionStepDefinitionList = Collections.singletonList(
                createAddTagStepDefinition()
        );

        List<ExecutionStep> executionSteps = executionStepsParser.parse(executionStepDefinitionList);
        assertThat(executionSteps.size()).isEqualTo(1);

        ProcessorExecutionStep processorExecutionStep = (ProcessorExecutionStep) executionSteps.get(0);
        assertThat(processorExecutionStep.getProcessor()).isInstanceOf(AddTagProcessor.class);

        Optional<List<ExecutionStep>> onFailureExecutionSteps = processorExecutionStep.getOnFailureExecutionSteps();
        assertThat(onFailureExecutionSteps.isPresent()).isFalse();
    }",1
"@Test
    public void testMultipleNamedCapturesWithSameName() throws InterruptedException {
        Map<String, String> bank = new HashMap<>();
        bank.put(""SINGLEDIGIT"", ""[0-9]"");
        Grok grok = new Grok(bank, ""%{SINGLEDIGIT:num}",1
"@Test
    public void testNumericCaptures() throws InterruptedException {
        Map<String, String> bank = new HashMap<>();
        bank.put(""BASE10NUM"", ""(?<![0-9.+-])(?>[+-]?(?:(?:[0-9]+(?:\\.[0-9]+)?)|(?:\\.[0-9]+)))"");
        bank.put(""NUMBER"", ""(?:%{BASE10NUM}",1
"@Test
    public void testConditionalElse() {
        String json = createJson(createMap(
                ""steps"", createList(
                        createMap(
                                ""if"", createMap(
                                        ""condition"", createMap(
                                                ""testCondition"", createMap(""value"", ""message1"")),
                                        ""then"", createList(
                                                createMap(""removeField"", createMap(
                                                        ""name"", ""on true"",
                                                        ""config"", createMap(""path"", ""field1"")
                                                ))
                                        ),
                                        ""else"", createList(
                                                createMap(""removeField"", createMap(
                                                        ""name"", ""on false"",
                                                        ""config"", createMap(""path"", ""field2"")
                                                ))
                                        )
                                ))
                )
        ));

        PipelineDefinition pipelineDefinition = PipelineDefinitionJsonParser.parse(json);
        assertThat(pipelineDefinition.getExecutionSteps().size()).isEqualTo(1);

        ConditionalExecutionStepDefinition executionStepDefinition =
                (ConditionalExecutionStepDefinition) pipelineDefinition.getExecutionSteps().get(0);

        List<ExecutionStepDefinition> onFalse = executionStepDefinition.getOnFalse().get();
        assertThat(onFalse.size()).isEqualTo(1);

        ProcessorExecutionStepDefinition onFalseProcessorExecutionStep = (ProcessorExecutionStepDefinition) onFalse.get(0);
        assertThat(onFalseProcessorExecutionStep.getName().get()).isEqualTo(""on false"");
        assertThat(onFalseProcessorExecutionStep.getOnFailureExecutionStepDefinitionList().isPresent()).isFalse();

        ProcessorDefinition processorDefinition2 = onFalseProcessorExecutionStep.getProcessorDefinition();
        assertThat(processorDefinition2.getType()).isEqualTo(""removeField"");
        assertThat(processorDefinition2.getConfig().get(""path"")).isEqualTo(""field2"");
    }",1
"@Test
    public void testConditionalExecutionStep() {
        String fieldExists1 = ""fieldExists1"";
        String fieldExists2 = ""fieldExists2"";
        String fieldToAdd = ""fieldToAdd"";
        String valueOnTrue = ""valueOnTrue"";
        String valueOnFalse = ""valueOnFalse"";

        Pipeline pipeline = createPipeline(createConditionalExecutionStep(
                createExistsCondition(fieldExists1, fieldExists2),
                createExecutionSteps(
                        createAddFieldExecutionStep(""newField1"", ""value1""),
                        createAddFieldExecutionStep(fieldToAdd, valueOnTrue)
                ),
                createExecutionSteps(
                        createAddFieldExecutionStep(""newField1"", ""value1""),
                        createAddFieldExecutionStep(fieldToAdd, valueOnFalse))));

        Doc doc1 = createDoc(fieldExists1, ""value1"", fieldExists2, ""value2"");
        ExecutionResult executionResult = pipelineExecutor.execute(pipeline, doc1);
        assertThat(executionResult.isSucceeded()).isTrue();
        assertThat(executionResult.isOvertime()).isFalse();
        assertThat(doc1.getSource().get(""newField1"")).isEqualTo(""value1"");
        String value1 = doc1.getField(fieldToAdd);
        assertThat(value1).isEqualTo(valueOnTrue);

        Doc doc2 = createDoc(fieldExists1, ""value3"");
        ExecutionResult executionResult2 = pipelineExecutor.execute(pipeline, doc2);
        assertThat(executionResult2.isSucceeded()).isTrue();
        assertThat(executionResult2.isOvertime()).isFalse();
        assertThat(doc2.getSource().get(""newField1"")).isEqualTo(""value1"");
        String value2 = doc2.getField(fieldToAdd);
        assertThat(value2).isEqualTo(valueOnFalse);
        assertThat(pipelineExecutorMetrics.getTotalDocsSucceededProcessing()).isEqualTo(2);
    }",1
"@Test
    public void testFailOnFailureExecutionStep() {
        Pipeline pipeline = createStopOnFailurePipeline(
                createAddFieldExecutionStep(""newField1"", ""value1""),
                createFailAlwaysExecutionStep(
                        createAddFieldExecutionStep(""newField2"", ""value2"")),
                        createFailAlwaysExecutionStep()
                );

        Doc doc = createDoc(""id"", ""testFailOnFailureExecutionStep"", ""message"", ""hola"");

        ExecutionResult executionResult = pipelineExecutor.execute(pipeline, doc);
        assertThat(executionResult.isSucceeded()).isFalse();

        assertThat(doc.getSource().get(""newField1"")).isEqualTo(""value1"");
        assertThat(doc.getSource().get(""newField2"")).isEqualTo(""value2"");
        assertThat(overtimeProcessingDocs.contains(doc)).isFalse();
        assertThat(executionResult.isOvertime()).isFalse();
        assertThat(pipelineExecutorMetrics.getTotalDocsFailedProcessing()).isEqualTo(1);
        assertThat(pipelineExecutorMetrics.getTotalDocsSucceededProcessing()).isEqualTo(0);
    }",1
"@Test
    public void testFailureWithException() {
        Pipeline pipeline = createStopOnFailurePipeline(
                createAddFieldExecutionStep(""newField1"", ""value1""),
                createFailAlwaysExecutionStep(new ProcessorExecutionException(""failProcessor"", new RuntimeException(""fail message"")))
        );
        Doc doc = createDoc(""id"", ""testFailureWithException"", ""message"", ""hola"",
                ""type"", ""test"");

        ExecutionResult result = pipelineExecutor.execute(pipeline, doc);
        assertThat(result.isSucceeded()).isFalse();
        assertThat(result.isOvertime()).isFalse();
        assertThat(result.getError().get().getException().isPresent()).isTrue();

        assertThat(doc.getSource().get(""newField1"")).isEqualTo(""value1"");
        assertThat(overtimeProcessingDocs.contains(doc)).isFalse();
        assertThat(pipelineExecutorMetrics.getTotalDocsFailedProcessing()).isEqualTo(1);
        assertThat(pipelineExecutorMetrics.getTotalDocsSucceededProcessing()).isEqualTo(0);
    }",1
"@Test
    public void testKillLongProcessingExecution() {
        Pipeline pipeline = createPipeline(
                createAddFieldExecutionStep(""newField1"", ""value1""),
                createSleepExecutionStep(EXPIRED_THRESHOLD_TIME_MS + 300)
        );
        Doc doc = createDoc(""id"", ""testKillLongProcessingExecution"", ""message"", ""hola"",
                ""type"", ""test"");

        ExecutionResult executionResult = pipelineExecutor.execute(pipeline, doc);
        assertThat(executionResult.isExpired()).isTrue();
        assertThat(Thread.currentThread().isInterrupted()).isFalse();

        assertThat(doc.getSource().get(""newField1"")).isEqualTo(""value1"");
        assertThat(overtimeProcessingDocs.contains(doc)).isTrue();
        assertThat(pipelineExecutorMetrics.getTotalDocsOvertimeProcessing()).isEqualTo(1);
        assertThat(pipelineExecutorMetrics.getTotalDocsProcessingExpired()).isEqualTo(1);
    }",1
"@Test
    public void testConditional() {
        String pipelineString = ""{"" +
                ""steps: [{"" +
                ""    if: {"" +
                ""        condition: {"" +
                ""            and: ["" +
                ""                {"" +
                ""                    testCondition.value: message1"" +
                ""                }",1
"@Test
    public void testAppendValuesWhileFieldExist() {
        List<String> existingList = new ArrayList<>();
        existingList.add(EXISTING_VALUE);

        List<String> values = Arrays.asList(APPENDED_VALUE, ANOTHER_VALUE);
        AppendListProcessor appendListProcessor = createProcessor(AppendListProcessor.class, ""path"", FIELD_NAME, ""values"", values);
        Doc doc = createDoc(FIELD_NAME, existingList);

        assertThat(appendListProcessor.process(doc).isSucceeded()).isTrue();
        assertThat((List) doc.getField(FIELD_NAME)).isEqualTo(Arrays.asList(EXISTING_VALUE, APPENDED_VALUE, ANOTHER_VALUE));
    }",1
"@Test
    public void testAppendValuesWithTemplate() {
        List<String> values = Arrays.asList(ANOTHER_VALUE, ""{{"" + TEMPLATE_FIELD + ""}",1
"@Test
    public void testConvertToBoolean() {
        testConversion(""yes"", true);
    }",1
"@Test
    public void testWithPartialColumnsNames() {
        String field = ""message"";
        String csv = ""1,\""this\"",is,an,ip,\""192.168.1.1\"",true"";

        Doc doc = createDoc(field, csv);

        Map<String,Object> config = new HashMap<>();
        config.put(""field"", field);
        config.put(""columns"", Arrays.asList(""id"", ""field1"", ""field2"", ""field3"", ""field4""));

        CsvProcessor csvProcessor = new CsvProcessor.Factory().create(config);

        ProcessResult processResult = csvProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String) doc.getField(""id"")).isEqualTo(""1"");
        assertThat((String) doc.getField(""field1"")).isEqualTo(""this"");
        assertThat((String) doc.getField(""field2"")).isEqualTo(""is"");
        assertThat((String) doc.getField(""field3"")).isEqualTo(""an"");
        assertThat((String) doc.getField(""field4"")).isEqualTo(""ip"");
        assertThat((String) doc.getField(""column6"")).isEqualTo(""192.168.1.1"");
        assertThat((String) doc.getField(""column7"")).isEqualTo(""true"");
    }",1
"@Test
    public void testWithSeparatorAndQuoteChar() {
        String field = ""message"";
        String csv = ""1\t\\this\\\tis\tan\tip\t\\192.168.1.1\\"";

        Doc doc = createDoc(field, csv);

        Map<String,Object> config = new HashMap<>();
        config.put(""field"", field);
        config.put(""separator"", ""\t"");
        config.put(""quoteChar"", ""\\"");

        CsvProcessor csvProcessor = new CsvProcessor.Factory().create(config);

        ProcessResult processResult = csvProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String) doc.getField(""column1"")).isEqualTo(""1"");
        assertThat((String) doc.getField(""column2"")).isEqualTo(""this"");
        assertThat((String) doc.getField(""column3"")).isEqualTo(""is"");
        assertThat((String) doc.getField(""column4"")).isEqualTo(""an"");
        assertThat((String) doc.getField(""column5"")).isEqualTo(""ip"");
        assertThat((String) doc.getField(""column6"")).isEqualTo(""192.168.1.1"");
    }",1
"@Test
    public void testIso8601Format() {
        String field = ""datetime"";
        String targetField = ""@timestamp"";
        ZoneId zoneId = ZoneId.of(""UTC"");
        ZonedDateTime zonedDateTime = LocalDateTime.now().atZone(zoneId);
        String iso8601Format1 = zonedDateTime.format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ss,SSS""));
        String iso8601Format2 = zonedDateTime.format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ss.SSSSSSxxx""));
        Doc doc = createDoc(field, iso8601Format1);

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", Arrays.asList(""ISO8601""),
                ""timeZone"", zoneId.toString());

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        assertThat(dateProcessor.process(doc).isSucceeded()).isTrue();
        assertThat((String) doc.getField(targetField)).isEqualTo(zonedDateTime.format(DateProcessor.ELASTIC));

        doc = createDoc(field, iso8601Format2);

        assertThat(dateProcessor.process(doc).isSucceeded()).isTrue();
        assertThat((String) doc.getField(targetField)).isEqualTo(zonedDateTime.format(DateProcessor.ELASTIC));
    }",1
"@Test
    public void testISOFormatWithNumberValueInField() {
        String field = ""datetime"";
        String targetField = ""timestamp"";

        ZoneId zoneId = ZoneId.of(""UTC"");
        ZonedDateTime zonedDateTime = LocalDateTime.now().atZone(zoneId);
        Doc doc = createDoc(field, zonedDateTime.toInstant().toEpochMilli() / 1000);

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", Arrays.asList(""dd/MMM/yyyy:HH:mm:ss""));

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        assertThat(dateProcessor.process(doc).isSucceeded()).isFalse();
        assertThat(doc.hasField(targetField)).isFalse();
    }",1
"@Test
    public void testOutputForamtUnix() {
        String field = ""datetime"";
        String targetField = ""@timestamp"";
        ZoneId zoneId = ZoneId.of(""Europe/Paris"");
        String outputFormat = ""UNIX"";
        ZonedDateTime zonedDateTime = LocalDateTime.now().atZone(zoneId);
        String iso8601Format = zonedDateTime.format(DateTimeFormatter.ofPattern(""yyyy-MM-dd'T'HH:mm:ss,SSS""));
        Doc doc = createDoc(field, iso8601Format);

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", Arrays.asList(""ISO8601""),
                ""outputFormat"", outputFormat,
                ""timeZone"", zoneId.toString());

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        assertThat(dateProcessor.process(doc).isSucceeded()).isTrue();
        assertThat((String)doc.getField(targetField)).isEqualTo(zonedDateTime.format(DateProcessor.UNIX));
    }",1
"@Test
    public void testParseInvalidObjects() {
        String field = ""datetime"";
        String targetField = ""@timestamp"";
        ZoneId zoneId = ZoneId.of(""UTC"");
        Doc docWithMap = createDoc(field, ImmutableMap.of(""its"", ""a"", ""map"", ""should"", ""not"", ""work""));

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", Arrays.asList(""UNIX_MS""),
                ""timeZone"", zoneId.toString());

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        assertThat(dateProcessor.process(docWithMap).isSucceeded()).isFalse();

        Doc docWithList = createDoc(field, Arrays.asList(""its"", ""a"", ""list"", ""should"", ""not"", ""work""));

        assertThat(dateProcessor.process(docWithList).isSucceeded()).isFalse();
    }",1
"@Test
    public void testSeveralISOPatterns() {
        String field = ""datetime"";
        String targetField = ""@timestamp"";
        ZoneId zoneId = ZoneId.of(""UTC"");
        ZonedDateTime zonedDateTime = LocalDateTime.now().atZone(zoneId);
        List<String> formats = Arrays.asList(""dd/MM/yyyy HH:mm:ss"", ""yyyy-MM-dd'T'HH:mm:ssZ"", ""yyyy-MM-dd HH:mm:ss.SSSSS"", ""ddMMyyyy HHmmssSSS"");

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", formats,
                ""timeZone"", zoneId.toString());

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        formats.forEach(format -> {
            DateTimeFormatter formatter = DateTimeFormatter.ofPattern(format);
            String dateString = zonedDateTime.format(formatter);
            Doc doc = createDoc(field, dateString);

            ZonedDateTime expectedDateTime = LocalDateTime.parse(dateString, formatter).atZone(zoneId);

            assertThat(dateProcessor.process(doc).isSucceeded()).isTrue();
            assertThat((String) doc.getField(targetField)).isEqualTo(expectedDateTime.format(DateProcessor.ELASTIC));
        }",1
"@Test
    public void testUnixFormatString() {
        String field = ""datetime"";
        String targetField = ""@timestamp"";
        ZoneId zoneId = ZoneId.of(""Europe/Paris"");
        ZonedDateTime zonedDateTime = LocalDateTime.now().atZone(zoneId).truncatedTo(ChronoUnit.SECONDS);
        Doc doc = createDoc(field, String.valueOf(zonedDateTime.toInstant().toEpochMilli() / 1000));

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", Arrays.asList(""UNIX""),
                ""timeZone"", zoneId.toString());

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        assertThat(dateProcessor.process(doc).isSucceeded()).isTrue();
        assertThat((String) doc.getField(targetField)).isEqualTo(zonedDateTime.format(DateProcessor.ELASTIC));
    }",1
"@Test
    public void testUnixMsFormat() {
        String field = ""datetime"";
        String targetField = ""@timestamp"";
        ZoneId zoneId = ZoneId.of(""Europe/Paris"");
        ZonedDateTime zonedDateTime = LocalDateTime.now().atZone(zoneId);
        Doc doc = createDoc(field, zonedDateTime.toInstant().toEpochMilli());

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", Arrays.asList(""UNIX_MS""),
                ""timeZone"", zoneId.toString());

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        assertThat(dateProcessor.process(doc).isSucceeded()).isTrue();
        assertThat((String)doc.getField(targetField)).isEqualTo(zonedDateTime.format(DateProcessor.ELASTIC));
    }",1
"@Test
    public void testUnixMsFormatString() {
        String field = ""datetime"";
        String targetField = ""@timestamp"";
        ZoneId zoneId = ZoneId.of(""Europe/Paris"");
        ZonedDateTime zonedDateTime = LocalDateTime.now().atZone(zoneId);
        Doc doc = createDoc(field, String.valueOf(zonedDateTime.toInstant().toEpochMilli()));

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField,
                ""formats"", Arrays.asList(""UNIX_MS""),
                ""timeZone"", zoneId.toString());

        DateProcessor dateProcessor = createProcessor(DateProcessor.class, config);

        assertThat(dateProcessor.process(doc).isSucceeded()).isTrue();
        assertThat((String)doc.getField(targetField)).isEqualTo(zonedDateTime.format(DateProcessor.ELASTIC));
    }",1
"@Test
    public void testConstructor(){
        Doc doc = createDoc(""docSize"", 15);
        DocSizeProcessor sizeProcessor = createProcessor(DocSizeProcessor.class, createConfig(""targetField"", ""docSize_test""));
        ProcessResult processResult = sizeProcessor.process(doc);
        assertThat(processResult.isSucceeded()).isTrue();
        assertThat(doc.hasField(""docSize_test"")).isTrue();
    }",1
"@Test
    public void testInternalIp() {
        String ip = ""192.168.1.1"";
        String source = ""ipString"";
        String target = ""geoip"";

        Map<String, Object> config = createConfig(""sourceField"", source,
                ""tagsOnSuccess"", Arrays.asList(""geoip""));

        GeoIpProcessor geoIpProcessor = createProcessor(GeoIpProcessor.class, config);

        Doc doc = createDoc(source, ip);

        assertThat(geoIpProcessor.process(doc).isSucceeded()).isTrue();
        assertThat(doc.hasField(target)).isFalse();
    }",1
"@Test
    public void testValidIpWithSpecificProperties() {
        String ip = ""81.2.69.144"";
        String source = ""ipString"";

        Map<String,Object> config = createConfig(""sourceField"", source,
                ""properties"", Arrays.asList(""ip"", ""country_name"", ""country_code2"", ""city_name""));
        GeoIpProcessor geoIpProcessor = createProcessor(GeoIpProcessor.class, config);

        Doc doc = createDoc(source, ip);

        ProcessResult processResult = geoIpProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat(doc.hasField(""geoip"")).isTrue();
        Map<String, Object> geoIp = doc.getField(""geoip"");
        assertThat(geoIp.size()).isGreaterThanOrEqualTo(3);
        assertThat(geoIp.get(""country_name"")).isEqualTo(""United Kingdom"");
        assertThat(geoIp.get(""ip"")).isEqualTo(ip);
    }",1
"@Test
    public void testConverters() throws InterruptedException {
        String field = ""message"";
        List<String> patterns = Arrays.asList(""%{NUMBER:int:int}",1
"@Test
    public void testGrokParseFailure() throws InterruptedException {
        String field = ""message"";
        List<String> patterns = Arrays.asList(""%{COMBINEDAPACHELOG}",1
"@Test
    public void testPatternsPriority() throws InterruptedException {
        String field = ""message"";
        List<String> patterns = Arrays.asList(
                ""%{COMBINEDAPACHELOG}",1
"@Test
    public void testValidJsonWithoutTarget() {
        String field = ""message"";

        Map<String,Object> jsonMap = JsonUtils.fromJsonString(Map.class, VALID_JSON);

        Doc doc = createDoc(field, VALID_JSON);

        JsonProcessor jsonProcessor = createProcessor(JsonProcessor.class, createConfig(""field"", field));

        ProcessResult processResult = jsonProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        jsonMap.entrySet().forEach(entry ->
            assertThat((Object) doc.getField(entry.getKey())).isEqualTo(entry.getValue())
        );
        assertThat(doc.hasField(field)).isTrue();
    }",1
"@Test
    public void testAllowDuplicateValues() throws InterruptedException {
        String field = ""message"";
        Doc doc = createDoc(field, KEY_VALUE_MESSAGE_WITH_DUPLICATE_KEYS);

        Map<String,Object> config = createConfig(""field"", field);

        KeyValueProcessor kvProcessor = createProcessor(KeyValueProcessor.class, config);

        ProcessResult processResult = kvProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((List) doc.getField(""sameKey"")).isEqualTo(Arrays.asList(""value1"", ""value2"", ""value3"", ""value4""));
    }",1
"@Test
    public void testDontAllowDuplicateValues() throws InterruptedException {
        String field = ""message"";
        Doc doc = createDoc(field, KEY_VALUE_MESSAGE_WITH_DUPLICATE_KEYS);

        Map<String,Object> config = createConfig(""field"", field,
                ""allowDuplicateValues"", false);

        KeyValueProcessor kvProcessor = createProcessor(KeyValueProcessor.class, config);

        ProcessResult processResult = kvProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String) doc.getField(""sameKey"")).isEqualTo(""value1"");
    }",1
"@Test
    public void testNullField() throws InterruptedException {
        String field = ""message"";
        Doc doc = createDoc(field, null);

        Map<String,Object> config = createConfig(""field"", field);

        KeyValueProcessor kvProcessor = createProcessor(KeyValueProcessor.class, config);

        ProcessResult processResult = kvProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isFalse();
    }",1
"@Test
    public void testWithTargetField() throws InterruptedException {
        String field = ""message"";
        String targetField = ""kv"";
        Doc doc = createDoc(field, getDefaultMessage());

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField);

        KeyValueProcessor kvProcessor = createProcessor(KeyValueProcessor.class, config);

        ProcessResult processResult = kvProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat(doc.hasField(targetField)).isTrue();
        Map<Object,String> kv = doc.getField(targetField);
        assertThat(kv.get(""simple"")).isEqualTo(""value"");
        assertThat(kv.get(""brackets"")).isEqualTo(""with space"");
        assertThat(kv.get(""roundBrackets"")).isEqualTo(""with two spaces"");
        assertThat(kv.get(""angleBrackets"")).isEqualTo(""without"");
        assertThat(kv.get(""%trim%"")).isEqualTo(""!value!"");
        assertThat(kv.get(""complex"")).isEqualTo(""innerKey=innerValue withBrackets=(another innerValue)"");
    }",1
"@Test
    public void testRenameField() {
        String fromField = RandomStringUtils.randomAlphanumeric(5);
        String nestedToField = RandomStringUtils.randomAlphanumeric(5) + ""."" + RandomStringUtils.randomAlphanumeric(5);
        Doc doc = createDoc(fromField, ""value"");

        Map<String, Object> config = createConfig(""from"", fromField,
                ""to"", nestedToField);
        RenameFieldProcessor renameFieldProcessor = createProcessor(RenameFieldProcessor.class, config);

        assertThat(renameFieldProcessor.process(doc).isSucceeded()).isTrue();

        assertThat((String)doc.getField(nestedToField)).isEqualTo(""value"");
        assertThatThrownBy(() -> doc.getField(fromField)).isInstanceOf(IllegalStateException.class);
    }",1
"@Test
    public void testRenameJsonWithTemplateInTo() {
        Map valueBeingRename = ImmutableMap.of(""x"", 5);

        Doc doc = createDoc(
                ""field-a"", ""field-b"",
                ""field-c"", valueBeingRename);

        Map<String, Object> config = createConfig(
                ""from"", ""field-c"",
                ""to"", ""{{field-a}",1
"@Test
    public void testRenameWithTemplateInTo() {
        Doc doc = createDoc(""field-a"", ""field-b"",
                            ""field-c"", ""value-of-c"");

        Map<String, Object> config = createConfig(
                ""from"", ""field-c"",
                ""to"", ""{{field-a}",1
"@Test
    public void testStringFieldNotContainedSeparator() {
        String field = ""fieldName"";
        String value = ""this string is gonna be without any commas"";

        Doc doc = createDoc(field, value);

        SplitProcessor splitProcessor = createProcessor(SplitProcessor.class, createConfig(""field"", field, ""separator"", "",""));

        ProcessResult processResult = splitProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String) doc.getField(field)).isEqualTo(value);
    }",1
"@Test
    public void testSubstitute() {
        String field = ""message"";
        String message = ""I'm g@nna \""remove\"" $ome spec!al characters"";

        String pattern = ""\\$|@|!|\\\""|'"";
        String replacement = ""."";
        Map<String, Object> config = createConfig(""field"", field,
                ""pattern"", pattern,
                ""replacement"", replacement);

        Doc doc = createDoc(field, message);

        SubstituteProcessor substituteProcessor = createProcessor(SubstituteProcessor.class, config);

        ProcessResult processResult = substituteProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String) doc.getField(field)).isEqualTo(""I.m g.nna .remove. .ome spec.al characters"");
    }",1
"@Test
    public void testListOfStringFields() {
        List<String> fields = Arrays.asList(""field1"", ""field2"", ""field3"");

        Doc doc = createDoc(""field1"", ""lower case"",
                ""field2"", ""camelCase"",
                ""field3"", ""UPPER CASE"");

        UpperCaseProcessor upperCaseProcessor = createProcessor(UpperCaseProcessor.class, ""fields"", fields);

        ProcessResult processResult = upperCaseProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String) doc.getField(""field1"")).isEqualTo(""LOWER CASE"");
        assertThat((String) doc.getField(""field2"")).isEqualTo(""CAMELCASE"");
        assertThat((String) doc.getField(""field3"")).isEqualTo(""UPPER CASE"");
    }",1
"@Test
    public void testLongInvalidUserAgent() {
        String field = ""agent"";
        String targetField = ""user_agent"";
        String uaString = ""CuYDtymfoAScnOxlaYbvTZiOZEWVJsbLZIZBGPvDVjuqcxytUchOaksgiArcMcBhbmfynRsdFMpgSpUrbLqPncRqpMLuvlNvAkEhllRxWcTQSTRqVZVBfIYDVaCdZSd"" +
                ""nGivuEqYjSvNrywusJkRPyduDWrLVulUhjwcjIdBcdGscnJbSMdnHAhynpMrkKCGZbObUUHVrnDQKahvIgWImBAjfmGiFiRkqMwbarGNyZKyAARSairELcVQjJUntvraJvwjaLERayVhdA"" +
                ""ChAQPQtxDLJWKFgrPsmopUOGIHDsvWfesGmBMlmtBuqVZYLmhdntvtMQIoWSETeqMWbvZhodEqewrrZhIepPffvrQCYaNtVLQDHtRxLtPkTotNypeNFrWpUDybqFGhXXMoGZmLjQIsEMYSNpAbx"" +
                ""GjwelEhCGtUWVpLQpqRjdImPEPJoWFjqMDYfmgXHiLXAZTxUWXIolDvPuAWQMMSdMWGoqunKcscNUgfLpepUUKcQInfkNtbfVgbKHQVnIQpxxsClYbdfUmtclWtEPlnacpqBmmTvqAuqFnETBCMoiw"" +
                ""MTNGYMkcnpnATSkFIiiBdfNDRxqFSVLjyJvErEUaNLwjZBjZQaTlZRqcdJLnNyncDiJnuTjYeBNbjesLxPHuhnmWQMyAqSUXQNnlAQEyIuMeMgUDOopchnbywdvZPAFeFqZiRZHvcyOuPfrrHnyTDXhvrb"" +
                ""PvsjXhGORhwKVxqeFTekIhaXJVRMyosFcixPIrMEJWQTWlrcBUkCoNFNkoAFgNgLnZKLNhqKGKMXAPydwaCDWnMpfSuLVrKtJItkPQlorTRZFumHILjeTXYWBQbFhsZQXZCgGKfFFVRmODbjNGuTGFBRNTkF"" +
                ""nQkyORSPrTBRYYoCnPrJISdVxKBDaNDObbUUdMruDDoZRHxiRmOLWoYXwJvYblLNTVPAWkuHjhaETjVrJIyjmDJJcwpGhjFsHbNkUviOonqgssqjRidcrOibeXmmZxopIPrJIQyFOpEOpqCxWXotAefjlUtraVxC"" +
                ""iVXZAnwbvAASmAZnVWEMfeyDnZsyAYkKkHVgfRZMNfvBTRHpOiljWfPxlfuGwEIOHDPjJrqcvBidPoGASKqGucXnHrCApdJLVsIfVgQvNdiipSULVHhTvCcYMvMbPEOLiLtxHxwSmmGNNyGHlPJHixdBnVecmlwDggRArN"" +
                ""YFThgTPZnhJLOVdnAvAqoLkNmnVZtqsycjxaOWgQHdZRGFLePqaoibfSYjZERticqPpDymJgQDgMLTbpwIbqHggWaNEcAeUKlRjImqLjeJDBkELMIvhPSWDWsoZAcpBNnFYKtSbMEGtTWUjNQAJUOLUVqFFWQeS"" +
                ""LcuegjfsKxRyLSLOSbhLimlZSbBTWvZOqHuSaWGGnHtEQODgmlovxEOLeVxromEJDjXOPKSxFTaoNbFBGdvaPyIhBiDugAUEptbgQDIBKWXAVBCBiTjNolVjpTbMqYyucMfTVuCVqOHqxOXamDEjlUgXKBfCdwuFiKFsFfut"" +
                ""pcBMdYntTglEUMDigTQeDmfRErWVxJDNJhgFyCwtxcXqCtStUqHLPiwKZMrwkqDyexijsBpSdtlKBRXWCXMjrXYQmcsqgLThYWPvmrNTbyfpNEQUCimIGryiHnyCLkIxwqeZCsGpbeenALhrCfNcNCumNqwoa"" +
                ""gPXIXySbhpLkkqPZZqIWAqeaufviIYnLKswSxoLQpMOlMBhmkkBPjejWHjflHJtFZUSZWoytPnpjGYOOBFdqDMpDLOwoZsnuAIRwdepUreybIyQIafxigaLrayUNisocGYdlJJWagcoNPjTUtdjWiWwwqeLXh"" +
                ""KvJGGVYgBSMYGeeLKsuEliUYQNZVAurpNmrlHCYrIpTdURiPRTWACViTHnUUvHZYWOsgUUWgVKGBQQfuMOVoMWuoIpfaVoNoVvUnlbdoTvpCcbyGOyEdInlatGCxgwAKYKDlyUbgcwDNoEtotgLJOYXYxoxh"" +
                ""rrXtnMCXjsJtWfdBUfHtTZXvibUxVrqcCxjpQFVhCCNrtvmxKyPPAEMmKYaYbbWgXCiXBHgUJKprxlaLHbgPlfAnNggqUHhkuDXQR"";
        Doc doc = createDoc(field, uaString);

        Map<String,Object> config = createConfig(""field"", field,
                ""targetField"", targetField);
        UserAgentProcessor uaProceesor = createProcessor(UserAgentProcessor.class, config);
        ProcessResult processResult = uaProceesor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat(doc.hasField(targetField)).isTrue();

        Map<String,String> userAgent = doc.getField(targetField);

        assertThat(userAgent.get(""name"")).isEqualTo(""Other"");
        assertThat(userAgent.get(""os"")).isEqualTo(""Other"");
        assertThat(userAgent.get(""os_name"")).isEqualTo(""Other"");
        assertThat(userAgent.get(""device"")).isEqualTo(""Other"");

        assertThat(doc.hasField(""tags"")).isTrue();
        assertThat((List)doc.getField(""tags"")).isNotEmpty().contains(""_user_agent_truncated"");

    }",1
"@Test
    public void testUserAgentWithPrefix() {
        String field = ""agent"";
        String prefix = ""UA-"";
        String uaString = ""Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36"";
        Doc doc = createDoc(field, uaString);

        Map<String,Object> config = createConfig(""field"", field,
                ""prefix"", prefix);
        UserAgentProcessor uaProceesor = createProcessor(UserAgentProcessor.class, config);

        ProcessResult processResult = uaProceesor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String)doc.getField(prefix + ""name"")).isEqualTo(""Chrome"");
        assertThat((String)doc.getField(prefix + ""major"")).isEqualTo(""54"");
        assertThat((String)doc.getField(prefix + ""minor"")).isEqualTo(""0"");
        assertThat((String)doc.getField(prefix + ""patch"")).isEqualTo(""2840"");

        assertThat((String)doc.getField(prefix + ""os"")).isEqualTo(""Mac OS X 10.10.5"");
        assertThat((String)doc.getField(prefix + ""os_name"")).isEqualTo(""Mac OS X"");
        assertThat((String)doc.getField(prefix + ""os_major"")).isEqualTo(""10"");
        assertThat((String)doc.getField(prefix + ""os_minor"")).isEqualTo(""10"");
        assertThat((String)doc.getField(prefix + ""os_patch"")).isEqualTo(""5"");

        assertThat((String)doc.getField(prefix + ""device"")).isEqualTo(""Other"");
    }",1
"@Test
    public void testInvalidXml() {
        String field = ""xml"";

        Doc doc = createDoc(field, INVALID_XML);

        XmlProcessor xmlProcessor = createProcessor(XmlProcessor.class, ""field"", field);

        ProcessResult processResult = xmlProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isFalse();
    }",1
"@Test
    public void testValidXml() {
        String field = ""xml"";

        Doc doc = createDoc(field, VALID_XML);

        XmlProcessor xmlProcessor = createProcessor(XmlProcessor.class, ""field"", field);

        ProcessResult processResult = xmlProcessor.process(doc);

        assertThat(processResult.isSucceeded()).isTrue();
        assertThat((String) doc.getField(""country.id"")).isEqualTo(""1"");
        assertThat((String) doc.getField(""country.name"")).isEqualTo(""Israel"");
        assertThat(doc.hasField(""country.TestEmptyField"")).isFalse();
        assertThatThrownBy(() -> doc.getField(""country.TestEmptyField"")).isInstanceOf(IllegalStateException.class);
        assertThat((List) doc.getField(""country.cities.city""))
                .isEqualTo(Arrays.asList(ImmutableMap.of(""name"", ""Jerusalem""),
                        ImmutableMap.of(""name"", ""Tel Aviv"")));
        assertThat((String) doc.getField(""country.lat"")).isEqualTo(""31.0461"");
        assertThat((String) doc.getField(""country.long"")).isEqualTo(""34.8516"");
        assertThat((String) doc.getField(""country.continent"")).isEqualTo(""Asia"");
        assertThat((String) doc.getField(""country.currency"")).isEqualTo(""New Shekel"");
        assertThat((List) doc.getField(""country.languages.language"")).isEqualTo(Arrays.asList(""Hebrew"", ""Arabic"", ""English""));
    }",1
"@Test
    public void testDocWithListField() {
        Template listTemplate = templateService.createTemplate(""this is {{list}",1
"@Test
    public void test_v4_1_16() throws Exception {
        NavMesh mesh = loadNavMesh(""graph_v4_1_16.zip"");
        float[] startPos = new float[] { 22.93f, -2.37f, -5.11f }",1
"@Test
    public void testDungeon32Bit() throws IOException {
        InputStream is = getClass().getClassLoader().getResourceAsStream(""dungeon_all_tiles_navmesh_32bit.bin"");
        NavMesh mesh = reader.read32Bit(is, 6);
        assertThat(mesh.getMaxTiles()).isEqualTo(128);
        assertThat(mesh.getParams().maxPolys).isEqualTo(0x8000);
        assertThat(mesh.getParams().tileWidth).isEqualTo(9.6f, offset(0.001f));
        List<MeshTile> tiles = mesh.getTilesAt(6, 9);
        assertThat(tiles).hasSize(1);
        assertThat(tiles.get(0).data.polys).hasSize(2);
        assertThat(tiles.get(0).data.verts).hasSize(7 * 3);
        tiles = mesh.getTilesAt(2, 9);
        assertThat(tiles).hasSize(1);
        assertThat(tiles.get(0).data.polys).hasSize(2);
        assertThat(tiles.get(0).data.verts).hasSize(9 * 3);
        tiles = mesh.getTilesAt(4, 3);
        assertThat(tiles).hasSize(1);
        assertThat(tiles.get(0).data.polys).hasSize(3);
        assertThat(tiles.get(0).data.verts).hasSize(6 * 3);
        tiles = mesh.getTilesAt(2, 8);
        assertThat(tiles).hasSize(1);
        assertThat(tiles.get(0).data.polys).hasSize(5);
        assertThat(tiles.get(0).data.verts).hasSize(17 * 3);
    }",1
"@Test
    public void detectWildcard() {
        Automaton automaton = new RegExp("".foo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(false));

        automaton = new RegExp(""f.+oo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(false));

        // The handling for .+ also ends up catching this. Probably ok.
        automaton = new RegExp(""f.*oo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(true));

        automaton = new RegExp(""f?.+oo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(true));

        automaton = new RegExp(""f?.*oo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(true));

        automaton = new RegExp(""foo.*"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(false));

        automaton = new RegExp(""[a-z]?foo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(false));

        automaton = new RegExp(""[a-z]+foo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(true));

        automaton = new RegExp(""[a-z]*foo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(true));

        automaton = new RegExp("".*foo"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(true));

        automaton = new RegExp(""(foo|.*bar)"").toAutomaton();
        assertThat(AutomatonHitEnum.hasLeadingWildcard(automaton), equalTo(true));
    }",1
"@Test
    public void leadingWildcardPerformance() {
        String source = makeLongSource();
        SourceExtracter<String> extracter = new StringSourceExtracter(source);
        HitEnum e = AutomatonHitEnum.factory("".*(hero|legend)"", Operations.DEFAULT_MAX_DETERMINIZED_STATES).build(source);
        long start = System.nanoTime();
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, containsString(""legend"")));
        assertThat(e, isEmpty());
        // Implementation of backwards/forward pass reduced
        // this from ~4500ms to ~15ms.
        Duration took = Duration.ofNanos(System.nanoTime() - start);
        assertThat(took.toMillis(), lessThan(200L));
        // System.out.println(took.toMillis());
    }",1
"@Test
    public void partialWithStar() {
        String source = ""hero of legend"";
        SourceExtracter<String> extracter = new StringSourceExtracter(source);
        HitEnum e = AutomatonHitEnum.factory(""her.*f"", Operations.DEFAULT_MAX_DETERMINIZED_STATES).build(source);
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, equalTo(""hero of"")));
        assertThat(e, isEmpty());

        e = AutomatonHitEnum.factory(""her.*o"", Operations.DEFAULT_MAX_DETERMINIZED_STATES).build(source);
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, equalTo(""hero o"")));
        assertThat(e, isEmpty());
    }",1
"@Test
    public void specificWords() {
        String source = ""hero of legend"";
        SourceExtracter<String> extracter = new StringSourceExtracter(source);
        HitEnum e = AutomatonHitEnum.factory(""hero|legend"", Operations.DEFAULT_MAX_DETERMINIZED_STATES).build(source);
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, equalTo(""hero"")));
        assertThat(e, advances());
        assertThat(e, hit(1, extracter, equalTo(""legend"")));
        assertThat(e, isEmpty());
    }",1
"@Test
    public void twoPhaseMatchCorrectness() {
        // Correctness is also checked via parent class, since self::buildEnum matches the two-phase
        // conditions
        String source = ""some words will do wherever they queue"";
        SourceExtracter<String> extracter = new StringSourceExtracter(source);
        HitEnum e = AutomatonHitEnum.factory("".*w"", Operations.DEFAULT_MAX_DETERMINIZED_STATES).build(source);
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, equalTo(""some words will do w"")));
        assertThat(e, isEmpty());

        e = AutomatonHitEnum.factory("".*w"", Operations.DEFAULT_MAX_DETERMINIZED_STATES).build(source);
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, equalTo(""some words will do w"")));
        assertThat(e, isEmpty());
    }",1
"@Test
    public void boostQuery() {
        Callback callback = mock(Callback.class);
        BoostQuery bq = new BoostQuery(new TermQuery(bar), 2f);
        new QueryFlattener().flatten(bq, null, callback);
        verify(callback).flattened(bar.bytes(), 2f, null);
    }",1
"@Test
    public void commonTermsQueryNoRemove() {
        IndexReader reader = readerWithTerms(bar, randomIntBetween(1, 20), baz, randomIntBetween(1, 20));
        Callback callback = mock(Callback.class);
        CommonTermsQuery q = new CommonTermsQuery(Occur.SHOULD, Occur.MUST, 10f);
        q.add(bar);
        q.add(baz);
        new QueryFlattener(100, false, false).flatten(q, reader, callback);
        verify(callback).flattened(bar.bytes(), 1f, null);
        verify(callback).flattened(baz.bytes(), 1f, null);
    }",1
"@Test
    public void aCoupleWordsUnrepaired() {
        String source = ""hero of legend"";
        BreakIterator itr = BreakIterator.getWordInstance(Locale.ENGLISH);
        itr.setText(source);
        SourceExtracter<String> extracter = new StringSourceExtracter(source);
        HitEnum e = new BreakIteratorHitEnum(itr);
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, equalTo(""hero"")));
        assertThat(e, advances());
        assertThat(e, hit(1, extracter, equalTo("" "")));
        assertThat(e, advances());
        assertThat(e, hit(2, extracter, equalTo(""of"")));
        assertThat(e, advances());
        assertThat(e, hit(3, extracter, equalTo("" "")));
        assertThat(e, advances());
        assertThat(e, hit(4, extracter, equalTo(""legend"")));
        assertThat(e, isEmpty());
    }",1
"@Test
    public void compareToReplaying() {
        List<HitEnumAndLength> allEnumsForReplaying = new ArrayList<HitEnumAndLength>();
        List<HitEnumAndLength> allEnumsForConcat = new ArrayList<HitEnumAndLength>();
        for (int i = 0; i < 100; i++) {
            ReplayingHitEnum inputForReplaying = new ReplayingHitEnum();
            ReplayingHitEnum inputForConcat = new ReplayingHitEnum();
            for (int j = 0; j < 100; j++) {
                int position = randomInt();
                int startOffset = randomInt();
                int endOffset = randomInt();
                float queryWeight = randomFloat();
                float corpusWeight = randomFloat();
                int source = randomInt();
                inputForReplaying.recordHit(position, startOffset, endOffset, queryWeight, corpusWeight, source);
                inputForConcat.recordHit(position, startOffset, endOffset, queryWeight, corpusWeight, source);
            }",1
"@Test
    public void single() {
        List<Integer> expectedPositions = new ArrayList<Integer>();
        int max = between(500, 10000);
        for (int i = 0; i < max; i++) {
            expectedPositions.add(getRandom().nextInt());
        }",1
"@Test
    public void overlapPicksMaxWeightAndSize() {
        ReplayingHitEnum replaying = new ReplayingHitEnum();
        // The first overlapping hit has corpus weight of 3
        replaying.recordHit(0, 0, 5, 2, 3, 1);
        // The second has query weight of 3
        replaying.recordHit(0, 1, 3, 3, 2, 2);
        HitEnum e = new OverlapMergingHitEnumWrapper(replaying);
        assertThat(e, advances());
        assertThat(e, allOf(
                // So together they should have a multiplied weight of 9 (3*3)
                atWeight(9), atPosition(0), atStartOffset(0), atEndOffset(5), atSource(33)));
        assertThat(e, isEmpty());
    }",1
"@Test
    public void single() {
        ReplayingHitEnum replaying = new ReplayingHitEnum();
        replaying.recordHit(0, 0, 2, 1.7f, 1);
        HitEnum e = new OverlapMergingHitEnumWrapper(replaying);
        assertThat(e, advances());
        assertThat(e, allOf(atPosition(0), atStartOffset(0), atEndOffset(2), atWeight(1.7f), atSource(1)));
        assertThat(e, isEmpty());
    }",1
"@Test
    public void largeAndBasicSpeedTest() {
        int size = 1000000;
        phrase(0, 0, 0, 0, 2);
        int[] inputs = new int[size];
        for (int i = 0; i < size; i++) {
            inputs[i] = 0;
        }",1
"@Test
    public void specificWords() {
        String source = ""hero of legend"";
        SourceExtracter<String> extracter = new StringSourceExtracter(source);
        HitEnum e = new RegexHitEnum(Pattern.compile(""hero|legend"").matcher(source));
        assertThat(e, advances());
        assertThat(e, hit(0, extracter, equalTo(""hero"")));
        assertThat(e, advances());
        assertThat(e, hit(1, extracter, equalTo(""legend"")));
        assertThat(e, isEmpty());
    }",1
"@Test
    public void basic() {
        for (boolean scoreOrdered : new boolean[] {true, false}",1
"@Test
    public void sentenceBreaks() {
        setup(""One sentence.  Two sentence.  Red sentence, blue sentence."");
        assertTrue(segmenter.acceptable(0, 12));
        assertThat(segmenter.memo(0, 7).pickBounds(0, 37), extracted(extracter, ""One sentence.  ""));
        assertTrue(segmenter.acceptable(17, 25));
        assertThat(segmenter.memo(17, 25).pickBounds(0, 1237), extracted(extracter, ""Two sentence.  ""));
        assertFalse(segmenter.acceptable(0, 28));
        // 15 is right on the ""T"" in ""Two"" and 27-29 are the end of that
        // sentence.
        for (int end = 27; end <= 29; end++) {
            assertTrue(segmenter.acceptable(15, end));
            assertThat(segmenter.memo(15, end).pickBounds(0, Integer.MAX_VALUE),
                    extracted(extracter, ""Two sentence.  ""));
        }",1
"@Test
    public void shortString() {
        setup(""short"");
        int end = source.length();
        for (int i = 0; i < end; i++) {
            assertTrue(segmenter.acceptable(0, i));
            assertThat(segmenter.memo(0, i).pickBounds(0, Integer.MAX_VALUE),
                    extracted(extracter, equalTo(""short"")));

            assertTrue(segmenter.acceptable(i, end));
            assertThat(segmenter.memo(i, end).pickBounds(0, Integer.MAX_VALUE),
                    extracted(extracter, equalTo(""short"")));
        }",1
"@Test
    public void startWithSomeEmptyThenSingleChar() {
        setup("""", """", """", ""a"");
        assertTrue(segmenter.acceptable(offsetGap * 3, offsetGap * 3 + 1));
        assertThat(segmenter.memo(offsetGap * 3, offsetGap * 3 + 1)
                .pickBounds(0, Integer.MAX_VALUE), extracted(extracter, equalTo(""a"")));
        if (offsetGap > 0) {
            assertFalse(segmenter.acceptable(0, 1));
        }",1
"@Test
    public void singleSentence() {
        setup(""More stuff!  More stuff too."");
        int end = source.length() - 1;
        for (int i = 0; i < end; i++) {
            assertTrue(segmenter.acceptable(0, i));
            assertThat(segmenter.memo(0, i).pickBounds(0, Integer.MAX_VALUE),
                    extracted(extracter, source));

            assertTrue(segmenter.acceptable(i, end));
            assertThat(segmenter.memo(i, end).pickBounds(0, Integer.MAX_VALUE),
                    extracted(extracter, source));
        }",1
"@Test
    public void getMessageTest() {
        ParameterizedErrorVM vm = new ParameterizedErrorVM(null, null);
        assertThat(vm.getMessage()).isNull();
        Map<String, String> paramMap = new HashMap<>();
        paramMap.put(""param1"", ""param1"");
        paramMap.put(""param2"", ""param2"");
        vm = new ParameterizedErrorVM(""message"", paramMap);
        assertThat(vm.getMessage()).isEqualTo(""message"");
    }",1
"@Test
	public void testMarshalAndSendNoUnmarshallerSet() throws Exception {

		connectionMock.close();

		template.setUnmarshaller(null);
		assertThatIllegalStateException().isThrownBy(() -> template.marshalSendAndReceive(new Object()));
	}",1
"@Test
	public void testSendAndReceiveMarshalNoResponse() throws Exception {

		Marshaller marshallerMock = mock(Marshaller.class);
		template.setMarshaller(marshallerMock);
		marshallerMock.marshal(isA(Object.class), isA(Result.class));

		connectionMock.send(isA(WebServiceMessage.class));
		when(connectionMock.hasError()).thenReturn(false);
		when(connectionMock.receive(messageFactory)).thenReturn(null);
		connectionMock.close();

		Object result = template.marshalSendAndReceive(new Object());

		assertThat(result).isNull();
	}",1
"@Test
	public void testSendAndReceiveMessageNoResponse() throws Exception {

		WebServiceMessageExtractor extractorMock = mock(WebServiceMessageExtractor.class);

		connectionMock.send(isA(WebServiceMessage.class));
		when(connectionMock.hasError()).thenReturn(false);
		when(connectionMock.receive(messageFactory)).thenReturn(null);
		connectionMock.close();

		Object result = template.sendAndReceive(null, extractorMock);

		assertThat(result).isNull();
	}",1
"@Test
	public void testSendAndReceiveResultNoResponse() throws Exception {

		connectionMock.send(isA(WebServiceMessage.class));
		when(connectionMock.hasError()).thenReturn(false);
		when(connectionMock.receive(messageFactory)).thenReturn(null);
		connectionMock.close();

		StringResult result = new StringResult();
		boolean b = template.sendSourceAndReceiveToResult(new StringSource(""<request />""), result);

		assertThat(b).isFalse();
	}",1
"@Test
	public void ordering() {

		ApplicationContext applicationContext = new ClassPathXmlApplicationContext(
				""interceptorsBeanDefinitionParserOrderTest.xml"", getClass());

		List<DelegatingSmartEndpointInterceptor> interceptors = new ArrayList<DelegatingSmartEndpointInterceptor>(
				applicationContext.getBeansOfType(DelegatingSmartEndpointInterceptor.class).values());

		assertThat(interceptors).hasSize(6);

		for (int i = 0; i < interceptors.size(); i++) {

			DelegatingSmartEndpointInterceptor delegatingInterceptor = interceptors.get(i);
			MyInterceptor interceptor = (MyInterceptor) delegatingInterceptor.getDelegate();

			assertThat(interceptor.getOrder()).isEqualTo(i);
		}",1
"@Test
	public void testProperties() {

		assertThat(context.getPropertyNames()).hasSize(0);

		String name = ""name"";

		assertThat(context.containsProperty(name)).isFalse();

		String value = ""value"";
		context.setProperty(name, value);

		assertThat(context.containsProperty(name)).isTrue();
		assertThat(context.getPropertyNames()).containsExactly(name);
		assertThat(context.getProperty(name)).isEqualTo(value);

		context.removeProperty(name);

		assertThat(context.containsProperty(name)).isFalse();
		assertThat(context.getPropertyNames()).isEmpty();
	}",1
"@Test
	public void testRequest() {
		assertThat(context.getRequest()).isEqualTo(request);
	}",1
"@Test
	public void testResponse() {

		WebServiceMessage response = new MockWebServiceMessage();
		expect(factoryMock.createWebServiceMessage()).andReturn(response);
		replay(factoryMock);

		WebServiceMessage result = context.getResponse();

		assertThat(result).isEqualTo(response);

		verify(factoryMock);
	}",1
"@Test
	public void testNoResponse() throws Exception {

		WebServiceMessage messageMock = createMock(WebServiceMessage.class);
		expect(messageMock.getPayloadSource()).andReturn(new StringSource(""<request/>""));
		WebServiceMessageFactory factoryMock = createMock(WebServiceMessageFactory.class);
		MessageContext messageContext = new DefaultMessageContext(messageMock, factoryMock);

		Method noResponse = getClass().getMethod(""noResponse"", MyGenericType.class);
		MethodEndpoint methodEndpoint = new MethodEndpoint(this, noResponse);
		expect(unmarshallerMock.unmarshal(isA(Source.class))).andReturn(new MyGenericType<MyType>());

		replay(marshallerMock, unmarshallerMock, messageMock, factoryMock);

		assertThat(noResponseInvoked).isFalse();

		adapter.invoke(messageContext, methodEndpoint);

		assertThat(noResponseInvoked).isTrue();

		verify(marshallerMock, unmarshallerMock, messageMock, factoryMock);
	}",1
"@Test
	public void testUnsupportedMethodMultipleParams() throws NoSuchMethodException {

		Method unsupported = getClass().getMethod(""unsupportedMultipleParams"", String.class, String.class);

		replay(marshallerMock, unmarshallerMock);

		assertThat(adapter.supportsInternal(new MethodEndpoint(this, unsupported))).isFalse();

		verify(marshallerMock, unmarshallerMock);
	}",1
"@Test
	public void testUnsupportedMethodWrongReturnType() throws NoSuchMethodException {

		Method unsupported = getClass().getMethod(""unsupportedWrongParam"", String.class);
		expect(marshallerMock.supports(unsupported.getGenericReturnType())).andReturn(false);

		replay(marshallerMock, unmarshallerMock);

		assertThat(adapter.supportsInternal(new MethodEndpoint(this, unsupported))).isFalse();

		verify(marshallerMock, unmarshallerMock);
	}",1
"@Test
	public void testNoResponse() throws Exception {

		Method noResponse = getClass().getMethod(""noResponse"", new Class[] { MyType.class }",1
"@Test
	public void testResponse() throws Exception {

		Method response = getClass().getMethod(""response"", new Class[] { MyType.class }",1
"@Test
	public void handleReturnValueString() throws Exception {

		MessageContext messageContext = new DefaultMessageContext(new MockWebServiceMessageFactory());

		String s = ""Foo"";
		JAXBElement<String> element = new JAXBElement<>(new QName(""http://springframework.org"", ""string""), String.class, s);
		processor.handleReturnValue(messageContext, stringReturnType, element);

		assertThat(messageContext.hasResponse()).isTrue();

		MockWebServiceMessage response = (MockWebServiceMessage) messageContext.getResponse();

		XmlAssert.assertThat(response.getPayloadAsString()).and(""<string xmlns='http://springframework.org'>Foo</string>"")
				.ignoreWhitespace().areIdentical();
	}",1
"@Test
	public void resolveArgument() throws JAXBException {

		WebServiceMessage request = new MockWebServiceMessage(
				""<myType xmlns='http://springframework.org'><string>Foo</string></myType>"");
		MessageContext messageContext = new DefaultMessageContext(request, new MockWebServiceMessageFactory());

		JAXBElement<?> result = processor.resolveArgument(messageContext, supportedParameter);

		assertThat(result.getValue()).isInstanceOf(MyType.class);

		MyType type = (MyType) result.getValue();

		assertThat(type.getString()).isEqualTo(""Foo"");
	}",1
"@Test
	public void supportsReturnType() {
		assertThat(processor.supportsReturnType(supportedReturnType)).isTrue();
	}",1
"@Test
	public void resolveArgumentFromCustomSAXSource() throws JAXBException {

		// Create a custom SAXSource that generates an appropriate sequence of events.
		XMLReader xmlReader = new AbstractXmlReader() {

			@Override
			public void parse(String systemId) throws SAXException {
				parse();
			}",1
"@Test
	public void resolveConvertedType() throws Exception {

		MockWebServiceMessage request = new MockWebServiceMessage(CONTENTS);
		MessageContext messageContext = new DefaultMessageContext(request, new MockWebServiceMessageFactory());

		Object result = resolver.resolveArgument(messageContext, convertedParameter);

		assertThat(result).isInstanceOf(Integer.class);
		assertThat(result).isEqualTo(42);
	}",1
"@Test
	public void resolveNamespacesMethod() throws Exception {

		MockWebServiceMessage request = new MockWebServiceMessage(
				""<root xmlns=\""http://springframework.org/spring-ws\"">text</root>"");
		MessageContext messageContext = new DefaultMessageContext(request, new MockWebServiceMessageFactory());

		Object result = resolver.resolveArgument(messageContext, namespaceMethodParameter);

		assertThat(result).isInstanceOf(String.class);
		assertThat(result).isEqualTo(""text"");
	}",1
"@Test
	public void resolveString() throws Exception {

		MockWebServiceMessage request = new MockWebServiceMessage(CONTENTS);
		MessageContext messageContext = new DefaultMessageContext(request, new MockWebServiceMessageFactory());

		Object result = resolver.resolveArgument(messageContext, stringParameter);

		assertThat(result).isInstanceOf(String.class);

		String s = (String) result;

		assertThat(s).isEqualTo(""text"");
	}",1
"@Test
	public void endpointInvalidBeanName() throws Exception {

		StaticApplicationContext applicationContext = new StaticApplicationContext();
		applicationContext.registerSingleton(""endpoint"", Object.class);

		AbstractEndpointMapping mapping = new AbstractEndpointMapping() {

			@Override
			protected Object getEndpointInternal(MessageContext message) throws Exception {
				assertThat(message).isEqualTo(messageContext);
				return ""noSuchBean"";
			}",1
"@Test
	public void invoke() throws Exception {

		MessageFactory messageFactory = MessageFactory.newInstance();
		SOAPMessage request = messageFactory.createMessage();
		request.getSOAPBody().addBodyElement(QName.valueOf(""{http://springframework.org/spring-ws}",1
"@Test
	public void registrationSingle() throws NoSuchMethodException {

		MethodEndpoint endpoint = mapping.lookupEndpoint(new QName(""http://springframework.org/spring-ws"", ""Request""));

		assertThat(endpoint).isNotNull();

		Method doIt = MyEndpoint.class.getMethod(""doIt"", Source.class);
		MethodEndpoint expected = new MethodEndpoint(""endpoint"", applicationContext, doIt);

		assertThat(endpoint).isEqualTo(expected);
	}",1
"@Test
	public void testGetLookupKeyForMessage() throws Exception {

		mapping.setExpression(""/root/text()"");
		mapping.afterPropertiesSet();

		MockWebServiceMessage request = new MockWebServiceMessage(""<root>value</root>"");
		MessageContext context = new DefaultMessageContext(request, new MockWebServiceMessageFactory());

		String result = mapping.getLookupKeyForMessage(context);

		assertThat(result).isNotNull();
		assertThat(result).isEqualTo(""value"");
	}",1
"@Test
	public void testGetters() {

		assertThat(endpoint.getBean()).isEqualTo(this);
		assertThat(endpoint.getMethod()).isEqualTo(method);
	}",1
"@Test
	public void testGetQNameForStaxSourceEventReader() throws Exception {

		String contents = ""<prefix:localname xmlns:prefix='namespace'/>"";
		XMLInputFactory inputFactory = XMLInputFactoryUtils.newInstance();
		XMLEventReader eventReader = inputFactory.createXMLEventReader(new StringReader(contents));
		Source source = StaxUtils.createStaxSource(eventReader);
		QName qName = PayloadRootUtils.getPayloadRootQName(source, TransformerFactoryUtils.newInstance());

		assertThat(qName).isNotNull();
		assertThat(qName.getLocalPart()).isEqualTo(""localname"");
		assertThat(qName.getNamespaceURI()).isEqualTo(""namespace"");
		assertThat(qName.getPrefix()).isEqualTo(""prefix"");
	}",1
"@Test
	public void testGetEndpointAdapterSupportedEndpoint() {

		EndpointAdapter adapterMock = createMock(EndpointAdapter.class);
		dispatcher.setEndpointAdapters(Collections.singletonList(adapterMock));

		Object endpoint = new Object();
		expect(adapterMock.supports(endpoint)).andReturn(true);

		replay(adapterMock, factoryMock);

		EndpointAdapter result = dispatcher.getEndpointAdapter(endpoint);

		verify(adapterMock, factoryMock);

		assertThat(result).isEqualTo(adapterMock);
	}",1
"@Test
	public void testGetEndpointAdapterUnsupportedEndpoint() {

		EndpointAdapter adapterMock = createMock(EndpointAdapter.class);
		dispatcher.setEndpointAdapters(Collections.singletonList(adapterMock));

		Object endpoint = new Object();
		expect(adapterMock.supports(endpoint)).andReturn(false);

		replay(adapterMock, factoryMock);

		assertThatIllegalStateException().isThrownBy(() -> dispatcher.getEndpointAdapter(endpoint));

		verify(adapterMock, factoryMock);
	}",1
"@Test
	public void testInterceptedRequestFlow() throws Exception {

		EndpointAdapter adapterMock = createMock(EndpointAdapter.class);
		dispatcher.setEndpointAdapters(Collections.singletonList(adapterMock));

		EndpointMapping mappingMock = createMock(EndpointMapping.class);
		dispatcher.setEndpointMappings(Collections.singletonList(mappingMock));

		EndpointInterceptor interceptorMock1 = createStrictMock(""interceptor1"", EndpointInterceptor.class);
		EndpointInterceptor interceptorMock2 = createStrictMock(""interceptor2"", EndpointInterceptor.class);

		Object endpoint = new Object();

		expect(interceptorMock1.handleRequest(messageContext, endpoint)).andReturn(false);
		expect(interceptorMock1.handleResponse(messageContext, endpoint)).andReturn(true);
		interceptorMock1.afterCompletion(messageContext, endpoint, null);

		EndpointInvocationChain chain = new EndpointInvocationChain(endpoint,
				new EndpointInterceptor[] { interceptorMock1, interceptorMock2 }",1
"@Test
	public void testNormalFlow() throws Exception {

		EndpointAdapter adapterMock = createMock(EndpointAdapter.class);
		dispatcher.setEndpointAdapters(Collections.singletonList(adapterMock));

		Object endpoint = new Object();
		expect(adapterMock.supports(endpoint)).andReturn(true);

		EndpointMapping mappingMock = createMock(EndpointMapping.class);
		dispatcher.setEndpointMappings(Collections.singletonList(mappingMock));

		EndpointInterceptor interceptorMock1 = createStrictMock(""interceptor1"", EndpointInterceptor.class);
		EndpointInterceptor interceptorMock2 = createStrictMock(""interceptor2"", EndpointInterceptor.class);

		expect(interceptorMock1.handleRequest(messageContext, endpoint)).andReturn(true);
		expect(interceptorMock2.handleRequest(messageContext, endpoint)).andReturn(true);

		adapterMock.invoke(messageContext, endpoint);

		expect(interceptorMock2.handleResponse(messageContext, endpoint)).andReturn(true);
		expect(interceptorMock1.handleResponse(messageContext, endpoint)).andReturn(true);

		interceptorMock2.afterCompletion(messageContext, endpoint, null);
		interceptorMock1.afterCompletion(messageContext, endpoint, null);

		EndpointInvocationChain chain = new EndpointInvocationChain(endpoint,
				new EndpointInterceptor[] { interceptorMock1, interceptorMock2 }",1
"@Test
	public void testProcessUnsupportedEndpointException() {

		EndpointExceptionResolver resolverMock = createMock(EndpointExceptionResolver.class);
		dispatcher.setEndpointExceptionResolvers(Collections.singletonList(resolverMock));

		Object endpoint = new Object();
		Exception ex = new Exception();

		expect(resolverMock.resolveException(messageContext, endpoint, ex)).andReturn(false);

		replay(factoryMock, resolverMock);

		try {
			dispatcher.processEndpointException(messageContext, endpoint, ex);
		}",1
"@Test
	public void testResolveException() throws Exception {

		final Exception ex = new Exception();

		EndpointMapping endpointMapping = messageContext -> {
			throw ex;
		}",1
"@Test
	public void testResolveExceptionsWithInterceptors() throws Exception {

		EndpointAdapter adapterMock = createMock(EndpointAdapter.class);
		dispatcher.setEndpointAdapters(Collections.singletonList(adapterMock));

		Object endpoint = new Object();
		expect(adapterMock.supports(endpoint)).andReturn(true);

		EndpointMapping mappingMock = createMock(EndpointMapping.class);
		dispatcher.setEndpointMappings(Collections.singletonList(mappingMock));

		EndpointExceptionResolver resolverMock = createMock(EndpointExceptionResolver.class);
		dispatcher.setEndpointExceptionResolvers(Collections.singletonList(resolverMock));

		EndpointInterceptor interceptorMock = createStrictMock(""interceptor1"", EndpointInterceptor.class);

		expect(interceptorMock.handleRequest(messageContext, endpoint)).andReturn(true);

		adapterMock.invoke(messageContext, endpoint);
		RuntimeException exception = new RuntimeException();
		expectLastCall().andThrow(exception);

		expect(resolverMock.resolveException(messageContext, endpoint, exception)).andReturn(true);

		expect(interceptorMock.handleResponse(messageContext, endpoint)).andReturn(true);

		interceptorMock.afterCompletion(messageContext, endpoint, null);

		EndpointInvocationChain chain = new EndpointInvocationChain(endpoint,
				new EndpointInterceptor[] { interceptorMock }",1
"@Test
	public void testNoMatch() throws Exception {

		SaajSoapMessage message = loadSaajMessage(""200408/response-no-message-id.xml"");
		MessageContext messageContext = new DefaultMessageContext(message, new SaajSoapMessageFactory(messageFactory));

		EndpointInvocationChain endpoint = mapping.getEndpoint(messageContext);

		assertThat(endpoint).isNull();
	}",1
"@Test
	public void testToName() throws Exception {

		SOAPMessage message = messageFactory.createMessage();
		QName qName = new QName(""localPart"");
		SOAPEnvelope envelope = message.getSOAPPart().getEnvelope();
		Name name = SaajUtils.toName(qName, envelope);

		assertThat(name).isNotNull();
		assertThat(name.getLocalName()).isEqualTo(qName.getLocalPart());
		assertThat(StringUtils.hasLength(name.getPrefix())).isFalse();
		assertThat(StringUtils.hasLength(name.getURI())).isFalse();
	}",1
"@Test
	public void testToNameNamespace() throws Exception {

		SOAPMessage message = messageFactory.createMessage();
		QName qName = new QName(""namespace"", ""localPart"");
		SOAPEnvelope envelope = message.getSOAPPart().getEnvelope();
		envelope.addNamespaceDeclaration(""prefix"", ""namespace"");
		Name name = SaajUtils.toName(qName, envelope);

		assertThat(name).isNotNull();
		assertThat(name.getURI()).isEqualTo(qName.getNamespaceURI());
		assertThat(name.getLocalName()).isEqualTo(qName.getLocalPart());
		assertThat(name.getPrefix()).isEqualTo(""prefix"");
	}",1
"@Test
	public void testToNameNamespacePrefix() throws Exception {

		SOAPMessage message = messageFactory.createMessage();
		QName qName = new QName(""namespace"", ""localPart"", ""prefix"");
		SOAPEnvelope envelope = message.getSOAPPart().getEnvelope();
		Name name = SaajUtils.toName(qName, envelope);

		assertThat(name).isNotNull();
		assertThat(name.getURI()).isEqualTo(qName.getNamespaceURI());
		assertThat(name.getLocalName()).isEqualTo(qName.getLocalPart());
		assertThat(name.getPrefix()).isEqualTo(qName.getPrefix());
	}",1
"@Test
	public void testToQNamePrefixNamespace() throws Exception {

		SOAPMessage message = messageFactory.createMessage();
		Name name = message.getSOAPPart().getEnvelope().createName(""localPart"", ""prefix"", ""namespace"");
		QName qName = SaajUtils.toQName(name);

		assertThat(qName).isNotNull();
		assertThat(qName.getNamespaceURI()).isEqualTo(name.getURI());
		assertThat(qName.getLocalPart()).isEqualTo(name.getLocalName());
		assertThat(qName.getPrefix()).isEqualTo(name.getPrefix());
	}",1
"@Test
	public void algorithm() throws Exception {

		KeyManagersFactoryBean factoryBean = new KeyManagersFactoryBean();
		factoryBean.setAlgorithm(""PKIX"");
		factoryBean.afterPropertiesSet();
		KeyManager[] keyManagers = factoryBean.getObject();

		assertThat(keyManagers).isNotNull();
		assertThat(keyManagers).hasSize(1);
	}",1
"@Test
	public void testHandleValidRequest() throws Exception {

		MockWebServiceMessage request = new MockWebServiceMessage();
		request.setPayload(new ClassPathResource(VALID_MESSAGE, getClass()));
		context = new DefaultMessageContext(request, new MockWebServiceMessageFactory());
		boolean result = interceptor.handleRequest(context);

		assertThat(result).isTrue();
		assertThat(context.hasResponse()).isFalse();
	}",1
"@Test
	public void testHandleValidResponse() throws Exception {

		MockWebServiceMessage request = new MockWebServiceMessage();
		context = new DefaultMessageContext(request, new MockWebServiceMessageFactory());
		MockWebServiceMessage response = (MockWebServiceMessage) context.getResponse();
		response.setPayload(new ClassPathResource(VALID_MESSAGE, getClass()));
		boolean result = interceptor.handleResponse(context);

		assertThat(result).isTrue();
	}",1
"@Test
	public void testResolveExceptionDefault() throws Exception {

		SoapFaultDefinition defaultFault = new SoapFaultDefinition();
		defaultFault.setFaultCode(SoapFaultDefinition.CLIENT);
		defaultFault.setFaultStringOrReason(""faultstring"");
		resolver.setDefaultFault(defaultFault);
		MessageFactory saajFactory = MessageFactory.newInstance(SOAPConstants.SOAP_1_1_PROTOCOL);
		SoapMessageFactory factory = new SaajSoapMessageFactory(saajFactory);
		MessageContext context = new DefaultMessageContext(factory);

		boolean result = resolver.resolveException(context, null, new NonAnnotatedException());

		assertThat(result).isTrue();
		assertThat(context.hasResponse()).isTrue();

		SoapMessage response = (SoapMessage) context.getResponse();

		assertThat(response.getSoapBody().hasFault()).isTrue();

		Soap11Fault fault = (Soap11Fault) response.getSoapBody().getFault();

		assertThat(fault.getFaultCode()).isEqualTo(SoapVersion.SOAP_11.getClientOrSenderFaultName());
		assertThat(fault.getFaultStringOrReason()).isEqualTo(""faultstring"");
		assertThat(fault.getFaultDetail()).isNull();
	}",1
"@Test
	public void testResolveExceptionReceiverSoap12() throws Exception {

		MessageFactory saajFactory = MessageFactory.newInstance(SOAPConstants.SOAP_1_2_PROTOCOL);
		SOAPMessage message = saajFactory.createMessage();
		SoapMessageFactory factory = new SaajSoapMessageFactory(saajFactory);
		MessageContext context = new DefaultMessageContext(new SaajSoapMessage(message), factory);

		boolean result = resolver.resolveException(context, null, new MyReceiverException());

		assertThat(result).isTrue();
		assertThat(context.hasResponse()).isTrue();

		SoapMessage response = (SoapMessage) context.getResponse();

		assertThat(response.getSoapBody().hasFault()).isTrue();

		Soap12Fault fault = (Soap12Fault) response.getSoapBody().getFault();

		assertThat(fault.getFaultCode()).isEqualTo(SoapVersion.SOAP_12.getServerOrReceiverFaultName());
		assertThat(fault.getFaultReasonText(Locale.ENGLISH)).isEqualTo(""Receiver error"");
		assertThat(fault.getFaultDetail()).isNull();
	}",1
"@Test
	public void testResolveExceptionServerSoap11() throws Exception {

		MessageFactory saajFactory = MessageFactory.newInstance(SOAPConstants.SOAP_1_1_PROTOCOL);
		SoapMessageFactory factory = new SaajSoapMessageFactory(saajFactory);
		MessageContext context = new DefaultMessageContext(factory);

		boolean result = resolver.resolveException(context, null, new MyServerException());

		assertThat(result).isTrue();
		assertThat(context.hasResponse()).isTrue();

		SoapMessage response = (SoapMessage) context.getResponse();

		assertThat(response.getSoapBody().hasFault()).isTrue();

		Soap11Fault fault = (Soap11Fault) response.getSoapBody().getFault();

		assertThat(fault.getFaultCode()).isEqualTo(SoapVersion.SOAP_11.getServerOrReceiverFaultName());
		assertThat(fault.getFaultStringOrReason()).isEqualTo(""Server error"");
		assertThat(fault.getFaultDetail()).isNull();
	}",1
"@Test
	public void testResolveExceptionClientSoap11() throws Exception {

		Properties mappings = new Properties();
		mappings.setProperty(Exception.class.getName(), ""SERVER, Server error"");
		mappings.setProperty(RuntimeException.class.getName(), ""CLIENT, Client error"");
		resolver.setExceptionMappings(mappings);

		MessageFactory messageFactory = MessageFactory.newInstance(SOAPConstants.SOAP_1_1_PROTOCOL);
		SOAPMessage message = messageFactory.createMessage();
		SoapMessageFactory factory = new SaajSoapMessageFactory(messageFactory);
		MessageContext context = new DefaultMessageContext(new SaajSoapMessage(message), factory);

		boolean result = resolver.resolveException(context, null, new IllegalArgumentException(""bla""));

		assertThat(result).isTrue();
		assertThat(context.hasResponse()).isTrue();

		SoapMessage response = (SoapMessage) context.getResponse();

		assertThat(response.getSoapBody().hasFault()).isTrue();

		Soap11Fault fault = (Soap11Fault) response.getSoapBody().getFault();

		assertThat(fault.getFaultCode()).isEqualTo(SoapVersion.SOAP_11.getClientOrSenderFaultName());
		assertThat(fault.getFaultStringOrReason()).isEqualTo(""Client error"");
		assertThat(fault.getFaultDetail()).isNull();
	}",1
"@Test
	public void testResolveExceptionReceiverSoap12() throws Exception {

		Properties mappings = new Properties();
		mappings.setProperty(Exception.class.getName(), ""SENDER, Sender error"");
		mappings.setProperty(RuntimeException.class.getName(), ""RECEIVER, Receiver error"");
		resolver.setExceptionMappings(mappings);

		MessageFactory messageFactory = MessageFactory.newInstance(SOAPConstants.SOAP_1_2_PROTOCOL);
		SOAPMessage message = messageFactory.createMessage();
		SoapMessageFactory factory = new SaajSoapMessageFactory(messageFactory);
		MessageContext context = new DefaultMessageContext(new SaajSoapMessage(message), factory);

		boolean result = resolver.resolveException(context, null, new IllegalArgumentException(""bla""));

		assertThat(result).isTrue();
		assertThat(context.hasResponse()).isTrue();

		SoapMessage response = (SoapMessage) context.getResponse();

		assertThat(response.getSoapBody().hasFault()).isTrue();

		Soap12Fault fault = (Soap12Fault) response.getSoapBody().getFault();

		assertThat(fault.getFaultCode()).isEqualTo(SoapVersion.SOAP_12.getServerOrReceiverFaultName());
		assertThat(fault.getFaultReasonText(Locale.ENGLISH)).isEqualTo(""Receiver error"");
		assertThat(fault.getFaultDetail()).isNull();
	}",1
"@Test
	public void testProcessMustUnderstandHeadersForActorSoap11() throws Exception {

		MessageFactory messageFactory = MessageFactory.newInstance(SOAPConstants.SOAP_1_1_PROTOCOL);
		SOAPMessage request = messageFactory.createMessage();
		SOAPHeaderElement header = request.getSOAPHeader()
				.addHeaderElement(new QName(""http://www.springframework.org"", ""Header"", ""spring-ws""));
		String headerActor = ""http://www/springframework.org/role"";
		header.setActor(headerActor);
		header.setMustUnderstand(true);
		SoapMessageFactory factory = new SaajSoapMessageFactory(messageFactory);
		MessageContext context = new DefaultMessageContext(new SaajSoapMessage(request), factory);
		expect(interceptorMock.understands(isA(SoapHeaderElement.class))).andReturn(true);

		replay(interceptorMock);

		SoapEndpointInvocationChain chain = new SoapEndpointInvocationChain(new Object(),
				new SoapEndpointInterceptor[] { interceptorMock }",1
"@Test
	public void testProcessMustUnderstandHeadersNotUnderstoodSoap12() throws Exception {

		MessageFactory messageFactory = MessageFactory.newInstance(SOAPConstants.SOAP_1_2_PROTOCOL);
		SOAPMessage request = messageFactory.createMessage();
		SOAPHeaderElement header = request.getSOAPHeader()
				.addHeaderElement(new QName(""http://www.springframework.org"", ""Header"", ""spring-ws""));
		header.setMustUnderstand(true);
		header.setRole(SOAPConstants.URI_SOAP_1_2_ROLE_NEXT);
		SoapMessageFactory factory = new SaajSoapMessageFactory(messageFactory);
		MessageContext context = new DefaultMessageContext(new SaajSoapMessage(request), factory);
		expect(interceptorMock.understands(isA(SoapHeaderElement.class))).andReturn(false);

		replay(interceptorMock);

		SoapEndpointInvocationChain chain = new SoapEndpointInvocationChain(new Object(),
				new SoapEndpointInterceptor[] { interceptorMock }",1
"@Test
	public void testExtractActionFromContentType() {

		String soapAction = ""http://springframework.org/spring-ws/Action"";

		String contentType = ""application/soap+xml; action="" + soapAction;
		String result = SoapUtils.extractActionFromContentType(contentType);

		assertThat(result).isEqualTo(soapAction);

		contentType = ""application/soap+xml; action	  = "" + soapAction;
		result = SoapUtils.extractActionFromContentType(contentType);

		assertThat(result).isEqualTo(soapAction);

		contentType = ""application/soap+xml; action="" + soapAction + "" ; charset=UTF-8"";
		result = SoapUtils.extractActionFromContentType(contentType);

		assertThat(result).isEqualTo(soapAction);

		contentType = ""application/soap+xml; charset=UTF-8; action="" + soapAction;
		result = SoapUtils.extractActionFromContentType(contentType);

		assertThat(result).isEqualTo(soapAction);
	}",1
"@Test
	public void testSetActionInContentType() {

		String soapAction = ""http://springframework.org/spring-ws/Action"";
		String contentType = ""application/soap+xml"";

		String result = SoapUtils.setActionInContentType(contentType, soapAction);

		assertThat(SoapUtils.extractActionFromContentType(result)).isEqualTo(soapAction);

		String anotherSoapAction = ""http://springframework.org/spring-ws/AnotherAction"";
		String contentTypeWithAction = ""application/soap+xml; action=http://springframework.org/spring-ws/Action"";
		result = SoapUtils.setActionInContentType(contentTypeWithAction, anotherSoapAction);

		assertThat(SoapUtils.extractActionFromContentType(result)).isEqualTo(anotherSoapAction);
	}",1
"@Test
	public void testGetDefaultStrategyMoreThanOne() {

		Properties strategies = new Properties();
		strategies.put(Strategy.class.getName(),
				StrategyImpl.class.getName() + "","" + ContextAwareStrategyImpl.class.getName());
		DefaultStrategiesHelper helper = new DefaultStrategiesHelper(strategies);

		StaticApplicationContext applicationContext = new StaticApplicationContext();
		applicationContext.registerSingleton(""strategy1"", StrategyImpl.class);
		applicationContext.registerSingleton(""strategy2"", ContextAwareStrategyImpl.class);

		assertThatExceptionOfType(BeanInitializationException.class)
				.isThrownBy(() -> helper.getDefaultStrategy(Strategy.class, applicationContext));
	}",1
"@Test
	public void testUnmarshalMime() throws Exception {

		MimeUnmarshaller unmarshallerMock = createMock(MimeUnmarshaller.class);
		MimeMessage messageMock = createMock(MimeMessage.class);

		Source source = new StringSource("""");
		Object unmarshalled = new Object();
		expect(messageMock.getPayloadSource()).andReturn(source);
		expect(unmarshallerMock.unmarshal(eq(source), isA(MimeContainer.class))).andReturn(unmarshalled);

		replay(unmarshallerMock, messageMock);

		Object result = MarshallingUtils.unmarshal(unmarshallerMock, messageMock);

		assertThat(result).isEqualTo(unmarshalled);

		verify(unmarshallerMock, messageMock);
	}",1
"@Test
	public void payloadMatch() {

		Source request = new StringSource(""<request xmlns='http://example.com'/>"");
		Source response = new StringSource(""<response xmlns='http://example.com'/>"");

		server.expect(payload(request)).andRespond(withPayload(response));

		StringResult result = new StringResult();
		template.sendSourceAndReceiveToResult(request, result);

		XmlAssert.assertThat(response.toString()).and(result.toString()).ignoreWhitespace().areSimilar();
	}",1
"@Test
	public void payloadNonMatch() {

		assertThatExceptionOfType(AssertionError.class).isThrownBy(() -> {

			Source expected = new StringSource(""<request xmlns='http://example.com'/>"");

			server.expect(payload(expected));

			StringResult result = new StringResult();
			String actual = ""<request xmlns='http://other.com'/>"";
			template.sendSourceAndReceiveToResult(new StringSource(actual), result);
		}",1
"@Test
	public void xpathExistsMatch() {

		final Map<String, String> ns = Collections.singletonMap(""ns"", ""http://example.com"");

		server.expect(xpath(""/ns:request"", ns).exists());

		template.sendSourceAndReceiveToResult(new StringSource(""<request xmlns='http://example.com'/>""),
				new StringResult());
	}",1
"@Test
	public void xsdMatch() throws Exception {

		Resource schema = new ByteArrayResource(
				""<schema xmlns=\""http://www.w3.org/2001/XMLSchema\"" targetNamespace=\""http://example.com\"" elementFormDefault=\""qualified\""><element name=\""request\""/></schema>""
						.getBytes());

		server.expect(validPayload(schema));

		StringResult result = new StringResult();
		String actual = ""<request xmlns='http://example.com'/>"";
		template.sendSourceAndReceiveToResult(new StringSource(actual), result);
	}",1
"@Test
	public void withSoapEnvelopeResource() throws Exception {

		StringBuilder xmlBuilder = new StringBuilder();
		xmlBuilder.append(""<?xml version='1.0'?>"");
		xmlBuilder.append(""<soap:Envelope xmlns:soap='http://www.w3.org/2003/05/soap-envelope'>"");
		xmlBuilder.append(""<soap:Header><header xmlns='http://springframework.org'/></soap:Header>"");
		xmlBuilder.append(""<soap:Body><payload xmlns='http://springframework.org'/></soap:Body>"");
		xmlBuilder.append(""</soap:Envelope>"");
		String envelope = xmlBuilder.toString();
		ResponseCreator responseCreator = ResponseCreators
				.withSoapEnvelope(new ByteArrayResource(envelope.getBytes(StandardCharsets.UTF_8)));
		WebServiceMessage response = responseCreator.createResponse(null, null, messageFactory);

		XmlAssert.assertThat(getSoapEnvelopeAsString((SoapMessage) response)).and(envelope).ignoreWhitespace().areSimilar();
	}",1
"@Test
	public void match() throws Exception {

		StringBuilder xmlBuilder = new StringBuilder();
		xmlBuilder.append(""<?xml version='1.0'?>"");
		xmlBuilder.append(""<soap:Envelope xmlns:soap='http://www.w3.org/2003/05/soap-envelope'>"");
		xmlBuilder.append(""<soap:Header><header xmlns='http://example.com'/></soap:Header>"");
		xmlBuilder.append(""<soap:Body><payload xmlns='http://example.com'/></soap:Body>"");
		xmlBuilder.append(""</soap:Envelope>"");
		String xml = xmlBuilder.toString();
		DOMResult result = new DOMResult();
		TransformerHelper transformerHelper = new TransformerHelper();
		transformerHelper.transform(new StringSource(xml), result);
		SoapMessage message = createMock(SoapMessage.class);
		expect(message.getDocument()).andReturn((Document) result.getNode()).once();
		replay(message);

		SoapEnvelopeDiffMatcher matcher = new SoapEnvelopeDiffMatcher(new StringSource(xml));
		matcher.match(message);

		verify(message);
	}",1
"@Test
	public void nonMatch() {

		assertThatExceptionOfType(AssertionError.class).isThrownBy(() -> {

			StringBuilder xmlBuilder = new StringBuilder();
			xmlBuilder.append(""<?xml version='1.0'?>"");
			xmlBuilder.append(""<soap:Envelope xmlns:soap='http://www.w3.org/2003/05/soap-envelope'>"");
			xmlBuilder.append(""<soap:Header><header xmlns='http://example.com'/></soap:Header>"");
			xmlBuilder.append(""<soap:Body><payload%s xmlns='http://example.com'/></soap:Body>"");
			xmlBuilder.append(""</soap:Envelope>"");
			String xml = xmlBuilder.toString();
			String actual = String.format(xml, ""1"");
			DOMResult result = new DOMResult();
			TransformerHelper transformerHelper = new TransformerHelper();
			transformerHelper.transform(new StringSource(actual), result);
			SoapMessage message = createMock(SoapMessage.class);
			expect(message.getDocument()).andReturn((Document) result.getNode()).once();
			replay(message);

			String expected = String.format(xml, ""2"");
			SoapEnvelopeDiffMatcher matcher = new SoapEnvelopeDiffMatcher(new StringSource(expected));
			matcher.match(message);
		}",1
"@Test
	public void doesNotExistNonMatch() throws AssertionError {

		assertThatExceptionOfType(AssertionError.class).isThrownBy(() -> {

			XPathExpectationsHelper helper = new XPathExpectationsHelper(""//a"");
			WebServiceMessageMatcher matcher = helper.doesNotExist();

			assertThat(matcher).isNotNull();

			WebServiceMessage message = createMock(WebServiceMessage.class);
			expect(message.getPayloadSource()).andReturn(new StringSource(""<a><b/></a>"")).times(2);

			replay(message);

			matcher.match(message);
		}",1
"@Test
	public void evaluatesToIntegerNonMatch() throws AssertionError {

		assertThatExceptionOfType(AssertionError.class).isThrownBy(() -> {

			XPathExpectationsHelper helper = new XPathExpectationsHelper(""//b"");
			WebServiceMessageMatcher matcher = helper.evaluatesTo(2);

			assertThat(matcher).isNotNull();

			WebServiceMessage message = createMock(WebServiceMessage.class);
			expect(message.getPayloadSource()).andReturn(new StringSource(""<a><b>1</b></a>"")).times(2);

			replay(message);

			matcher.match(message);
		}",1
"@Test
	public void evaluatesToTrueNonMatch() throws AssertionError {

		assertThatExceptionOfType(AssertionError.class).isThrownBy(() -> {

			XPathExpectationsHelper helper = new XPathExpectationsHelper(""//b=2"");
			WebServiceMessageMatcher matcher = helper.evaluatesTo(true);

			assertThat(matcher).isNotNull();

			WebServiceMessage message = createMock(WebServiceMessage.class);
			expect(message.getPayloadSource()).andReturn(new StringSource(""<a><b>1</b></a>"")).times(2);

			replay(message);

			matcher.match(message);
		}",1
"@Test
	public void receive() throws Exception {

		byte[] bytes = SOAP_CONTENT.getBytes(StandardCharsets.UTF_8);
		httpServletRequest.addHeader(""Content-Type"", ""text/xml"");
		httpServletRequest.addHeader(""Content-Length"", Integer.toString(bytes.length));
		httpServletRequest.addHeader(HEADER_NAME, HEADER_VALUE);
		httpServletRequest.setContent(bytes);
		SaajSoapMessage message = (SaajSoapMessage) connection.receive(messageFactory);

		assertThat(message).isNotNull();

		StringResult result = new StringResult();
		Transformer transformer = transformerFactory.newTransformer();
		transformer.transform(message.getPayloadSource(), result);

		XmlAssert.assertThat(result.toString()).and(CONTENT).ignoreWhitespace().areIdentical();

		SOAPMessage saajMessage = message.getSaajMessage();
		String[] headerValues = saajMessage.getMimeHeaders().getHeader(HEADER_NAME);

		assertThat(headerValues).isNotNull();
		assertThat(headerValues).hasSize(1);
		assertThat(headerValues[0]).isEqualTo(HEADER_VALUE);
	}",1
"@Test
	public void testDetectWsdlDefinitions() throws Exception {

		servlet.setContextClass(WsdlDefinitionWebApplicationContext.class);
		servlet.init(config);
		MockHttpServletRequest request = new MockHttpServletRequest(HttpTransportConstants.METHOD_GET, ""/definition.wsdl"");
		MockHttpServletResponse response = new MockHttpServletResponse();
		servlet.service(request, response);
		DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactoryUtils.newInstance();
		documentBuilderFactory.setNamespaceAware(true);
		DocumentBuilder documentBuilder = documentBuilderFactory.newDocumentBuilder();
		Document result = documentBuilder.parse(new ByteArrayInputStream(response.getContentAsByteArray()));
		Document expected = documentBuilder.parse(getClass().getResourceAsStream(""wsdl11-input.wsdl""));

		XmlAssert.assertThat(result).and(expected).ignoreWhitespace().areIdentical();
	}",1
"@Test
	public void handleGet() throws Exception {

		request.setMethod(HttpTransportConstants.METHOD_GET);
		String definition = ""<definition xmlns='http://schemas.xmlsoap.org/wsdl/'/>"";
		expect(definitionMock.getSource()).andReturn(new StringSource(definition));

		replay(definitionMock);

		adapter.handle(request, response, definitionMock);

		XmlAssert.assertThat(response.getContentAsString()).and(definition).ignoreWhitespace().areIdentical();

		verify(definitionMock);
	}",1
"@Test
	public void handleSimpleWsdl11DefinitionWithTransformLocation() throws Exception {

		adapter.setTransformLocations(true);
		adapter.setTransformSchemaLocations(true);

		request.setMethod(HttpTransportConstants.METHOD_GET);
		request.setScheme(""http"");
		request.setServerName(""example.com"");
		request.setServerPort(80);
		request.setContextPath(""/context"");
		request.setServletPath(""/service.wsdl"");
		request.setPathInfo(null);
		request.setRequestURI(""/context/service.wsdl"");

		SimpleWsdl11Definition definition = new SimpleWsdl11Definition(
				new ClassPathResource(""echo-input.wsdl"", getClass()));

		adapter.handle(request, response, definition);

		InputStream inputStream = new ByteArrayInputStream(response.getContentAsByteArray());
		DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactoryUtils.newInstance();
		documentBuilderFactory.setNamespaceAware(true);
		DocumentBuilder documentBuilder = documentBuilderFactory.newDocumentBuilder();
		Document resultingDocument = documentBuilder.parse(inputStream);

		documentBuilder = documentBuilderFactory.newDocumentBuilder();
		Document expectedDocument = documentBuilder.parse(getClass().getResourceAsStream(""echo-expected.wsdl""));

		XmlAssert.assertThat(resultingDocument).and(expectedDocument).ignoreWhitespace().areIdentical();
	}",1
"@Test
	public void getDestinationName() throws Exception {

		URI uri = new URI(""jms:RequestQueue?replyToName=RESP_QUEUE"");
		String destinationName = JmsTransportUtils.getDestinationName(uri);

		assertThat(destinationName).isEqualTo(""RequestQueue"");

		uri = new URI(""jms:RequestQueue"");
		destinationName = JmsTransportUtils.getDestinationName(uri);

		assertThat(destinationName).isEqualTo(""RequestQueue"");
	}",1
"@Test
	public void getReplyToName() throws Exception {

		URI uri = new URI(""jms:RequestQueue?replyToName=RESP_QUEUE"");
		String replyToName = JmsTransportUtils.getReplyToName(uri);

		assertThat(replyToName).isEqualTo(""RESP_QUEUE"");

		uri = new URI(""jms:RequestQueue?priority=5"");
		replyToName = JmsTransportUtils.getReplyToName(uri);

		assertThat(replyToName).isNull();
	}",1
"@Test
	public void jndi() throws Exception {

		URI uri = new URI(""jms:jms/REQUEST_QUEUE?replyToName=jms/REPLY_QUEUE"");
		String destination = JmsTransportUtils.getDestinationName(uri);

		assertThat(destination).isEqualTo(""jms/REQUEST_QUEUE"");

		String replyTo = JmsTransportUtils.getReplyToName(uri);

		assertThat(replyTo).isEqualTo(""jms/REPLY_QUEUE"");
	}",1
"@Test
	public void testPopulateBinding() throws Exception {

		String namespace = ""http://springframework.org/spring-ws"";
		definition.addNamespace(""tns"", namespace);
		definition.setTargetNamespace(namespace);

		PortType portType = definition.createPortType();
		portType.setQName(new QName(namespace, ""PortType""));
		portType.setUndefined(false);
		definition.addPortType(portType);
		Operation operation = definition.createOperation();
		operation.setName(""Operation"");
		operation.setUndefined(false);
		operation.setStyle(OperationType.REQUEST_RESPONSE);
		portType.addOperation(operation);
		Input input = definition.createInput();
		input.setName(""Input"");
		operation.setInput(input);
		Output output = definition.createOutput();
		output.setName(""Output"");
		operation.setOutput(output);
		Fault fault = definition.createFault();
		fault.setName(""Fault"");
		operation.addFault(fault);

		Properties soapActions = new Properties();
		soapActions.setProperty(""Operation"", namespace + ""/Action"");
		provider.setSoapActions(soapActions);

		provider.setServiceName(""Service"");

		String locationUri = ""http://localhost:8080/services"";
		provider.setLocationUri(locationUri);

		provider.setCreateSoap11Binding(true);
		provider.setCreateSoap12Binding(true);

		provider.addBindings(definition);
		provider.addServices(definition);

		Binding binding = definition.getBinding(new QName(namespace, ""PortTypeSoap11""));

		assertThat(binding).isNotNull();

		binding = definition.getBinding(new QName(namespace, ""PortTypeSoap12""));

		assertThat(binding).isNotNull();

		Service service = definition.getService(new QName(namespace, ""Service""));

		assertThat(service).isNotNull();
		assertThat(service.getPorts()).hasSize(2);

		Port port = service.getPort(""PortTypeSoap11"");

		assertThat(port).isNotNull();

		port = service.getPort(""PortTypeSoap12"");

		assertThat(port).isNotNull();
	}",1
"@Test
	public void testAddMessages() throws Exception {

		String definitionNamespace = ""http://springframework.org/spring-ws"";
		definition.addNamespace(""tns"", definitionNamespace);
		definition.setTargetNamespace(definitionNamespace);
		String schemaNamespace = ""http://www.springframework.org/spring-ws/schema"";
		definition.addNamespace(""schema"", schemaNamespace);

		Resource resource = new ClassPathResource(""schema.xsd"", getClass());
		Document schemaDocument = documentBuilder.parse(SaxUtils.createInputSource(resource));
		Types types = definition.createTypes();
		definition.setTypes(types);
		Schema schema = (Schema) definition.getExtensionRegistry().createExtension(Types.class,
				new QName(""http://www.w3.org/2001/XMLSchema"", ""schema""));
		types.addExtensibilityElement(schema);
		schema.setElement(schemaDocument.getDocumentElement());

		provider.addMessages(definition);

		assertThat(definition.getMessages()).hasSize(2);

		Message message = definition.getMessage(new QName(definitionNamespace, ""GetOrderRequest""));

		assertThat(message).isNotNull();

		Part part = message.getPart(""GetOrderRequest"");

		assertThat(part).isNotNull();
		assertThat(part.getElementName()).isEqualTo(new QName(schemaNamespace, ""GetOrderRequest""));

		message = definition.getMessage(new QName(definitionNamespace, ""GetOrderResponse""));

		assertThat(message).isNotNull();

		part = message.getPart(""GetOrderResponse"");

		assertThat(part).isNotNull();
		assertThat(part.getElementName()).isEqualTo(new QName(schemaNamespace, ""GetOrderResponse""));
	}",1
"@Test
	public void testContentHandlerDocumentNamespacePrefixes() throws Exception {

		xmlReader.setFeature(""http://xml.org/sax/features/namespace-prefixes"", true);
		handler = new DomContentHandler(result);
		expected = documentBuilder.parse(new InputSource(new StringReader(XML_1)));
		xmlReader.setContentHandler(handler);
		xmlReader.parse(new InputSource(new StringReader(XML_1)));

		assertThat(result).and(expected).areSimilar();
	}",1
"@Test
	public void testContentHandlerDocumentNoNamespacePrefixes() throws Exception {

		handler = new DomContentHandler(result);
		expected = documentBuilder.parse(new InputSource(new StringReader(XML_1)));
		xmlReader.setContentHandler(handler);
		xmlReader.parse(new InputSource(new StringReader(XML_1)));

		assertThat(result).and(expected).areSimilar();
	}",1
"@Test
	public void testContentHandlerElement() throws Exception {

		Element rootElement = result.createElementNS(""namespace"", ""root"");
		result.appendChild(rootElement);
		handler = new DomContentHandler(rootElement);
		expected = documentBuilder.parse(new InputSource(new StringReader(XML_2_EXPECTED)));
		xmlReader.setContentHandler(handler);
		xmlReader.parse(new InputSource(new StringReader(XML_2_SNIPPET)));

		assertThat(result).and(expected).areSimilar();
	}",1
"@Test
	public void testGetQNameForNodeNoNamespace() throws Exception {

		DocumentBuilderFactory factory = DocumentBuilderFactoryUtils.newInstance();
		DocumentBuilder builder = factory.newDocumentBuilder();
		Document document = builder.newDocument();
		Element element = document.createElement(""localname"");
		QName qName = QNameUtils.getQNameForNode(element);

		assertThat(qName).isNotNull();
		assertThat(qName.getLocalPart()).isEqualTo(""localname"");
		assertThat(qName.getNamespaceURI()).isEmpty();
		assertThat(qName.getPrefix()).isEmpty();
	}",1
"@Test
	public void testStringResult() throws Exception {

		Document document = DocumentBuilderFactoryUtils.newInstance().newDocumentBuilder().newDocument();
		Element element = document.createElementNS(""namespace"", ""prefix:localName"");
		document.appendChild(element);

		Transformer transformer = TransformerFactoryUtils.newInstance().newTransformer();
		StringResult result = new StringResult();
		transformer.transform(new DOMSource(document), result);

		assertThat(result.toString()).and(""<prefix:localName xmlns:prefix='namespace'/>"").ignoreWhitespace().areIdentical();
	}",1
"@Test
	public void testDoWithSaxSource() throws Exception {

		XMLReader reader = XMLReaderFactory.createXMLReader();
		InputSource inputSource = new InputSource();

		TraxUtils.SourceCallback mock = createMock(TraxUtils.SourceCallback.class);
		mock.saxSource(reader, inputSource);

		replay(mock);

		TraxUtils.doWithSource(new SAXSource(reader, inputSource), mock);

		verify(mock);
	}",1
"@Test
	public void testDoWithStaxResultEventWriter() throws Exception {

		XMLOutputFactory outputFactory = XMLOutputFactory.newInstance();
		XMLEventWriter eventWriter = outputFactory.createXMLEventWriter(new StringWriter());

		TraxUtils.ResultCallback mock = createMock(TraxUtils.ResultCallback.class);
		mock.staxResult(eventWriter);

		replay(mock);

		TraxUtils.doWithResult(StaxUtils.createStaxResult(eventWriter), mock);

		verify(mock);
	}",1
"@Test
	public void testDoWithStaxResultStreamWriter() throws Exception {

		XMLOutputFactory outputFactory = XMLOutputFactory.newInstance();
		XMLStreamWriter streamWriter = outputFactory.createXMLStreamWriter(new StringWriter());

		TraxUtils.ResultCallback mock = createMock(TraxUtils.ResultCallback.class);
		mock.staxResult(streamWriter);

		replay(mock);

		TraxUtils.doWithResult(StaxUtils.createStaxResult(streamWriter), mock);

		verify(mock);
	}",1
"@Test
	public void testGetDocument() throws Exception {

		DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactoryUtils.newInstance();
		documentBuilderFactory.setNamespaceAware(true);
		DocumentBuilder documentBuilder = documentBuilderFactory.newDocumentBuilder();
		Document document = documentBuilder.newDocument();

		assertThat(TraxUtils.getDocument(new DOMSource(document))).isSameAs(document);

		Element element = document.createElement(""element"");
		document.appendChild(element);

		assertThat(TraxUtils.getDocument(new DOMSource(element))).isSameAs(document);
	}",1
"@Test
	public void testLoadMultipleSchemas() throws Exception {

		Resource envelope = new ClassPathResource(""envelope.xsd"", getClass());
		Resource encoding = new ClassPathResource(""encoding.xsd"", getClass());
		Schema schema = SchemaLoaderUtils.loadSchema(new Resource[] { envelope, encoding }",1
"@Test
	public void testIncludesAndImports() throws Exception {

		Resource hr = new ClassPathResource(""hr.xsd"", getClass());
		collection.setXsds(hr);
		collection.setInline(true);
		collection.afterPropertiesSet();

		XsdSchema[] schemas = collection.getXsdSchemas();

		assertThat(schemas).hasSize(2);
		assertThat(schemas[0].getTargetNamespace()).isEqualTo(""http://mycompany.com/hr/schemas"");

		Resource hr_employee = new ClassPathResource(""hr_employee.xsd"", getClass());
		Document expected = documentBuilder.parse(SaxUtils.createInputSource(hr_employee));
		DOMResult domResult = new DOMResult();
		transformer.transform(schemas[0].getSource(), domResult);

		XmlAssert.assertThat(domResult.getNode()).and(expected).ignoreWhitespace().areIdentical();
		assertThat(schemas[1].getTargetNamespace()).isEqualTo(""http://mycompany.com/hr/schemas/holiday"");

		Resource holiday = new ClassPathResource(""holiday.xsd"", getClass());
		expected = documentBuilder.parse(SaxUtils.createInputSource(holiday));
		domResult = new DOMResult();
		transformer.transform(schemas[1].getSource(), domResult);

		XmlAssert.assertThat(domResult.getNode()).and(expected).ignoreWhitespace().areIdentical();
	}",1
"@Test
  public void testGetProtocol() throws Exception {
    Draft_6455 draft_6455 = new Draft_6455(Collections.<IExtension>emptyList(),
        Collections.<IProtocol>emptyList());
    assertNull(draft_6455.getProtocol());
    draft_6455.acceptHandshakeAsServer(handshakedataProtocolExtension);
    assertNull(draft_6455.getProtocol());
    draft_6455 = new Draft_6455(Collections.<IExtension>emptyList(),
        Collections.<IProtocol>singletonList(new Protocol(""chat"")));
    assertNull(draft_6455.getProtocol());
    draft_6455.acceptHandshakeAsServer(handshakedataProtocolExtension);
    assertNotNull(draft_6455.getProtocol());
  }",1
"@Test
  public void createFramesBinary() throws Exception {
    Draft_6455 draft_6455 = new Draft_6455();
    BinaryFrame curframe = new BinaryFrame();
    ByteBuffer test0 = ByteBuffer.wrap(""Test0"".getBytes());
    curframe.setPayload(test0);
    curframe.setTransferemasked(false);
    List<Framedata> createdFrame = draft_6455.createFrames(test0, false);
    assertEquals(1, createdFrame.size());
    assertEquals(curframe, createdFrame.get(0));
    curframe = new BinaryFrame();
    ByteBuffer test1 = ByteBuffer.wrap(""Test1"".getBytes());
    curframe.setPayload(test1);
    curframe.setTransferemasked(true);
    createdFrame = draft_6455.createFrames(test1, true);
    assertEquals(1, createdFrame.size());
    assertEquals(curframe, createdFrame.get(0));
  }",1
"@Test
  public void createFramesText() throws Exception {
    Draft_6455 draft_6455 = new Draft_6455();
    TextFrame curframe = new TextFrame();
    curframe.setPayload(ByteBuffer.wrap(Charsetfunctions.utf8Bytes(""Test0"")));
    curframe.setTransferemasked(false);
    List<Framedata> createdFrame = draft_6455.createFrames(""Test0"", false);
    assertEquals(1, createdFrame.size());
    assertEquals(curframe, createdFrame.get(0));
    curframe = new TextFrame();
    curframe.setPayload(ByteBuffer.wrap(Charsetfunctions.utf8Bytes(""Test0"")));
    curframe.setTransferemasked(true);
    createdFrame = draft_6455.createFrames(""Test0"", true);
    assertEquals(1, createdFrame.size());
    assertEquals(curframe, createdFrame.get(0));
  }",1
"@Test
  public void testConstructor() throws Exception {
    try {
      Draft_6455 draft_6455 = new Draft_6455(null, null);
      fail(""IllegalArgumentException expected"");
    }",1
"@Test
  public void testHashCode() throws Exception {
    Draft draft0 = new Draft_6455();
    Draft draft1 = draft0.copyInstance();
    Draft draft2 = new Draft_6455(Collections.<IExtension>emptyList(),
        Collections.<IProtocol>singletonList(new Protocol(""chat"")));
    Draft draft3 = draft2.copyInstance();
    assertEquals(draft2.hashCode(), draft3.hashCode());
    assertEquals(draft0.hashCode(), draft2.hashCode());
    assertEquals(draft0.hashCode(), draft1.hashCode());
    //Hashcode changes for draft2 due to a provided protocol
    draft2.acceptHandshakeAsServer(handshakedataProtocolExtension);
    draft1.acceptHandshakeAsServer(handshakedataProtocolExtension);
    assertNotEquals(draft2.hashCode(), draft3.hashCode());
    assertNotEquals(draft0.hashCode(), draft2.hashCode());
    assertEquals(draft0.hashCode(), draft1.hashCode());
    draft2 = draft2.copyInstance();
    draft1 = draft1.copyInstance();
    //Hashcode changes for draft draft2 due to a provided protocol
    draft2.acceptHandshakeAsServer(handshakedataProtocol);
    draft1.acceptHandshakeAsServer(handshakedataProtocol);
    assertNotEquals(draft2.hashCode(), draft3.hashCode());
    assertNotEquals(draft0.hashCode(), draft2.hashCode());
    assertEquals(draft0.hashCode(), draft1.hashCode());
    draft2 = draft2.copyInstance();
    draft1 = draft1.copyInstance();
    //Hashcode changes for draft draft0 due to a provided protocol (no protocol)
    draft2.acceptHandshakeAsServer(handshakedataExtension);
    draft1.acceptHandshakeAsServer(handshakedataExtension);
    assertEquals(draft2.hashCode(), draft3.hashCode());
    assertEquals(draft0.hashCode(), draft2.hashCode());
    // THIS IS A DIFFERENCE BETWEEN equals and hashcode since the hashcode of an empty string = 0
    assertEquals(draft0.hashCode(), draft1.hashCode());
    draft2 = draft2.copyInstance();
    draft1 = draft1.copyInstance();
    //Hashcode changes for draft draft0 due to a provided protocol (no protocol)
    draft2.acceptHandshakeAsServer(handshakedata);
    draft1.acceptHandshakeAsServer(handshakedata);
    assertEquals(draft2.hashCode(), draft3.hashCode());
    assertEquals(draft0.hashCode(), draft2.hashCode());
    // THIS IS A DIFFERENCE BETWEEN equals and hashcode since the hashcode of an empty string = 0
    assertEquals(draft0.hashCode(), draft1.hashCode());
  }",1
"@Test
    public void should_generate_manager_class_for_index_dsl() throws Exception {
        setExec(aptUtils -> {

            final GlobalParsingContext globalContext = new GlobalParsingContext(
                    V3_7.INSTANCE,
                    InsertStrategy.ALL_FIELDS,
                    new LowerCaseNaming(),
                    FieldFilter.EXPLICIT_ENTITY_FIELD_FILTER,
                    FieldFilter.EXPLICIT_UDT_FIELD_FILTER,
                    Optional.empty());

            final String className = TestEntityWithSASI.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityParser entityParser = new EntityParser(aptUtils);

            final EntityMetaSignature entityMetaSignature = entityParser.parseEntity(typeElement, globalContext);

            final ManagerAndDSLClasses managerAndDSLClasses = ManagerCodeGen.buildManager(globalContext, aptUtils, entityMetaSignature);

            final StringBuilder builder = new StringBuilder();
            try {
                JavaFile.builder(TypeUtils.GENERATED_PACKAGE, managerAndDSLClasses.managerClass)
                        .build()
                        .writeTo(builder);
            }",1
"@Test
    public void should_build_entity_with_static_counter_column() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithStaticCounterColumn.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            final TypeSpec typeSpec = builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList()).sourceCode;

            assertThat(buildSource(typeSpec)).isEqualTo(
                    readCodeBlockFromFile(""expected_code/entity_meta_builder/should_build_entity_with_static_counter_column.txt""));
        }",1
"@Test
    public void should_build_view_meta() throws Exception {
        setExec(aptUtils -> {
            final String className = TestViewSensorByType.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            final TypeSpec typeSpec = builder.buildEntityMeta(EntityType.VIEW, typeElement, context, parsingResults, emptyList()).sourceCode;

            assertThat(buildSource(typeSpec)).isEqualTo(
                    readCodeBlockFromFile(""expected_code/entity_meta_builder/should_build_view_meta.txt""));
        }",1
"@Test
    public void should_fail_building_abstract_class() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithAbstractClass.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList());

        }",1
"@Test
    public void should_fail_building_class_with_no_partition_key() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithNoPartitionKey.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList());
        }",1
"@Test
    public void should_fail_building_class_with_wrong_composite_partition_key_order() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithWrongCompositePartitionKey.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList());
        }",1
"@Test
    public void should_fail_building_view_meta_without_view_annotation() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithSimplePartitionKey.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            builder.buildEntityMeta(EntityType.VIEW, typeElement, context, parsingResults, emptyList());

        }",1
"@Test
    public void should_generate_udt_property_class() throws Exception {
        setExec(aptUtils -> {
            final String className = TestUDT.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final UDTMetaCodeGen builder = new UDTMetaCodeGen(aptUtils);

            final GlobalParsingContext globalContext = GlobalParsingContext.defaultContext();
            final EntityParsingContext context = new EntityParsingContext(typeElement,
                    ClassName.get(TestUDT.class), new LowerCaseNaming(), globalContext);
            final List<FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, globalContext);

            final TypeSpec typeSpec = builder.buildUDTClassProperty(typeElement, context, parsingResults, Collections.emptyList());

            assertThat(typeSpec.toString().trim()).isEqualTo(
                    readCodeBlockFromFile(""expected_code/udt_meta_builder/should_generate_udt_property_class.txt""));

        }",1
"@Test
    public void should_generate_udt_with_custom_constructor_property_class() throws Exception {
        setExec(aptUtils -> {
            final String className = TestUDTWithCustomConstructor.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final UDTMetaCodeGen builder = new UDTMetaCodeGen(aptUtils);

            final GlobalParsingContext globalContext = GlobalParsingContext.defaultContext();
            final EntityParsingContext context = new EntityParsingContext(typeElement,
                    ClassName.get(TestUDT.class), new LowerCaseNaming(), globalContext);
            final List<AccessorsExclusionContext> exclusionContexts = Arrays.asList(
                    new AccessorsExclusionContext(""name"", false, true),
                    new AccessorsExclusionContext(""list"", false, true));
            final List<FieldMetaSignature> fieldMetaSignatures = getTypeParsingResults(aptUtils, typeElement, exclusionContexts, globalContext);

            final List<FieldMetaSignature> constructorInjectedFieldMetaSignatures = fieldMetaSignatures
                    .stream()
                    .filter(fieldMeta -> !fieldMeta.context.fieldName.equals(""date""))
                    .collect(Collectors.toList());

            final TypeSpec typeSpec = builder.buildUDTClassProperty(typeElement, context, fieldMetaSignatures, constructorInjectedFieldMetaSignatures);

            assertThat(typeSpec.toString().trim()).isEqualTo(
                    readCodeBlockFromFile(""expected_code/udt_meta_builder/should_generate_udt_with_custom_constructor_property_class.txt""));

        }",1
"@Test
    public void should_build_treemap_for_computed_annotation_ecj() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForAnnotationTree.class.getCanonicalName());
                final VariableElement writetime = findFieldByName(typeElement, ""writetime"");

                // @Computed(function = ""writetime"", alias = ""writetime_col"", cqlClass = Long.class, targetColumns = {""id"", ""value""}",1
"@Test
    public void should_build_treemap_for_frozen_udt_annotation_ecj() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForAnnotationTree.class.getCanonicalName());
                final VariableElement testUdt = findFieldByName(typeElement, ""testUdt"");

                // @Frozen
                // private TestUDT testUdt;
                AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, testUdt);
                final Set<String> annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(TestUDT.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).containsOnly(Frozen.class.getSimpleName());

                final TypedMap typedMap = annotationTree.getAnnotations().get(Frozen.class);
                assertThat(typedMap.isEmpty()).isTrue();

            }",1
"@Test
    public void should_build_trees_for_other_fields_javac() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForAnnotationTree.class.getCanonicalName());
                final VariableElement idElm = findFieldByName(typeElement, ""id"");
                final VariableElement timeElm = findFieldByName(typeElement, ""time"");
                final VariableElement listElm = findFieldByName(typeElement, ""list"");
                final VariableElement setElm = findFieldByName(typeElement, ""set"");

                //   @Enumerated(value = Enumerated.Encoding.NAME) private Long id;
                AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, idElm);
                Set<String> annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(Long.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).containsOnly(Enumerated.class.getSimpleName());

                // private @JSON Date time;
                annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, timeElm);
                annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(Date.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).containsOnly(JSON.class.getSimpleName());

                // private List<Integer> list;
                annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, listElm);
                annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(List.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).isEmpty();

                // private Set<@Enumerated(value = Enumerated.Encoding.NAME) Double> set;
                annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, setElm);
                annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(Set.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).isEmpty();

                // @Enumerated(value = Enumerated.Encoding.NAME) Double
                annotationTree = annotationTree.next();
                annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(Double.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).containsOnly(Enumerated.class.getSimpleName());


            }",1
"@Test
    public void should_build_trees_map_for_level1_nesting_ecj() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForAnnotationTree.class.getCanonicalName());
                final VariableElement level1NestingElm = findFieldByName(typeElement, ""level1Nesting"");

                // private List<Map<Integer,String>> level1Nesting;
                AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils, globalParsingContext, level1NestingElm);
                Set<String> annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(List.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).isEmpty();

                // Map<Integer,String>
                annotationTree = annotationTree.next();
                annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(Map.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).isEmpty();

                // Integer
                annotationTree = annotationTree.next();
                annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(Integer.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).isEmpty();

                // String
                annotationTree = annotationTree.next();
                annotationNames = getAnnotationNames(annotationTree.getAnnotations());
                assertThat(isTypeOf(String.class, annotationTree.getCurrentType())).isTrue();
                assertThat(annotationNames).isEmpty();


            }",1
"@Test
    public void should_create_codec_for_computed() throws Exception {
        setExec(aptUtils -> {
            final CodecFactory codecFactory = new CodecFactory(aptUtils);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForCodecs.class.getCanonicalName());
            final FieldParsingContext context = getFieldParsingContext(aptUtils, typeElement);

            // @Computed(function = ""writetime"",  alias = ""writetime"", targettargetColumnsap""}",1
"@Test
    public void should_create_codec_for_enumerated() throws Exception {
        setExec(aptUtils -> {
            final CodecFactory codecFactory = new CodecFactory(aptUtils);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForCodecs.class.getCanonicalName());
            final FieldParsingContext context = getFieldParsingContext(aptUtils, typeElement);

            // @Enumerated(value = NAME) private ConsistencyLevel consistencyLevel
            final VariableElement elm = findFieldInType(typeElement, ""consistencyLevel"");
            final AnnotationTree tree = AnnotationTree.buildFrom(aptUtils, context.entityContext.globalContext, elm);
            final CodecInfo codecInfo = codecFactory.createCodec(ClassName.get(ConsistencyLevel.class), tree, context, Optional.empty());

            assertThat(codecInfo.sourceType.toString()).isEqualTo(ConsistencyLevel.class.getCanonicalName());
            assertThat(codecInfo.targetType.toString()).isEqualTo(String.class.getCanonicalName());
            assertThat(codecInfo.codecCode.toString()).isEqualTo(
                    ""new info.archinnov.achilles.internals.codec.EnumNameCodec<>(java.util.Arrays.asList(com.datastax.driver.core.ConsistencyLevel.values()), com.datastax.driver.core.ConsistencyLevel.class)"");
        }",1
"@Test
    public void should_create_codec_for_string() throws Exception {
        setExec(aptUtils -> {
            final CodecFactory codecFactory = new CodecFactory(aptUtils);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForCodecs.class.getCanonicalName());
            final FieldParsingContext context = getFieldParsingContext(aptUtils, typeElement);

            // private String value
            final VariableElement elm = findFieldInType(typeElement, ""value"");
            final AnnotationTree tree = AnnotationTree.buildFrom(aptUtils, context.entityContext.globalContext, elm);
            final CodecInfo codecInfo = codecFactory.createCodec(ClassName.get(String.class), tree, context, Optional.empty());

            assertThat(codecInfo.sourceType.toString()).isEqualTo(String.class.getCanonicalName());
            assertThat(codecInfo.targetType.toString()).isEqualTo(String.class.getCanonicalName());
            assertThat(codecInfo.codecCode.toString()).isEqualTo(""new info.archinnov.achilles.internals.codec.FallThroughCodec<>(java.lang.String.class)"");
        }",1
"@Test
    public void should_create_custom_codec_for_counter() throws Exception {
        setExec(aptUtils -> {
            final CodecFactory codecFactory = new CodecFactory(aptUtils);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForCodecs.class.getCanonicalName());
            final FieldParsingContext context = getFieldParsingContext(aptUtils, typeElement);

            // @Counter @Codec(StringToLongCodec.class) private String counterWithCodec;
            final VariableElement elm = findFieldInType(typeElement, ""counterWithCodec"");
            final AnnotationTree tree = AnnotationTree.buildFrom(aptUtils, context.entityContext.globalContext, elm);
            final CodecInfo codecInfo = codecFactory.createCodec(ClassName.get(String.class), tree, context, Optional.empty());

            assertThat(codecInfo.sourceType.toString()).isEqualTo(String.class.getCanonicalName());
            assertThat(codecInfo.targetType.toString()).isEqualTo(Long.class.getCanonicalName());
            assertThat(codecInfo.codecCode.toString()).isEqualTo(
                    ""new "" + StringToLongCodec.class.getCanonicalName() + ""()"");
        }",1
"@Test
    public void should_create_native_codec_for_computed() throws Exception {
        setExec(aptUtils -> {
            final CodecFactory codecFactory = new CodecFactory(aptUtils);
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityForCodecs.class.getCanonicalName());
            final FieldParsingContext context = getFieldParsingContext(aptUtils, typeElement);

            // @Computed(function = ""writetime"",  alias = ""writetime"", targettargetColumnsap""}",1
"@Test
    public void should_fail_creating_JavaType_for_wildcard_type() throws Exception {
        final WildcardTypeName wildCardType = WildcardTypeName.subtypeOf(TypeName.OBJECT);
        setExec(aptUtils -> {
            final CodecFactory codecFactory = new CodecFactory(aptUtils);
            codecFactory.buildJavaTypeForJackson(wildCardType);
        }",1
"@Test
    public void should_fail_because_incorrect_field_type_for_immutable_constructor_param_javac() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final EntityParser parser = new EntityParser(aptUtils);
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestImmutableEntityWithWrongParamTypeInConstructor.class.getCanonicalName());
                parser.parseEntity(typeElement, globalParsingContext);
            }",1
"@Test
    public void should_fail_because_no_matching_field_name_for_constructor_param_javac() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final EntityParser parser = new EntityParser(aptUtils);
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityWithNoMatchingFieldForParamInConstructor.class.getCanonicalName());
                parser.parseEntity(typeElement, globalParsingContext);
            }",1
"@Test
    public void should_generate_meta_signature_for_complex_types_javac() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final EntityParser parser = new EntityParser(aptUtils);
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityWithComplexTypes.class.getCanonicalName());
                final EntityMetaCodeGen.EntityMetaSignature metaSignature = parser.parseEntity(typeElement, globalParsingContext);

                assertThat(metaSignature).isNotNull();
            }",1
"@Test
    public void should_generate_meta_signature_for_view_javac() throws Exception {
        //Given
        setExec(aptUtils -> {
            try {
                final EntityParser parser = new EntityParser(aptUtils);
                final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestViewSensorByType.class.getCanonicalName());
                final EntityMetaCodeGen.EntityMetaSignature metaSignature = parser.parseView(typeElement, globalParsingContext);

                assertThat(metaSignature).isNotNull();
            }",1
"@Test
    public void should_build_frozen_list_index_info() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext context = new EntityParsingContext(typeElement, ClassName.get(TestEntityForFieldInfo.class), strategy, globalParsingContext);

            // @Index @Frozen private List<String> indexedFrozenList;
            VariableElement elm = findFieldInType(typeElement, ""indexedFrozenList"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);

            final CodeBlock codeBlock = parser.buildNativeIndexInfo(annotationTree, elm, context)._1();
            assertThat(codeBlock.toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(
                            ""info.archinnov.achilles.internals.metamodel.index.IndexInfo.forNative(info.archinnov.achilles.internals.metamodel.index.IndexType.FULL, \""indexed_frozen_list_index\"", \""\"", \""\"")"");
        }",1
"@Test
    public void should_build_list_index_info() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext context = new EntityParsingContext(typeElement, ClassName.get(TestEntityForFieldInfo.class), strategy, globalParsingContext);
            // @Index private List<String> indexedList;
            VariableElement elm = findFieldInType(typeElement, ""indexedList"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);

            final CodeBlock codeBlock = parser.buildNativeIndexInfo(annotationTree, elm, context)._1();
            assertThat(codeBlock.toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(""info.archinnov.achilles.internals.metamodel.index.IndexInfo.forNative(info.archinnov.achilles.internals.metamodel.index.IndexType.COLLECTION, \""indexed_list_index\"", \""\"", \""\"")"");
        }",1
"@Test
    public void should_build_partition_column_info() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final TypeName typeName = ClassName.get(TestEntityForFieldInfo.class);

            // @PartitionKey(1) private Long id;
            VariableElement elm = findFieldInType(typeElement, ""id"");
            AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);
            final Tuple2<CodeBlock, ColumnInfo> codeBlock = parser.buildColumnInfo(globalParsingContext, annotationTree,  elm, ""id"", typeName);
            assertThat(codeBlock._1().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(""new info.archinnov.achilles.internals.metamodel.columns.PartitionKeyInfo(1, false)"");
        }",1
"@Test
    public void should_build_static_column_info() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final TypeName typeName = ClassName.get(TestEntityForFieldInfo.class);

            // @Static private int staticCol;
            VariableElement elm = findFieldInType(typeElement, ""staticCol"");
            AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);
            final Tuple2<CodeBlock, ColumnInfo> codeBlock = parser.buildColumnInfo(globalParsingContext, annotationTree,  elm, ""staticCol"", typeName);
            assertThat(codeBlock._1().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(""new info.archinnov.achilles.internals.metamodel.columns.ColumnInfo(false)"");
        }",1
"@Test
    public void should_build_static_column_type() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final TypeName typeName = ClassName.get(TestEntityForFieldInfo.class);

            // @Static private int staticCol;
            VariableElement elm = findFieldInType(typeElement, ""staticCol"");

            final Tuple2<CodeBlock, ColumnType> codeBlock = parser.buildColumnType(globalParsingContext, elm, ""staticCol"", typeName);
            assertThat(codeBlock._1().toString()).isEqualTo(""info.archinnov.achilles.internals.metamodel.columns.ColumnType.STATIC"");
        }",1
"@Test
    public void should_fail_compilation_when_no_suitable_setter() throws Exception {
        setExec(aptUtils -> {
            FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext context = new EntityParsingContext(typeElement, ClassName.get(TestEntityForFieldInfo.class), strategy, globalParsingContext);

            // private Set<@Enumerated(value = ORDINAL) ConsistencyLevel> set;
            VariableElement elm = findFieldInType(typeElement, ""set"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);

            parser.buildFieldInfo(elm, annotationTree, context);
        }",1
"@Test
    public void should_fail_if_both_partition_and_computed_column() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final TypeName typeName = ClassName.get(TestEntityForFieldInfo.class);

            // @PartitionKey(1) @Computed(function = ""xx"", targettargetColumnsx""}",1
"@Test
    public void should_fail_if_clustering_column_order_zero() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final TypeName typeName = ClassName.get(TestEntityForFieldInfo.class);

            // @ClusteringColumn(0) private String wrongClusteringOrder;
            VariableElement elm = findFieldInType(typeElement, ""wrongClusteringOrder"");
            AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);
            parser.buildColumnInfo(globalParsingContext, annotationTree,  elm, ""wrongClusteringOrder"", typeName);
        }",1
"@Test
    public void should_generate_field_info_for_primitiveBoolean() throws Exception {
        setExec(aptUtils -> {
            FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext context = new EntityParsingContext(typeElement, ClassName.get(TestEntityForFieldInfo.class), strategy, globalParsingContext);

            // private boolean primitiveBoolean;
            VariableElement elm = findFieldInType(typeElement, ""primitiveBoolean"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);

            FieldInfoContext fieldInfo = parser.buildFieldInfo(elm, annotationTree, context);

            assertThat(fieldInfo.codeBlock.toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/method_parser/should_generate_field_info_for_primitiveBoolean.txt""));
        }",1
"@Test
    public void should_generate_field_info_for_public_final_columns() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final List<AccessorsExclusionContext> exclusionContexts = Arrays.asList(new AccessorsExclusionContext(""immutableColumn"", true, true));
            final EntityParsingContext context = new EntityParsingContext(typeElement,
                    ClassName.get(TestEntityForFieldInfo.class), strategy, exclusionContexts,
                    globalParsingContext);

            VariableElement elm = findFieldInType(typeElement, ""immutableColumn"");

            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);

            FieldInfoContext fieldInfo = parser.buildFieldInfo(elm, annotationTree, context);

            assertThat(fieldInfo.codeBlock.toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/method_parser/should_generate_field_info_for_public_final_columns.txt""));
        }",1
"@Test
    public void should_fail_parsing_codec_from_registry() throws Exception {

        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = globalParsingContext;
            new CodecRegistryParser(aptUtils).parseCodecs(env, globalContext);
        }",1
"@Test
    public void should_fail_parsing_non_frozen_nested_udt() throws Exception {
        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = new GlobalParsingContext(V3_6.INSTANCE, InsertStrategy.ALL_FIELDS, new LowerCaseNaming(),
                    EXPLICIT_ENTITY_FIELD_FILTER, EXPLICIT_UDT_FIELD_FILTER, Optional.empty());
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalContext);

            // @Column
            // private TestNonFrozenNestedUDT nonFrozenNestedUDT;
            VariableElement elm = findFieldInType(typeElement, ""nonFrozenNestedUDT"");

            fieldParser.parse(elm, entityContext);

        }",1
"@Test
    public void should_fail_parsing_SASI_analyzed_but_not_string() throws Exception {
        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = new GlobalParsingContext(V3_7.INSTANCE, InsertStrategy.ALL_FIELDS, new LowerCaseNaming(),
                    EXPLICIT_ENTITY_FIELD_FILTER, EXPLICIT_UDT_FIELD_FILTER, Optional.empty());
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForSASI.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalContext);

            // @Column
            // @SASI(analyzed = true)
            // private Long analyzedNotString;
            VariableElement elm = findFieldInType(typeElement, ""analyzedNotString"");

            fieldParser.parse(elm, entityContext);

        }",1
"@Test
    public void should_fail_parsing_SASI_analyzed_but_SPARSE() throws Exception {
        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = new GlobalParsingContext(V3_7.INSTANCE, InsertStrategy.ALL_FIELDS, new LowerCaseNaming(),
                    EXPLICIT_ENTITY_FIELD_FILTER, EXPLICIT_UDT_FIELD_FILTER, Optional.empty());
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForSASI.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalContext);

            // @Column
            // @SASI(analyzed = true, indexMode = SPARSE)
            // private String analyzedSparse;
            VariableElement elm = findFieldInType(typeElement, ""analyzedSparse"");

            fieldParser.parse(elm, entityContext);

        }",1
"@Test
    public void should_fail_parsing_SASI_lowercase_But_NotAnalyzed() throws Exception {
        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = new GlobalParsingContext(V3_7.INSTANCE, InsertStrategy.ALL_FIELDS, new LowerCaseNaming(),
                    EXPLICIT_ENTITY_FIELD_FILTER, EXPLICIT_UDT_FIELD_FILTER, Optional.empty());
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForSASI.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalContext);

            // @Column
            // @SASI(analyzed = false, analyzerClass = NON_TOKENIZING_ANALYZER, normalization = LOWERCASE)
            // private String normalizationNotAnalyzed
            VariableElement elm = findFieldInType(typeElement, ""normalizationNotAnalyzed"");

            fieldParser.parse(elm, entityContext);

        }",1
"@Test
    public void should_parse_computed_field_with_codec() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // @Computed(function = ""writetime"",  alias = ""writetime"", targettargetColumnsap""}",1
"@Test
    public void should_parse_field_with_case_sensitive_overriden_name() throws Exception {
        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // @Column(""\""overRiden\"""")
            // private String overridenName;
            VariableElement elm = findFieldInType(typeElement, ""overridenName"");

            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(String.class.getCanonicalName());
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_field_with_case_sensitive_overriden_name.txt""));
        }",1
"@Test
    public void should_parse_list_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private List<TestUDT> listUdt;
            VariableElement elm = findFieldInType(typeElement, ""listUdt"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.List<com.datastax.driver.core.UDTValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_list_udt.txt""));
        }",1
"@Test
    public void should_parse_map_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Map<Integer, TestUDT> mapUdt;
            VariableElement elm = findFieldInType(typeElement, ""mapUdt"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Map<java.lang.Integer, com.datastax.driver.core.UDTValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_map_udt.txt""));
        }",1
"@Test
    public void should_parse_map_with_nested_json() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Map<Integer, @JSON List<Map<Integer, String>>> mapWithNestedJson;
            VariableElement elm = findFieldInType(typeElement, ""mapWithNestedJson"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Map<java.lang.Integer, java.lang.String>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_map_with_nested_json.txt""));
        }",1
"@Test
    public void should_parse_nested_int_array() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            //  private List<@Frozen Map<@Enumerated ProtocolVersion, List<int[]>>> nestedArrays;
            VariableElement elm = findFieldInType(typeElement, ""nestedArrays"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.List<java.util.Map<java.lang.String, java.util.List<int[]>>>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_nested_int_array.txt""));
        }",1
"@Test
    public void should_parse_nested_tuple() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Map<Integer, Tuple2<Integer, String>> nestedTuple;
            VariableElement elm = findFieldInType(typeElement, ""nestedTuple"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Map<java.lang.Integer, com.datastax.driver.core.TupleValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_nested_tuple.txt""));
        }",1
"@Test
    public void should_parse_nested_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private TestNestedUDT nestedUDT;
            VariableElement elm = findFieldInType(typeElement, ""nestedUDT"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(UDTValue.class.getCanonicalName());
            assertThat(parsingResult.udtMetaSignature.isPresent()).isTrue();
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_nested_udt.txt""));
        }",1
"@Test
    public void should_parse_non_frozen_udt() throws Exception {
        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = new GlobalParsingContext(V3_6.INSTANCE, InsertStrategy.ALL_FIELDS, new LowerCaseNaming(),
                    EXPLICIT_ENTITY_FIELD_FILTER, EXPLICIT_UDT_FIELD_FILTER, Optional.empty());
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalContext);

            // @Column
            // private TestUDT nonFrozenUDT;
            VariableElement elm = findFieldInType(typeElement, ""nonFrozenUDT"");

            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(UDTValue.class.getCanonicalName());
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_non_frozen_udt.txt""));
        }",1
"@Test
    public void should_parse_optional_protocol_version_from_inline_codec() throws Exception {

        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = globalParsingContext;
            new CodecRegistryParser(aptUtils).parseCodecs(env, globalContext);
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy,
                    globalContext);

            // @Column
            // private Optional<@Enumerated(Encoding.ORDINAL) ProtocolVersion> optionalEncodingAsOrdinal;
            VariableElement elm = findFieldInType(typeElement, ""optionalEncodingAsOrdinal"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.lang.Integer"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_optional_protocol_version_from_inline_codec.txt""));
        }",1
"@Test
    public void should_parse_optional_string() throws Exception {

        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = globalParsingContext;
            new CodecRegistryParser(aptUtils).parseCodecs(env, globalContext);
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy,
                    globalContext);

            // @Column
            // private Optional<String> optionalString;
            VariableElement elm = findFieldInType(typeElement, ""optionalString"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.lang.String"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_optional_string.txt""));
        }",1
"@Test
    public void should_parse_set_nesting() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Set<Map<Integer,String>> setNesting;
            VariableElement elm = findFieldInType(typeElement, ""setNesting"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Set<java.util.Map<java.lang.Integer, java.lang.String>>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_set_nesting.txt""));
        }",1
"@Test
    public void should_parse_set_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Set<TestUDT> setUdt;
            VariableElement elm = findFieldInType(typeElement, ""setUdt"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Set<com.datastax.driver.core.UDTValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_set_udt.txt""));
        }",1
"@Test
    public void should_parse_tuple_nesting() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Tuple2<Integer, List<String>> tupleNesting;
            VariableElement elm = findFieldInType(typeElement, ""tupleNesting"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(TUPLE_VALUE_CLASSNAME);
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_tuple_nesting.txt""));
        }",1
"@Test
    public void should_fail_parsing_function_forbidden_keyspace_name() throws Exception {
        setExec(aptUtils -> {
            final String className = TestFunctionRegistryWithForbiddenKeyspaceName.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            FunctionParser.parseFunctionRegistryAndValidateTypes(aptUtils, typeElement, context);
        }",1
"@Test
    public void should_fail_parsing_function_with_unsupported_param_type() throws Exception {
        setExec(aptUtils -> {
            final String className = TestFunctionRegistryWithUnsupportedParamType.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            FunctionParser.parseFunctionRegistryAndValidateTypes(aptUtils, typeElement, context);
        }",1
"@Test
    public void should_parse_function_with_keyspace() throws Exception {
        setExec(aptUtils -> {
            final String className = TestFunctionRegistryWithKeyspaceName.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final List<FunctionSignature> UDFSignatures = FunctionParser.parseFunctionRegistryAndValidateTypes(aptUtils, typeElement, context);

            /**
             * Long toLong(String val);
             * Integer toInt(String val);
             */

            assertThat(UDFSignatures).hasSize(2);
            final FunctionSignature signature1 = UDFSignatures.get(0);
            assertThat(signature1.keyspace.get()).isEqualTo(""ks"");
            assertThat(signature1.name).isEqualTo(""toLong"");
            assertThat(signature1.returnTypeSignature.targetCQLTypeName).isEqualTo(OBJECT_LONG);
            assertThat(signature1.sourceParameterTypes).containsExactly(STRING);

            final FunctionSignature signature2 = UDFSignatures.get(1);
            assertThat(signature2.keyspace.get()).isEqualTo(""ks"");
            assertThat(signature2.name).isEqualTo(""toInt"");
            assertThat(signature2.returnTypeSignature.targetCQLTypeName).isEqualTo(OBJECT_INT);
            assertThat(signature2.sourceParameterTypes).containsExactly(STRING);
        }",1
"@Test
    public void should_parse_functions_with_complex_return_types_ecj() throws Exception {
        /**
         * Eclipse compiler orders method by their name:
         *
         * 0 complicated
         * 1 doubleArray
         * 2 enumeratedParam
         * 3 floatArray
         * 4 intArray
         * 5 intToStringCodec
         * 6 jdkInstant
         * 7 jdkLocalDate
         * 8 jdkLocalTime
         * 9 jdkOptional
         * 10 jdkZonedDateTime
         * 11 json
         * 12 listOfMap
         * 13 listUDT
         * 14 localDate
         * 15 longArray
         * 16 mapUDT
         * 17 objectByteArray
         * 18 primitiveByteArray
         * 19 setEnum
         * 20 timeuuid
         * 21 tuple1
         * 22 tuple2
         * 23 udf
         */
        //Given
        setExec(aptUtils -> {
            final ClassName testUDTType = ClassName.get(TestUDT.class);
            final String className = TestFunctionRegistryWithComplexReturnTypes.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final List<FunctionSignature> udfSignatures = FunctionParser.parseFunctionRegistryAndValidateTypes(aptUtils, typeElement, context);

            assertThat(udfSignatures).hasSize(24);
            final FunctionSignature enumeratedParam = udfSignatures.get(2);
            assertThat(enumeratedParam.getFunctionName()).isEqualTo(""enumeratedParam"");
            assertThat(enumeratedParam.parameterSignatures).hasSize(0);
            assertThat(enumeratedParam.returnTypeSignature.sourceTypeName).isEqualTo(CONSISTENCY_LEVEL);
            assertThat(enumeratedParam.returnTypeSignature.targetCQLTypeName).isEqualTo(OBJECT_INT);
            assertThat(enumeratedParam.returnTypeSignature.targetCQLDataType).isEqualTo(""int"");

            final FunctionSignature json = udfSignatures.get(11);
            assertThat(json.returnTypeSignature.sourceTypeName).isEqualTo(JAVA_UTIL_DATE);
            assertThat(json.returnTypeSignature.targetCQLTypeName).isEqualTo(STRING);
            assertThat(json.returnTypeSignature.targetCQLDataType).isEqualTo(""text"");

            final FunctionSignature primitiveByteArray = udfSignatures.get(18);
            assertThat(primitiveByteArray.returnTypeSignature.sourceTypeName).isEqualTo(TypeName.get(byte[].class));
            assertThat(primitiveByteArray.returnTypeSignature.targetCQLTypeName).isEqualTo(BYTE_BUFFER);
            assertThat(primitiveByteArray.returnTypeSignature.targetCQLDataType).isEqualTo(""blob"");

            final FunctionSignature objectByteArray = udfSignatures.get(17);
            assertThat(objectByteArray.returnTypeSignature.sourceTypeName).isEqualTo(TypeName.get(Byte[].class));
            assertThat(objectByteArray.returnTypeSignature.targetCQLTypeName).isEqualTo(BYTE_BUFFER);
            assertThat(objectByteArray.returnTypeSignature.targetCQLDataType).isEqualTo(""blob"");

            final FunctionSignature intToStringCodec = udfSignatures.get(5);
            assertThat(intToStringCodec.returnTypeSignature.sourceTypeName).isEqualTo(OBJECT_INT);
            assertThat(intToStringCodec.returnTypeSignature.targetCQLTypeName).isEqualTo(STRING);
            assertThat(intToStringCodec.returnTypeSignature.targetCQLDataType).isEqualTo(""text"");

            final FunctionSignature udf = udfSignatures.get(23);
            assertThat(udf.returnTypeSignature.sourceTypeName).isEqualTo(testUDTType);
            assertThat(udf.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_DRIVER_UDT_VALUE_TYPE);
            assertThat(udf.returnTypeSignature.targetCQLDataType).isEqualTo(""my_type"");

            final FunctionSignature listUDT = udfSignatures.get(13);
            assertThat(listUDT.returnTypeSignature.sourceTypeName).isEqualTo(genericType(LIST, testUDTType));
            assertThat(listUDT.returnTypeSignature.targetCQLTypeName).isEqualTo(genericType(LIST, JAVA_DRIVER_UDT_VALUE_TYPE));
            assertThat(listUDT.returnTypeSignature.targetCQLDataType).isEqualTo(""list<my_type>"");

            final FunctionSignature mapUDT = udfSignatures.get(16);
            assertThat(mapUDT.returnTypeSignature.sourceTypeName).isEqualTo(genericType(MAP, OBJECT_INT, testUDTType));
            assertThat(mapUDT.returnTypeSignature.targetCQLTypeName).isEqualTo(genericType(MAP, OBJECT_INT, JAVA_DRIVER_UDT_VALUE_TYPE));
            assertThat(mapUDT.returnTypeSignature.targetCQLDataType).isEqualTo(""map<int, my_type>"");

            final FunctionSignature setEnum = udfSignatures.get(19);
            assertThat(setEnum.returnTypeSignature.sourceTypeName).isEqualTo(genericType(SET, CONSISTENCY_LEVEL));
            assertThat(setEnum.returnTypeSignature.targetCQLTypeName).isEqualTo(genericType(SET, STRING));
            assertThat(setEnum.returnTypeSignature.targetCQLDataType).isEqualTo(""set<text>"");

            final FunctionSignature listOfMap = udfSignatures.get(12);
            assertThat(listOfMap.returnTypeSignature.sourceTypeName).isEqualTo(genericType(LIST, genericType(MAP, OBJECT_INT, STRING)));
            assertThat(listOfMap.returnTypeSignature.targetCQLTypeName).isEqualTo(genericType(LIST, genericType(MAP, OBJECT_INT, STRING)));
            assertThat(listOfMap.returnTypeSignature.targetCQLDataType).isEqualTo(""list<map<int, text>>"");

            final FunctionSignature tuple1 = udfSignatures.get(21);
            assertThat(tuple1.returnTypeSignature.sourceTypeName).isEqualTo(genericType(TUPLE1, CONSISTENCY_LEVEL));
            assertThat(tuple1.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_DRIVER_TUPLE_VALUE_TYPE);
            assertThat(tuple1.returnTypeSignature.targetCQLDataType).isEqualTo(""frozen<tuple<text>>"");

            final FunctionSignature tuple2 = udfSignatures.get(22);
            assertThat(tuple2.returnTypeSignature.sourceTypeName).isEqualTo(genericType(TUPLE2, OBJECT_INT, genericType(LIST, OBJECT_INT)));
            assertThat(tuple2.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_DRIVER_TUPLE_VALUE_TYPE);
            assertThat(tuple2.returnTypeSignature.targetCQLDataType).isEqualTo(""frozen<tuple<int, list<text>>>"");

            final FunctionSignature complicated = udfSignatures.get(0);
            assertThat(complicated.returnTypeSignature.sourceTypeName).isEqualTo(genericType(MAP, testUDTType, genericType(MAP, OBJECT_INT, genericType(TUPLE3, OBJECT_INT, OBJECT_INT, CONSISTENCY_LEVEL))));
            assertThat(complicated.returnTypeSignature.targetCQLTypeName).isEqualTo(genericType(MAP, STRING, genericType(MAP, OBJECT_INT, JAVA_DRIVER_TUPLE_VALUE_TYPE)));
            assertThat(complicated.returnTypeSignature.targetCQLDataType).isEqualTo(""map<text, map<int, frozen<tuple<text, int, int>>>>"");

            final FunctionSignature timeuuid = udfSignatures.get(20);
            assertThat(timeuuid.returnTypeSignature.sourceTypeName).isEqualTo(UUID);
            assertThat(timeuuid.returnTypeSignature.targetCQLTypeName).isEqualTo(UUID);
            assertThat(timeuuid.returnTypeSignature.targetCQLDataType).isEqualTo(""timeuuid"");

            final FunctionSignature longArray = udfSignatures.get(15);
            assertThat(longArray.returnTypeSignature.sourceTypeName).isEqualTo(TypeName.get(long[].class));
            assertThat(longArray.returnTypeSignature.targetCQLTypeName).isEqualTo(TypeName.get(long[].class));
            assertThat(longArray.returnTypeSignature.targetCQLDataType).isEqualTo(""list<bigint>"");

            final FunctionSignature intArray = udfSignatures.get(4);
            assertThat(intArray.returnTypeSignature.sourceTypeName).isEqualTo(TypeName.get(int[].class));
            assertThat(intArray.returnTypeSignature.targetCQLTypeName).isEqualTo(TypeName.get(int[].class));
            assertThat(intArray.returnTypeSignature.targetCQLDataType).isEqualTo(""list<int>"");

            final FunctionSignature doubleArray = udfSignatures.get(1);
            assertThat(doubleArray.returnTypeSignature.sourceTypeName).isEqualTo(TypeName.get(double[].class));
            assertThat(doubleArray.returnTypeSignature.targetCQLTypeName).isEqualTo(TypeName.get(double[].class));
            assertThat(doubleArray.returnTypeSignature.targetCQLDataType).isEqualTo(""list<double>"");

            final FunctionSignature floatArray = udfSignatures.get(3);
            assertThat(floatArray.returnTypeSignature.sourceTypeName).isEqualTo(TypeName.get(float[].class));
            assertThat(floatArray.returnTypeSignature.targetCQLTypeName).isEqualTo(TypeName.get(float[].class));
            assertThat(floatArray.returnTypeSignature.targetCQLDataType).isEqualTo(""list<float>"");

            final FunctionSignature localDate = udfSignatures.get(14);
            assertThat(localDate.returnTypeSignature.sourceTypeName).isEqualTo(JAVA_DRIVER_LOCAL_DATE);
            assertThat(localDate.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_DRIVER_LOCAL_DATE);
            assertThat(localDate.returnTypeSignature.targetCQLDataType).isEqualTo(""date"");

            final FunctionSignature jdkInstant = udfSignatures.get(6);
            assertThat(jdkInstant.returnTypeSignature.sourceTypeName).isEqualTo(JAVA_TIME_INSTANT);
            assertThat(jdkInstant.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_TIME_INSTANT);
            assertThat(jdkInstant.returnTypeSignature.targetCQLDataType).isEqualTo(""timestamp"");

            final FunctionSignature jdkLocalDate = udfSignatures.get(7);
            assertThat(jdkLocalDate.returnTypeSignature.sourceTypeName).isEqualTo(JAVA_TIME_LOCAL_DATE);
            assertThat(jdkLocalDate.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_TIME_LOCAL_DATE);
            assertThat(jdkLocalDate.returnTypeSignature.targetCQLDataType).isEqualTo(""date"");

            final FunctionSignature jdkLocalTime = udfSignatures.get(8);
            assertThat(jdkLocalTime.returnTypeSignature.sourceTypeName).isEqualTo(JAVA_TIME_LOCAL_TIME);
            assertThat(jdkLocalTime.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_TIME_LOCAL_TIME);
            assertThat(jdkLocalTime.returnTypeSignature.targetCQLDataType).isEqualTo(""time"");

            final FunctionSignature jdkZonedDateTime = udfSignatures.get(10);
            assertThat(jdkZonedDateTime.returnTypeSignature.sourceTypeName).isEqualTo(JAVA_TIME_ZONED_DATE_TME);
            assertThat(jdkZonedDateTime.returnTypeSignature.targetCQLTypeName).isEqualTo(JAVA_TIME_ZONED_DATE_TME);
            assertThat(jdkZonedDateTime.returnTypeSignature.targetCQLDataType).isEqualTo(""tuple<timestamp, varchar>"");

            final FunctionSignature jdkOptional = udfSignatures.get(9);
            assertThat(jdkOptional.returnTypeSignature.sourceTypeName).isEqualTo(genericType(OPTIONAL, STRING));
            assertThat(jdkOptional.returnTypeSignature.targetCQLTypeName).isEqualTo(STRING);
            assertThat(jdkOptional.returnTypeSignature.targetCQLDataType).isEqualTo(""text"");
        }",1
"@Test
    public void should_fail_validating_class_without_default_constructor() throws Exception {
        setExec(aptUtils -> {
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityWithNoPublicConstructor.class.getCanonicalName());
            final TypeName typeName = ClassName.get(TestEntityWithNoPublicConstructor.class);
            beanValidator.validateConstructor(aptUtils, typeName, typeElement);
        }",1
"@Test
    public void should_validate_entity_with_EntityCreator_constructor() throws Exception {
        setExec(aptUtils -> {
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestEntityWithEntityCreatorConstructor.class.getCanonicalName());
            final TypeName typeName = ClassName.get(TestEntityWithEntityCreatorConstructor.class);
            final ConstructorInfo constructorInfo = beanValidator.validateConstructor(aptUtils, typeName, typeElement);

            assertThat(constructorInfo).isNotNull();
            assertThat(constructorInfo.type).isSameAs(ENTITY_CREATOR);
        }",1
"@Test
    public void should_validate_immutable_entity() throws Exception {
        setExec(aptUtils -> {
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(TestImmutableEntity.class.getCanonicalName());
            final TypeName typeName = ClassName.get(TestImmutableEntity.class);
            final ConstructorInfo constructorInfo = beanValidator.validateConstructor(aptUtils, typeName, typeElement);

            assertThat(constructorInfo).isNotNull();
            assertThat(constructorInfo.type).isSameAs(IMMUTABLE);
        }",1
"@Test
    public void should_validate_view_against_base_table() throws Exception {
        setExec(aptUtils -> {
            final TypeElement typeElementBase = aptUtils.elementUtils.getTypeElement(TestEntitySensor.class.getCanonicalName());
            final TypeElement typeElementView = aptUtils.elementUtils.getTypeElement(TestViewSensorByType.class.getCanonicalName());

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final EntityMetaCodeGen.EntityMetaSignature baseSignature = builder.buildEntityMeta(TABLE, typeElementBase, context, getTypeParsingResults(aptUtils, typeElementBase, context), emptyList());
            final EntityMetaCodeGen.EntityMetaSignature viewSignature = builder.buildEntityMeta(VIEW, typeElementView, context, getTypeParsingResults(aptUtils, typeElementView, context), emptyList());

            beanValidator.validateViewsAgainstBaseTable(aptUtils, Arrays.asList(viewSignature), Arrays.asList(baseSignature));
        }",1
"@Test
    public void should_fail_on_invalidLowerBound() throws Exception {
        String object = Object.class.getCanonicalName();
        final TypeName typeName = TypeName.get(TestTypes.class.getDeclaredField(""invalidLowerBound"").getGenericType());
        typeValidator.validateAllowedTypes(aptUtils, typeName, typeName);
        verify(aptUtils, times(1)).validateTrue(eq(true), anyString(), anyVararg());
        verify(aptUtils, times(1)).validateTrue(eq(false), messageCaptor.capture(), objectCaptor.capture(), objectCaptor.capture());

        assertThat(messageCaptor.getValue()).isEqualTo(""Type '%s' in '%s' is not a valid type for CQL"");
        assertThat(objectCaptor.getAllValues()).containsExactly(object, typeName.toString());
    }",1
"@Test
    public void should_convert_type_name_to_string() throws Exception {
        //Given
        final TypeName nativeBool = TypeName.get(boolean.class);
        final TypeName objectLong = TypeName.get(Long.class);
        final TypeName localDate = TypeName.get(LocalDate.class);
        final TypeName bigDecimal = TypeName.get(BigDecimal.class);
        final TypeName listString = genericType(LIST, STRING);
        final TypeName mapStringTuple = genericType(MAP, STRING, JAVA_DRIVER_TUPLE_VALUE_TYPE);
        final TypeName mapStringListUDT = genericType(MAP, STRING, genericType(LIST, JAVA_DRIVER_UDT_VALUE_TYPE));


        //When
        assertThat(TypeNameHelper.asString(nativeBool)).isEqualTo(""Boolean"");
        assertThat(TypeNameHelper.asString(objectLong)).isEqualTo(""Long"");
        assertThat(TypeNameHelper.asString(localDate)).isEqualTo(""DriverLocalDate"");
        assertThat(TypeNameHelper.asString(bigDecimal)).isEqualTo(""BigDecimal"");
        assertThat(TypeNameHelper.asString(listString)).isEqualTo(""List_String"");
        assertThat(TypeNameHelper.asString(mapStringTuple)).isEqualTo(""Map_String_TupleValue"");
        assertThat(TypeNameHelper.asString(mapStringListUDT)).isEqualTo(""Map_String_List_UDTValue"");

        //Then
    
    }",1
"@Test
    public void should_handle_3_levels_of_nesting_udt() throws Exception {
       //Given
       final EntityLayer1 entity = new EntityLayer1(""layer1"", new Layer2(""layer2"", new Layer3(""layer3"")));
       manager.crud().insert(entity).execute();

       //When
       final EntityLayer1 found = manager.crud().findById(""layer1"").get();

       //Then
       assertThat(found).isNotNull();
       assertThat(found.getLayer()).isEqualTo(""layer1"");
       assertThat(found.getLayer2()).isNotNull();
       assertThat(found.getLayer2().getLayer()).isEqualTo(""layer2"");
       assertThat(found.getLayer2().getLayer3()).isNotNull();
       assertThat(found.getLayer2().getLayer3().getLayer()).isEqualTo(""layer3"");
   }",1
"@Test
    public void should_select_some_columns_from_udt() throws Exception {
        //Given
        final EntityLayer1 entity = new EntityLayer1(""layer1_nested"", new Layer2(""layer2"", new Layer3(""layer3"")));
        manager.crud().insert(entity).execute();

        //When
        final TypedMap found = manager.dsl()
                .select()
                .layer()
                .layer2().layer()
                .layer2().layer3().allColumns()
                .fromBaseTable()
                .where()
                .layer().Eq(entity.getLayer())
                .getTypedMap();

        //Then
        assertThat(found).isNotNull();
        assertThat(found.<String>getTyped(""layer"")).isEqualTo(entity.getLayer());
        assertThat(found.<String>getTyped(""layer2.layer"")).isEqualTo(entity.getLayer2().getLayer());
        assertThat(found.<UDTValue>getTyped(""layer2.layer3"").getString(""layer"")).isEqualTo(entity.getLayer2().getLayer3().getLayer());
    }",1
"@Test
    public void should_fail_validating_schema_when_partition_key_missing() throws Exception {
        //Given
        final Cluster cluster = CassandraEmbeddedServerBuilder.builder()
                .withScript(""EntityWithMissingPartitionKey/schema.cql"")
                .buildNativeCluster();
        cluster.init();

        //When
        exception.expect(AchillesBeanMappingException.class);
        exception.expectMessage(""The mapped partition key(s) [id] for entity "" +
                ""info.archinnov.achilles.internals.entities.EntityWithMissingPartitionKey "" +
                ""do not correspond to live schema partition key(s) [id, bucket]"");

        //Then
        ManagerFactoryBuilder
                .builder(cluster)
                .withManagedEntityClasses(EntityWithMissingPartitionKey.class)
                .build();
    }",1
"@Test
    public void should_insert() throws Exception {
        //Given
        final long id = RandomUtils.nextLong(0L, Long.MAX_VALUE);
        final Tuple2<Integer, Map<Integer, List<String>>> tuple = Tuple2.of(10, ImmutableMap.of(20, asList(""10"", ""20"")));

        final EntityWithComplexTuple entity = new EntityWithComplexTuple(id, tuple);

        //When
        manager
                .crud()
                .insert(entity)
                .execute();

        //Then
        final Row actual = session.execute(""SELECT * FROM complex_tuple WHERE id = "" + id).one();

        assertThat(actual).isNotNull();
        final TupleValue tupleValue = actual.getTupleValue(""tuple"");
        assertThat(tupleValue.getInt(0)).isEqualTo(10);
        final Map<Integer, List<String>> map = tupleValue.getMap(1, new TypeToken<Integer>() {
        }",1
"@Test
    public void should_insert() throws Exception {
        //Given
        final long id = RandomUtils.nextLong(0L, Long.MAX_VALUE);
        final TestUDT udt = new TestUDT();
        udt.setList(asList(""list""));
        udt.setName(""name"");
        udt.setMap(ImmutableMap.of(1, ""1""));
        UUID timeuuid = UUIDs.timeBased();
        java.time.Instant jdkInstant = Instant.now();
        java.time.LocalDate jdkLocalDate = java.time.LocalDate.now();
        java.time.LocalTime jdkLocalTime = java.time.LocalTime.now();
        java.time.ZonedDateTime jdkZonedDateTime = java.time.ZonedDateTime.now();

        final EntityWithComplexTypes entity = new EntityWithComplexTypes();
        entity.setId(id);
        entity.setCodecOnClass(new ClassAnnotatedByCodec());
        entity.setComplexNestingMap(ImmutableMap.of(udt,
                ImmutableMap.of(1, Tuple3.of(1, 2, ConsistencyLevel.ALL))));
        entity.setConsistencyLevel(ConsistencyLevel.EACH_QUORUM);
        entity.setInteger(123);
        entity.setJsonMap(ImmutableMap.of(1, asList(1, 2, 3)));
        entity.setListNesting(asList(ImmutableMap.of(1, ""one"")));
        entity.setListUdt(asList(udt));
        entity.setMapUdt(ImmutableMap.of(1, udt));
        entity.setMapWithNestedJson(ImmutableMap.of(1, asList(ImmutableMap.of(1, ""one""))));
        entity.setObjectBoolean(new Boolean(true));
        entity.setObjectByte(new Byte(""5""));
        entity.setObjectByteArray(new Byte[]{7}",1
"@Test
    public void should_query_using_collection_index_fromJSON() throws Exception {
        //Given
        final Long id = RandomUtils.nextLong(0L, Long.MAX_VALUE);
        scriptExecutor.executeScriptTemplate(""EntityWithIndicesForJSON/insertRows.cql"", ImmutableMap.of(""id"", id));

        //When
        final List<EntityWithIndicesForJSON> actual = manager
                .indexed()
                .select()
                .allColumns_FromBaseTable()
                .where()
                .indexed_collectionIndex().Contains_FromJson(""\""4\"""")
                .getList();

        //Then
        assertThat(actual).hasSize(1);
        final EntityWithIndicesForJSON entity = actual.get(0);
        assertThat(entity.getSimpleIndex()).isEqualTo(""411"");
    }",1
"@Test
    public void should_query_using_index_and_clustering_column_fromJSON() throws Exception {
        //Given
        final Long id = RandomUtils.nextLong(0L, Long.MAX_VALUE);
        scriptExecutor.executeScriptTemplate(""EntityWithIndicesForJSON/insertRows.cql"", ImmutableMap.of(""id"", id));

        //When
        final List<EntityWithIndicesForJSON> actual = manager
                .indexed()
                .select()
                .allColumns_FromBaseTable()
                .where()
                .indexed_simpleIndex().Eq(""312"")
                .clust1().Eq_FromJson(""3"")
                .clust3().Eq_FromJson(""\""2\"""")
                .getList();

        //Then
        assertThat(actual).hasSize(1);
        final EntityWithIndicesForJSON entity = actual.get(0);
        assertThat(entity.getSimpleIndex()).isEqualTo(""312"");
    }",1
"@Test
    public void testKeyUrlWithMatcher() {
        Policy policy = new Policy();
        policy.getType().add(new MatchType(RateLimitType.URL, ""matcherURL""));

        String key = target.key(httpServletRequest, route, policy);
        assertThat(key).isEqualTo(""key-prefix:id:/**:matcherURL"");
    }",1
"@Test
    public void testKeyUserNullPrincipal() {
        Policy policy = new Policy();
        policy.getType().add(new MatchType(RateLimitType.USER, null));

        String key = target.key(httpServletRequest, route, policy);
        assertThat(key).isEqualTo(""key-prefix:id:anonymous"");
    }",1
"@Test
    public void testKeyUserWithMatcher() {
        Policy policy = new Policy();
        policy.getType().add(new MatchType(RateLimitType.USER, ""matcherUser""));
        when(httpServletRequest.getRemoteUser()).thenReturn(""user"");

        String key = target.key(httpServletRequest, route, policy);
        assertThat(key).isEqualTo(""key-prefix:id:user:matcherUser"");
    }",1
"@Test
    public void testValidOnPolicyWithLimitAndRole() {
        properties.setKeyPrefix(""prefix"");
        Policy policy = getPolicy(1L, null);
        policy.getType().add(new Policy.MatchType(RateLimitType.ROLE, ""user""));
        properties.getDefaultPolicyList().add(policy);
        properties.getPolicyList().put(""key"", Lists.newArrayList(policy));
        Set<ConstraintViolation<RateLimitProperties>> violations = validator.validate(properties);
        assertThat(violations).isEmpty();
    }",1
"@Test
    public void testValidOnPolicyWithQuotaNoLimit() {
        properties.setKeyPrefix(""prefix"");
        Policy policy = getPolicy(null, Duration.ofSeconds(1));
        properties.getDefaultPolicyList().add(policy);
        properties.getPolicyList().put(""key"", Lists.newArrayList(policy));
        Set<ConstraintViolation<RateLimitProperties>> violations = validator.validate(properties);
        assertThat(violations).isEmpty();
    }",1
"@Test
    public void testConsumeRemainingLimitException() {
        doThrow(new RuntimeException()).when(redisTemplate).execute(any(), anyList(), anyString(), anyString());

        Policy policy = new Policy();
        policy.setLimit(100L);
        target.consume(policy, ""key"", 0L);
        verify(rateLimiterErrorHandler).handleError(matches("".* key, .*""), any());
    }",1
"@Test
    public void testShouldFilterOnNullStartTime() {
        rateLimitProperties.setEnabled(true);
        Policy defaultPolicy = new Policy();
        rateLimitProperties.getDefaultPolicyList().add(defaultPolicy);

        assertThat(target.shouldFilter()).isEqualTo(false);
    }",1
"@Test
    public void testShouldFilterOnDisabledProperty() {
        assertThat(target.shouldFilter()).isEqualTo(false);
    }",1
"@Test
    public void testLocalFileStore() throws IOException {
        String randomContent = UUID.randomUUID();
        String relativePath = FileUtil.generateFilePath(""txt"");
        InputStream baos = new ByteArrayInputStream(randomContent.getBytes());
        iFileStore.storeFile(baos, relativePath);
        baos.close();

        // 验证
        File file = new File(basePath + relativePath);
        Assert.assertTrue(file.exists());

        // 验证 loadFileBytes
        byte[] bytes1 = iFileStore.loadFileBytes(relativePath);
        Assert.assertEquals(new String(bytes1), randomContent);

        // 验证 loadFile
        ByteArrayOutputStream os = new ByteArrayOutputStream();
        iFileStore.loadFile(relativePath, os);
        byte[] bytes2 = os.toByteArray();
        os.close();
        Assert.assertEquals(new String(bytes2), randomContent);

        Assert.assertTrue(file.delete());
        Assert.assertTrue(!file.exists());
    }",1
"@Test
  public void eq1() throws Throwable {
    // Arrange
    Object a = -1;
    Object b = null;
    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.JSONPath"");
    Method m = c.getDeclaredMethod(""eq"", Reflector.forName(""java.lang.Object""), Reflector.forName(""java.lang.Object""));
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(null, a, b);
    // Assert result
    Assert.assertEquals(false, retval);
  }",1
"@Test
  public void isEOF2() throws Throwable {
    // Arrange
    Object objectUnderTest = Reflector.getInstance(""com.alibaba.fastjson.JSONPath$JSONPathParser"");
    Reflector.setField(objectUnderTest, ""path"", ""!"");
    Reflector.setField(objectUnderTest, ""pos"", 1);
    Reflector.setField(objectUnderTest, ""level"", 0);
    Reflector.setField(objectUnderTest, ""ch"", '\u0000');
    // Act
    Class<?> c = Reflector.forName(""com.alibaba.fastjson.JSONPath$JSONPathParser"");
    Method m = c.getDeclaredMethod(""isEOF"");
    m.setAccessible(true);
    boolean retval = (Boolean)m.invoke(objectUnderTest);
    // Assert result
    Assert.assertEquals(true, retval);
  }",1
"@Test
    public void checkDate16() throws Throwable {
        // Arrange
        char y0 = '2';
        char y1 = '0';
        char y2 = '2';
        char y3 = '0';
        char M0 = '1';
        char M1 = '3';
        int d0 = 48;
        int d1 = 52;

        // Act
        Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
        Method m = c.getDeclaredMethod(""checkDate"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""int""), Reflector.forName(""int""));
        m.setAccessible(true);
        boolean retval = (Boolean)m.invoke(null, y0, y1, y2, y3, M0, M1, d0, d1);

        // Assert result
        Assert.assertEquals(false, retval);
    }",1
"@Test
    public void checkDate3() throws Throwable {
        // Arrange
        char y0 = '2';
        char y1 = '0';
        char y2 = '2';
        char y3 = '0';
        char M0 = '0';
        char M1 = '2';
        int d0 = 48;
        int d1 = 97;

        // Act
        Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
        Method m = c.getDeclaredMethod(""checkDate"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""int""), Reflector.forName(""int""));
        m.setAccessible(true);
        boolean retval = (Boolean)m.invoke(null, y0, y1, y2, y3, M0, M1, d0, d1);

        // Assert result
        Assert.assertEquals(false, retval);
    }",1
"@Test
    public void checkDate6() throws Throwable {
        // Arrange
        char y0 = '2';
        char y1 = '0';
        char y2 = '2';
        char y3 = '0';
        char M0 = '0';
        char M1 = '2';
        int d0 = 49;
        int d1 = 97;

        // Act
        Class<?> c = Reflector.forName(""com.alibaba.fastjson.parser.JSONScanner"");
        Method m = c.getDeclaredMethod(""checkDate"", Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""char""), Reflector.forName(""int""), Reflector.forName(""int""));
        m.setAccessible(true);
        boolean retval = (Boolean)m.invoke(null, y0, y1, y2, y3, M0, M1, d0, d1);

        // Assert result
        Assert.assertEquals(false, retval);
    }",1
"@Test
  public void shouldTestError() {
    init();
    for (LoggerVarArgsTestData variance : getVarArgsVariations()) {
      log.error(variance.getMessage(), variance.getParams());
      logEvents = LogHelper.getFatalEvents(getMockAppender(), getCategory());

      Affirm.affirmEquals(String.format(""Lost [%s] message?"", ""ERROR""), count + 1, logEvents.size());
      Affirm.affirmEquals(""Error wired?"", 0, LogHelper.getErrorEvents(getMockAppender(), getCategory()).size());
      Affirm.affirmEquals(""Message malformed"", variance.getExpected(), logEvents.get(count).getMessage());

      count++;
    }",1
"@Test
  public void shouldFailOnlyEqualsIsImplemented() {
    PojoClass aClassImplementingEqualsOnly = PojoClassFactory.getPojoClass(AClassImplementingEqualsOnly.class);
    List<PojoMethod> methods = aClassImplementingEqualsOnly.getPojoMethods();

    Assert.assertEquals(2, methods.size());
    boolean constructorFound = false;
    boolean equalsFound = false;

    for (PojoMethod method : methods) {
      if (method.isConstructor())
        constructorFound = true;
      if (method.getName().equals(""equals"")
          && method.getPojoParameters().size() == 1
          && method.getReturnType().equals(boolean.class))
        equalsFound = true;
    }",1
"@Test
  public void shouldPassWhenEqualsAndHashCodeAreImplemented() {
    PojoClass aClassImplementingEqualsAndHashcode = PojoClassFactory.getPojoClass(AClassImplementingEqualsAndHashCode.class);
    List<PojoMethod> methods = aClassImplementingEqualsAndHashcode.getPojoMethods();

    Assert.assertEquals(3, methods.size());

    boolean constructorFound = false;
    boolean equalsFound = false;
    boolean hashCodeFound = false;

    for (PojoMethod method : methods) {
      if (method.isConstructor())
        constructorFound = true;
      if (method.getName().equals(""hashCode"")
          && method.getPojoParameters().size() == 0
          && method.getReturnType().equals(int.class))
        hashCodeFound = true;
      if (method.getName().equals(""equals"")
          && method.getPojoParameters().size() == 1
          && method.getReturnType().equals(boolean.class))
        equalsFound = true;
    }",1
"@Test
  public void testIsStaticFinal() {
    PojoClass pojoClass = PojoClassFactory.getPojoClass(StaticFinalData.class);
    List<PojoField> pojoFields = pojoClass.getPojoFields();
    Assert.assertEquals(4, pojoFields.size());
    for (PojoField fieldEntry : pojoFields) {
      if (fieldEntry.getName().equals(""staticAndNotFinal"")) {
        Assert.assertTrue(""Static and not Final test failed!!"",
            fieldEntry.isStatic()
                && !fieldEntry.isFinal()
                && !ValidationHelper.isStaticFinal(fieldEntry));
      }",1
"@Test
    public void testCompile() {
        NamedVariablePatternMatcher matcher = new NamedVariablePatternMatcher();

        assertNull(matcher.compilePattern(null));
        assertNull(matcher.compilePattern(""""));

        CompiledPattern pattern = matcher.compilePattern(""action.{format}",1
"@Test
  public void testInvalidImagesFail() throws Exception {
    final Job.Builder b = Job.newBuilder().setName(""foo"").setVersion(""1"");

    assertEquals(newHashSet(""Tag cannot be empty""),
        validator.validate(b.setImage(""repo:"").build()));

    assertEquals(newHashSet(""Tag cannot be empty""),
        validator.validate(b.setImage(""repo:"").build()));

    assertEquals(newHashSet(""Tag cannot be empty""),
        validator.validate(b.setImage(""repo:""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae"").build()));

    assertEquals(newHashSet(""Digest cannot be empty""),
        validator.validate(b.setImage(""foo@"").build()));

    assertEquals(newHashSet(""Illegal digest: \"":123\""""),
        validator.validate(b.setImage(""foo@:123"").build()));

    assertEquals(newHashSet(""Illegal digest: \"":123\""""),
        validator.validate(b.setImage(""foo:bar@:123"").build()));

    assertEquals(newHashSet(""Illegal digest: \""sha256:\""""),
        validator.validate(b.setImage(""foo@sha256:"").build()));

    assertEquals(newHashSet(""Illegal digest: \""sha256:\""""),
        validator.validate(b.setImage(""foo:bar@sha256:"").build()));

    assertEquals(newHashSet(""Illegal digest: \""sha256:\""""),
        validator.validate(b.setImage(""foo:4711/baz:bar@sha256:"").build()));

    assertFalse(validator.validate(b.setImage(""repo:/"").build()).isEmpty());

    assertEquals(newHashSet(""Invalid domain name: \""1.2.3.4.\""""),
        validator.validate(b.setImage(""1.2.3.4.:4711/namespace/repo"").build()));

    assertEquals(newHashSet(""Invalid domain name: \"" reg.istry\""""),
        validator.validate(b.setImage("" reg.istry:4711/repo"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""reg .istry\""""),
        validator.validate(b.setImage(""reg .istry:4711/repo"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""reg.istry \""""),
        validator.validate(b.setImage(""reg.istry :4711/repo"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""1.2.3.4.\""""),
        validator.validate(b.setImage(""1.2.3.4.:4711/namespace/repo""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae"").build()));

    assertEquals(newHashSet(""Invalid port in endpoint: \""reg.istry: 4711\""""),
        validator.validate(b.setImage(""reg.istry: 4711/repo"").build()));

    assertEquals(newHashSet(""Invalid port in endpoint: \""reg.istry:4711 \""""),
        validator.validate(b.setImage(""reg.istry:4711 /repo"").build()));

    assertEquals(newHashSet(""Invalid port in endpoint: \""reg.istry:4711 \""""),
        validator.validate(b.setImage(""reg.istry:4711 /repo""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae"").build()));

    assertEquals(newHashSet(""Invalid image name (reg.istry:4711/ repo), only ^([a-z0-9._-]+)$ is ""
                            + ""allowed for each slash-separated name component ""
                            + ""(failed on \"" repo\"")""),
        validator.validate(b.setImage(""reg.istry:4711/ repo"").build()));

    assertEquals(newHashSet(""Invalid image name (reg.istry:4711/namespace /repo), only ""
                            + ""^([a-z0-9._-]+)$ is allowed for each slash-separated name component ""
                            + ""(failed on \""namespace \"")""),
        validator.validate(b.setImage(""reg.istry:4711/namespace /repo"").build()));

    assertEquals(newHashSet(""Invalid image name (reg.istry:4711/namespace/ repo), only ""
                            + ""^([a-z0-9._-]+)$ is allowed for each slash-separated name component ""
                            + ""(failed on \"" repo\"")""),
        validator.validate(b.setImage(""reg.istry:4711/namespace/ repo"").build()));

    assertEquals(newHashSet(""Invalid image name (reg.istry:4711/namespace/repo ), only ""
                            + ""^([a-z0-9._-]+)$ is allowed for each slash-separated name component ""
                            + ""(failed on \""repo \"")""),
        validator.validate(b.setImage(""reg.istry:4711/namespace/repo "").build()));

    assertEquals(newHashSet(""Invalid image name (reg.istry:4711/namespace/ repo""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae), only ""
                            + ""^([a-z0-9._-]+)$ is allowed for each slash-separated name component ""
                            + ""(failed on \"" repo\"")""),
        validator.validate(b.setImage(""reg.istry:4711/namespace/ repo""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""foo-.ba|z\""""),
        validator.validate(b.setImage(""foo-.ba|z/namespace/baz"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""reg..istry\""""),
        validator.validate(b.setImage(""reg..istry/namespace/baz"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""reg..istry\""""),
        validator.validate(b.setImage(""reg..istry/namespace/baz"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""reg..istry\""""),
        validator.validate(b.setImage(""reg..istry/namespace/baz:foo"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""reg..istry\""""),
        validator.validate(b.setImage(""reg..istry/namespace/baz:foo""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae"").build()));

    assertEquals(newHashSet(""Invalid domain name: \""reg..istry\""""),
        validator.validate(b.setImage(""reg..istry/namespace/baz""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae"").build()));

    assertEquals(newHashSet(""Invalid port in endpoint: \""foo:345345345\""""),
        validator.validate(b.setImage(""foo:345345345/namespace/baz"").build()));

    assertEquals(newHashSet(""Invalid port in endpoint: \""foo:345345345\""""),
        validator.validate(b.setImage(""foo:345345345/namespace/baz:bar"").build()));

    assertEquals(newHashSet(""Invalid port in endpoint: \""foo:345345345\""""),
        validator.validate(b.setImage(""foo:345345345/namespace/baz:bar""
            + ""@sha256:2c26b46b68ffc68ff99b453c1d30413413422d706483bfa0f98a5e886266e7ae"").build()));

    assertEquals(newHashSet(""Invalid port in endpoint: \""foo:-17\""""),
        validator.validate(b.setImage(""foo:-17/namespace/baz"").build()));

    final String foos = Strings.repeat(""foo"", 100);
    final String image = foos + ""/bar"";
    assertEquals(newHashSet(""Invalid image name ("" + image + ""), repository name cannot be larger""
                            + "" than 255 characters""),
        validator.validate(b.setImage(image).build()));
  }",1
"@Test
  public void testServiceDiscovery() throws Exception {
    // start a container that runs nginx and registers with SkyDNS
    final TemporaryJob nginx = jobs.job()
        .image(NGINX)
        .port(""http"", 80, ports.localPort(""http""))
        .registration(""nginx"", ""http"", ""http"")
        .deploy();

    // run a container that does SRV lookup to find the nginx service and then curl's it
    final TemporaryJob alpine = jobs.job()
        .image(ALPINE)
        .port(""nc"", 4711, ports.localPort(""nc""))
        .command(""sh"", ""-c"",
            ""apk add --update bind-tools ""
            + ""&& export SRV=$(dig -t SRV +short _nginx._http.test.$SPOTIFY_DOMAIN) ""
            + ""&& export HOST=$(echo $SRV | cut -d' ' -f4) ""
            + ""&& export PORT=$(echo $SRV | cut -d' ' -f3) ""
            + ""&& nc -lk -p 4711 -e curl http://$HOST:$PORT""
        )
        .deploy();

    final HostAndPort alpineAddress = alpine.address(""nc"");

    // Connect to alpine container to get the curl response. If we get back the nginx welcome page
    // we know that helios properly registered the nginx service in SkyDNS.
    final Callable<String> socketResponse = () -> {
      try (final Socket s = new Socket(alpineAddress.getHost(), alpineAddress.getPort())) {
        return IOUtils.toString(s.getInputStream(), Charsets.UTF_8).trim();
      }",1
"@Test
  public void jobDeployedWithHistoryLastUsedRecentlyNotReaped() throws Exception {
    final MasterModel masterModel = mock(MasterModel.class);
    testReap(name.getMethodName(), deployments(JobId.fromString(name.getMethodName()), 3),
        events(ImmutableList.of(HOURS.toMillis(20), HOURS.toMillis(40))), null, masterModel, false);
  }",1
"@Test
  public void jobDeployedWithHistoryLastUsedTooLongAgoNotReaped() throws Exception {
    final MasterModel masterModel = mock(MasterModel.class);
    testReap(name.getMethodName(), deployments(JobId.fromString(name.getMethodName()), 3),
        events(ImmutableList.of(HOURS.toMillis(20), HOURS.toMillis(22))), null, masterModel, false);
  }",1
"@Test
  public void testCreateJobWithPartialRolloutOptions() throws Exception {
    final JobId jobId = JobId.parse(""foobar:1"");
    final Job job = Job.newBuilder()
        .setName(""foobar"")
        .setVersion(""1"")
        .setImage(""busybox:latest"")
        .setRolloutOptions(RolloutOptions.newBuilder()
            .setTimeout(null)
            .setParallelism(2)
            .setMigrate(null)
            .setOverlap(true)
            .setToken(null)
            .setIgnoreFailures(null)
            .build())
        .setCreatingUser(""user1"")
        .setCreated(0L)
        .build();

    final CreateJobResponse jobResponse = resource.post(job, ""user1"");
    assertThat(jobResponse,
        new CustomTypeSafeMatcher<CreateJobResponse>(""CreateJobResponse that is OK"") {
          @Override
          protected boolean matchesSafely(final CreateJobResponse response) {
            return response.getStatus() == OK
                   && response.getErrors().isEmpty()
                   && response.getId().contains(jobId.toString());
          }",1
"@Test
  public void testStartManualNoHosts() throws Exception {
    // Create a DeploymentGroupTasks object with no rolloutTasks (defaults to empty list).
    final DeploymentGroupTasks deploymentGroupTasks = DeploymentGroupTasks.newBuilder()
        .setDeploymentGroup(MANUAL_DEPLOYMENT_GROUP)
        .build();

    final RollingUpdateOpFactory opFactory = new RollingUpdateOpFactory(
        deploymentGroupTasks, eventFactory);
    final ZooKeeperClient client = mock(ZooKeeperClient.class);
    when(client.exists(anyString())).thenReturn(null);
    final RollingUpdateOp op = opFactory.start(MANUAL_DEPLOYMENT_GROUP, client);

    // Three ZK operations should return:
    // * create tasks node
    // * delete the tasks
    // * set the status to DONE
    assertEquals(
        ImmutableSet.of(
            new CreateEmpty(""/status/deployment-group-tasks/my_group""),
            new Delete(""/status/deployment-group-tasks/my_group""),
            new SetData(""/status/deployment-groups/my_group"", DeploymentGroupStatus.newBuilder()
                .setState(DeploymentGroupStatus.State.DONE)
                .setError(null)
                .build()
                .toJsonBytes())),
        ImmutableSet.copyOf(op.operations()));

    // Two events should return: rollingUpdateStarted and rollingUpdateDone
    assertEquals(2, op.events().size());
    verify(eventFactory).rollingUpdateStarted(MANUAL_DEPLOYMENT_GROUP);
    verify(eventFactory).rollingUpdateDone(MANUAL_DEPLOYMENT_GROUP);
  }",1
"@Test
  public void testTransitionToFailed() {
    final DeploymentGroupTasks deploymentGroupTasks = DeploymentGroupTasks.newBuilder()
        .setTaskIndex(0)
        .setRolloutTasks(Lists.newArrayList(
            RolloutTask.of(RolloutTask.Action.UNDEPLOY_OLD_JOBS, ""host1""),
            RolloutTask.of(RolloutTask.Action.AWAIT_RUNNING, ""host1""),
            RolloutTask.of(RolloutTask.Action.DEPLOY_NEW_JOB, ""host1"")))
        .setDeploymentGroup(MANUAL_DEPLOYMENT_GROUP)
        .build();

    final RollingUpdateOpFactory opFactory = new RollingUpdateOpFactory(
        deploymentGroupTasks, eventFactory);
    final RollingUpdateOp op = opFactory.error(""foo"", ""host1"", RollingUpdateError.HOST_NOT_FOUND);

    final Map<String, Object> failEvent = Maps.newHashMap();
    when(eventFactory.rollingUpdateTaskFailed(
        any(DeploymentGroup.class), any(RolloutTask.class),
        anyString(), any(RollingUpdateError.class))).thenReturn(failEvent);

    // When state -> FAILED we expected
    //  * deployment group tasks are deleted
    //  * deployment group status is updated (to FAILED)
    assertEquals(
        ImmutableSet.of(
            new SetData(""/status/deployment-groups/my_group"", DeploymentGroupStatus.newBuilder()
                .setState(DeploymentGroupStatus.State.FAILED)
                .setError(""host1: foo"")
                .build()
                .toJsonBytes()),
            new Delete(""/status/deployment-group-tasks/my_group"")),
        ImmutableSet.copyOf(op.operations()));

    // ...and that a failed-task event and a rolling-update failed event are emitted
    assertEquals(2, op.events().size());

    verify(eventFactory).rollingUpdateTaskFailed(
        eq(MANUAL_DEPLOYMENT_GROUP),
        eq(deploymentGroupTasks.getRolloutTasks().get(deploymentGroupTasks.getTaskIndex())),
        anyString(),
        eq(RollingUpdateError.HOST_NOT_FOUND),
        eq(Collections.<String, Object>emptyMap()));

    verify(eventFactory).rollingUpdateFailed(
        eq(MANUAL_DEPLOYMENT_GROUP),
        eq(failEvent));
  }",1
"@Test
  public void verifyRecoversFromBackupRestoreOffline() throws Exception {
    // Create backup
    try {
      zk.curatorWithSuperAuth().create().forPath(""/version"", ""1"".getBytes());
    }",1
"@Test
  public void testAttributesIncludeAdditionalAttributes() throws Exception {
    // a counter to keep track of how often the Supplier is called
    final AtomicInteger counter = new AtomicInteger(0);
    final Supplier<Map<String, String>> additionalAttributes = () -> {
      final int count = counter.incrementAndGet();
      return ImmutableMap.of(""foo"", ""bar"", ""counter"", String.valueOf(count));
    }",1
"@Test
  public void testExecHealthCheckBuilder() {
    final ExecHealthCheck healthCheck = HealthCheck.newExecHealthCheck()
        .setCommand(Collections.singletonList(""whoami"")).build();
    assertEquals(""cmd"", healthCheck.getCommand(), ImmutableList.of(""whoami""));
  }",1
"@Test
  public void testConfigHasGoogleContainerRegistryCredentials() throws Exception {
    // generate a file that we will pretend contains GCR credentials, in order to verify that
    // HeliosSoloDeployment sets up the expected environment variables and volume binds
    // when this config value exists (and is a real file)
    final File credentialsFile = temporaryFolder.newFile(""fake-credentials"");
    final String credentialsPath = credentialsFile.getPath();

    final String image = ""helios-test"";

    final Config config = ConfigFactory.empty()
        .withValue(""helios.solo.profile"", ConfigValueFactory.fromAnyRef(""test""))
        .withValue(""helios.solo.profiles.test.image"", ConfigValueFactory.fromAnyRef(image))
        .withValue(""helios.solo.profiles.test.google-container-registry.credentials"",
            ConfigValueFactory.fromAnyRef(credentialsPath)
        );

    buildHeliosSoloDeployment(new HeliosSoloDeployment.Builder(null, config));

    ContainerConfig soloContainerConfig = null;
    for (final ContainerConfig cc : containerConfig.getAllValues()) {
      if (cc.image().contains(image)) {
        soloContainerConfig = cc;
      }",1
"@Test
  public void testUndeployLeftoverJobs() throws Exception {
    final HeliosSoloDeployment solo = buildHeliosSoloDeployment();

    final ListenableFuture<List<String>> hostsFuture = Futures.<List<String>>immediateFuture(
        ImmutableList.of(HOST1, HOST2));
    when(heliosClient.listHosts()).thenReturn(hostsFuture);

    // These futures represent HostStatuses when the job is still deployed
    final ListenableFuture<HostStatus> statusFuture11 = Futures.immediateFuture(
        HostStatus.newBuilder()
            .setStatus(Status.UP)
            .setStatuses(ImmutableMap.of(JOB_ID1, TASK_STATUS1))
            .setJobs(ImmutableMap.of(JOB_ID1, Deployment.of(JOB_ID1, Goal.START)))
            .build());
    final ListenableFuture<HostStatus> statusFuture21 = Futures.immediateFuture(
        HostStatus.newBuilder()
            .setStatus(Status.UP)
            .setStatuses(ImmutableMap.of(JOB_ID2, TASK_STATUS2))
            .setJobs(ImmutableMap.of(JOB_ID2, Deployment.of(JOB_ID2, Goal.START)))
            .build());

    // These futures represent HostStatuses when the job is undeployed
    final ListenableFuture<HostStatus> statusFuture12 = Futures.immediateFuture(
        HostStatus.newBuilder()
            .setStatus(Status.UP)
            .setStatuses(Collections.<JobId, TaskStatus>emptyMap())
            .setJobs(ImmutableMap.of(JOB_ID1, Deployment.of(JOB_ID1, Goal.START)))
            .build());
    final ListenableFuture<HostStatus> statusFuture22 = Futures.immediateFuture(
        HostStatus.newBuilder()
            .setStatus(Status.UP)
            .setStatuses(Collections.<JobId, TaskStatus>emptyMap())
            .setJobs(ImmutableMap.of(JOB_ID2, Deployment.of(JOB_ID2, Goal.START)))
            .build());
    //noinspection unchecked
    when(heliosClient.hostStatus(HOST1)).thenReturn(statusFuture11);
    //noinspection unchecked
    when(heliosClient.hostStatus(HOST2)).thenReturn(statusFuture21);

    final ListenableFuture<JobUndeployResponse> undeployFuture1 = Futures.immediateFuture(
        new JobUndeployResponse(JobUndeployResponse.Status.OK, HOST1, JOB_ID1));
    final ListenableFuture<JobUndeployResponse> undeployFuture2 = Futures.immediateFuture(
        new JobUndeployResponse(JobUndeployResponse.Status.OK, HOST2, JOB_ID2));

    // when undeploy is called, respond correctly & patch the mock to return
    // the undeployed HostStatus
    when(heliosClient.undeploy(JOB_ID1, HOST1)).thenAnswer(
        new Answer<ListenableFuture<JobUndeployResponse>>() {
          @Override
          public ListenableFuture<JobUndeployResponse> answer(final InvocationOnMock invocation)
              throws Throwable {
            when(heliosClient.hostStatus(HOST1)).thenReturn(statusFuture12);
            return undeployFuture1;
          }",1
"@Test
    public void testWrite() throws Exception {
        Bean bean1 = new Bean();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-01.txt""), json);
    }",1
"@Test
	public void testBrokenStatement() {

		List<Statement> brokenSg1Statements = new ArrayList<>();
		brokenSg1Statements.add(getTestStatement(2,
				5, 1, EntityIdValue.ET_ITEM));
		brokenSg1Statements.add(getBrokenStatement());
		brokenSg1Statements.add(getTestStatement(2,
				5, 2, EntityIdValue.ET_ITEM));
		StatementGroup brokenSg1 = Datamodel
				.makeStatementGroup(brokenSg1Statements);

		List<Statement> fixedSg1Statements = new ArrayList<>();
		fixedSg1Statements.add(getTestStatement(2, 5,
				1, EntityIdValue.ET_ITEM));
		fixedSg1Statements.add(getTestStatement(2, 5,
				2, EntityIdValue.ET_ITEM));
		StatementGroup fixedSg1 = Datamodel
				.makeStatementGroup(fixedSg1Statements);

		StatementGroup sg2 = getTestStatementGroup(2,
				5, 1, EntityIdValue.ET_ITEM);

		List<StatementGroup> brokenSgs = new ArrayList<>();
		brokenSgs.add(brokenSg1);
		brokenSgs.add(sg2);
		List<StatementGroup> fixedSgs = new ArrayList<>();
		fixedSgs.add(fixedSg1);
		fixedSgs.add(sg2);

		ItemDocument brokenId = Datamodel.makeItemDocument(
				getTestItemIdValue(2),
				Collections.emptyList(),
				Collections.emptyList(),
				Collections.emptyList(), brokenSgs,
				Collections.emptyMap());

		ItemDocument fixedId = Datamodel.makeItemDocument(
				getTestItemIdValue(2),
				Collections.emptyList(),
				Collections.emptyList(),
				Collections.emptyList(), fixedSgs,
				Collections.emptyMap());

		DatamodelConverter dmc = new DatamodelConverter(
				new DataObjectFactoryImpl());

		assertEquals(fixedId, dmc.copy(brokenId));
	}",1
"@Test
	public void testSerializer() throws IOException {
		ByteArrayOutputStream out = new ByteArrayOutputStream();
		JsonSerializer serializer = new JsonSerializer(out);

		ItemIdValue qid1 = Datamodel.makeWikidataItemIdValue(""Q1"");
		ItemDocument id1 = Datamodel.makeItemDocument(
				qid1,
				Collections.singletonList(Datamodel.makeMonolingualTextValue(""Label1"", ""lang1"")),
				Collections.emptyList(), Collections.emptyList(),
				Collections.singletonList(Datamodel.makeStatementGroup(Collections.singletonList(
						Datamodel.makeStatement(qid1,
								Datamodel.makeNoValueSnak(Datamodel.makeWikidataPropertyIdValue(""P42"")),
								Collections.emptyList(), Collections.emptyList(),
								StatementRank.NORMAL, ""MyId""
				)))), Collections.emptyMap(), 1234);
		ItemDocument id2 = Datamodel.makeItemDocument(
				Datamodel.makeWikidataItemIdValue(""Q2""),
				Collections.emptyList(), Collections.emptyList(), Collections.emptyList(),
				Collections.emptyList(), Collections.emptyMap(), 12);
		PropertyDocument pd1 = Datamodel.makePropertyDocument(
				Datamodel.makeWikidataPropertyIdValue(""P1""),
				Collections.emptyList(), Collections.emptyList(),
				Collections.singletonList(Datamodel.makeMonolingualTextValue(""Alias1"", ""lang1"")),
				Collections.emptyList(), Datamodel.makeDatatypeIdValue(DatatypeIdValue.DT_COMMONS_MEDIA),
				3456);

		serializer.open();
		serializer.processItemDocument(id1);
		serializer.processItemDocument(id2);
		serializer.processPropertyDocument(pd1);
		serializer.close();

		List<EntityDocument> inputDocuments = Arrays.asList(id1, id2, pd1);

		List<EntityDocument> outputDocuments = new ArrayList<>();

		ObjectMapper mapper = new DatamodelMapper(""http://www.wikidata.org/entity/"");
		ObjectReader documentReader = mapper.readerFor(EntityDocumentImpl.class);

		MappingIterator<EntityDocument> documentIterator = documentReader.readValues(out.toString());
		while (documentIterator.hasNextValue()) {
			outputDocuments.add(documentIterator.nextValue());
		}",1
"@Test
	public void accessSnakGroups() {
		EntityIdValue value1 = new ItemIdValueImpl(""Q1"",
				""http://wikidata.org/entity/"");
		EntityIdValue value2 = new ItemIdValueImpl(""Q2"",
				""http://wikidata.org/entity/"");
		PropertyIdValue property1 = new PropertyIdValueImpl(""P1"", ""http://wikidata.org/entity/"");
		PropertyIdValue property2 = new PropertyIdValueImpl(""P2"", ""http://wikidata.org/entity/"");
		Snak snak1 = new ValueSnakImpl(property1, value1);
		Snak snak2 = new ValueSnakImpl(property1, value2);
		Snak snak3 = new ValueSnakImpl(property2, value2);

		List<Snak> snakList1 = new ArrayList<>();
		snakList1.add(snak1);
		snakList1.add(snak2);

		SnakGroup snakGroup1 = new SnakGroupImpl(snakList1);
		SnakGroup snakGroup2 = new SnakGroupImpl(
				Collections.singletonList(snak3));
		List<SnakGroup> snakGroups = new ArrayList<>();
		snakGroups.add(snakGroup1);
		snakGroups.add(snakGroup2);

		Claim claim = new ClaimImpl(subject, mainSnak, snakGroups);

		Iterator<Snak> snaks = claim.getAllQualifiers();

		assertTrue(snaks.hasNext());
		assertEquals(snak1, snaks.next());
		assertTrue(snaks.hasNext());
		assertEquals(snak2, snaks.next());
		assertTrue(snaks.hasNext());
		assertEquals(snak3, snaks.next());
		assertFalse(snaks.hasNext());
	}",1
"@Test
	public void equalityBasedOnContent() {
		ItemDocument irDiffLabel = new ItemDocumentImpl(iid,
				Collections.emptyList(), descList, aliasList,
				statementGroups, sitelinks, 1234);
		ItemDocument irDiffDesc = new ItemDocumentImpl(iid,
				labelList, Collections.emptyList(), aliasList,
				statementGroups, sitelinks, 1234);
		ItemDocument irDiffAlias = new ItemDocumentImpl(iid,
				labelList, descList, Collections.emptyList(),
				statementGroups, sitelinks, 1234);
		ItemDocument irDiffStatementGroups = new ItemDocumentImpl(iid,
				labelList, descList, aliasList,
				Collections.emptyList(), sitelinks, 1234);
		ItemDocument irDiffSiteLinks = new ItemDocumentImpl(iid,
				labelList, descList, aliasList,
				statementGroups, Collections.emptyList(),
				1234);
		ItemDocument irDiffRevisions = new ItemDocumentImpl(iid,
				labelList, descList, aliasList,
				statementGroups, sitelinks, 1235);

		PropertyDocument pr = new PropertyDocumentImpl(
				new PropertyIdValueImpl(""P42"", ""foo""),
				labelList, descList, aliasList,
				Collections.emptyList(),
				new DatatypeIdImpl(DatatypeIdValue.DT_STRING), 1234);

		// we need to use empty lists of Statement groups to test inequality
		// based on different item ids with all other data being equal
		ItemDocument irDiffItemIdValue = new ItemDocumentImpl(
				new ItemIdValueImpl(""Q23"", ""http://example.org/""),
				labelList, descList, aliasList,
				Collections.emptyList(), sitelinks, 1234);

		assertEquals(ir1, ir1);
		assertEquals(ir1, ir2);
		assertNotEquals(ir1, irDiffLabel);
		assertNotEquals(ir1, irDiffDesc);
		assertNotEquals(ir1, irDiffAlias);
		assertNotEquals(ir1, irDiffStatementGroups);
		assertNotEquals(ir1, irDiffSiteLinks);
		assertNotEquals(ir1, irDiffRevisions);
		assertNotEquals(irDiffStatementGroups, irDiffItemIdValue);
		assertNotEquals(ir1, pr);
		assertNotEquals(ir1, null);
		assertNotEquals(ir1, this);
	}",1
"@Test
	public void equalityBasedOnContent() {
		StringValue s3 = new StringValueImpl(""another string"");

		assertEquals(s1, s1);
		assertEquals(s1, s2);
		assertNotEquals(s1, s3);
		assertNotEquals(s1, null);
		assertNotEquals(s1, this);
	}",1
"@Test
	public void testDeleteAndAdd() {
		// Explicitly deleted statement won't merge
		Reference r1 = ReferenceBuilder.newInstance().withPropertyValue(P1, Q1)
				.build();
		Reference r2 = ReferenceBuilder.newInstance().withPropertyValue(P2, Q2)
				.build();

		Statement s3 = StatementBuilder.forSubjectAndProperty(Q1, P2)
				.withReference(r1).withValue(Q1).withId(""ID-s3"").build();
		Statement s4 = StatementBuilder.forSubjectAndProperty(Q1, P2)
				.withReference(r2).withValue(Q1).withId(""ID-s4"").build();

		ItemDocument currentDocument = ItemDocumentBuilder.forItemId(Q1)
				.withStatement(s4).build();

		List<Statement> addStatements = Collections.singletonList(s3);
		List<Statement> deleteStatements = Collections.singletonList(s4);

		StatementUpdate su = new StatementUpdate(currentDocument,
				addStatements, deleteStatements);

		assertTrue(su.toDelete.contains(""ID-s4""));
		assertTrue(su.toKeep.containsKey(P2));
		assertEquals(1, su.toKeep.get(P2).size());
		assertEquals(s3, su.toKeep.get(P2).get(0).statement);
		assertFalse(su.isEmptyEdit());
	}",1
"@Test
	public void testDeleteAndAdd() {
		// Explicitly deleted statement won't merge
		Reference r1 = ReferenceBuilder.newInstance().withPropertyValue(P1, Q1)
				.build();
		Reference r2 = ReferenceBuilder.newInstance().withPropertyValue(P2, Q2)
				.build();

		Statement s3 = StatementBuilder.forSubjectAndProperty(Q1, P2)
				.withReference(r1).withValue(Q1).withId(""ID-s3"").build();
		Statement s4 = StatementBuilder.forSubjectAndProperty(Q1, P2)
				.withReference(r2).withValue(Q1).withId(""ID-s4"").build();

		ItemDocument currentDocument = ItemDocumentBuilder.forItemId(Q1)
				.withStatement(s4).build();

		List<Statement> addStatements = Collections.singletonList(s3);
		List<Statement> deleteStatements = Collections.singletonList(s4);

		StatementUpdate su = new StatementUpdate(currentDocument,
				addStatements, deleteStatements);

		assertTrue(su.toDelete.contains(""ID-s4""));
		assertTrue(su.toKeep.containsKey(P2));
		assertEquals(1, su.toKeep.get(P2).size());
		assertEquals(s3, su.toKeep.get(P2).get(0).statement);
		assertFalse(su.isEmptyEdit());
	}",1
"@Test
  public void shouldReuseGroupNameMappingFileWithIncrementalBuild()
      throws Exception {
    final File groupNameMappingFile = WroUtil.createTempFile();

    final Resource g1Resource = spy(Resource.create(""1.js""));
    try {
      final WroModel model = new WroModel();
      model.addGroup(new Group(""g1"").addResource(g1Resource));
      model.addGroup(new Group(""g2"").addResource(Resource.create(""2.js"")));
      victim = new Wro4jMojo() {
        @Override
        protected WroManagerFactory newWroManagerFactory()
            throws MojoExecutionException {
          final DefaultStandaloneContextAwareManagerFactory managerFactory = new DefaultStandaloneContextAwareManagerFactory();
          managerFactory.setUriLocatorFactory(WroTestUtils.createResourceMockingLocatorFactory());
          managerFactory.setModelFactory(WroTestUtils.simpleModelFactory(model));
          managerFactory.setNamingStrategy(new DefaultHashEncoderNamingStrategy());

          return managerFactory;
        }",1
"@Test
  public void constructorShouldBePrivate() {
    final Class<?> mapRandomGeneratorClass = getGeneratorClass();
    PojoClass mapRandomGeneratorPojo = PojoClassFactory.getPojoClass(mapRandomGeneratorClass);

    List<PojoMethod> constructors = new ArrayList<PojoMethod>();

    for (PojoMethod constructor : mapRandomGeneratorPojo.getPojoConstructors()) {
      if (!constructor.isSynthetic())
        constructors.add(constructor);
    }",1
"@Test
  public void testLotsOfConcurrentJobs() throws Exception {
    startDefaultMaster();

    final HeliosClient client = defaultClient();
    startDefaultAgent(testHost());

    awaitHostRegistered(client, testHost(), LONG_WAIT_SECONDS, SECONDS);
    awaitHostStatus(client, testHost(), UP, LONG_WAIT_SECONDS, SECONDS);

    final int numberOfJobs = 40;
    final List<JobId> jobIds = Lists.newArrayListWithCapacity(numberOfJobs);

    final String jobName = testJobName + ""_"" + toHexString(ThreadLocalRandom.current().nextInt());

    // create and deploy a bunch of jobs
    for (Integer i = 0; i < numberOfJobs; i++) {
      final Job job = Job.newBuilder()
          .setName(jobName)
          .setVersion(i.toString())
          .setImage(BUSYBOX)
          .setCommand(IDLE_COMMAND)
          .setCreatingUser(TEST_USER)
          .build();

      final JobId jobId = job.getId();
      final CreateJobResponse created = client.createJob(job).get();
      assertEquals(CreateJobResponse.Status.OK, created.getStatus());

      final Deployment deployment = Deployment.of(jobId, START, TEST_USER);
      final JobDeployResponse deployed = client.deploy(deployment, testHost()).get();
      assertEquals(JobDeployResponse.Status.OK, deployed.getStatus());

      jobIds.add(jobId);
    }",1
"@Test
	public void testEmptySiteLinkFilterForItem() {
		SiteLink s1 = Datamodel.makeSiteLink(""Title 1"", ""site1"", Collections.emptyList());
		SiteLink s2 = Datamodel.makeSiteLink(""Title 2"", ""site2"", Collections.emptyList());
		SiteLink s3 = Datamodel.makeSiteLink(""Title 3"", ""site3"", Collections.emptyList());
		SiteLink s4 = Datamodel.makeSiteLink(""Title 4"", ""site4"", Collections.emptyList());

		DocumentDataFilter documentDataFilter = new DocumentDataFilter();
		documentDataFilter.setSiteLinkFilter(Collections.emptySet());
		DatamodelFilter filter = new DatamodelFilter(new DataObjectFactoryImpl(), documentDataFilter);

		Map<String, SiteLink> siteLinks = new HashMap<>();
		siteLinks.put(s1.getSiteKey(), s1);
		siteLinks.put(s2.getSiteKey(), s2);
		siteLinks.put(s3.getSiteKey(), s3);
		siteLinks.put(s4.getSiteKey(), s4);

		ItemDocument itemDocument = Datamodel.makeItemDocument(
				Datamodel.makeWikidataItemIdValue(""Q42""),
				Collections.emptyList(),
				Collections.emptyList(),
				Collections.emptyList(),
				Collections.emptyList(),
				siteLinks
		);

		ItemDocument itemDocumentFiltered = Datamodel.makeItemDocument(Datamodel.makeWikidataItemIdValue(""Q42""),
				Collections.emptyList(), Collections.emptyList(), Collections.emptyList(),
				Collections.emptyList(), Collections.emptyMap()
		);

		assertEquals(itemDocumentFiltered, filter.filter(itemDocument));
	}",1
"@Test
	public void testPropertyFilterForItem() {
		ItemIdValue s = Datamodel.makeWikidataItemIdValue(""Q42"");
		PropertyIdValue p1 = Datamodel.makeWikidataPropertyIdValue(""P1"");
		PropertyIdValue p2 = Datamodel.makeWikidataPropertyIdValue(""P2"");
		PropertyIdValue p3 = Datamodel.makeWikidataPropertyIdValue(""P3"");
		PropertyIdValue p4 = Datamodel.makeWikidataPropertyIdValue(""P4"");

		Set<PropertyIdValue> propertyFilter = new HashSet<>();
		propertyFilter.add(p1);
		propertyFilter.add(p3);
		DocumentDataFilter documentDataFilter = new DocumentDataFilter();
		documentDataFilter.setPropertyFilter(propertyFilter);
		DatamodelFilter filter = new DatamodelFilter(new DataObjectFactoryImpl(), documentDataFilter);

		ItemDocument itemDocument = Datamodel.makeItemDocument(
				s,
				Collections.emptyList(),
				Collections.emptyList(),
				Collections.emptyList(),
				Arrays.asList(
						makeTestStatementGroup(p1, s),
						makeTestStatementGroup(p2, s),
						makeTestStatementGroup(p3, s),
						makeTestStatementGroup(p4, s)
				),
				Collections.emptyMap()
		);

		ItemDocument itemDocumentFiltered = Datamodel.makeItemDocument(
				s,
				Collections.emptyList(),
				Collections.emptyList(),
				Collections.emptyList(),
				Arrays.asList(
						makeTestStatementGroup(p1, s),
						makeTestStatementGroup(p3, s)
				),
				Collections.emptyMap()
		);

		assertEquals(itemDocumentFiltered, filter.filter(itemDocument));
	}",1
"@Test
	public void testSetBit() {
		long word = 0;

		for (byte i = 0; i < 0x40; i++) {
			word = BitVectorImpl.setBitInWord(i, true, word);
		}",1
"@Test
    public void testGetNumber() {
        Mockito.doReturn("" 1234"").when(pippoSettings).getString(""key"", null);
        Mockito.doCallRealMethod().when(pippoSettings).getInteger(""key"", 0);
        Mockito.doCallRealMethod().when(pippoSettings).getLong(""key"", 0);
        Mockito.doCallRealMethod().when(pippoSettings).getFloat(""key"", 0.0f);
        Mockito.doCallRealMethod().when(pippoSettings).getDouble(""key"", 2.4d);

        int valueInt = pippoSettings.getInteger(""key"", 0);
        long valueLong = pippoSettings.getLong(""key"", 0);
        float valueFloat = pippoSettings.getFloat(""key"", 0.0f);
        double valueDouble = pippoSettings.getDouble(""key"", 2.4d);

        assertEquals(1234, valueInt);
        assertEquals(1234L, valueLong);
        assertEquals(Float.parseFloat(""1234""), valueFloat, 0.0f);
        assertEquals(Double.parseDouble(""1234""), valueDouble, 0.0d);

        // case when number followed by some char sequence
        Mockito.doReturn("" 1234 abc"").when(pippoSettings).getString(""key"", null);
        valueInt = pippoSettings.getInteger(""key"", 0);
        valueLong = pippoSettings.getLong(""key"", 0);
        valueFloat = pippoSettings.getFloat(""key"", 0.0f);
        valueDouble = pippoSettings.getDouble(""key"", 2.4d);

        assertEquals(0, valueInt);
        assertEquals(0L, valueLong);
        assertEquals(0.0f, valueFloat, 0.0f);
        assertEquals(2.4d, valueDouble, 0.0d);
    }",1
"@Test
  public void testDumpProperty() throws IOException {
    StringWriter outWriter = new StringWriter();
    ObjectMapper mapper = new ObjectMapper();
    String jsonStr = null;
    String xmlStr = null;
    try {
      Configuration testConf = new Configuration(false);
      out = new BufferedWriter(new FileWriter(CONFIG));
      startConfig();
      appendProperty(""test.key1"", ""value1"");
      appendProperty(""test.key2"", ""value2"", true);
      appendProperty(""test.key3"", ""value3"");
      endConfig();
      Path fileResource = new Path(CONFIG);
      testConf.addResource(fileResource);
      out.close();

      // case 1: dump an existing property
      // test json format
      outWriter = new StringWriter();
      Configuration.dumpConfiguration(testConf, ""test.key2"", outWriter);
      jsonStr = outWriter.toString();
      outWriter.close();
      mapper = new ObjectMapper();
      SingleJsonConfiguration jconf1 =
          mapper.readValue(jsonStr, SingleJsonConfiguration.class);
      JsonProperty jp1 = jconf1.getProperty();
      assertEquals(""test.key2"", jp1.getKey());
      assertEquals(""value2"", jp1.getValue());
      assertEquals(true, jp1.isFinal);
      assertEquals(fileResource.toString(), jp1.getResource());

      // test xml format
      outWriter = new StringWriter();
      testConf.writeXml(""test.key2"", outWriter);
      xmlStr = outWriter.toString();
      outWriter.close();
      Configuration actualConf1 = getActualConf(xmlStr);
      assertEquals(1, actualConf1.size());
      assertEquals(""value2"", actualConf1.get(""test.key2""));
      assertTrue(actualConf1.getFinalParameters().contains(""test.key2""));
      assertEquals(fileResource.toString(),
          actualConf1.getPropertySources(""test.key2"")[0]);

      // case 2: dump an non existing property
      // test json format
      try {
        outWriter = new StringWriter();
        Configuration.dumpConfiguration(testConf,
            ""test.unknown.key"", outWriter);
        outWriter.close();
      }",1
"@Test
  public void testGettingPropertiesWithPrefix() throws Exception {
    Configuration conf = new Configuration();
    for (int i = 0; i < 10; i++) {
      conf.set(""prefix."" + ""name"" + i, ""value"" + i);
    }",1
"@Test
  public void testTimeDuration() {
    Configuration conf = new Configuration(false);

    assertEquals(7000L,
        conf.getTimeDuration(""test.time.a"", 7L, SECONDS, MILLISECONDS));

    conf.setTimeDuration(""test.time.a"", 7L, SECONDS);
    assertEquals(""7s"", conf.get(""test.time.a""));
    assertEquals(0L, conf.getTimeDuration(""test.time.a"", 30, MINUTES));
    assertEquals(0L, conf.getTimeDuration(""test.time.a"", 30, SECONDS, MINUTES));
    assertEquals(7L, conf.getTimeDuration(""test.time.a"", 30, SECONDS));
    assertEquals(7L,
        conf.getTimeDuration(""test.time.a"", 30, MILLISECONDS, SECONDS));
    assertEquals(7000L, conf.getTimeDuration(""test.time.a"", 30, MILLISECONDS));
    assertEquals(7000000L,
        conf.getTimeDuration(""test.time.a"", 30, MICROSECONDS));
    assertEquals(7000000000L,
        conf.getTimeDuration(""test.time.a"", 30, NANOSECONDS));
    conf.setTimeDuration(""test.time.b"", 1, DAYS);
    assertEquals(""1d"", conf.get(""test.time.b""));
    assertEquals(1, conf.getTimeDuration(""test.time.b"", 1, DAYS));
    assertEquals(24, conf.getTimeDuration(""test.time.b"", 1, HOURS));
    assertEquals(MINUTES.convert(1, DAYS),
        conf.getTimeDuration(""test.time.b"", 1, MINUTES));

    // check default
    assertEquals(30L, conf.getTimeDuration(""test.time.X"", 30, SECONDS));
    conf.set(""test.time.X"", ""30"");
    assertEquals(30L, conf.getTimeDuration(""test.time.X"", 40, SECONDS));
    assertEquals(30000L,
        conf.getTimeDuration(""test.time.X"", 40, SECONDS, MILLISECONDS));
    assertEquals(10L, conf.getTimeDuration(""test.time.c"", ""10"", SECONDS));
    assertEquals(30L, conf.getTimeDuration(""test.time.c"", ""30s"", SECONDS));
    assertEquals(120L, conf.getTimeDuration(""test.time.c"", ""2m"", SECONDS));
    conf.set(""test.time.c"", ""30"");
    assertEquals(30L, conf.getTimeDuration(""test.time.c"", ""40s"", SECONDS));

    // check suffix insensitive
    conf.set(""test.time.d"", ""30S"");
    assertEquals(30L, conf.getTimeDuration(""test.time.d"", 40, SECONDS));

    for (Configuration.ParsedTimeDuration ptd :
        Configuration.ParsedTimeDuration.values()) {
      conf.setTimeDuration(""test.time.unit"", 1, ptd.unit());
      assertEquals(1 + ptd.suffix(), conf.get(""test.time.unit""));
      assertEquals(1, conf.getTimeDuration(""test.time.unit"", 2, ptd.unit()));
    }",1
"@Test
  public void testVariableSubstitution() throws IOException {
    // stubbing only environment dependent functions
    Configuration mock = Mockito.spy(conf);
    Mockito.when(mock.getProperty(""user.name"")).thenReturn(""hadoop_user"");
    Mockito.when(mock.getenv(""FILE_NAME"")).thenReturn(""hello"");

    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    declareProperty(""my.int"", ""${intvar}",1
"@Test
  public void testGetProperty() throws Exception {
    Configuration configurations = getMultiPropertiesConf();
    // list various of property names
    String[] testKeys = new String[] {
        ""test.key1"",
        ""test.unknown.key"",
        """",
        ""test.key2"",
        null
    }",1
"@Test
  public void testWriteXml() throws Exception {
    StringWriter sw = new StringWriter();
    ConfServlet.writeResponse(getTestConf(), sw, ""xml"");
    String xml = sw.toString();

    DocumentBuilderFactory docBuilderFactory = XMLUtils.newSecureDocumentBuilderFactory();
    DocumentBuilder builder = docBuilderFactory.newDocumentBuilder();
    Document doc = builder.parse(new InputSource(new StringReader(xml)));
    NodeList nameNodes = doc.getElementsByTagName(""name"");
    boolean foundSetting = false;
    for (int i = 0; i < nameNodes.getLength(); i++) {
      Node nameNode = nameNodes.item(i);
      String key = nameNode.getTextContent();
      if (TEST_KEY.equals(key)) {
        foundSetting = true;
        Element propertyElem = (Element)nameNode.getParentNode();
        String val = propertyElem.getElementsByTagName(""value"").item(0).getTextContent();
        assertEquals(TEST_VAL, val);
      }",1
"@Test
  public void testOpsWhenACLAttributeExists() throws Exception {
    final Configuration conf = new Configuration();
    KeyProvider kp = 
        new UserProvider.Factory().createProvider(new URI(""user:///""), conf);
    KeyACLs mock = mock(KeyACLs.class);
    when(mock.isACLPresent(""testKey"", KeyOpType.MANAGEMENT)).thenReturn(true);
    when(mock.isACLPresent(""testKey"", KeyOpType.GENERATE_EEK)).thenReturn(true);
    when(mock.isACLPresent(""testKey"", KeyOpType.DECRYPT_EEK)).thenReturn(true);
    when(mock.isACLPresent(""testKey"", KeyOpType.ALL)).thenReturn(true);
    UserGroupInformation u1 = UserGroupInformation.createRemoteUser(""u1"");
    UserGroupInformation u2 = UserGroupInformation.createRemoteUser(""u2"");
    UserGroupInformation u3 = UserGroupInformation.createRemoteUser(""u3"");
    UserGroupInformation sudo = UserGroupInformation.createRemoteUser(""sudo"");
    when(mock.hasAccessToKey(""testKey"", u1, KeyOpType.MANAGEMENT)).thenReturn(true);
    when(mock.hasAccessToKey(""testKey"", u2, KeyOpType.GENERATE_EEK)).thenReturn(true);
    when(mock.hasAccessToKey(""testKey"", u3, KeyOpType.DECRYPT_EEK)).thenReturn(true);
    when(mock.hasAccessToKey(""testKey"", sudo, KeyOpType.ALL)).thenReturn(true);
    final KeyProviderCryptoExtension kpExt =
        new KeyAuthorizationKeyProvider(
            KeyProviderCryptoExtension.createKeyProviderCryptoExtension(kp),
            mock);

    final KeyVersion barKv = u1.doAs(
        new PrivilegedExceptionAction<KeyVersion>() {
          @Override
          public KeyVersion run() throws Exception {
            Options opt = newOptions(conf);
            Map<String, String> m = new HashMap<String, String>();
            m.put(""key.acl.name"", ""testKey"");
            opt.setAttributes(m);
            try {
              KeyVersion kv = 
                  kpExt.createKey(""foo"", SecureRandom.getSeed(16), opt);
              kpExt.rollNewVersion(kv.getName());
              kpExt.rollNewVersion(kv.getName(), SecureRandom.getSeed(16));
              kpExt.deleteKey(kv.getName());
            }",1
"@Test
  public void testDelegationTokensOpsHttpKerberized() throws Exception {
    testDelegationTokensOps(false, true);
  }",1
"@Test
  public void testDelegationTokensOpsHttpPseudo() throws Exception {
    testDelegationTokensOps(false, false);
  }",1
"@Test
  public void testKMSJMX() throws Exception {
    Configuration conf = new Configuration();
    final File confDir = getTestDir();
    conf = createBaseKMSConf(confDir, conf);
    final String processName = ""testkmsjmx"";
    conf.set(KMSConfiguration.METRICS_PROCESS_NAME_KEY, processName);
    writeConf(confDir, conf);

    runServer(null, null, confDir, new KMSCallable<Void>() {
      @Override
      public Void call() throws Exception {
        final URL jmxUrl = new URL(
            getKMSUrl() + ""/jmx?user.name=whatever&qry=Hadoop:service=""
                + processName + "",name=JvmMetrics"");
        LOG.info(""Requesting jmx from "" + jmxUrl);
        final StringBuilder sb = new StringBuilder();
        final InputStream in = jmxUrl.openConnection().getInputStream();
        final byte[] buffer = new byte[64 * 1024];
        int len;
        while ((len = in.read(buffer)) > 0) {
          sb.append(new String(buffer, 0, len));
        }",1
"@Test
  public void testKMSTimeout() throws Exception {
    File confDir = getTestDir();
    Configuration conf = createBaseKMSConf(confDir);
    conf.setInt(CommonConfigurationKeysPublic.KMS_CLIENT_TIMEOUT_SECONDS, 1);
    writeConf(confDir, conf);

    ServerSocket sock;
    int port;
    try {
      sock = new ServerSocket(0, 50, InetAddress.getByName(""localhost""));
      port = sock.getLocalPort();
    }",1
"@Test
  public void testKMSWithZKDTSM() throws Exception {
    doKMSWithZK(false, true);
  }",1
"@Test
  public void testStartStopHttpKerberos() throws Exception {
    testStartStop(false, true);
  }",1
"@Test
  public void testStartStopHttpsPseudo() throws Exception {
    testStartStop(true, false);
  }",1
"@Test
  public void testCustom() {
    final Configuration conf = new Configuration(false);
    for (KMSACLs.Type type : KMSACLs.Type.values()) {
      conf.set(type.getAclConfigKey(), type.toString() + "" "");
    }",1
"@Test
  public void testJksProvider() throws Exception {
    Configuration conf = new Configuration();
    final Path jksPath = new Path(testRootDir.toString(), ""test.jks"");
    final String ourUrl =
        JavaKeyStoreProvider.SCHEME_NAME + ""://file"" + jksPath.toUri();

    File file = new File(testRootDir, ""test.jks"");
    file.delete();
    conf.set(KeyProviderFactory.KEY_PROVIDER_PATH, ourUrl);
    checkSpecificProvider(conf, ourUrl);

    // START : Test flush error by failure injection
    conf.set(KeyProviderFactory.KEY_PROVIDER_PATH, ourUrl.replace(
        JavaKeyStoreProvider.SCHEME_NAME,
        FailureInjectingJavaKeyStoreProvider.SCHEME_NAME));
    // get a new instance of the provider to ensure it was saved correctly
    KeyProvider provider = KeyProviderFactory.getProviders(conf).get(0);
    // inject failure during keystore write
    FailureInjectingJavaKeyStoreProvider fProvider =
        (FailureInjectingJavaKeyStoreProvider) provider;
    fProvider.setWriteFail(true);
    provider.createKey(""key5"", new byte[]{1}",1
"@Test
  public void testSeekFile() throws Exception {
    Path smallSeekFile = setPath(""/test/smallSeekFile.txt"");
    long size = 5 * 1024 * 1024;

    ContractTestUtils.generateTestFile(this.fs, smallSeekFile, size, 256, 255);
    LOG.info(""5MB file created: smallSeekFile.txt"");

    FSDataInputStream instream = this.fs.open(smallSeekFile);
    int seekTimes = 5;
    LOG.info(""multiple fold position seeking test...:"");
    for (int i = 0; i < seekTimes; i++) {
      long pos = size / (seekTimes - i) - 1;
      LOG.info(""begin seeking for pos: "" + pos);
      instream.seek(pos);
      assertTrue(""expected position at:"" + pos + "", but got:""
          + instream.getPos(), instream.getPos() == pos);
      LOG.info(""completed seeking at pos: "" + instream.getPos());
    }",1
"@Test
  public void testManySuccessAndErrorsAndWaiting() {
    AbfsClientThrottlingAnalyzer analyzer = new AbfsClientThrottlingAnalyzer(
        ""test"", abfsConfiguration);
    validate(0, analyzer.getSleepDuration());
    final int numberOfRequests = 20;
    for (int i = 0; i < numberOfRequests; i++) {
      analyzer.addBytesTransferred(8 * MEGABYTE, false);
      analyzer.addBytesTransferred(2 * MEGABYTE, true);
    }",1
"@Test
  public void testGetFsAction(){
    FTPFileSystem ftp = new FTPFileSystem();
    int[] accesses = new int[] {FTPFile.USER_ACCESS, FTPFile.GROUP_ACCESS,
        FTPFile.WORLD_ACCESS}",1
"@Test
  public void testUMaskParser() throws IOException {
    Configuration conf = new Configuration();
    
    // Ensure that we get the right octal values back for all legal values
    for(FsAction u : FsAction.values()) {
      for(FsAction g : FsAction.values()) {
        for(FsAction o : FsAction.values()) {
          FsPermission f = new FsPermission(u, g, o);
          String asOctal = String.format(""%1$03o"", f.toShort());
          conf.set(FsPermission.UMASK_LABEL, asOctal);
          FsPermission fromConf = FsPermission.getUMask(conf);
          assertEquals(f, fromConf);
        }",1
"@Test
  public void testFilterFileSystem() throws Exception {
    int errors = 0;
    for (Method m : FileSystem.class.getDeclaredMethods()) {
      if (Modifier.isStatic(m.getModifiers()) ||
          Modifier.isPrivate(m.getModifiers()) ||
          Modifier.isFinal(m.getModifiers())) {
        continue;
      }",1
"@Test
  public void testFilterFileSystem() throws Exception {
    for (Method m : AbstractFileSystem.class.getDeclaredMethods()) {
      if (Modifier.isStatic(m.getModifiers()))
        continue;
      if (Modifier.isPrivate(m.getModifiers()))
        continue;
      if (Modifier.isFinal(m.getModifiers()))
        continue;
      
      try {
        DontCheck.class.getMethod(m.getName(), m.getParameterTypes());
        LOG.info(""Skipping "" + m);
      }",1
"@Test
  public void testStatistics() throws Exception {
    int fileSchemeCount = 0;
    for (Statistics stats : FileSystem.getAllStatistics()) {
      if (stats.getScheme().equals(""file"")) {
        fileSchemeCount++;
      }",1
"@Test
  public void testSyncable() throws IOException {
    FileSystem fs = fileSys.getRawFileSystem();
    Path file = new Path(TEST_ROOT_DIR, ""syncable"");
    FSDataOutputStream out = fs.create(file);
    final int bytesWritten = 1;
    byte[] expectedBuf = new byte[] {'0', '1', '2', '3'}",1
"@Test
  public void testTrashRestarts() throws Exception {
    Configuration conf = new Configuration();
    conf.setClass(""fs.trash.classname"",
        AuditableTrashPolicy.class,
        TrashPolicy.class);
    conf.setClass(""fs.file.impl"", TestLFS.class, FileSystem.class);
    conf.set(FS_TRASH_INTERVAL_KEY, ""50""); // in milliseconds for test
    Trash trash = new Trash(conf);
    // create 5 checkpoints
    for(int i=0; i<5; i++) {
      trash.checkpoint();
    }",1
"@Test
  public void testChooseRandomWithStorageTypeTwoTrial() throws Exception {
    Node n;
    DatanodeDescriptor dd;
    n = CLUSTER.chooseRandomWithStorageType(""/l2/d3/r4"", null, null,
        StorageType.ARCHIVE);
    HashSet<Node> excluded = new HashSet<>();
    // exclude the host on r4 (since there is only one host, no randomness here)
    excluded.add(n);

    // search with given scope being desired scope
    for (int i = 0; i < 10; i++) {
      n = CLUSTER.chooseRandomWithStorageTypeTwoTrial(
          ""/l2/d3"", null, StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd = (DatanodeDescriptor) n;
      assertTrue(dd.getHostName().equals(""host13"") ||
          dd.getHostName().equals(""host14""));
    }",1
"@Test
  public void testChooseRandomWithStorageTypeWrapper() throws Exception {
    Node n;
    DatanodeDescriptor dd;
    n = CLUSTER.chooseRandomWithStorageType(""/l2/d3/r4"", null, null,
        StorageType.ARCHIVE);
    HashSet<Node> excluded = new HashSet<>();
    // exclude the host on r4 (since there is only one host, no randomness here)
    excluded.add(n);

    // search with given scope being desired scope
    for (int i = 0; i < 10; i++) {
      n = CLUSTER.chooseRandomWithStorageType(
          ""/l2/d3"", null, StorageType.ARCHIVE);
      assertTrue(n instanceof DatanodeDescriptor);
      dd = (DatanodeDescriptor) n;
      assertTrue(dd.getHostName().equals(""host13"") ||
          dd.getHostName().equals(""host14""));
    }",1
"@Test
  public void testFuzz() throws InterruptedException {
    Replica[] replicas = new Replica[100000];
    Random rand = new Random(0);
    for (int i=0; i<replicas.length; i++) {
      Block b = new Block(rand.nextLong(), i, i<<4);
      switch (rand.nextInt(2)) {
        case 0:
          replicas[i] = new FinalizedReplica(b, null, null);
          break;
        case 1:
          replicas[i] = new ReplicaBeingWritten(b, null, null, null);
          break;
        case 2:
          replicas[i] = new ReplicaWaitingToBeRecovered(b, null, null);
          break;
      }",1
"@Test
  public void testConvertAddingECPolicyResponse() throws Exception {
    // Check conversion of the built-in policies.
    for (ErasureCodingPolicy policy :
        SystemErasureCodingPolicies.getPolicies()) {
      AddErasureCodingPolicyResponse response =
          new AddErasureCodingPolicyResponse(policy);
      HdfsProtos.AddErasureCodingPolicyResponseProto proto = PBHelperClient
          .convertAddErasureCodingPolicyResponse(response);
      // Optional fields should not be set.
      assertFalse(""Unnecessary field is set."", proto.hasErrorMsg());
      // Convert proto back to an object and check for equality.
      AddErasureCodingPolicyResponse convertedResponse = PBHelperClient
          .convertAddErasureCodingPolicyResponse(proto);
      assertEquals(""Converted policy not equal"", response.getPolicy(),
          convertedResponse.getPolicy());
      assertEquals(""Converted policy not equal"", response.isSucceed(),
          convertedResponse.isSucceed());
    }",1
"@Test
  public void testConvertErasureCodingPolicy() throws Exception {
    // Check conversion of the built-in policies.
    for (ErasureCodingPolicy policy :
        SystemErasureCodingPolicies.getPolicies()) {
      HdfsProtos.ErasureCodingPolicyProto proto = PBHelperClient
          .convertErasureCodingPolicy(policy);
      // Optional fields should not be set.
      assertFalse(""Unnecessary field is set."", proto.hasName());
      assertFalse(""Unnecessary field is set."", proto.hasSchema());
      assertFalse(""Unnecessary field is set."", proto.hasCellSize());
      // Convert proto back to an object and check for equality.
      ErasureCodingPolicy convertedPolicy = PBHelperClient
          .convertErasureCodingPolicy(proto);
      assertEquals(""Converted policy not equal"", policy, convertedPolicy);
    }",1
"@Test
  public void testPurgeLogs() throws Exception {
    for (int txid = 1; txid <= 5; txid++) {
      writeSegment(cluster, qjm, txid, 1, true);
    }",1
"@Test
  public void testDelegationTokenUgi() throws Exception {
    final DistributedFileSystem dfs = cluster.getFileSystem();
    Token<?>[] tokens = dfs.addDelegationTokens(""renewer"", null);
    Assert.assertEquals(1, tokens.length);
    Token<?> token1 = tokens[0];
    DelegationTokenIdentifier ident =
        (DelegationTokenIdentifier) token1.decodeIdentifier();
    UserGroupInformation expectedUgi = ident.getUser();

    // get 2 new instances (clones) of the identifier, query their ugi
    // twice each, all ugi instances should be equivalent
    for (int i=0; i<2; i++) {
      DelegationTokenIdentifier identClone =
          (DelegationTokenIdentifier)token1.decodeIdentifier();
      Assert.assertEquals(ident, identClone);
      Assert.assertNotSame(ident, identClone);
      Assert.assertSame(expectedUgi, identClone.getUser());
      Assert.assertSame(expectedUgi, identClone.getUser());
    }",1
"@Test
  public void testAllNodesHoldingReplicasDecommissioned() throws Exception {
    addNodes(nodes);
    for (int i = 0; i < NUM_TEST_ITERS; i++) {
      doTestAllNodesHoldingReplicasDecommissioned(i);
    }",1
"@Test
  public void testMetaSaveInMaintenanceReplicas() throws Exception {
    List<DatanodeStorageInfo> origStorages = getStorages(0, 1);
    List<DatanodeDescriptor> origNodes = getNodes(origStorages);
    BlockInfo block = makeBlockReplicasMaintenance(0, origNodes);
    File file = new File(""test.log"");
    PrintWriter out = new PrintWriter(file);
    bm.metaSave(out);
    out.flush();
    FileInputStream fstream = new FileInputStream(file);
    DataInputStream in = new DataInputStream(fstream);
    BufferedReader reader = new BufferedReader(new InputStreamReader(in));
    StringBuilder buffer = new StringBuilder();
    String line;
    try {
      while ((line = reader.readLine()) != null) {
        buffer.append(line);
        System.out.println(line);
      }",1
"@Test
  public void testMetaSaveMissingReplicas() throws Exception {
    List<DatanodeStorageInfo> origStorages = getStorages(0, 1);
    List<DatanodeDescriptor> origNodes = getNodes(origStorages);
    BlockInfo block = makeBlockReplicasMissing(0, origNodes);
    File file = new File(""test.log"");
    PrintWriter out = new PrintWriter(file);
    bm.metaSave(out);
    out.flush();
    FileInputStream fstream = new FileInputStream(file);
    DataInputStream in = new DataInputStream(fstream);
    BufferedReader reader = new BufferedReader(new InputStreamReader(in));
    StringBuilder buffer = new StringBuilder();
    String line;
    try {
      while ((line = reader.readLine()) != null) {
        buffer.append(line);
      }",1
"@Test
  public void testStorageWithRemainingCapacity() throws Exception {
    final Configuration conf = new HdfsConfiguration();
    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).build();
    FileSystem fs = FileSystem.get(conf);
    Path file1 = null;
    try {
      cluster.waitActive();
      final FSNamesystem namesystem = cluster.getNamesystem();
      final String poolId = namesystem.getBlockPoolId();
      final DatanodeRegistration nodeReg =
        InternalDataNodeTestUtils.getDNRegistrationForBP(cluster.getDataNodes().
        		get(0), poolId);
      final DatanodeDescriptor dd = NameNodeAdapter.getDatanode(namesystem,
    		  nodeReg);
      // By default, MiniDFSCluster will create 1 datanode with 2 storages.
      // Assigning 64k for remaining storage capacity and will 
      //create a file with 100k.
      for(DatanodeStorageInfo storage:  dd.getStorageInfos()) { 
    	  storage.setUtilizationForTesting(65536, 0, 65536, 0);
      }",1
"@Test
  public void testNumVersionsReportedCorrect() throws IOException {
    //Create the DatanodeManager which will be tested
    FSNamesystem fsn = Mockito.mock(FSNamesystem.class);
    Mockito.when(fsn.hasWriteLock()).thenReturn(true);
    DatanodeManager dm = mockDatanodeManager(fsn, new Configuration());

    //Seed the RNG with a known value so test failures are easier to reproduce
    Random rng = new Random();
    int seed = rng.nextInt();
    rng = new Random(seed);
    LOG.info(""Using seed "" + seed + "" for testing"");

    //A map of the Storage IDs to the DN registration it was registered with
    HashMap <String, DatanodeRegistration> sIdToDnReg =
      new HashMap<String, DatanodeRegistration>();

    for(int i=0; i<NUM_ITERATIONS; ++i) {

      //If true, remove a node for every 3rd time (if there's one)
      if(rng.nextBoolean() && i%3 == 0 && sIdToDnReg.size()!=0) {
        //Pick a random node.
        int randomIndex = rng.nextInt() % sIdToDnReg.size();
        //Iterate to that random position 
        Iterator<Map.Entry<String, DatanodeRegistration>> it =
          sIdToDnReg.entrySet().iterator();
        for(int j=0; j<randomIndex-1; ++j) {
          it.next();
        }",1
"@Test
  public void testRemoveIncludedNode() throws IOException {
    FSNamesystem fsn = Mockito.mock(FSNamesystem.class);

    // Set the write lock so that the DatanodeManager can start
    Mockito.when(fsn.hasWriteLock()).thenReturn(true);

    DatanodeManager dm = mockDatanodeManager(fsn, new Configuration());
    HostFileManager hm = new HostFileManager();
    HostSet noNodes = new HostSet();
    HostSet oneNode = new HostSet();
    HostSet twoNodes = new HostSet();
    DatanodeRegistration dr1 = new DatanodeRegistration(
      new DatanodeID(""127.0.0.1"", ""127.0.0.1"", ""someStorageID-123"",
          12345, 12345, 12345, 12345),
      new StorageInfo(HdfsServerConstants.NodeType.DATA_NODE),
      new ExportedBlockKeys(), ""test"");
    DatanodeRegistration dr2 = new DatanodeRegistration(
      new DatanodeID(""127.0.0.1"", ""127.0.0.1"", ""someStorageID-234"",
          23456, 23456, 23456, 23456),
      new StorageInfo(HdfsServerConstants.NodeType.DATA_NODE),
      new ExportedBlockKeys(), ""test"");

    twoNodes.add(entry(""127.0.0.1:12345""));
    twoNodes.add(entry(""127.0.0.1:23456""));
    oneNode.add(entry(""127.0.0.1:23456""));

    hm.refresh(twoNodes, noNodes);
    Whitebox.setInternalState(dm, ""hostConfigManager"", hm);

    // Register two data nodes to simulate them coming up.
    // We need to add two nodes, because if we have only one node, removing it
    // will cause the includes list to be empty, which means all hosts will be
    // allowed.
    dm.registerDatanode(dr1);
    dm.registerDatanode(dr2);

    // Make sure that both nodes are reported
    List<DatanodeDescriptor> both =
        dm.getDatanodeListForReport(HdfsConstants.DatanodeReportType.ALL);

    // Sort the list so that we know which one is which
    Collections.sort(both);

    Assert.assertEquals(""Incorrect number of hosts reported"",
        2, both.size());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:12345"", both.get(0).getInfoAddr());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:23456"", both.get(1).getInfoAddr());

    // Remove one node from includes, but do not add it to excludes.
    hm.refresh(oneNode, noNodes);

    // Make sure that only one node is still reported
    List<DatanodeDescriptor> onlyOne =
        dm.getDatanodeListForReport(HdfsConstants.DatanodeReportType.ALL);

    Assert.assertEquals(""Incorrect number of hosts reported"",
        1, onlyOne.size());
    Assert.assertEquals(""Unexpected host reported"",
        ""127.0.0.1:23456"", onlyOne.get(0).getInfoAddr());

    // Remove all nodes from includes
    hm.refresh(noNodes, noNodes);

    // Check that both nodes are reported again
    List<DatanodeDescriptor> bothAgain =
        dm.getDatanodeListForReport(HdfsConstants.DatanodeReportType.ALL);

    // Sort the list so that we know which one is which
    Collections.sort(bothAgain);

    Assert.assertEquals(""Incorrect number of hosts reported"",
        2, bothAgain.size());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:12345"", bothAgain.get(0).getInfoAddr());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:23456"", bothAgain.get(1).getInfoAddr());
  }",1
"@Test
  public void testDfsReservedPercentageForDifferentStorageTypes()
      throws IOException {
    conf.setClass(DFSConfigKeys.DFS_DATANODE_DU_RESERVED_CALCULATOR_KEY,
        ReservedSpaceCalculator.ReservedSpaceCalculatorPercentage.class,
        ReservedSpaceCalculator.class);
    conf.setLong(DFS_DATANODE_DU_RESERVED_PERCENTAGE_KEY, 15);

    File volDir = new File(baseDir, ""volume-0"");
    volDir.mkdirs();

    DF usage = mock(DF.class);
    when(usage.getCapacity()).thenReturn(4000L);
    when(usage.getAvailable()).thenReturn(1000L);

    // when storage type reserved is not configured, should consider
    // dfs.datanode.du.reserved.pct
    FsVolumeImpl volume = new FsVolumeImplBuilder()
        .setConf(conf)
        .setDataset(dataset)
        .setStorageID(""storage-id"")
        .setStorageDirectory(
            new StorageDirectory(StorageLocation.parse(
                ""[RAM_DISK]"" + volDir.getPath())))
        .setUsage(usage)
        .build();

    assertEquals(600, volume.getReserved());
    assertEquals(3400, volume.getCapacity());
    assertEquals(400, volume.getAvailable());

    // when storage type reserved is configured.
    conf.setLong(
        DFS_DATANODE_DU_RESERVED_PERCENTAGE_KEY + "".""
            + StringUtils.toLowerCase(StorageType.RAM_DISK.toString()), 10);
    conf.setLong(
        DFS_DATANODE_DU_RESERVED_PERCENTAGE_KEY + "".""
            + StringUtils.toLowerCase(StorageType.SSD.toString()), 50);
    conf.setLong(
        DFS_DATANODE_DU_RESERVED_PERCENTAGE_KEY + "".""
            + StringUtils.toLowerCase(StorageType.NVDIMM.toString()), 20);
    FsVolumeImpl volume1 = new FsVolumeImplBuilder()
        .setConf(conf)
        .setDataset(dataset)
        .setStorageID(""storage-id"")
        .setStorageDirectory(
            new StorageDirectory(StorageLocation.parse(
                ""[RAM_DISK]"" + volDir.getPath())))
        .setUsage(usage)
        .build();
    assertEquals(400, volume1.getReserved());
    assertEquals(3600, volume1.getCapacity());
    assertEquals(600, volume1.getAvailable());
    FsVolumeImpl volume2 = new FsVolumeImplBuilder()
        .setConf(conf)
        .setDataset(dataset)
        .setStorageID(""storage-id"")
        .setStorageDirectory(
            new StorageDirectory(StorageLocation.parse(
                ""[SSD]"" + volDir.getPath())))
        .setUsage(usage)
        .build();
    assertEquals(2000, volume2.getReserved());
    assertEquals(2000, volume2.getCapacity());
    assertEquals(0, volume2.getAvailable());
    FsVolumeImpl volume3 = new FsVolumeImplBuilder()
        .setConf(conf)
        .setDataset(dataset)
        .setStorageID(""storage-id"")
        .setStorageDirectory(
            new StorageDirectory(StorageLocation.parse(
                ""[DISK]"" + volDir.getPath())))
        .setUsage(usage)
        .build();
    assertEquals(600, volume3.getReserved());
    FsVolumeImpl volume4 = new FsVolumeImplBuilder()
        .setConf(conf)
        .setDataset(dataset)
        .setStorageID(""storage-id"")
        .setStorageDirectory(
            new StorageDirectory(StorageLocation.parse(volDir.getPath())))
        .setUsage(usage)
        .build();
    assertEquals(600, volume4.getReserved());
    FsVolumeImpl volume5 = new FsVolumeImplBuilder()
        .setConf(conf)
        .setDataset(dataset)
        .setStorageID(""storage-id"")
        .setStorageDirectory(
            new StorageDirectory(StorageLocation.parse(
                ""[NVDIMM]"" + volDir.getPath())))
        .setUsage(usage)
        .build();
    assertEquals(800, volume5.getReserved());
    assertEquals(3200, volume5.getCapacity());
    assertEquals(200, volume5.getAvailable());
  }",1
"@Test
  public void testIBRClearanceForStandbyOnReRegister() throws Exception {
    final BPOfferService bpos = setupBPOSForNNs(mockNN1, mockNN2);
    bpos.start();
    try {
      waitForInitialization(bpos);
      // Should start with neither NN as active.
      assertNull(bpos.getActiveNN());
      // Have NN1 claim active at txid 1
      mockHaStatuses[0] = new NNHAStatusHeartbeat(HAServiceState.ACTIVE, 1);
      bpos.triggerHeartbeatForTests();
      // Now mockNN1 is acting like active namenode and mockNN2 as Standby
      assertSame(mockNN1, bpos.getActiveNN());
      // Return nothing when active Active Namenode gets IBRs
      Mockito.doNothing().when(mockNN1).blockReceivedAndDeleted(
          Mockito.any(DatanodeRegistration.class), Mockito.anyString(), Mockito
              .any(StorageReceivedDeletedBlocks[].class));

      final IOException re = new IOException(
          ""Standby NN is currently not able to process IBR"");

      final AtomicBoolean ibrReported = new AtomicBoolean(false);
      // throw exception for standby when first IBR is receieved
      Mockito.doAnswer(new Answer<Void>() {
        @Override
        public Void answer(InvocationOnMock invocation) throws Throwable {
          ibrReported.set(true);
          throw re;
        }",1
"@Test
  public void testInvalidate() throws IOException {
    final SimulatedFSDataset fsdataset = getSimulatedFSDataset();
    int bytesAdded = addSomeBlocks(fsdataset);
    Block[] deleteBlocks = new Block[2];
    deleteBlocks[0] = new Block(1, 0, 0);
    deleteBlocks[1] = new Block(2, 0, 0);
    fsdataset.invalidate(bpid, deleteBlocks);
    checkInvalidBlock(new ExtendedBlock(bpid, deleteBlocks[0]));
    checkInvalidBlock(new ExtendedBlock(bpid, deleteBlocks[1]));
    long sizeDeleted = blockIdToLen(1) + blockIdToLen(2);
    assertEquals(bytesAdded-sizeDeleted, fsdataset.getDfsUsed());
    assertEquals(fsdataset.getCapacity()-bytesAdded+sizeDeleted,  fsdataset.getRemaining());
    
    // Now make sure the rest of the blocks are valid
    for (int i=3; i <= NUMBLOCKS; ++i) {
      Block b = new Block(i, 0, 0);
      assertTrue(fsdataset.isValidBlock(new ExtendedBlock(bpid, b)));
    }",1
"@Test
  public void testStorageReportHasStorageTypeAndState() throws IOException {

    // Make sure we are not testing with the default type, that would not
    // be a very good test.
    assertNotSame(storageType, StorageType.DEFAULT);
    NameNode nn = cluster.getNameNode();
    DataNode dn = cluster.getDataNodes().get(0);

    // Insert a spy object for the NN RPC.
    DatanodeProtocolClientSideTranslatorPB nnSpy =
        InternalDataNodeTestUtils.spyOnBposToNN(dn, nn);

    // Trigger a heartbeat so there is an interaction with the spy
    // object.
    DataNodeTestUtils.triggerHeartbeat(dn);

    // Verify that the callback passed in the expected parameters.
    ArgumentCaptor<StorageReport[]> captor =
        ArgumentCaptor.forClass(StorageReport[].class);

    Mockito.verify(nnSpy).sendHeartbeat(
        any(DatanodeRegistration.class),
        captor.capture(),
        anyLong(), anyLong(), anyInt(), anyInt(), anyInt(),
        any(), Mockito.anyBoolean(),
        Mockito.any(SlowPeerReports.class),
        Mockito.any(SlowDiskReports.class));

    StorageReport[] reports = captor.getValue();

    for (StorageReport report: reports) {
      assertThat(report.getStorage().getStorageType(), is(storageType));
      assertThat(report.getStorage().getState(), is(DatanodeStorage.State.NORMAL));
    }",1
"@Test
  public void testPlannerScale() throws Exception {
    final int diskCount = 256; // it is rare to see more than 48 disks
    DiskBalancerTestUtil util = new DiskBalancerTestUtil();
    DiskBalancerVolumeSet vSet =
        util.createRandomVolumeSet(StorageType.SSD, diskCount);
    NullConnector nullConnector = new NullConnector();
    DiskBalancerCluster cluster = new DiskBalancerCluster(nullConnector);

    DiskBalancerDataNode node =
        new DiskBalancerDataNode(UUID.randomUUID().toString());
    int diskNum = 0;
    for (DiskBalancerVolume vol : vSet.getVolumes()) {
      vol.setPath(""volume"" + diskNum++);
      node.addVolume(vol);
    }",1
"@Test
  public void testGetConnectionWithConcurrency() throws Exception {
    Map<ConnectionPoolId, ConnectionPool> poolMap = connManager.getPools();
    Configuration copyConf = new Configuration(conf);
    copyConf.setInt(RBFConfigKeys.DFS_ROUTER_MAX_CONCURRENCY_PER_CONNECTION_KEY, 20);

    ConnectionPool pool = new ConnectionPool(
        copyConf, TEST_NN_ADDRESS, TEST_USER1, 1, 10, 0.5f,
        ClientProtocol.class, null);
    poolMap.put(
        new ConnectionPoolId(TEST_USER1, TEST_NN_ADDRESS, ClientProtocol.class),
        pool);
    assertEquals(1, pool.getNumConnections());
    // one connection can process the maximum number of requests concurrently.
    for (int i = 0; i < 20; i++) {
      ConnectionContext cc = pool.getConnection();
      assertTrue(cc.isUsable());
      cc.getClient();
    }",1
"@Test
  public void testValidClientIndex() throws Exception {
    ConnectionPool pool = new ConnectionPool(conf, TEST_NN_ADDRESS, TEST_USER1,
        2, 2, 0.5f, ClientProtocol.class, null);
    for(int i = -3; i <= 3; i++) {
      pool.getClientIndex().set(i);
      ConnectionContext conn = pool.getConnection();
      assertNotNull(conn);
      assertTrue(conn.isUsable());
    }",1
"@Test
  public void testSuccessfulBaseCase() throws Exception {
    removeStandbyNameDirs();

    // skip the first NN, its up
    for (int index = 1; index < maxNNCount; index++) {
      try {
        cluster.restartNameNode(index);
        fail(""Did not throw"");
      }",1
"@Test
  public void testNonRandomGetProxy() throws Exception {
    final AtomicInteger nn1Count = new AtomicInteger(0);
    final AtomicInteger nn2Count = new AtomicInteger(0);

    Map<InetSocketAddress, ClientProtocol> proxyMap = new HashMap<>();

    final ClientProtocol nn1Mock = mock(ClientProtocol.class);
    when(nn1Mock.getStats()).thenAnswer(createAnswer(nn1Count, 1));
    proxyMap.put(ns1nn1, nn1Mock);

    final ClientProtocol nn2Mock = mock(ClientProtocol.class);
    when(nn2Mock.getStats()).thenAnswer(createAnswer(nn2Count, 2));
    proxyMap.put(ns1nn2, nn2Mock);

    ConfiguredFailoverProxyProvider<ClientProtocol> provider1 =
        new ConfiguredFailoverProxyProvider<>(conf, ns1Uri,
            ClientProtocol.class, createFactory(proxyMap));
    ClientProtocol proxy1 = provider1.getProxy().proxy;
    proxy1.getStats();
    assertEquals(1, nn1Count.get());
    assertEquals(0, nn2Count.get());
    proxy1.getStats();
    assertEquals(2, nn1Count.get());
    assertEquals(0, nn2Count.get());
    nn1Count.set(0);
    nn2Count.set(0);

    for (int i = 0; i < NUM_ITERATIONS; i++) {
      ConfiguredFailoverProxyProvider<ClientProtocol> provider2 =
          new ConfiguredFailoverProxyProvider<>(conf, ns1Uri,
              ClientProtocol.class, createFactory(proxyMap));
      ClientProtocol proxy2 = provider2.getProxy().proxy;
      proxy2.getStats();
    }",1
"@Test
  public void testRandomGetProxy() throws Exception {
    final AtomicInteger nn1Count = new AtomicInteger(0);
    final AtomicInteger nn2Count = new AtomicInteger(0);
    final AtomicInteger nn3Count = new AtomicInteger(0);

    Map<InetSocketAddress, ClientProtocol> proxyMap = new HashMap<>();

    final ClientProtocol nn1Mock = mock(ClientProtocol.class);
    when(nn1Mock.getStats()).thenAnswer(createAnswer(nn1Count, 1));
    proxyMap.put(ns2nn1, nn1Mock);

    final ClientProtocol nn2Mock = mock(ClientProtocol.class);
    when(nn2Mock.getStats()).thenAnswer(createAnswer(nn2Count, 2));
    proxyMap.put(ns2nn2, nn2Mock);

    final ClientProtocol nn3Mock = mock(ClientProtocol.class);
    when(nn3Mock.getStats()).thenAnswer(createAnswer(nn3Count, 3));
    proxyMap.put(ns2nn3, nn3Mock);


    for (int i = 0; i < NUM_ITERATIONS; i++) {
      ConfiguredFailoverProxyProvider<ClientProtocol> provider =
          new ConfiguredFailoverProxyProvider<>(conf, ns2Uri,
              ClientProtocol.class, createFactory(proxyMap));
      ClientProtocol proxy = provider.getProxy().proxy;
      proxy.getStats();
    }",1
"@Test
  public void testNN0TriggersLogRolls() throws Exception {
    testStandbyTriggersLogRolls(0);
  }",1
"@Test
  public void testFileNotFoundExceptionWithSingleProxy() throws Exception {
    ClientProtocol active = Mockito.mock(ClientProtocol.class);
    Mockito
        .when(active.getBlockLocations(anyString(), anyLong(), anyLong()))
        .thenThrow(new RemoteException(""java.io.FileNotFoundException"",
            ""File does not exist!""));

    ClientProtocol standby = Mockito.mock(ClientProtocol.class);
    Mockito
        .when(standby.getBlockLocations(anyString(), anyLong(), anyLong()))
        .thenThrow(
            new RemoteException(""org.apache.hadoop.ipc.StandbyException"",
                ""Standby NameNode""));

    RequestHedgingProxyProvider<ClientProtocol> provider =
        new RequestHedgingProxyProvider<>(conf, nnUri,
            ClientProtocol.class, createFactory(standby, active));
    try {
      provider.getProxy().proxy.getBlockLocations(""/tmp/test.file"", 0L, 20L);
      Assert.fail(""Should fail since the active namenode throws""
          + "" FileNotFoundException!"");
    }",1
"@Test
  public void testHedgingWhenConnectException() throws Exception {
    ClientProtocol active = Mockito.mock(ClientProtocol.class);
    Mockito.when(active.getStats()).thenThrow(new ConnectException());

    ClientProtocol standby = Mockito.mock(ClientProtocol.class);
    Mockito.when(standby.getStats())
        .thenThrow(
            new RemoteException(""org.apache.hadoop.ipc.StandbyException"",
            ""Standby NameNode""));

    RequestHedgingProxyProvider<ClientProtocol> provider =
        new RequestHedgingProxyProvider<>(conf, nnUri,
          ClientProtocol.class, createFactory(active, standby));
    try {
      provider.getProxy().proxy.getStats();
      Assert.fail(""Should fail since the active namenode throws""
          + "" ConnectException!"");
    }",1
"@Test
  public void testSingleProxyFailover() throws Exception {
    String singleNS = ""mycluster-"" + Time.monotonicNow();
    URI singleNNUri = new URI(""hdfs://"" + singleNS);
    Configuration singleConf = new Configuration();
    singleConf.set(HdfsClientConfigKeys.DFS_NAMESERVICES, singleNS);
    singleConf.set(HdfsClientConfigKeys.
        DFS_HA_NAMENODES_KEY_PREFIX + ""."" + singleNS, ""nn1"");

    singleConf.set(HdfsClientConfigKeys.
            DFS_NAMENODE_RPC_ADDRESS_KEY + ""."" + singleNS + "".nn1"",
        RandomStringUtils.randomAlphabetic(8) + "".foo.bar:9820"");
    ClientProtocol active = Mockito.mock(ClientProtocol.class);
    Mockito
        .when(active.getBlockLocations(anyString(), anyLong(), anyLong()))
        .thenThrow(new RemoteException(""java.io.FileNotFoundException"",
            ""File does not exist!""));

    RequestHedgingProxyProvider<ClientProtocol> provider =
        new RequestHedgingProxyProvider<>(singleConf, singleNNUri,
            ClientProtocol.class, createFactory(active));
    try {
      provider.getProxy().proxy.getBlockLocations(""/tmp/test.file"", 0L, 20L);
      Assert.fail(""Should fail since the active namenode throws""
          + "" FileNotFoundException!"");
    }",1
"@Test
  public void testCorruptBlock() throws Exception {
    // Create a file with single block with two replicas
    final Path file = getTestPath(""testCorruptBlock"");
    final short replicaCount = 2;
    createFile(file, 100, replicaCount);
    DFSTestUtil.waitForReplication(fs, file, replicaCount, 15000);

    // Disable the heartbeats, so that no corrupted replica
    // can be fixed
    for (DataNode dn : cluster.getDataNodes()) {
      DataNodeTestUtils.setHeartbeatsDisabledForTests(dn, true);
    }",1
"@Test
  public void testRemoveRandom() throws Exception {
    final int n = NUM_SNAPSHOTS;
    testRemove(""Random"", n, i -> ThreadLocalRandom.current().nextInt(n - i));
  }",1
"@Test
  public void testDiffReportWithRpcLimit() throws Exception {
    final Path root = new Path(""/"");
    hdfs.mkdirs(root);
    for (int i = 1; i < 4; i++) {
      final Path path = new Path(root, ""dir"" + i);
      hdfs.mkdirs(path);
    }",1
"@Test
  public void testDiffReportWithRpcLimit2() throws Exception {
    final Path root = new Path(""/"");
    hdfs.mkdirs(root);
    for (int i = 1; i <=3; i++) {
      final Path path = new Path(root, ""dir"" + i);
      hdfs.mkdirs(path);
    }",1
"@Test
  public void testBackupNodeTailsEdits() throws Exception {
    Configuration conf = new HdfsConfiguration();
    HAUtil.setAllowStandbyReads(conf, true);
    MiniDFSCluster cluster = null;
    FileSystem fileSys = null;
    BackupNode backup = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf)
                                  .numDataNodes(0).build();
      fileSys = cluster.getFileSystem();
      backup = startBackupNode(conf, StartupOption.BACKUP, 1);
      
      BackupImage bnImage = (BackupImage) backup.getFSImage();
      testBNInSync(cluster, backup, 1);
      
      // Force a roll -- BN should roll with NN.
      NameNode nn = cluster.getNameNode();
      NamenodeProtocols nnRpc = nn.getRpcServer();
      nnRpc.rollEditLog();
      assertEquals(bnImage.getEditLog().getCurSegmentTxId(),
          nn.getFSImage().getEditLog().getCurSegmentTxId());
      
      // BN should stay in sync after roll
      testBNInSync(cluster, backup, 2);
      
      long nnImageBefore =
        nn.getFSImage().getStorage().getMostRecentCheckpointTxId();
      // BN checkpoint
      backup.doCheckpoint();
      
      // NN should have received a new image
      long nnImageAfter =
        nn.getFSImage().getStorage().getMostRecentCheckpointTxId();
      
      assertTrue(""nn should have received new checkpoint. before: "" +
          nnImageBefore + "" after: "" + nnImageAfter,
          nnImageAfter > nnImageBefore);

      // BN should stay in sync after checkpoint
      testBNInSync(cluster, backup, 3);

      // Stop BN
      StorageDirectory sd = bnImage.getStorage().getStorageDir(0);
      backup.stop();
      backup = null;
      
      // When shutting down the BN, it shouldn't finalize logs that are
      // still open on the NN
      EditLogFile editsLog = FSImageTestUtil.findLatestEditsLog(sd);
      assertEquals(editsLog.getFirstTxId(),
          nn.getFSImage().getEditLog().getCurSegmentTxId());
      assertTrue(""Should not have finalized "" + editsLog,
          editsLog.isInProgress());
      
      // do some edits
      assertTrue(fileSys.mkdirs(new Path(""/edit-while-bn-down"")));
  
      // start a new backup node
      backup = startBackupNode(conf, StartupOption.BACKUP, 1);

      testBNInSync(cluster, backup, 4);
      assertNotNull(backup.getNamesystem()
          .getFileInfo(""/edit-while-bn-down"", false, false, false));
      
      // Trigger an unclean shutdown of the backup node. Backup node will not
      // unregister from the active when this is done simulating a node crash.
      backup.stop(false);
           
      // do some edits on the active. This should go through without failing.
      // This will verify that active is still up and can add entries to
      // master editlog.
      assertTrue(fileSys.mkdirs(new Path(""/edit-while-bn-down-2"")));
      
    }",1
"@Test
  public void testBackupNodeTailsEdits() throws Exception {
    Configuration conf = new HdfsConfiguration();
    HAUtil.setAllowStandbyReads(conf, true);
    MiniDFSCluster cluster = null;
    FileSystem fileSys = null;
    BackupNode backup = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf)
                                  .numDataNodes(0).build();
      fileSys = cluster.getFileSystem();
      backup = startBackupNode(conf, StartupOption.BACKUP, 1);
      
      BackupImage bnImage = (BackupImage) backup.getFSImage();
      testBNInSync(cluster, backup, 1);
      
      // Force a roll -- BN should roll with NN.
      NameNode nn = cluster.getNameNode();
      NamenodeProtocols nnRpc = nn.getRpcServer();
      nnRpc.rollEditLog();
      assertEquals(bnImage.getEditLog().getCurSegmentTxId(),
          nn.getFSImage().getEditLog().getCurSegmentTxId());
      
      // BN should stay in sync after roll
      testBNInSync(cluster, backup, 2);
      
      long nnImageBefore =
        nn.getFSImage().getStorage().getMostRecentCheckpointTxId();
      // BN checkpoint
      backup.doCheckpoint();
      
      // NN should have received a new image
      long nnImageAfter =
        nn.getFSImage().getStorage().getMostRecentCheckpointTxId();
      
      assertTrue(""nn should have received new checkpoint. before: "" +
          nnImageBefore + "" after: "" + nnImageAfter,
          nnImageAfter > nnImageBefore);

      // BN should stay in sync after checkpoint
      testBNInSync(cluster, backup, 3);

      // Stop BN
      StorageDirectory sd = bnImage.getStorage().getStorageDir(0);
      backup.stop();
      backup = null;
      
      // When shutting down the BN, it shouldn't finalize logs that are
      // still open on the NN
      EditLogFile editsLog = FSImageTestUtil.findLatestEditsLog(sd);
      assertEquals(editsLog.getFirstTxId(),
          nn.getFSImage().getEditLog().getCurSegmentTxId());
      assertTrue(""Should not have finalized "" + editsLog,
          editsLog.isInProgress());
      
      // do some edits
      assertTrue(fileSys.mkdirs(new Path(""/edit-while-bn-down"")));
  
      // start a new backup node
      backup = startBackupNode(conf, StartupOption.BACKUP, 1);

      testBNInSync(cluster, backup, 4);
      assertNotNull(backup.getNamesystem()
          .getFileInfo(""/edit-while-bn-down"", false, false, false));
      
      // Trigger an unclean shutdown of the backup node. Backup node will not
      // unregister from the active when this is done simulating a node crash.
      backup.stop(false);
           
      // do some edits on the active. This should go through without failing.
      // This will verify that active is still up and can add entries to
      // master editlog.
      assertTrue(fileSys.mkdirs(new Path(""/edit-while-bn-down-2"")));
      
    }",1
"@Test
  public void testChooseTarget() throws Exception {
    doTestChooseTargetNormalCase();
    doTestChooseTargetSpecialCase();
  }",1
"@Test
  public void testRawWrites() throws IOException {
    EditLogFileOutputStream elos = new EditLogFileOutputStream(conf,
        TEST_EDITS, 0);
    try {
      byte[] small = new byte[] { 1, 2, 3, 4, 5, 8, 7 }",1
"@Test
  public void testAskForTransactionsMidfile() throws IOException {
    File f = new File(TestEditLog.TEST_DIR + ""/askfortransactionsmidfile"");
    NNStorage storage = setupEdits(Collections.<URI>singletonList(f.toURI()), 
                                   10);
    StorageDirectory sd = storage.dirIterator(NameNodeDirType.EDITS).next();
    
    FileJournalManager jm = new FileJournalManager(conf, sd, storage);
    
    // 10 rolls, so 11 rolled files, 110 txids total.
    final int TOTAL_TXIDS = 10 * 11;
    for (int txid = 1; txid <= TOTAL_TXIDS; txid++) {
      assertEquals((TOTAL_TXIDS - txid) + 1, getNumberOfTransactions(jm, txid,
          true, false));
    }",1
"@Test
  public void testDisplayRecentEditLogOpCodes() throws IOException {
    // start a cluster
    Configuration conf = getConf();
    MiniDFSCluster cluster = null;
    FileSystem fileSys = null;
    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES)
        .enableManagedDfsDirsRedundancy(false).build();
    cluster.waitActive();
    fileSys = cluster.getFileSystem();
    final FSNamesystem namesystem = cluster.getNamesystem();

    FSImage fsimage = namesystem.getFSImage();
    for (int i = 0; i < 20; i++) {
      fileSys.mkdirs(new Path(""/tmp/tmp"" + i));
    }",1
"@Test
  public void testFSEditLogOpCodes() throws IOException {
    //try all codes
    for(FSEditLogOpCodes c : FSEditLogOpCodes.values()) {
      final byte code = c.getOpCode();
      assertEquals(""c="" + c + "", code="" + code,
          c, FSEditLogOpCodes.fromByte(code));
    }",1
"@Test
  public void testValidateEditLogWithCorruptBody() throws IOException {
    File testDir = new File(TEST_DIR, ""testValidateEditLogWithCorruptBody"");
    SortedMap<Long, Long> offsetToTxId = Maps.newTreeMap();
    final int NUM_TXNS = 20;
    File logFile = prepareUnfinalizedTestEditLog(testDir, NUM_TXNS,
        offsetToTxId);
    // Back up the uncorrupted log
    File logFileBak = new File(testDir, logFile.getName() + "".bak"");
    Files.copy(logFile, logFileBak);
    EditLogValidation validation =
        EditLogFileInputStream.scanEditLog(logFile, Long.MAX_VALUE, true);
    assertTrue(!validation.hasCorruptHeader());
    // We expect that there will be an OP_START_LOG_SEGMENT, followed by
    // NUM_TXNS opcodes, followed by an OP_END_LOG_SEGMENT.
    assertEquals(NUM_TXNS + 1, validation.getEndTxId());
    // Corrupt each edit and verify that validation continues to work
    for (Map.Entry<Long, Long> entry : offsetToTxId.entrySet()) {
      long txOffset = entry.getKey();
      long txId = entry.getValue();

      // Restore backup, corrupt the txn opcode
      Files.copy(logFileBak, logFile);
      corruptByteInFile(logFile, txOffset);
      validation = EditLogFileInputStream.scanEditLog(logFile,
          Long.MAX_VALUE, true);
      long expectedEndTxId = (txId == (NUM_TXNS + 1)) ?
          NUM_TXNS : (NUM_TXNS + 1);
      assertEquals(""Failed when corrupting txn opcode at "" + txOffset,
          expectedEndTxId, validation.getEndTxId());
      assertTrue(!validation.hasCorruptHeader());
    }",1
"@Test
  public void testWithFSEditLogLock() throws Exception {
    Configuration conf = new Configuration();
    int jmxCachePeriod = 1;
    new ConfigBuilder().add(""namenode.period"", jmxCachePeriod)
        .save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-namenode""));
    MiniDFSCluster cluster = null;
    try {
      cluster = new MiniDFSCluster.Builder(conf).build();
      cluster.waitActive();
      synchronized (cluster.getNameNode().getFSImage().getEditLog()) {
        Thread.sleep(jmxCachePeriod * 1000);
        MBeanClient client = new MBeanClient();
        client.start();
        client.join(20000);
        assertTrue(""JMX calls are blocked when FSEditLog"" +
            "" is synchronized by another thread"", client.succeeded);
        client.interrupt();
      }",1
"@Test
  public void testCustomProvider() throws Exception {
    final UserGroupInformation[] users = new UserGroupInformation[]{
        UserGroupInformation.createUserForTesting(
            System.getProperty(""user.name""), new String[]{""supergroup""}",1
"@Test
  public void testLocationLimitInListingOps() throws Exception {
    final Configuration conf = new Configuration();
    conf.setInt(DFSConfigKeys.DFS_LIST_LIMIT, 9); // 3 blocks * 3 replicas
    MiniDFSCluster cluster = null;
    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
      cluster.waitActive();
      final DistributedFileSystem hdfs = cluster.getFileSystem();
      ArrayList<String> source = new ArrayList<String>();

      // tmp1 holds files with 3 blocks, 3 replicas
      // tmp2 holds files with 3 blocks, 1 replica
      hdfs.mkdirs(new Path(""/tmp1""));
      hdfs.mkdirs(new Path(""/tmp2""));

      source.add(""f1"");
      source.add(""f2"");

      int numEntries = source.size();
      for (int j=0;j<numEntries;j++) {
          DFSTestUtil.createFile(hdfs, new Path(""/tmp1/""+source.get(j)), 4096,
          3*1024-100, 1024, (short) 3, 0);
      }",1
"@Test
  public void testRemoveLeases() throws Exception {
    FSNamesystem fsn = mock(FSNamesystem.class);
    LeaseManager lm = new LeaseManager(fsn);
    ArrayList<Long> ids = Lists.newArrayList(INodeId.ROOT_INODE_ID + 1,
            INodeId.ROOT_INODE_ID + 2, INodeId.ROOT_INODE_ID + 3,
            INodeId.ROOT_INODE_ID + 4);
    for (long id : ids) {
      lm.addLease(""foo"", id);
    }",1
"@Test
  public void testLastContactTime() throws Exception {
    Configuration conf = new Configuration();
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY, 1);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY, 1);
    MiniDFSCluster cluster = null;
    HostsFileWriter hostsFileWriter = new HostsFileWriter();
    hostsFileWriter.initialize(conf, ""temp/TestNameNodeMXBean"");

    try {
      cluster = new MiniDFSCluster.Builder(conf, baseDir.getRoot()).numDataNodes(3).build();
      cluster.waitActive();

      FSNamesystem fsn = cluster.getNameNode().namesystem;

      MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();
      ObjectName mxbeanName = new ObjectName(
        ""Hadoop:service=NameNode,name=NameNodeInfo"");

      List<String> hosts = new ArrayList<>();
      for(DataNode dn : cluster.getDataNodes()) {
        hosts.add(dn.getDisplayName());
      }",1
"@Test
  public void testChooseExcess() {
    final BlockStoragePolicy hot = POLICY_SUITE.getPolicy(HOT);
    final BlockStoragePolicy warm = POLICY_SUITE.getPolicy(WARM);
    final BlockStoragePolicy cold = POLICY_SUITE.getPolicy(COLD);

    final short replication = 3;
    for(int n = 0; n <= 6; n++) {
      for(int d = 0; d <= n; d++) {
        final int a = n - d;
        final List<StorageType> chosen = asList(d, a);
        {
          final int nDisk = Math.max(0, d - replication); 
          final int nArchive = a;
          final StorageType[] expected = newStorageTypes(nDisk, nArchive);
          checkChooseExcess(hot, replication, chosen, expected);
        }",1
"@Test
  public void testDefaultPolicies() {
    final Map<Byte, String> expectedPolicyStrings = new HashMap<Byte, String>();
    expectedPolicyStrings.put(COLD,
        ""BlockStoragePolicy{COLD:"" + COLD + "", storageTypes=[ARCHIVE], "" +
            ""creationFallbacks=[], replicationFallbacks=[]}",1
"@Test
  public void testGetAllStoragePoliciesFromFs() throws IOException {
    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)
        .numDataNodes(REPLICATION)
        .storageTypes(
            new StorageType[] {StorageType.DISK, StorageType.ARCHIVE}",1
"@Test  
  public void testDataTransferProtocol() throws IOException {
    Random random = new Random();
    int oneMil = 1024*1024;
    Path file = new Path(""dataprotocol.dat"");
    int numDataNodes = 1;
    
    Configuration conf = new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_REPLICATION_KEY, numDataNodes); 
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(numDataNodes).build();
    try {
    cluster.waitActive();
    datanode = cluster.getFileSystem().getDataNodeStats(DatanodeReportType.LIVE)[0];
    dnAddr = NetUtils.createSocketAddr(datanode.getXferAddr());
    FileSystem fileSys = cluster.getFileSystem();
    
    int fileLen = Math.min(conf.getInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, 4096), 4096);
    
      DFSTestUtil.createFile(fileSys, file, fileLen, fileLen,
          fileSys.getDefaultBlockSize(file),
          fileSys.getDefaultReplication(file), 0L);

    // get the first blockid for the file
    final ExtendedBlock firstBlock = DFSTestUtil.getFirstBlock(fileSys, file);
    final String poolId = firstBlock.getBlockPoolId();
    long newBlockId = firstBlock.getBlockId() + 1;

    recvBuf.reset();
    sendBuf.reset();
    
    // bad version
    recvOut.writeShort((short)(DataTransferProtocol.DATA_TRANSFER_VERSION-1));
    sendOut.writeShort((short)(DataTransferProtocol.DATA_TRANSFER_VERSION-1));
    sendRecvData(""Wrong Version"", true);

    // bad ops
    sendBuf.reset();
    sendOut.writeShort((short)DataTransferProtocol.DATA_TRANSFER_VERSION);
    sendOut.writeByte(Op.WRITE_BLOCK.code - 1);
    sendRecvData(""Wrong Op Code"", true);
    
    /* Test OP_WRITE_BLOCK */
    sendBuf.reset();
    
    DataChecksum badChecksum = Mockito.spy(DEFAULT_CHECKSUM);
    Mockito.doReturn(-1).when(badChecksum).getBytesPerChecksum();

    writeBlock(poolId, newBlockId, badChecksum);
    recvBuf.reset();
    sendResponse(Status.ERROR, null, null, recvOut);
    sendRecvData(""wrong bytesPerChecksum while writing"", true);

    sendBuf.reset();
    recvBuf.reset();
    writeBlock(poolId, ++newBlockId, DEFAULT_CHECKSUM);

    PacketHeader hdr = new PacketHeader(
      4,     // size of packet
      0,     // offset in block,
      100,   // seqno
      false, // last packet
      -1 - random.nextInt(oneMil), // bad datalen
      false);
    hdr.write(sendOut);

    sendResponse(Status.SUCCESS, """", null, recvOut);
    new PipelineAck(100, new int[] {PipelineAck.combineHeader
      (PipelineAck.ECN.DISABLED, Status.ERROR)}",1
"@Test
  public void testGetLongStatistics() {
    short iterations = 0; // number of the iter.hasNext()
    final Iterator<LongStatistic> iter = statistics.getLongStatistics();

    while (iter.hasNext()) {
      final LongStatistic longStat = iter.next();
      assertNotNull(longStat);
      final OpType opType = OpType.fromSymbol(longStat.getName());
      assertNotNull(opType);
      assertTrue(expectedOpsCountMap.containsKey(opType));
      assertEquals(expectedOpsCountMap.get(opType).longValue(),
          longStat.getValue());
      iterations++;
    }",1
"@Test
  public void testIsTracked() {
    assertFalse(statistics.isTracked(null));
    assertFalse(statistics.isTracked(NO_SUCH_OP));

    final Iterator<LongStatistic> iter = statistics.getLongStatistics();
    while (iter.hasNext()) {
      final LongStatistic longStatistic = iter.next();
      assertTrue(statistics.isTracked(longStatistic.getName()));
    }",1
"@Test
  public void testReset() {
    statistics.reset();
    for (OpType opType : OpType.values()) {
      expectedOpsCountMap.get(opType).set(0);
    }",1
"@Test
  public void testIdempotentClose() throws Exception {
    final int numBlocks = 2;
    DFSTestUtil.createStripedFile(cluster, filePath, null, numBlocks,
        stripesPerBlock, false, ecPolicy);

    try (DFSInputStream in = fs.getClient().open(filePath.toString())) {
      assertTrue(in instanceof DFSStripedInputStream);
      // Close twice
      in.close();
    }",1
"@Test
  public void testRefreshBlock() throws Exception {
    final int numBlocks = 4;
    DFSTestUtil.createStripedFile(cluster, filePath, null, numBlocks,
        stripesPerBlock, false, ecPolicy);
    LocatedBlocks lbs = fs.getClient().namenode.getBlockLocations(
        filePath.toString(), 0, blockGroupSize * numBlocks);
    final DFSStripedInputStream in = new DFSStripedInputStream(fs.getClient(),
        filePath.toString(), false, ecPolicy, null);

    List<LocatedBlock> lbList = lbs.getLocatedBlocks();
    for (LocatedBlock aLbList : lbList) {
      LocatedStripedBlock lsb = (LocatedStripedBlock) aLbList;
      LocatedBlock[] blks = StripedBlockUtil.parseStripedBlockGroup(lsb,
          cellSize, dataBlocks, parityBlocks);
      for (int j = 0; j < dataBlocks; j++) {
        LocatedBlock refreshed = in.refreshLocatedBlock(blks[j]);
        assertEquals(blks[j].getBlock(), refreshed.getBlock());
        assertEquals(blks[j].getStartOffset(), refreshed.getStartOffset());
        assertArrayEquals(blks[j].getLocations(), refreshed.getLocations());
      }",1
"@Test
  public void testLocatedBlocks2Locations() {
    DatanodeInfo d = DFSTestUtil.getLocalDatanodeInfo();
    DatanodeInfo[] ds = new DatanodeInfo[1];
    ds[0] = d;

    // ok
    ExtendedBlock b1 = new ExtendedBlock(""bpid"", 1, 1, 1);
    LocatedBlock l1 = new LocatedBlock(b1, ds);
    l1.setStartOffset(0);
    l1.setCorrupt(false);

    // corrupt
    ExtendedBlock b2 = new ExtendedBlock(""bpid"", 2, 1, 1);
    LocatedBlock l2 = new LocatedBlock(b2, ds);
    l2.setStartOffset(0);
    l2.setCorrupt(true);

    List<LocatedBlock> ls = Arrays.asList(l1, l2);
    LocatedBlocks lbs = new LocatedBlocks(10, false, ls, l2, true, null, null);

    BlockLocation[] bs = DFSUtilClient.locatedBlocks2Locations(lbs);

    assertTrue(""expected 2 blocks but got "" + bs.length,
               bs.length == 2);

    int corruptCount = 0;
    for (BlockLocation b: bs) {
      if (b.isCorrupt()) {
        corruptCount++;
      }",1
"@Test
  public void testDFSClient() throws Exception {
    Configuration conf = getTestConfiguration();
    final long grace = 1000L;
    MiniDFSCluster cluster = null;
    LeaseRenewer.setLeaseRenewerGraceDefault(grace);

    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
      final String filepathstring = ""/test/LeaseChecker/foo"";
      final Path[] filepaths = new Path[4];
      for(int i = 0; i < filepaths.length; i++) {
        filepaths[i] = new Path(filepathstring + i);
      }",1
"@Test
  public void testEnableAndDisableErasureCodingPolicy() throws Exception {
    Configuration conf = getTestConfiguration();
    MiniDFSCluster cluster = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(1).build();
      DistributedFileSystem fs = cluster.getFileSystem();
      ECSchema toAddSchema = new ECSchema(""rs"", 3, 2);
      ErasureCodingPolicy toAddPolicy =
          new ErasureCodingPolicy(toAddSchema, 128 * 1024, (byte) 254);
      String policyName = toAddPolicy.getName();
      ErasureCodingPolicy[] policies =
          new ErasureCodingPolicy[]{toAddPolicy}",1
"@Test
  public void testInvalidScriptMappingFileReadStatistics() throws Exception {
    // Even though network location of the client machine is unknown,
    // MiniDFSCluster's datanode is on the local host and thus the network
    // distance is 0.
    testReadFileSystemStatistics(0, true, true);
  }",1
"@Test
  public void testStatistics() throws IOException {
    FileSystem.getStatistics(HdfsConstants.HDFS_URI_SCHEME,
        DistributedFileSystem.class).reset();
    @SuppressWarnings(""unchecked"")
    ThreadLocal<StatisticsData> data = (ThreadLocal<StatisticsData>)
        Whitebox.getInternalState(
        FileSystem.getStatistics(HdfsConstants.HDFS_URI_SCHEME,
        DistributedFileSystem.class), ""threadData"");
    data.set(null);

    int lsLimit = 2;
    final Configuration conf = getTestConfiguration();
    conf.setInt(DFSConfigKeys.DFS_LIST_LIMIT, lsLimit);
    final MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).build();
    try {
      cluster.waitActive();
      final FileSystem fs = cluster.getFileSystem();
      Path dir = new Path(""/test"");
      Path file = new Path(dir, ""file"");

      int readOps = 0;
      int writeOps = 0;
      int largeReadOps = 0;

      long opCount = getOpStatistics(OpType.MKDIRS);
      fs.mkdirs(dir);
      checkStatistics(fs, readOps, ++writeOps, largeReadOps);
      checkOpStatistics(OpType.MKDIRS, opCount + 1);
      
      opCount = getOpStatistics(OpType.CREATE);
      FSDataOutputStream out = fs.create(file, (short)1);
      out.close();
      checkStatistics(fs, readOps, ++writeOps, largeReadOps);
      checkOpStatistics(OpType.CREATE, opCount + 1);

      opCount = getOpStatistics(OpType.GET_FILE_STATUS);
      FileStatus status = fs.getFileStatus(file);
      checkStatistics(fs, ++readOps, writeOps, largeReadOps);
      checkOpStatistics(OpType.GET_FILE_STATUS, opCount + 1);
      
      opCount = getOpStatistics(OpType.GET_FILE_BLOCK_LOCATIONS);
      fs.getFileBlockLocations(file, 0, 0);
      checkStatistics(fs, ++readOps, writeOps, largeReadOps);
      checkOpStatistics(OpType.GET_FILE_BLOCK_LOCATIONS, opCount + 1);
      fs.getFileBlockLocations(status, 0, 0);
      checkStatistics(fs, ++readOps, writeOps, largeReadOps);
      checkOpStatistics(OpType.GET_FILE_BLOCK_LOCATIONS, opCount + 2);
      
      opCount = getOpStatistics(OpType.OPEN);
      FSDataInputStream in = fs.open(file);
      in.close();
      checkStatistics(fs, ++readOps, writeOps, largeReadOps);
      checkOpStatistics(OpType.OPEN, opCount + 1);
      
      opCount = getOpStatistics(OpType.SET_REPLICATION);
      fs.setReplication(file, (short)2);
      checkStatistics(fs, readOps, ++writeOps, largeReadOps);
      checkOpStatistics(OpType.SET_REPLICATION, opCount + 1);
      
      opCount = getOpStatistics(OpType.RENAME);
      Path file1 = new Path(dir, ""file1"");
      fs.rename(file, file1);
      checkStatistics(fs, readOps, ++writeOps, largeReadOps);
      checkOpStatistics(OpType.RENAME, opCount + 1);
      
      opCount = getOpStatistics(OpType.GET_CONTENT_SUMMARY);
      fs.getContentSummary(file1);
      checkStatistics(fs, ++readOps, writeOps, largeReadOps);
      checkOpStatistics(OpType.GET_CONTENT_SUMMARY, opCount + 1);
      
      
      // Iterative ls test
      long mkdirOp = getOpStatistics(OpType.MKDIRS);
      long listStatusOp = getOpStatistics(OpType.LIST_STATUS);
      long locatedListStatusOP = getOpStatistics(OpType.LIST_LOCATED_STATUS);
      for (int i = 0; i < 10; i++) {
        Path p = new Path(dir, Integer.toString(i));
        fs.mkdirs(p);
        mkdirOp++;
        FileStatus[] list = fs.listStatus(dir);
        if (list.length > lsLimit) {
          // if large directory, then count readOps and largeReadOps by 
          // number times listStatus iterates
          int iterations = (int)Math.ceil((double)list.length/lsLimit);
          largeReadOps += iterations;
          readOps += iterations;
          listStatusOp += iterations;
        }",1
"@Test
  public void testGetFileStatusOnFile() throws Exception {
    checkFile(fs, file1, 1);
    // test getFileStatus on a file
    FileStatus status = fs.getFileStatus(file1);
    assertFalse(file1 + "" should be a file"", status.isDirectory());
    assertEquals(blockSize, status.getBlockSize());
    assertEquals(1, status.getReplication());
    assertEquals(fileSize, status.getLen());
    ContractTestUtils.assertNotErasureCoded(fs, file1);
    assertEquals(file1.makeQualified(fs.getUri(),
        fs.getWorkingDirectory()).toString(), 
        status.getPath().toString());
    assertTrue(file1 + "" should have erasure coding unset in "" +
            ""FileStatus#toString(): "" + status,
        status.toString().contains(""isErasureCoded=false""));
  }",1
"@Test
  public void testListStatusOnFile() throws IOException {
    FileStatus[] stats = fs.listStatus(file1);
    assertEquals(1, stats.length);
    FileStatus status = stats[0];
    assertFalse(file1 + "" should be a file"", status.isDirectory());
    assertEquals(blockSize, status.getBlockSize());
    assertEquals(1, status.getReplication());
    assertEquals(fileSize, status.getLen());
    ContractTestUtils.assertNotErasureCoded(fs, file1);
    assertEquals(file1.makeQualified(fs.getUri(),
        fs.getWorkingDirectory()).toString(), 
        status.getPath().toString());

    RemoteIterator<FileStatus> itor = fc.listStatus(file1);
    status = itor.next();
    assertEquals(stats[0], status);
    assertFalse(file1 + "" should be a file"", status.isDirectory());
  }",1
"@Test
  public void testHdfsAdminStoragePolicies() throws Exception {
    HdfsAdmin hdfsAdmin = new HdfsAdmin(FileSystem.getDefaultUri(conf), conf);
    FileSystem fs = FileSystem.get(conf);
    final Path foo = new Path(""/foo"");
    final Path bar = new Path(foo, ""bar"");
    final Path wow = new Path(bar, ""wow"");
    DFSTestUtil.createFile(fs, wow, SIZE, REPL, 0);

    final BlockStoragePolicySuite suite = BlockStoragePolicySuite
        .createDefaultSuite();
    final BlockStoragePolicy warm = suite.getPolicy(""WARM"");
    final BlockStoragePolicy cold = suite.getPolicy(""COLD"");
    final BlockStoragePolicy hot = suite.getPolicy(""HOT"");

    /*
     * test: set storage policy
     */
    hdfsAdmin.setStoragePolicy(foo, warm.getName());
    hdfsAdmin.setStoragePolicy(bar, cold.getName());
    hdfsAdmin.setStoragePolicy(wow, hot.getName());

    /*
     * test: get storage policy after set
     */
    assertEquals(hdfsAdmin.getStoragePolicy(foo), warm);
    assertEquals(hdfsAdmin.getStoragePolicy(bar), cold);
    assertEquals(hdfsAdmin.getStoragePolicy(wow), hot);

    /*
     * test: unset storage policy
     */
    hdfsAdmin.unsetStoragePolicy(foo);
    hdfsAdmin.unsetStoragePolicy(bar);
    hdfsAdmin.unsetStoragePolicy(wow);

    /*
     * test: get storage policy after unset. HOT by default.
     */
    assertEquals(hdfsAdmin.getStoragePolicy(foo), hot);
    assertEquals(hdfsAdmin.getStoragePolicy(bar), hot);
    assertEquals(hdfsAdmin.getStoragePolicy(wow), hot);

    /*
     * test: get all storage policies
     */
    // Get policies via HdfsAdmin
    Set<String> policyNamesSet1 = new HashSet<>();
    for (BlockStoragePolicySpi policy : hdfsAdmin.getAllStoragePolicies()) {
      policyNamesSet1.add(policy.getName());
    }",1
"@Test
  public void testHugeFileCount() throws IOException {
    final Path parent = new Path(
        PathUtils.getTestDir(getClass()).getPath(),
        GenericTestUtils.getMethodName());
    assertTrue(dfs.mkdirs(parent));

    for (int i = 1; i <= 5; i++) {
      FSDataOutputStream out =
          dfs.create(new Path(parent, ""Folder1/"" + ""file"" + i),(short)1);
      out.close();
    }",1
"@Test
  public void testDefaultPolicy() throws Exception {
    final Configuration conf = new HdfsConfiguration();
    final ReplaceDatanodeOnFailure p = ReplaceDatanodeOnFailure.get(conf);

    final DatanodeInfo[] infos = new DatanodeInfo[5];
    final DatanodeInfo[][] datanodes = new DatanodeInfo[infos.length + 1][];
    datanodes[0] = DatanodeInfo.EMPTY_ARRAY;
    for(int i = 0; i < infos.length; ) {
      infos[i] = DFSTestUtil.getLocalDatanodeInfo(9867 + i);
      i++;
      datanodes[i] = new DatanodeInfo[i];
      System.arraycopy(infos, 0, datanodes[i], 0, datanodes[i].length);
    }",1
"@Test
  public void testFileDistributionCalculatorForException() throws Exception {
    File fsimageFile = null;
    Configuration conf = new Configuration();
    // Avoid using the same cluster dir to cause the global originalFsimage
    // file to be cleared.
    conf.set(HDFS_MINIDFS_BASEDIR, GenericTestUtils.getRandomizedTempPath());
    HashMap<String, FileStatus> files = Maps.newHashMap();

    // Create a initial fsimage file
    try (MiniDFSCluster cluster =
        new MiniDFSCluster.Builder(conf).numDataNodes(1).build()) {
      cluster.waitActive();
      DistributedFileSystem hdfs = cluster.getFileSystem();

      // Create a reasonable namespace
      Path dir = new Path(""/dir"");
      hdfs.mkdirs(dir);
      files.put(dir.toString(), pathToFileEntry(hdfs, dir.toString()));
      // Create files with byte size that can't be divided by step size,
      // the byte size for here are 3, 9, 15, 21.
      for (int i = 0; i < FILES_PER_DIR; i++) {
        Path file = new Path(dir, ""file"" + i);
        DFSTestUtil.createFile(hdfs, file, 6 * i + 3, (short) 1, 0);

        files.put(file.toString(),
            pathToFileEntry(hdfs, file.toString()));
      }",1
"@Test
  public void testWebImageViewer() throws Exception {
    WebImageViewer viewer = new WebImageViewer(
        NetUtils.createSocketAddr(""localhost:0""));
    try {
      viewer.initServer(originalFsimage.getAbsolutePath());
      int port = viewer.getPort();

      // create a WebHdfsFileSystem instance
      URI uri = new URI(""webhdfs://localhost:"" + String.valueOf(port));
      Configuration conf = new Configuration();
      WebHdfsFileSystem webhdfs = (WebHdfsFileSystem)FileSystem.get(uri, conf);

      // verify the number of directories
      FileStatus[] statuses = webhdfs.listStatus(new Path(""/""));
      assertEquals(dirCount, statuses.length);

      // verify the number of files in the directory
      statuses = webhdfs.listStatus(new Path(""/dir0""));
      assertEquals(FILES_PER_DIR, statuses.length);

      // compare a file
      FileStatus status = webhdfs.listStatus(new Path(""/dir0/file0""))[0];
      FileStatus expected = writtenFiles.get(""/dir0/file0"");
      compareFile(expected, status);

      // LISTSTATUS operation to an empty directory
      statuses = webhdfs.listStatus(new Path(""/emptydir""));
      assertEquals(0, statuses.length);

      // LISTSTATUS operation to a invalid path
      URL url = new URL(""http://localhost:"" + port +
                    ""/webhdfs/v1/invalid/?op=LISTSTATUS"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_NOT_FOUND, url);

      // LISTSTATUS operation to a invalid prefix
      url = new URL(""http://localhost:"" + port + ""/foo"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_NOT_FOUND, url);

      // Verify the Erasure Coded empty file status
      Path emptyECFilePath = new Path(""/ec/EmptyECFile.txt"");
      FileStatus actualEmptyECFileStatus =
          webhdfs.getFileStatus(new Path(emptyECFilePath.toString()));
      FileStatus expectedEmptyECFileStatus = writtenFiles.get(
          emptyECFilePath.toString());
      System.out.println(webhdfs.getFileStatus(new Path(emptyECFilePath
              .toString())));
      compareFile(expectedEmptyECFileStatus, actualEmptyECFileStatus);

      // Verify the Erasure Coded small file status
      Path smallECFilePath = new Path(""/ec/SmallECFile.txt"");
      FileStatus actualSmallECFileStatus =
          webhdfs.getFileStatus(new Path(smallECFilePath.toString()));
      FileStatus expectedSmallECFileStatus = writtenFiles.get(
          smallECFilePath.toString());
      compareFile(expectedSmallECFileStatus, actualSmallECFileStatus);

      // GETFILESTATUS operation
      status = webhdfs.getFileStatus(new Path(""/dir0/file0""));
      compareFile(expected, status);

      // GETFILESTATUS operation to a invalid path
      url = new URL(""http://localhost:"" + port +
                    ""/webhdfs/v1/invalid/?op=GETFILESTATUS"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_NOT_FOUND, url);

      // invalid operation
      url = new URL(""http://localhost:"" + port + ""/webhdfs/v1/?op=INVALID"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_BAD_REQUEST, url);

      // invalid method
      url = new URL(""http://localhost:"" + port + ""/webhdfs/v1/?op=LISTSTATUS"");
      HttpURLConnection connection = (HttpURLConnection) url.openConnection();
      connection.setRequestMethod(""POST"");
      connection.connect();
      assertEquals(HttpURLConnection.HTTP_BAD_METHOD,
          connection.getResponseCode());
    }",1
"@Test
  public void testMutativeOperationsWithAutoHaEnabled() throws Exception {
    Mockito.doReturn(STANDBY_READY_RESULT).when(mockProtocol).getServiceStatus();
    
    // Turn on auto-HA in the config
    HdfsConfiguration conf = getHAConf();
    conf.setBoolean(DFSConfigKeys.DFS_HA_AUTO_FAILOVER_ENABLED_KEY, true);
    conf.set(DFSConfigKeys.DFS_HA_FENCE_METHODS_KEY, getFencerTrueCommand());
    tool.setConf(conf);

    // Should fail without the forcemanual flag
    assertEquals(-1, runTool(""-transitionToActive"", ""nn1""));
    assertTrue(errOutput.contains(""Refusing to manually manage""));
    assertEquals(-1, runTool(""-transitionToStandby"", ""nn1""));
    assertTrue(errOutput.contains(""Refusing to manually manage""));
    assertEquals(-1, runTool(""-transitionToObserver"", ""nn1""));
    assertTrue(errOutput.contains(""Refusing to manually manage""));

    Mockito.verify(mockProtocol, Mockito.never())
      .transitionToActive(anyReqInfo());
    Mockito.verify(mockProtocol, Mockito.never())
        .transitionToStandby(anyReqInfo());
    Mockito.verify(mockProtocol, Mockito.never())
        .transitionToObserver(anyReqInfo());


    // Force flag should bypass the check and change the request source
    // for the RPC
    setupConfirmationOnSystemIn();
    assertEquals(0, runTool(""-transitionToActive"", ""-forcemanual"", ""nn1""));
    setupConfirmationOnSystemIn();
    assertEquals(0, runTool(""-transitionToStandby"", ""-forcemanual"", ""nn1""));
    setupConfirmationOnSystemIn();
    assertEquals(0, runTool(""-transitionToObserver"", ""-forcemanual"", ""nn1""));

    Mockito.verify(mockProtocol, Mockito.times(1)).transitionToActive(
        reqInfoCaptor.capture());
    Mockito.verify(mockProtocol, Mockito.times(1)).transitionToStandby(
        reqInfoCaptor.capture());
    Mockito.verify(mockProtocol, Mockito.times(1)).transitionToObserver(
        reqInfoCaptor.capture());

    // All of the RPCs should have had the ""force"" source
    for (StateChangeRequestInfo ri : reqInfoCaptor.getAllValues()) {
      assertEquals(RequestSource.REQUEST_BY_USER_FORCED, ri.getSource());
    }",1
"@Test
  public void testAllocateRecycle() throws Exception {
    final int countThreshold = 4;
    final int countLimit = 8;
    final long countResetTimePeriodMs = 200L;
    final ByteArrayManager.Impl bam = new ByteArrayManager.Impl(
        new ByteArrayManager.Conf(
            countThreshold, countLimit, countResetTimePeriodMs));
    
    final CounterMap counters = bam.getCounters();
    final ManagerMap managers = bam.getManagers();
    
    final int[] uncommonArrays = {0, 1, 2, 4, 8, 16, 32, 64}",1
"@Test
  public void testCyclicIteration() throws Exception {
    for(int n = 0; n < 5; n++) {
      checkCyclicIteration(n);
    }",1
"@Test
  public void testPollNMultiArray() {
    LOG.info(""Test pollN multi array"");

    // use addAll
    set.addAll(list);

    // poll existing elements (less than size)
    Integer[] poll = new Integer[10];
    poll = set.pollToArray(poll);
    assertEquals(10, poll.length);

    for (Integer i : poll) {
      // should be in original items
      assertTrue(list.contains(i));
      // should not be in the set anymore
      assertFalse(set.contains(i));
    }",1
"@Test
  public void testRemoveAll() {
    LOG.info(""Test remove all"");
    for (Integer i : list) {
      assertTrue(set.add(i));
    }",1
"@Test
  public void testPollAll() {
    LOG.info(""Test poll all"");
    for (Integer i : list) {
      assertTrue(set.add(i));
    }",1
"@Test
  public void testPollMulti() {
    LOG.info(""Test poll multi"");
    for (Integer i : list) {
      assertTrue(set.add(i));
    }",1
"@Test
  public void testPollNMulti() {
    LOG.info(""Test pollN multi"");

    // use addAll
    set.addAll(list);

    // poll existing elements
    List<Integer> l = set.pollN(10);
    assertEquals(10, l.size());

    for (int i = 0; i < 10; i++) {
      assertEquals(list.get(i), l.get(i));
    }",1
"@Test
  public void testRemoveMulti() {
    LOG.info(""Test remove multi"");
    for (Integer i : list) {
      assertTrue(set.add(i));
    }",1
"@Test
  public void testDivideByteRangeIntoStripes() {
    ByteBuffer assembled =
        ByteBuffer.allocate(stripesPerBlock * stripeSize);
    for (int bgSize : blockGroupSizes) {
      LocatedStripedBlock blockGroup = createDummyLocatedBlock(bgSize);
      byte[][] internalBlkBufs = createInternalBlkBuffers(bgSize);
      for (int brStart : byteRangeStartOffsets) {
        for (int brSize : byteRangeSizes) {
          if (brStart + brSize > bgSize) {
            continue;
          }",1
"@Test
  public void testByteRange() throws IOException {
    ByteRangeInputStream.URLOpener oMock = getMockURLOpener(
        new URL(""http://test""));
    ByteRangeInputStream.URLOpener rMock = getMockURLOpener(null);
    ByteRangeInputStream bris = new ByteRangeInputStreamImpl(oMock, rMock);

    bris.seek(0);

    assertEquals(""getPos wrong"", 0, bris.getPos());

    bris.read();

    assertEquals(""Initial call made incorrectly (offset check)"",
        0, bris.startPos);
    assertEquals(""getPos should return 1 after reading one byte"", 1,
        bris.getPos());
    verify(oMock, times(1)).connect(0, false);

    bris.read();

    assertEquals(""getPos should return 2 after reading two bytes"", 2,
        bris.getPos());
    // No additional connections should have been made (no seek)
    verify(oMock, times(1)).connect(0, false);

    rMock.setURL(new URL(""http://resolvedurl/""));

    bris.seek(100);
    bris.read();

    assertEquals(""Seek to 100 bytes made incorrectly (offset Check)"",
        100, bris.startPos);
    assertEquals(""getPos should return 101 after reading one byte"", 101,
        bris.getPos());
    verify(rMock, times(1)).connect(100, true);

    bris.seek(101);
    bris.read();

    // Seek to 101 should not result in another request
    verify(rMock, times(1)).connect(100, true);
    verify(rMock, times(0)).connect(101, true);

    bris.seek(2500);
    bris.read();

    assertEquals(""Seek to 2500 bytes made incorrectly (offset Check)"",
        2500, bris.startPos);

    doReturn(getMockConnection(null))
        .when(rMock).connect(anyLong(), anyBoolean());
    bris.seek(500);
    try {
      bris.read();
      fail(""Exception should be thrown when content-length is not given"");
    }",1
"@Test
  public void testPropagatedClose() throws IOException {
    ByteRangeInputStream bris =
        mock(ByteRangeInputStream.class, CALLS_REAL_METHODS);
    InputStreamAndFileLength mockStream = new InputStreamAndFileLength(1L,
        mock(InputStream.class));
    doReturn(mockStream).when(bris).openInputStream(Mockito.anyLong());
    Whitebox.setInternalState(bris, ""status"",
                              ByteRangeInputStream.StreamStatus.SEEK);

    int brisOpens = 0;
    int brisCloses = 0;
    int isCloses = 0;

    // first open, shouldn't close underlying stream
    bris.getInputStream();
    verify(bris, times(++brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // stream is open, shouldn't close underlying stream
    bris.getInputStream();
    verify(bris, times(brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // seek forces a reopen, should close underlying stream
    bris.seek(1);
    bris.getInputStream();
    verify(bris, times(++brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(++isCloses)).close();

    // verify that the underlying stream isn't closed after a seek
    // ie. the state was correctly updated
    bris.getInputStream();
    verify(bris, times(brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // seeking to same location should be a no-op
    bris.seek(1);
    bris.getInputStream();
    verify(bris, times(brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // close should of course close
    bris.close();
    verify(bris, times(++brisCloses)).close();
    verify(mockStream.in, times(++isCloses)).close();

    // it's already closed, underlying stream should not close
    bris.close();
    verify(bris, times(++brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // it's closed, don't reopen it
    boolean errored = false;
    try {
      bris.getInputStream();
    }",1
"@Test public void testRoundtrip() throws Exception {
    runRoundTrip("""");
    runRoundTrip(""<>&'\"""");
    runRoundTrip(""ab>cd<ef&ghi'\"""");
    runRoundTrip(""A string\n with no quotable chars in it!"");
    runRoundTrip(null);
    StringBuilder buffer = new StringBuilder();
    for(char ch=0; ch < 127; ++ch) {
      buffer.append(ch);
    }",1
"@Test
  public void testIdempotentResetState() throws IOException {
    DataOutputBuffer dob = new DataOutputBuffer();
    CompressionOutputStream cmpOut = codec.createOutputStream(dob);
    cmpOut.write(DATA1.getBytes(StandardCharsets.UTF_8));
    cmpOut.finish();
    cmpOut.finish();
    cmpOut.finish();
    cmpOut.resetState();
    cmpOut.resetState();
    cmpOut.finish();
    cmpOut.resetState();
    cmpOut.close();
    dob.close();

    DataInputBuffer dib = new DataInputBuffer();
    dib.reset(dob.getData(), 0, dob.getLength());
    CompressionInputStream cmpIn = codec.createInputStream(dib);
    byte[] buf = new byte[1024];
    StringBuilder result = new StringBuilder();
    int len = 0;
    while (true) {
      len = cmpIn.read(buf);
      if (len < 0) {
        break;
      }",1
"@Test
  public void testGetEmptyChunk() {
    byte[] ret = CoderUtil.getEmptyChunk(chunkSize);
    for (int i = 0; i < chunkSize; i++) {
      assertEquals(0, ret[i]);
    }",1
"@Test
  public void testMultiThreadedStatOnError() throws Exception {
    final String testInvalidFilePath = ""C:\\nonexisting_path\\nonexisting_file"";

    int numOfThreads = 10;
    ExecutorService executorService =
        Executors.newFixedThreadPool(numOfThreads);
    for (int i = 0; i < numOfThreads; i++) {
      try {
        Future<Boolean> result =
            executorService.submit(() -> doStatTest(testInvalidFilePath));
        result.get();
      }",1
"@Test
  public void testOldFormat() throws IOException {
    //Make sure we still correctly write the old format if desired.
    
    //Write the data array with old ObjectWritable API
    //which will set allowCompactArrays false.
    ObjectWritable.writeObject(out, i, i.getClass(), null);

    //Get ready to read it back
    in.reset(out.getData(), out.getLength());
    
    //Read the int[] object as written by ObjectWritable, but
    //""going around"" ObjectWritable
    @SuppressWarnings(""deprecation"")
    String className = UTF8.readString(in);
    assertEquals(""The int[] written by ObjectWritable as a non-compact array ""
        + ""was not labelled as an array of int"", 
        i.getClass().getName(), className);
    
    int length = in.readInt();
    assertEquals(""The int[] written by ObjectWritable as a non-compact array ""
        + ""was not expected length"", i.length, length);
    
    int[] readValue = new int[length];
    try {
      for (int i = 0; i < length; i++) {
        readValue[i] = (int)((Integer)ObjectWritable.readObject(in, null));
      }",1
"@Test
  public void testThrowUndefinedValueException() throws IOException {
    // Get a buffer containing a simple text array
    Text[] elements = {new Text(""zero""), new Text(""one""), new Text(""two"")}",1
"@Test
  public void testCompare() throws Exception {
    byte[][] values = new byte[][]{""abc"".getBytes(), 
                                   ""ad"".getBytes(),
                                   ""abcd"".getBytes(),
                                   """".getBytes(),
                                   ""b"".getBytes()}",1
"@Test
  public void testGetClosestOnCurrentApi() throws Exception {
    final String TEST_PREFIX = ""testGetClosestOnCurrentApi.mapfile"";
    MapFile.Writer writer = null;
    MapFile.Reader reader = null;
    try {
      writer = createWriter(TEST_PREFIX, Text.class, Text.class);
      int FIRST_KEY = 1;
      // Test keys: 11,21,31,...,91
      for (int i = FIRST_KEY; i < 100; i += 10) {      
        Text t = new Text(Integer.toString(i));
        writer.append(t, t);
      }",1
"@Test
  public void testSerializationAvailability() throws IOException {
    Configuration conf = new Configuration();
    Path path = new Path(GenericTestUtils.getTempPath(
        ""serializationAvailability""));
    // Check if any serializers aren't found.
    try {
      SequenceFile.createWriter(
          conf,
          SequenceFile.Writer.file(path),
          SequenceFile.Writer.keyClass(String.class),
          SequenceFile.Writer.valueClass(NullWritable.class));
      // Note: This may also fail someday if JavaSerialization
      // is activated by default.
      fail(""Must throw IOException for missing serializer for the Key class"");
    }",1
"@Test
  public void testSetFileAccessMethods() {
    try {
      FileSystem fs = FileSystem.getLocal(conf);
      int size = 10;
      writeData(fs, size);
      SetFile.Reader reader = createReader(fs);
      assertTrue(""testSetFileWithConstruction1 error !!!"", reader.next(new IntWritable(0)));
      // don't know why reader.get(i) return i+1
      assertEquals(""testSetFileWithConstruction2 error !!!"", new IntWritable(size/2 + 1), reader.get(new IntWritable(size/2)));      
      assertNull(""testSetFileWithConstruction3 error !!!"", reader.get(new IntWritable(size*2)));
    }",1
"@Test
  public void testCoding() throws Exception {
    String before = ""Bad \t encoding \t testcase"";
    Text text = new Text(before);
    String after = text.toString();
    assertTrue(before.equals(after));

    for (int i = 0; i < NUM_ITERATIONS; i++) {
      // generate a random string
      if (i == 0)
        before = getLongString();
      else
        before = getTestString();
    
      // test string to utf8
      ByteBuffer bb = Text.encode(before);
          
      byte[] utf8Text = bb.array();
      byte[] utf8Java = before.getBytes(StandardCharsets.UTF_8);
      assertEquals(0, WritableComparator.compareBytes(
              utf8Text, 0, bb.limit(),
              utf8Java, 0, utf8Java.length));
      // test utf8 to string
      after = Text.decode(utf8Java);
      assertTrue(before.equals(after));
    }",1
"@Test
  public void testLongOperationsSuccessful() throws Exception {
    // Test long successful operations
    // There is no entry in cache expected when the first operation starts
    testOperations(r.nextInt(), 100, 20, true, false, newCall());
  }",1
"@Test
  public void testRpcMetrics() throws Exception {
    final Server server;
    TestRpcService proxy = null;

    final int interval = 1;
    conf.setBoolean(CommonConfigurationKeys.
        RPC_METRICS_QUANTILE_ENABLE, true);
    conf.set(CommonConfigurationKeys.
        RPC_METRICS_PERCENTILES_INTERVALS_KEY, """" + interval);

    server = setupTestServer(conf, 5);
    String testUser = ""testUser"";
    UserGroupInformation anotherUser =
        UserGroupInformation.createRemoteUser(testUser);
    TestRpcService proxy2 =
        anotherUser.doAs(new PrivilegedAction<TestRpcService>() {
          public TestRpcService run() {
            try {
              return RPC.getProxy(TestRpcService.class, 0,
                  server.getListenerAddress(), conf);
            }",1
"@Test
  public void testServerAddress() throws IOException {
    Server server;

    server = setupTestServer(conf, 5);
    try {
      InetSocketAddress bindAddr = NetUtils.getConnectAddress(server);
      assertEquals(InetAddress.getLocalHost(), bindAddr.getAddress());
    }",1
"@Test
  public void testStopProxy() throws IOException {
    RPC.setProtocolEngine(conf,
        StoppedProtocol.class, StoppedRpcEngine.class);

    StoppedProtocol proxy = RPC.getProxy(StoppedProtocol.class,
        StoppedProtocol.versionID, null, conf);
    StoppedInvocationHandler invocationHandler = (StoppedInvocationHandler)
        Proxy.getInvocationHandler(proxy);
    assertEquals(0, invocationHandler.getCloseCalled());
    RPC.stopProxy(proxy);
    assertEquals(1, invocationHandler.getCloseCalled());
  }",1
"@Test
  public void testBasicLogging() {
    assertTrue(helper.record().shouldLog());

    for (int i = 0; i < 5; i++) {
      timer.advance(LOG_PERIOD / 10);
      assertFalse(helper.record().shouldLog());
    }",1
"@Test
  public void testRandomTextDataGenerator() {
    RandomTextDataGenerator rtdg = new RandomTextDataGenerator(10, 0L, 5);
    List<String> words = rtdg.getRandomWords();

    // check the size
    assertEquals(""List size mismatch"", 10, words.size());

    // check the words
    Set<String> wordsSet = new HashSet<String>(words);
    assertEquals(""List size mismatch due to duplicates"", 10, wordsSet.size());

    // check the word lengths
    for (String word : wordsSet) {
      assertEquals(""Word size mismatch"", 5, word.length());
    }",1
"@Test
  public void testWideTuple() throws Exception {
    Text emptyText = new Text(""Should be empty"");
    Writable[] values = new Writable[64];
    Arrays.fill(values,emptyText);
    values[42] = new Text(""Number 42"");
                                     
    TupleWritable tuple = new TupleWritable(values);
    tuple.setWritten(42);
    
    for (int pos=0; pos<tuple.size();pos++) {
      boolean has = tuple.has(pos);
      if (pos == 42) {
        assertTrue(has);
      }",1
"@Test
  public void testUserMRComparator() throws Exception {
    conf.setMapperClass(IdentityMapper.class);
    conf.setReducerClass(DescendingKeysReducer.class);
    conf.setOutputKeyComparatorClass(DecreasingIntComparator.class);
    
    RunningJob r_job = jc.submitJob(conf);
    while (!r_job.isComplete()) {
      Thread.sleep(1000);
    }",1
"@Test
  public void testFailAbortV1() throws Exception {
    testFailAbortInternal(1);
  }",1
"@Test
  public void testRecoveryV2() throws Exception {
    testRecoveryInternal(2, 2);
  }",1
"@Test
  public void testBadIndex() throws Exception {
    final int parts = 30;
    fs.delete(p, true);
    conf.setInt(MRJobConfig.SHUFFLE_INDEX_CACHE, 1);
    IndexCache cache = new IndexCache(conf);

    Path f = new Path(p, ""badindex"");
    FSDataOutputStream out = fs.create(f, false);
    CheckedOutputStream iout = new CheckedOutputStream(out, new CRC32());
    DataOutputStream dout = new DataOutputStream(iout);
    for (int i = 0; i < parts; ++i) {
      for (int j = 0; j < MapTask.MAP_OUTPUT_INDEX_RECORD_LENGTH / 8; ++j) {
        if (0 == (i % 3)) {
          dout.writeLong(i);
        }",1
"@Test
  public void testRemoveMap() throws Exception {
    // This test case use two thread to call getIndexInformation and 
    // removeMap concurrently, in order to construct race condition.
    // This test case may not repeatable. But on my macbook this test 
    // fails with probability of 100% on code before MAPREDUCE-2541,
    // so it is repeatable in practice.
    fs.delete(p, true);
    conf.setInt(MRJobConfig.SHUFFLE_INDEX_CACHE, 10);
    // Make a big file so removeMapThread almost surely runs faster than 
    // getInfoThread 
    final int partsPerMap = 100000;
    final int bytesPerFile = partsPerMap * 24;
    final IndexCache cache = new IndexCache(conf);

    final Path big = new Path(p, ""bigIndex"");
    final String user = 
      UserGroupInformation.getCurrentUser().getShortUserName();
    writeFile(fs, big, bytesPerFile, partsPerMap);
    
    // run multiple times
    for (int i = 0; i < 20; ++i) {
      Thread getInfoThread = new Thread() {
        @Override
        public void run() {
          try {
            cache.getIndexInformation(""bigIndex"", partsPerMap, big, user);
          }",1
"@Test
  public void testRecordSpanningMultipleSplits()
      throws IOException {
    checkRecordSpanningMultipleSplits(""recordSpanningMultipleSplits.txt"",
        10, false);
  }",1
"@Test
  public void testRecordSpanningMultipleSplitsCompressed()
      throws IOException {
    // The file is generated with bz2 block size of 100k. The split size
    // needs to be larger than that for the CompressedSplitLineReader to
    // work.
    checkRecordSpanningMultipleSplits(""recordSpanningMultipleSplits.txt.bz2"",
        200 * 1000, true);
  }",1
"@Test
  public void testRenameMapOutputForReduce() throws Exception {
    final JobConf conf = new JobConf();

    final MROutputFiles mrOutputFiles = new MROutputFiles();
    mrOutputFiles.setConf(conf);

    // make sure both dirs are distinct
    //
    conf.set(MRConfig.LOCAL_DIR, localDirs[0].toString());
    final Path mapOut = mrOutputFiles.getOutputFileForWrite(1);
    conf.set(MRConfig.LOCAL_DIR, localDirs[1].toString());
    final Path mapOutIdx = mrOutputFiles.getOutputIndexFileForWrite(1);
    Assert.assertNotEquals(""Paths must be different!"",
        mapOut.getParent(), mapOutIdx.getParent());

    // make both dirs part of LOCAL_DIR
    conf.setStrings(MRConfig.LOCAL_DIR, localDirs);

    final FileContext lfc = FileContext.getLocalFSFileContext(conf);
    lfc.create(mapOut, EnumSet.of(CREATE)).close();
    lfc.create(mapOutIdx, EnumSet.of(CREATE)).close();

    final JobId jobId = MRBuilderUtils.newJobId(12345L, 1, 2);
    final TaskId tid = MRBuilderUtils.newTaskId(jobId, 0, TaskType.MAP);
    final TaskAttemptId taid = MRBuilderUtils.newTaskAttemptId(tid, 0);

    LocalContainerLauncher.renameMapOutputForReduce(conf, taid, mrOutputFiles);
  }",1
"@Test
  public void testDuplicateDownload() throws Exception {
    JobID jobId = new JobID();
    JobConf conf = new JobConf();
    conf.setClass(""fs.mock.impl"", MockFileSystem.class, FileSystem.class);

    URI mockBase = new URI(""mock://test-nn1/"");
    when(mockfs.getUri()).thenReturn(mockBase);
    Path working = new Path(""mock://test-nn1/user/me/"");
    when(mockfs.getWorkingDirectory()).thenReturn(working);
    when(mockfs.resolvePath(any(Path.class))).thenAnswer(
        (Answer<Path>) args -> (Path) args.getArguments()[0]);

    final URI file = new URI(""mock://test-nn1/user/me/file.txt#link"");
    final Path filePath = new Path(file);
    File link = new File(""link"");

    when(mockfs.getFileStatus(any(Path.class))).thenAnswer(new Answer<FileStatus>() {
      @Override
      public FileStatus answer(InvocationOnMock args) throws Throwable {
        Path p = (Path) args.getArguments()[0];
        if (""file.txt"".equals(p.getName())) {
          return createMockTestFileStatus(filePath);
        }",1
"@Test
  public void testValueIterator() throws Exception {
    Path tmpDir = new Path(""build/test/test.reduce.task"");
    Configuration conf = new Configuration();
    for (Pair[] testCase: testCases) {
      runValueIterator(tmpDir, testCase, conf, null);
    }",1
"@Test
  public void testValueIteratorWithCompression() throws Exception {
    Path tmpDir = new Path(""build/test/test.reduce.task.compression"");
    Configuration conf = new Configuration();
    DefaultCodec codec = new DefaultCodec();
    codec.setConf(conf);
    for (Pair[] testCase: testCases) {
      runValueIterator(tmpDir, testCase, conf, codec);
    }",1
"@Test
  public void testPercentFilter() throws Exception {
    LOG.info(""Testing Percent Filter with frequency: 1000"");
    // set the filter class
    SequenceFileInputFilter.setFilterClass(job, 
                                           SequenceFileInputFilter.PercentFilter.class);
    SequenceFileInputFilter.PercentFilter.setFrequency(job, 1000);
      
    // clean input dir
    fs.delete(inDir, true);
    
    // for a variety of lengths
    for (int length = 0; length < MAX_LENGTH;
         length+= random.nextInt(MAX_LENGTH/10)+1) {
      LOG.info(""******Number of records: ""+length);
      createSequenceFile(length);
      int count = countRecords(1);
      LOG.info(""Accepted ""+count+"" records"");
      int expectedCount = length/1000;
      if (expectedCount*1000!=length)
        expectedCount++;
      assertThat(count).isEqualTo(expectedCount);
    }",1
"@Test
  public void testFormat() throws Exception {
    JobConf job = new JobConf(conf);
    FileSystem fs = FileSystem.getLocal(conf);
    Path dir = new Path(System.getProperty(""test.build.data"",""."") + ""/mapred"");
    Path file = new Path(dir, ""test.seq"");
    
    Reporter reporter = Reporter.NULL;
    
    int seed = new Random().nextInt();
    //LOG.info(""seed = ""+seed);
    Random random = new Random(seed);

    fs.delete(dir, true);

    FileInputFormat.setInputPaths(job, dir);

    // for a variety of lengths
    for (int length = 0; length < MAX_LENGTH;
         length+= random.nextInt(MAX_LENGTH/10)+1) {

      //LOG.info(""creating; entries = "" + length);

      // create a file with length entries
      SequenceFile.Writer writer =
        SequenceFile.createWriter(fs, conf, file,
                                  IntWritable.class, BytesWritable.class);
      try {
        for (int i = 0; i < length; i++) {
          IntWritable key = new IntWritable(i);
          byte[] data = new byte[random.nextInt(10)];
          random.nextBytes(data);
          BytesWritable value = new BytesWritable(data);
          writer.append(key, value);
        }",1
"@Test
  public void testStatusUpdateDoesNotExitInUberMode() throws Exception {
    setupTest(true);

    task.statusUpdate(umbilical);
  }",1
"@Test
  public void testReduceTaskStatusStartAndFinishTimes() {
    checkTaskStatues(false);
  }",1
"@Test
  public void testFormat() throws Exception {
    JobConf job = new JobConf();
    job.set(JobContext.TASK_ATTEMPT_ID, attempt);
    FileOutputFormat.setOutputPath(job, workDir.getParent().getParent());
    FileOutputFormat.setWorkOutputPath(job, workDir);
    FileSystem fs = workDir.getFileSystem(job);
    if (!fs.mkdirs(workDir)) {
      fail(""Failed to create output directory"");
    }",1
"@Test
  public void testResourceRequestLocalityInvalid() throws Exception {
    try {
      verifyResourceRequestLocality(""rack/node1"", null,
          new ResourceRequest[]{}",1
"@Test
  public void testCheckpointCreateDirect() throws Exception {
    checkpointCreate(ByteBuffer.allocateDirect(BUFSIZE));
  }",1
"@Test
  public void testDetermineCacheVisibilities() throws IOException {
    fs.setPermission(TEST_VISIBILITY_PARENT_DIR,
        new FsPermission((short)00777));
    fs.setPermission(TEST_VISIBILITY_CHILD_DIR,
        new FsPermission((short)00777));
    fs.setWorkingDirectory(TEST_VISIBILITY_CHILD_DIR);
    Job job = Job.getInstance(conf);
    Path relativePath = new Path(SECOND_CACHE_FILE);
    Path wildcardPath = new Path(""*"");
    Map<URI, FileStatus> statCache = new HashMap<>();
    Configuration jobConf;

    job.addCacheFile(firstCacheFile.toUri());
    job.addCacheFile(relativePath.toUri());
    jobConf = job.getConfiguration();

    // skip test if scratch dir is not PUBLIC
    assumeTrue(TEST_VISIBILITY_PARENT_DIR + "" is not public"",
        ClientDistributedCacheManager.isPublic(
            jobConf, TEST_VISIBILITY_PARENT_DIR.toUri(), statCache));

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file paths were not found to be publicly visible ""
        + ""even though the full path is publicly accessible"",
        ""true,true"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, null, firstCacheFile, relativePath);

    job = Job.getInstance(conf);
    job.addCacheFile(wildcardPath.toUri());
    jobConf = job.getConfiguration();
    statCache.clear();

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file path was not found to be publicly visible ""
        + ""even though the full path is publicly accessible"",
        ""true"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, null, wildcardPath.getParent());

    Path qualifiedParent = fs.makeQualified(TEST_VISIBILITY_PARENT_DIR);
    fs.setPermission(TEST_VISIBILITY_PARENT_DIR,
        new FsPermission((short)00700));
    job = Job.getInstance(conf);
    job.addCacheFile(firstCacheFile.toUri());
    job.addCacheFile(relativePath.toUri());
    jobConf = job.getConfiguration();
    statCache.clear();

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file paths were found to be publicly visible ""
        + ""even though the parent directory is not publicly accessible"",
        ""false,false"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, qualifiedParent,
        firstCacheFile, relativePath);

    job = Job.getInstance(conf);
    job.addCacheFile(wildcardPath.toUri());
    jobConf = job.getConfiguration();
    statCache.clear();

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file path was found to be publicly visible ""
        + ""even though the parent directory is not publicly accessible"",
        ""false"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, qualifiedParent, wildcardPath.getParent());
  }",1
"@Test
  public void testListLocatedStatus() throws Exception {
    Configuration conf = getConfiguration();
    conf.setBoolean(""fs.test.impl.disable.cache"", false);
    conf.setInt(FileInputFormat.LIST_STATUS_NUM_THREADS, numThreads);
    conf.set(org.apache.hadoop.mapreduce.lib.input.FileInputFormat.INPUT_DIR,
        ""test:///a1/a2"");
    MockFileSystem mockFs =
        (MockFileSystem) new Path(""test:///"").getFileSystem(conf);
    Assert.assertEquals(""listLocatedStatus already called"",
        0, mockFs.numListLocatedStatusCalls);
    JobConf job = new JobConf(conf);
    TextInputFormat fileInputFormat = new TextInputFormat();
    fileInputFormat.configure(job);
    InputSplit[] splits = fileInputFormat.getSplits(job, 1);
    Assert.assertEquals(""Input splits are not correct"", 2, splits.length);
    Assert.assertEquals(""listLocatedStatuss calls"",
        1, mockFs.numListLocatedStatusCalls);
    FileSystem.closeAll();
  }",1
"@Test
  public void testListStatusNestedRecursive() throws IOException {
    Configuration conf = new Configuration();
    conf.setInt(FileInputFormat.LIST_STATUS_NUM_THREADS, numThreads);

    List<Path> expectedPaths = org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat
        .configureTestNestedRecursive(conf, localFs);
    JobConf jobConf = new JobConf(conf);
    TextInputFormat fif = new TextInputFormat();
    fif.configure(jobConf);
    FileStatus[] statuses = fif.listStatus(jobConf);

    org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat
        .verifyFileStatuses(expectedPaths, Lists.newArrayList(statuses),
            localFs);
  }",1
"@Test
  public void testMultipleClose() throws IOException {
    URL testFileUrl = getClass().getClassLoader().
        getResource(""recordSpanningMultipleSplits.txt.bz2"");
    assertNotNull(""Cannot find recordSpanningMultipleSplits.txt.bz2"",
        testFileUrl);
    File testFile = new File(testFileUrl.getFile());
    Path testFilePath = new Path(testFile.getAbsolutePath());
    long testFileSize = testFile.length();
    Configuration conf = new Configuration();
    conf.setInt(org.apache.hadoop.mapreduce.lib.input.
        LineRecordReader.MAX_LINE_LENGTH, Integer.MAX_VALUE);
    FileSplit split = new FileSplit(testFilePath, 0, testFileSize,
        (String[])null);

    LineRecordReader reader = new LineRecordReader(conf, split);
    LongWritable key = new LongWritable();
    Text value = new Text();
    //noinspection StatementWithEmptyBody
    while (reader.next(key, value)) ;
    reader.close();
    reader.close();

    BZip2Codec codec = new BZip2Codec();
    codec.setConf(conf);
    Set<Decompressor> decompressors = new HashSet<Decompressor>();
    for (int i = 0; i < 10; ++i) {
      decompressors.add(CodecPool.getDecompressor(codec));
    }",1
"@Test
  public void testUncompressedInputWithLargeSplitSize() throws Exception {
    Configuration conf = new Configuration();
    // single char delimiter
    String inputData = ""abcde +fghij+ klmno+pqrst+uvwxyz"";
    Path inputFile = createInputFile(conf, inputData);
    conf.set(""textinputformat.record.delimiter"", ""+"");
    // split size over max value of integer
    long longSplitSize = (long)Integer.MAX_VALUE + 1;
    for (int bufferSize = 1; bufferSize <= inputData.length(); bufferSize++) {
      conf.setInt(""io.file.buffer.size"", bufferSize);
      testLargeSplitRecordForFile(conf, longSplitSize, inputData.length(),
          inputFile);
    }",1
"@Test
  public void testUncompressedInputContainingCRLF() throws Exception {
    Configuration conf = new Configuration();
    String inputData = ""a\r\nb\rc\nd\r\n"";
    Path inputFile = createInputFile(conf, inputData);
    for(int bufferSize = 1; bufferSize <= inputData.length(); bufferSize++) {
      for(int splitSize = 1; splitSize < inputData.length(); splitSize++) {
        conf.setInt(""io.file.buffer.size"", bufferSize);
        testSplitRecordsForFile(conf, splitSize, inputData.length(), inputFile);
      }",1
"@Test
  public void testUncompressedInputCustomDelimiterPosValue()
      throws Exception {
    Configuration conf = new Configuration();
    conf.setInt(""io.file.buffer.size"", 10);
    conf.setInt(org.apache.hadoop.mapreduce.lib.input.
        LineRecordReader.MAX_LINE_LENGTH, Integer.MAX_VALUE);
    String inputData = ""abcdefghij++kl++mno"";
    Path inputFile = createInputFile(conf, inputData);
    String delimiter = ""++"";
    byte[] recordDelimiterBytes = delimiter.getBytes(StandardCharsets.UTF_8);
    // the first split must contain two records to make sure that it also pulls
    // in the record from the 2nd split
    int splitLength = 15;
    FileSplit split = new FileSplit(inputFile, 0, splitLength, (String[]) null);
    LineRecordReader reader = new LineRecordReader(conf, split,
        recordDelimiterBytes);
    LongWritable key = new LongWritable();
    Text value = new Text();
    // Get first record: ""abcdefghij""
    assertTrue(""Expected record got nothing"", reader.next(key, value));
    assertEquals(""Wrong length for record value"", 10, value.getLength());
    // Position should be 12 right after ""abcdefghij++""
    assertEquals(""Wrong position after record read"", 12, reader.getPos());
    // Get second record: ""kl""
    assertTrue(""Expected record got nothing"", reader.next(key, value));
    assertEquals(""Wrong length for record value"", 2, value.getLength());
    // Position should be 16 right after ""abcdefghij++kl++""
    assertEquals(""Wrong position after record read"", 16, reader.getPos());
    // Get third record: ""mno""
    assertTrue(""Expected record got nothing"", reader.next(key, value));
    assertEquals(""Wrong length for record value"", 3, value.getLength());
    // Position should be 19 right after ""abcdefghij++kl++mno""
    assertEquals(""Wrong position after record read"", 19, reader.getPos());
    assertFalse(reader.next(key, value));
    assertEquals(""Wrong position after record read"", 19, reader.getPos());
    reader.close();
    // No record is in the second split because the second split will drop
    // the first record, which was already reported by the first split.
    split = new FileSplit(inputFile, splitLength,
        inputData.length() - splitLength, (String[]) null);
    reader = new LineRecordReader(conf, split, recordDelimiterBytes);
    // The position should be 19 right after ""abcdefghij++kl++mno"" and should
    // not change
    assertEquals(""Wrong position after record read"", 19, reader.getPos());
    assertFalse(""Unexpected record returned"", reader.next(key, value));
    assertEquals(""Wrong position after record read"", 19, reader.getPos());
    reader.close();

    // multi char delimiter with starting part of the delimiter in the data
    inputData = ""abcd+efgh++ijk++mno"";
    inputFile = createInputFile(conf, inputData);
    splitLength = 5;
    split = new FileSplit(inputFile, 0, splitLength, (String[]) null);
    reader = new LineRecordReader(conf, split, recordDelimiterBytes);
    // Get first record: ""abcd+efgh""
    assertTrue(""Expected record got nothing"", reader.next(key, value));
    assertEquals(""Wrong position after record read"", 11, reader.getPos());
    assertEquals(""Wrong length for record value"", 9, value.getLength());
    // should have jumped over the delimiter, no record
    assertFalse(""Unexpected record returned"", reader.next(key, value));
    assertEquals(""Wrong position after record read"", 11, reader.getPos());
    reader.close();
    // next split: check for duplicate or dropped records
    split = new FileSplit(inputFile, splitLength,
        inputData.length() - splitLength, (String[]) null);
    reader = new LineRecordReader(conf, split, recordDelimiterBytes);
    // Get second record: ""ijk"" first in this split
    assertTrue(""Expected record got nothing"", reader.next(key, value));
    assertEquals(""Wrong position after record read"", 16, reader.getPos());
    assertEquals(""Wrong length for record value"", 3, value.getLength());
    // Get third record: ""mno"" second in this split
    assertTrue(""Expected record got nothing"", reader.next(key, value));
    assertEquals(""Wrong position after record read"", 19, reader.getPos());
    assertEquals(""Wrong length for record value"", 3, value.getLength());
    // should be at the end of the input
    assertFalse(reader.next(key, value));
    assertEquals(""Wrong position after record read"", 19, reader.getPos());
    reader.close();

    inputData = ""abcd|efgh|+|ij|kl|+|mno|pqr"";
    inputFile = createInputFile(conf, inputData);
    delimiter = ""|+|"";
    recordDelimiterBytes = delimiter.getBytes(StandardCharsets.UTF_8);
    // walking over the buffer and split sizes checks for proper processing
    // of the ambiguous bytes of the delimiter
    for (int bufferSize = 1; bufferSize <= inputData.length(); bufferSize++) {
      for (int splitSize = 1; splitSize < inputData.length(); splitSize++) {
        conf.setInt(""io.file.buffer.size"", bufferSize);
        split = new FileSplit(inputFile, 0, bufferSize, (String[]) null);
        reader = new LineRecordReader(conf, split, recordDelimiterBytes);
        // Get first record: ""abcd|efgh"" always possible
        assertTrue(""Expected record got nothing"", reader.next(key, value));
        assertThat(value.toString()).isEqualTo(""abcd|efgh"");
        assertEquals(""Wrong position after record read"", 9, value.getLength());
        // Position should be 12 right after ""|+|""
        int recordPos = 12;
        assertEquals(""Wrong position after record read"", recordPos,
            reader.getPos());
        // get the next record: ""ij|kl"" if the split/buffer allows it
        if (reader.next(key, value)) {
          // check the record info: ""ij|kl""
          assertThat(value.toString()).isEqualTo(""ij|kl"");
          // Position should be 20 right after ""|+|""
          recordPos = 20;
          assertEquals(""Wrong position after record read"", recordPos,
              reader.getPos());
        }",1
"@Test
  public void testRecoveryV1() throws Exception {
    testRecoveryInternal(1, 1);
  }",1
"@Test
  public void testCountersIncrement() {
    Counters fCounters = new Counters();
    Counter fCounter = fCounters.findCounter(FRAMEWORK_COUNTER);
    fCounter.setValue(100);
    Counter gCounter = fCounters.findCounter(""test"", ""foo"");
    gCounter.setValue(200);

    Counters counters = new Counters();
    counters.incrAllCounters(fCounters);
    Counter counter;
    for (CounterGroup cg : fCounters) {
      CounterGroup group = counters.getGroup(cg.getName());
      if (group.getName().equals(""test"")) {
        counter = counters.findCounter(""test"", ""foo"");
        assertEquals(200, counter.getValue());
      }",1
"@Test
  public void testHashCode() {
    TaskType[] types = TaskType.values();

    for (int i = 0; i < types.length; i++) {
      JobID jobId = new JobID(""1234"" + i, i);
      TaskID taskId1 = new TaskID(jobId, types[i], i);
      TaskID taskId2 = new TaskID(jobId, types[i], i);

      assertTrue(""The hashcode() method gave unequal hash codes for two equal ""
          + ""task IDs"", taskId1.hashCode() == taskId2.hashCode());
    }",1
"@Test
  public void testCommitWindow() throws Exception {
    Configuration conf = new Configuration();
    conf.set(MRJobConfig.MR_AM_STAGING_DIR, stagingDir);
    AsyncDispatcher dispatcher = new AsyncDispatcher();
    dispatcher.init(conf);
    dispatcher.start();

    TestingJobEventHandler jeh = new TestingJobEventHandler();
    dispatcher.register(JobEventType.class, jeh);

    SystemClock clock = SystemClock.getInstance();
    AppContext appContext = mock(AppContext.class);
    ApplicationAttemptId attemptid = ApplicationAttemptId.fromString(
        ""appattempt_1234567890000_0001_0"");
    when(appContext.getApplicationID()).thenReturn(attemptid.getApplicationId());
    when(appContext.getApplicationAttemptId()).thenReturn(attemptid);
    when(appContext.getEventHandler()).thenReturn(
        dispatcher.getEventHandler());
    when(appContext.getClock()).thenReturn(clock);
    OutputCommitter committer = mock(OutputCommitter.class);
    TestingRMHeartbeatHandler rmhh =
        new TestingRMHeartbeatHandler();

    CommitterEventHandler ceh = new CommitterEventHandler(appContext,
        committer, rmhh);
    ceh.init(conf);
    ceh.start();

    // verify trying to commit when RM heartbeats are stale does not commit
    ceh.handle(new CommitterJobCommitEvent(null, null));
    long timeToWaitMs = 5000;
    while (rmhh.getNumCallbacks() != 1 && timeToWaitMs > 0) {
      Thread.sleep(10);
      timeToWaitMs -= 10;
    }",1
"@Test
  public void testJobNotCompletedWhenAllReducersAreFinished()
      throws Exception {
    testJobCompletionWhenReducersAreFinished(false);
  }",1
"@Test
  public void testReducerMemoryRequestWithoutUnits() {
    Clock clock = SystemClock.getInstance();
    for (String memoryResourceName : ImmutableList.of(
        MRJobConfig.RESOURCE_TYPE_NAME_MEMORY,
        MRJobConfig.RESOURCE_TYPE_ALTERNATIVE_NAME_MEMORY)) {
      EventHandler eventHandler = mock(EventHandler.class);
      JobConf jobConf = new JobConf();
      jobConf.setInt(MRJobConfig.REDUCE_RESOURCE_TYPE_PREFIX +
          memoryResourceName, 2048);
      TaskAttemptImpl taImpl =
          createReduceTaskAttemptImplForTest(eventHandler, clock, jobConf);
      long memorySize =
          getResourceInfoFromContainerRequest(taImpl, eventHandler).
          getMemorySize();
      assertEquals(2048, memorySize);
    }",1
"@Test
  public void testConcurrentTaskLimitsDisabledIfSmaller() throws Exception {
    final int MAP_COUNT = 1;
    final int REDUCE_COUNT = 1;
    final int MAP_LIMIT = 1;
    final int REDUCE_LIMIT = 1;
    Configuration conf = new Configuration();
    conf.setInt(MRJobConfig.JOB_RUNNING_MAP_LIMIT, MAP_LIMIT);
    conf.setInt(MRJobConfig.JOB_RUNNING_REDUCE_LIMIT, REDUCE_LIMIT);
    conf.setFloat(MRJobConfig.COMPLETED_MAPS_FOR_REDUCE_SLOWSTART, 0.0f);
    ApplicationId appId = ApplicationId.newInstance(1, 1);
    ApplicationAttemptId appAttemptId =
        ApplicationAttemptId.newInstance(appId, 1);
    JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
    Job mockJob = mock(Job.class);
    when(mockJob.getReport()).thenReturn(
        MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", JobState.RUNNING, 0,
            0, 0, 0, 0, 0, 0, ""jobfile"", null, false, """"));
    when(mockJob.getTotalMaps()).thenReturn(MAP_COUNT);
    when(mockJob.getTotalReduces()).thenReturn(REDUCE_COUNT);

    final MockScheduler mockScheduler = new MockScheduler(appAttemptId);
    MyContainerAllocator allocator =
        new MyContainerAllocator(null, conf, appAttemptId, mockJob,
            SystemClock.getInstance()) {
          @Override
          protected void register() {
          }",1
"@Test
  public void testExcludeSchedReducesFromHeadroom() throws Exception {
    LOG.info(""Running testExcludeSchedReducesFromHeadroom"");
    Configuration conf = new Configuration();
    conf.setInt(MRJobConfig.MR_JOB_REDUCER_UNCONDITIONAL_PREEMPT_DELAY_SEC, -1);
    MyResourceManager rm = new MyResourceManager(conf);
    rm.start();

    // Submit the application
    RMApp app = MockRMAppSubmitter.submitWithMemory(1024, rm);
    rm.drainEvents();

    MockNM amNodeManager = rm.registerNode(""amNM:1234"", 1260);
    amNodeManager.nodeHeartbeat(true);
    rm.drainEvents();

    ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()
        .getAppAttemptId();
    rm.sendAMLaunched(appAttemptId);
    rm.drainEvents();

    JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
    Job mockJob = mock(Job.class);
    when(mockJob.getReport()).thenReturn(
        MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", JobState.RUNNING, 0,
            0, 0, 0, 0, 0, 0, ""jobfile"", null, false, """"));
    Task mockTask = mock(Task.class);
    TaskAttempt mockTaskAttempt = mock(TaskAttempt.class);
    when(mockJob.getTask((TaskId)any())).thenReturn(mockTask);
    when(mockTask.getAttempt((TaskAttemptId)any())).thenReturn(mockTaskAttempt);
    when(mockTaskAttempt.getProgress()).thenReturn(0.01f);
    MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,
        appAttemptId, mockJob);

    MockNM nodeManager = rm.registerNode(""h1:1234"", 4096);
    rm.drainEvents();
    // Register nodes to RM.
    MockNM nodeManager2 = rm.registerNode(""h2:1234"", 1024);
    rm.drainEvents();

    // Request 2 maps and 1 reducer(sone on nodes which are not registered).
    ContainerRequestEvent event1 =
            ContainerRequestCreator.createRequest(jobId, 1,
                    Resource.newInstance(1024, 1),
                    new String[]{""h1""}",1
"@Test
  public void testReportedAppProgressWithOnlyMaps() throws Exception {

    LOG.info(""Running testReportedAppProgressWithOnlyMaps"");

    Configuration conf = new Configuration();
    final MyResourceManager rm = new MyResourceManager(conf);
    rm.start();
    DrainDispatcher rmDispatcher = (DrainDispatcher) rm.getRMContext()
        .getDispatcher();

    // Submit the application
    RMApp rmApp = MockRMAppSubmitter.submitWithMemory(1024, rm);
    rm.drainEvents();

    MockNM amNodeManager = rm.registerNode(""amNM:1234"", 11264);
    amNodeManager.nodeHeartbeat(true);
    rm.drainEvents();

    final ApplicationAttemptId appAttemptId = rmApp.getCurrentAppAttempt()
        .getAppAttemptId();
    rm.sendAMLaunched(appAttemptId);
    rm.drainEvents();

    MRApp mrApp = new MRApp(appAttemptId, ContainerId.newContainerId(
      appAttemptId, 0), 10, 0, false, this.getClass().getName(), true, 1) {
      @Override
        protected Dispatcher createDispatcher() {
          return new DrainDispatcher();
        }",1
"@Test
  public void testSimple() throws Exception {

    LOG.info(""Running testSimple"");

    Configuration conf = new Configuration();
    MyResourceManager rm = new MyResourceManager(conf);
    rm.start();

    // Submit the application
    RMApp app = MockRMAppSubmitter.submitWithMemory(1024, rm);
    rm.drainEvents();

    MockNM amNodeManager = rm.registerNode(""amNM:1234"", 2048);
    amNodeManager.nodeHeartbeat(true);
    rm.drainEvents();

    ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()
        .getAppAttemptId();
    rm.sendAMLaunched(appAttemptId);
    rm.drainEvents();

    JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
    Job mockJob = mock(Job.class);
    when(mockJob.getReport()).thenReturn(
        MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", JobState.RUNNING, 0,
            0, 0, 0, 0, 0, 0, ""jobfile"", null, false, """"));
    MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,
        appAttemptId, mockJob);

    // add resources to scheduler
    MockNM nodeManager1 = rm.registerNode(""h1:1234"", 10240);
    MockNM nodeManager2 = rm.registerNode(""h2:1234"", 10240);
    MockNM nodeManager3 = rm.registerNode(""h3:1234"", 10240);
    rm.drainEvents();

    // create the container request
    ContainerRequestEvent event1 = ContainerRequestCreator.createRequest(jobId,
        1, Resource.newInstance(1024, 1), new String[] {""h1""}",1
"@Test
  public void testUpdateCollectorInfo() throws Exception {
    LOG.info(""Running testUpdateCollectorInfo"");
    Configuration conf = new Configuration();
    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);
    conf.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION, 2.0f);
    ApplicationId appId = ApplicationId.newInstance(1, 1);
    ApplicationAttemptId attemptId = ApplicationAttemptId.newInstance(appId, 1);
    JobId jobId = MRBuilderUtils.newJobId(appId, 0);
    Job mockJob = mock(Job.class);
    when(mockJob.getReport()).thenReturn(
        MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", JobState.RUNNING, 0,
            0, 0, 0, 0, 0, 0, ""jobfile"", null, false, """"));
    String localAddr = ""localhost:1234"";
    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();

    // Generate a timeline delegation token.
    TimelineDelegationTokenIdentifier ident =
        new TimelineDelegationTokenIdentifier(new Text(ugi.getUserName()),
        new Text(""renewer""), null);
    ident.setSequenceNumber(1);
    Token<TimelineDelegationTokenIdentifier> collectorToken =
        new Token<TimelineDelegationTokenIdentifier>(ident.getBytes(),
        new byte[0], TimelineDelegationTokenIdentifier.KIND_NAME,
        new Text(localAddr));
    org.apache.hadoop.yarn.api.records.Token token =
        org.apache.hadoop.yarn.api.records.Token.newInstance(
            collectorToken.getIdentifier(), collectorToken.getKind().toString(),
            collectorToken.getPassword(),
            collectorToken.getService().toString());
    CollectorInfo collectorInfo = CollectorInfo.newInstance(localAddr, token);
    // Mock scheduler to server Allocate request.
    final MockSchedulerForTimelineCollector mockScheduler =
        new MockSchedulerForTimelineCollector(collectorInfo);
    MyContainerAllocator allocator =
        new MyContainerAllocator(null, conf, attemptId, mockJob,
            SystemClock.getInstance()) {
          @Override
          protected void register() {
          }",1
"@Test
  public void testUpdatedNodes() throws Exception {
    Configuration conf = new Configuration();
    MyResourceManager rm = new MyResourceManager(conf);
    rm.start();

    // Submit the application
    RMApp app = MockRMAppSubmitter.submitWithMemory(1024, rm);
    rm.drainEvents();
    MockNM amNodeManager = rm.registerNode(""amNM:1234"", 2048);
    amNodeManager.nodeHeartbeat(true);
    rm.drainEvents();

    ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt()
        .getAppAttemptId();
    rm.sendAMLaunched(appAttemptId);
    rm.drainEvents();

    JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0);
    Job mockJob = mock(Job.class);
    MyContainerAllocator allocator = new MyContainerAllocator(rm, conf,
        appAttemptId, mockJob);

    // add resources to scheduler
    MockNM nm1 = rm.registerNode(""h1:1234"", 10240);
    MockNM nm2 = rm.registerNode(""h2:1234"", 10240);
    rm.drainEvents();

    // create the map container request
    ContainerRequestEvent event =
            ContainerRequestCreator.createRequest(jobId, 1,
                    Resource.newInstance(1024, 1),
                    new String[] {""h1""}",1
"@Test
  public void testMRWebAppRedirection() throws Exception {

    String[] schemePrefix =
        { WebAppUtils.HTTP_PREFIX, WebAppUtils.HTTPS_PREFIX }",1
"@Test
  public void testTokenStore() throws IOException {
    testTokenStore(testDir.getAbsoluteFile().toURI().toString());
  }",1
"@Test
  public void testJobCacheLimitLargerThanMax() throws Exception {
    HistoryFileManager historyManager = mock(HistoryFileManager.class);
    JobHistory jobHistory = spy(new JobHistory());
    doReturn(historyManager).when(jobHistory).createHistoryFileManager();

    Configuration conf = new Configuration();
    // Set the cache threshold to 50 tasks
    conf.setInt(JHAdminConfig.MR_HISTORY_LOADED_TASKS_CACHE_SIZE, 500);
    jobHistory.init(conf);
    jobHistory.start();

    CachedHistoryStorage storage = spy((CachedHistoryStorage) jobHistory
        .getHistoryStorage());

    assertTrue(storage.getUseLoadedTasksCache());
    assertThat(storage.getLoadedTasksCacheSize()).isEqualTo(500);

    // Create a bunch of large jobs (>> 50 tasks)
    Job[] lgJobs = new Job[10];
    JobId[] lgJobIds = new JobId[10];
    for (int i = 0; i < lgJobs.length; i++) {
      lgJobs[i] = mock(Job.class);
      lgJobIds[i] = mock(JobId.class);
      when(lgJobs[i].getID()).thenReturn(lgJobIds[i]);
      when(lgJobs[i].getTotalMaps()).thenReturn(700);
      when(lgJobs[i].getTotalReduces()).thenReturn(50);
    }",1
"@Test
  public void testRefreshLoadedJobCache() throws Exception {
    HistoryFileManager historyManager = mock(HistoryFileManager.class);
    jobHistory = spy(new JobHistory());
    doReturn(historyManager).when(jobHistory).createHistoryFileManager();

    Configuration conf = new Configuration();
    // Set the cache size to 2
    conf.setInt(JHAdminConfig.MR_HISTORY_LOADED_JOB_CACHE_SIZE, 2);
    jobHistory.init(conf);
    jobHistory.start();

    CachedHistoryStorage storage = spy((CachedHistoryStorage) jobHistory
        .getHistoryStorage());

    assertFalse(storage.getUseLoadedTasksCache());

    Job[] jobs = new Job[3];
    JobId[] jobIds = new JobId[3];

    for (int i = 0; i < 3; i++) {
      jobs[i] = mock(Job.class);
      jobIds[i] = mock(JobId.class);
      when(jobs[i].getID()).thenReturn(jobIds[i]);
    }",1
"@Test
  public void testPurgeOldMetrics() throws Exception {
    // create test source with a single metric counter of value 1
    PurgableSource source = new PurgableSource();
    MetricsSourceBuilder sb = MetricsAnnotations.newSourceBuilder(source);
    final MetricsSource s = sb.build();

    List<MetricsTag> injectedTags = new ArrayList<MetricsTag>();
    MetricsSourceAdapter sa = new MetricsSourceAdapter(
        ""tst"", ""tst"", ""testdesc"", s, injectedTags, null, null, 1, false);

    MBeanInfo info = sa.getMBeanInfo();
    boolean sawIt = false;
    for (MBeanAttributeInfo mBeanAttributeInfo : info.getAttributes()) {
      sawIt |= mBeanAttributeInfo.getName().equals(source.lastKeyName);
    }",1
"@Test public void testCommon() {
    MetricsVisitor visitor = mock(MetricsVisitor.class);
    MetricsRegistry registry = new MetricsRegistry(""test"");
    List<AbstractMetric> metrics = MetricsLists.builder(""test"")
        .addCounter(info(""c1"", ""int counter""), 1)
        .addCounter(info(""c2"", ""long counter""), 2L)
        .addGauge(info(""g1"", ""int gauge""), 5)
        .addGauge(info(""g2"", ""long gauge""), 6L)
        .addGauge(info(""g3"", ""float gauge""), 7f)
        .addGauge(info(""g4"", ""double gauge""), 8d)
        .metrics();

    for (AbstractMetric metric : metrics) {
      metric.visit(visitor);
    }",1
"@Test public void testClear() {
    final SinkQueue<Integer> q = new SinkQueue<Integer>(128);
    for (int i = 0; i < q.capacity() + 97; ++i) {
      q.enqueue(i);
    }",1
"@Test public void testInfoOverflow() {
    MetricsInfo i0 = info(""m0"", ""m desc"");
    for (int i = 0; i < MAX_INFO_NAMES + 1; ++i) {
      info(""m""+ i, ""m desc"");
      if (i < MAX_INFO_NAMES) {
        assertSame(""m0 is still there"", i0, info(""m0"", ""m desc""));
      }",1
"@Test public void testTagOverflow() {
    MetricsTag t0 = tag(""t0"", ""t desc"", ""t value"");
    for (int i = 0; i < MAX_TAG_NAMES + 1; ++i) {
      tag(""t""+ i, ""t desc"", ""t value"");
      if (i < MAX_TAG_NAMES) {
        assertSame(""t0 still there"", t0, tag(""t0"", ""t desc"", ""t value""));
      }",1
"@Test
  public void testQuantileError() throws IOException {
    final int count = 100000;
    Random rnd = new Random(0xDEADDEAD);
    int[] values = new int[count];
    for (int i = 0; i < count; i++) {
      values[i] = i + 1;
    }",1
"@Test
  public void testIsLocalAddress() throws Exception {
    // Test - local host is local address
    assertTrue(NetUtils.isLocalAddress(InetAddress.getLocalHost()));
    
    // Test - all addresses bound network interface is local address
    Enumeration<NetworkInterface> interfaces = NetworkInterface
        .getNetworkInterfaces();
    if (interfaces != null) { // Iterate through all network interfaces
      while (interfaces.hasMoreElements()) {
        NetworkInterface i = interfaces.nextElement();
        Enumeration<InetAddress> addrs = i.getInetAddresses();
        if (addrs == null) {
          continue;
        }",1
"@Test
  public void testChooseRandomInclude3() {
    String scope = ""/d1"";
    Map<Node, Integer> frequency = pickNodesAtRandom(200, scope, null);
    LOG.info(""No node is excluded."");
    for (int i = 0; i < 5; ++i) {
      // all nodes should be more than zero
      assertTrue(dataNodes[i] + "" should have been chosen."",
          frequency.get(dataNodes[i]) > 0);
    }",1
"@Test
  public void testRemove() throws Exception {
    // this cluster topology is:
    // /d1/r1, /d1/r2, /d2/r3, /d3/r1, /d3/r2, /d4/r1
    // so root """" has four children
    assertEquals(4, cluster.clusterMap.getNumOfChildren());
    for(int i=0; i<dataNodes.length; i++) {
      cluster.remove(dataNodes[i]);
    }",1
"@Test
  public void testChooseRandomExcludedNode() {
    String scope = ""~"" + NodeBase.getPath(dataNodes[0]);
    Map<Node, Integer> frequency = pickNodesAtRandom(100, scope);

    for (Node key : dataNodes) {
      // all nodes except the first should be more than zero
      assertTrue(frequency.get(key) > 0 || key == dataNodes[0]);
    }",1
"@Test
  public void testNegativeLookup() throws Exception {
    ServiceRecord record = getMarshal().fromBytes(""somepath"",
        CONTAINER_RECORD.getBytes());
    getRegistryDNS().register(
        ""/registry/users/root/services/org-apache-slider/test1/components/""
            + ""ctr-e50-1451931954322-0016-01-000002"",
        record);

    // start assessing whether correct records are available
    Name name = Name.fromString(""missing.dev.test."");
    Record question = Record.newRecord(name, Type.A, DClass.IN);
    Message query = Message.newQuery(question);

    byte[] responseBytes = getRegistryDNS().generateReply(query, null);
    Message response = new Message(responseBytes);
    assertEquals(""not successful"", Rcode.NXDOMAIN, response.getRcode());
    assertNotNull(""Null response"", response);
    assertEquals(""Questions do not match"", query.getQuestion(),
        response.getQuestion());
    List<Record> sectionArray = response.getSection(Section.AUTHORITY);
    assertEquals(""Wrong number of recs in AUTHORITY"", isSecure() ? 2 : 1,
        sectionArray.size());
    boolean soaFound = false;
    for (Record rec : sectionArray) {
      soaFound = rec.getType() == Type.SOA;
      if (soaFound) {
        break;
      }",1
"@Test
  public void testReverseLookup() throws Exception {
    ServiceRecord record = getMarshal().fromBytes(""somepath"",
        CONTAINER_RECORD.getBytes());
    getRegistryDNS().register(
        ""/registry/users/root/services/org-apache-slider/test1/components/""
            + ""ctr-e50-1451931954322-0016-01-000002"",
        record);

    // start assessing whether correct records are available
    List<Record> recs = assertDNSQuery(
        ""19.0.17.172.in-addr.arpa."", Type.PTR, 1);
    assertEquals(""wrong result"",
        ""httpd-1.test1.root.dev.test."",
        ((PTRRecord) recs.get(0)).getTarget().toString());
  }",1
"@Test
  public void testMultiple1() throws Exception {
    testMultiple(1);
  }",1
"@Test
  public void testMultiple1() throws Exception {
    testMultiple(1);
  }",1
"@Test
  public void testStaticMapUpdate() throws IOException {
    assumeNotWindows();
    File tempStaticMapFile = File.createTempFile(""nfs-"", "".map"");
    tempStaticMapFile.delete();
    Configuration conf = new Configuration();
    conf.setLong(IdMappingConstant.USERGROUPID_UPDATE_MILLIS_KEY, 1000);    
    conf.set(IdMappingConstant.STATIC_ID_MAPPING_FILE_KEY,
        tempStaticMapFile.getPath());

    ShellBasedIdMapping refIdMapping =
        new ShellBasedIdMapping(conf, true);
    ShellBasedIdMapping incrIdMapping = new ShellBasedIdMapping(conf);

    BiMap<Integer, String> uidNameMap = refIdMapping.getUidNameMap();
    BiMap<Integer, String> gidNameMap = refIdMapping.getGidNameMap();

    // Force empty map, to see effect of incremental map update of calling
    // getUid()
    incrIdMapping.clearNameMaps();
    uidNameMap = refIdMapping.getUidNameMap();
    for (BiMap.Entry<Integer, String> me : uidNameMap.entrySet()) {
      tempStaticMapFile.delete();
      incrIdMapping.clearNameMaps();
      Integer id = me.getKey();
      String name = me.getValue();

      // The static map is empty, so the id found for ""name"" would be
      // the same as ""id""
      Integer nid = incrIdMapping.getUid(name);
      assertEquals(id, nid);
      
      // Clear map and update staticMap file
      incrIdMapping.clearNameMaps();
      Integer rid = id + 10000;
      String smapStr = ""uid "" + rid + "" "" + id;
      createStaticMapFile(tempStaticMapFile, smapStr);

      // Now the id found for ""name"" should be the id specified by
      // the staticMap
      nid = incrIdMapping.getUid(name);
      assertEquals(rid, nid);
    }",1
"@Test
  public void testExternalTokenFiles() throws Exception {
    StringBuilder tokenFullPathnames = new StringBuilder();
    String tokenFilenames = ""token1,token2"";
    String tokenFiles[] = StringUtils.getTrimmedStrings(tokenFilenames);
    final File testDir = new File(""target"",
        TestUserGroupInformation.class.getName() + ""-tmpDir"").getAbsoluteFile();
    String testDirPath = testDir.getAbsolutePath();

    // create path for token files
    for (String tokenFile: tokenFiles) {
      if (tokenFullPathnames.length() > 0) {
        tokenFullPathnames.append("","");
      }",1
"@Test
  public void testServiceStartup() {
    ServiceManager serviceManager = new ServiceManager(""ServiceManager"");

    // Add services
    for (int i = 0; i < NUM_OF_SERVICES; i++) {
      CompositeServiceImpl service = new CompositeServiceImpl(i);
      if (i == FAILED_SERVICE_SEQ_NUMBER) {
        service.setThrowExceptionOnStart(true);
      }",1
"@Test
  public void testServiceStopFromInited() {
    ServiceManager serviceManager = new ServiceManager(""ServiceManager"");

    // Add services
    for (int i = 0; i < NUM_OF_SERVICES; i++) {
      CompositeServiceImpl service = new CompositeServiceImpl(i);
      serviceManager.addTestService(service);
    }",1
"@Test
  public void testDistCh() throws Exception {
    final Configuration conf = new Configuration();

    conf.set(CapacitySchedulerConfiguration.PREFIX+CapacitySchedulerConfiguration.ROOT+"".""+CapacitySchedulerConfiguration.QUEUES, ""default"");
    conf.set(CapacitySchedulerConfiguration.PREFIX+CapacitySchedulerConfiguration.ROOT+"".default.""+CapacitySchedulerConfiguration.CAPACITY, ""100"");
    final MiniDFSCluster cluster=  new MiniDFSCluster.Builder(conf).numDataNodes(2).format(true).build();
    
    final FileSystem fs = cluster.getFileSystem();
    final FsShell shell = new FsShell(conf);
    
    try {
      final FileTree tree = new FileTree(fs, ""testDistCh"");
      final FileStatus rootstatus = fs.getFileStatus(tree.rootdir);

      runLsr(shell, tree.root, 0);

      final String[] args = new String[NUN_SUBS];
      final ChPermissionStatus[] newstatus = new ChPermissionStatus[NUN_SUBS];

      
      args[0]=""/test/testDistCh/sub0:sub1::"";
      newstatus[0] = new ChPermissionStatus(rootstatus, ""sub1"", """", """");

      args[1]=""/test/testDistCh/sub1::sub2:"";
      newstatus[1] = new ChPermissionStatus(rootstatus, """", ""sub2"", """");

      args[2]=""/test/testDistCh/sub2:::437"";
      newstatus[2] = new ChPermissionStatus(rootstatus, """", """", ""437"");

      args[3]=""/test/testDistCh/sub3:sub1:sub2:447"";
      newstatus[3] = new ChPermissionStatus(rootstatus, ""sub1"", ""sub2"", ""447"");
 
      args[4]=""/test/testDistCh/sub4::sub5:437"";
      newstatus[4] = new ChPermissionStatus(rootstatus, """", ""sub5"", ""437"");

      args[5]=""/test/testDistCh/sub5:sub1:sub5:"";
      newstatus[5] = new ChPermissionStatus(rootstatus, ""sub1"", ""sub5"", """");

      args[6]=""/test/testDistCh/sub6:sub3::437"";
      newstatus[6] = new ChPermissionStatus(rootstatus, ""sub3"", """", ""437"");
      
      System.out.println(""args="" + Arrays.asList(args).toString().replace("","", "",\n  ""));
      System.out.println(""newstatus="" + Arrays.asList(newstatus).toString().replace("","", "",\n  ""));

      //run DistCh
      new DistCh(MiniMRClientClusterFactory.create(this.getClass(), 2, conf).getConfig()).run(args);
      runLsr(shell, tree.root, 0);

      //check results
      for(int i = 0; i < NUN_SUBS; i++) {
        Path sub = new Path(tree.root + ""/sub"" + i);
        checkFileStatus(newstatus[i], fs.getFileStatus(sub));
        for(FileStatus status : fs.listStatus(sub)) {
          checkFileStatus(newstatus[i], status);
        }",1
"@Test
  public void testMultipleProducerConsumer() {
    ProducerConsumer<Integer, Integer> workers =
        new ProducerConsumer<Integer, Integer>(10);
    for (int i = 0; i < 10; i++) {
      workers.addWorker(new CopyProcessor());
    }",1
"@Test
  public void testRemovals() throws Exception {
    final int NUM_ELEMS = 100000;
    ChunkedArrayList<Integer> list = new ChunkedArrayList<Integer>();
    for (int i = 0; i < NUM_ELEMS; i++) {
      list.add(i);
    }",1
"@Test
  public void testGetDeclaredFieldsIncludingInherited() {
    Parent child = new Parent() {
      private int childField;
      @SuppressWarnings(""unused"")
      public int getChildField() { return childField; }",1
"@Test
  public void testBigJar() throws Exception {
    Random r = new Random(System.currentTimeMillis());
    File dir = new File(TEST_ROOT_DIR, Long.toHexString(r.nextLong()));
    Assert.assertTrue(dir.mkdirs());
    File input = generateBigJar(dir);
    File output = new File(dir, ""job2.jar"");
    try {
      try (InputStream is = new FileInputStream(input)) {
        RunJar.unJarAndSave(is, dir, ""job2.jar"", Pattern.compile("".*""));
      }",1
"@Test
  public void testAMRMContainerPromotionAndDemotionWithAutoUpdate()
      throws Exception {
    AMRMClientImpl<AMRMClient.ContainerRequest> amClient =
        (AMRMClientImpl<AMRMClient.ContainerRequest>) AMRMClient
            .createAMRMClient();
    amClient.init(conf);
    amClient.start();

    // start am nm client
    NMClientImpl nmClient = (NMClientImpl) NMClient.createNMClient();
    Assert.assertNotNull(nmClient);
    nmClient.init(conf);
    nmClient.start();
    assertEquals(STATE.STARTED, nmClient.getServiceState());

    amClient.registerApplicationMaster(""Host"", 10000, """");

    // setup container request
    assertEquals(0, amClient.ask.size());
    assertEquals(0, amClient.release.size());

    // START OPPORTUNISTIC Container, Send allocation request to RM
    Resource reqResource = Resource.newInstance(512, 1);
    amClient.addContainerRequest(
        new AMRMClient.ContainerRequest(reqResource, null, null, priority2, 0,
            true, null, ExecutionTypeRequest
            .newInstance(ExecutionType.OPPORTUNISTIC, true)));

    // RM should allocate container within 1 calls to allocate()
    AllocateResponse allocResponse = waitForAllocation(amClient, 1, 0);

    assertEquals(1, allocResponse.getAllocatedContainers().size());
    startContainer(allocResponse, nmClient);

    Container c = allocResponse.getAllocatedContainers().get(0);
    amClient.requestContainerUpdate(c,
        UpdateContainerRequest.newInstance(c.getVersion(),
            c.getId(), ContainerUpdateType.PROMOTE_EXECUTION_TYPE,
            null, ExecutionType.GUARANTEED));

    allocResponse = waitForAllocation(amClient, 0, 1);

    // Make sure container is updated.
    UpdatedContainer updatedContainer = allocResponse
        .getUpdatedContainers().get(0);

    // If container auto update is not enabled, we need to notify
    // NM about this update.
    if (!autoUpdate) {
      nmClient.updateContainerResource(updatedContainer.getContainer());
    }",1
"@Test
  public void testAutomaticTimelineDelegationTokenLoading()
          throws Exception {
    Configuration conf = getConf();
    conf.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);
    SecurityUtil.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.KERBEROS, conf);
    conf.set(YarnConfiguration.TIMELINE_HTTP_AUTH_TYPE,
            KerberosAuthenticationHandler.TYPE);
    TimelineDelegationTokenIdentifier timelineDT =
            new TimelineDelegationTokenIdentifier();
    final Token<TimelineDelegationTokenIdentifier> dToken =
            new Token<>(
                    timelineDT.getBytes(), new byte[0], timelineDT.getKind(), new Text());
    // create a mock client
    YarnClientImpl client = spy(new YarnClientImpl() {

      @Override
      TimelineClient createTimelineClient() throws IOException, YarnException {
        timelineClient = mock(TimelineClient.class);
        when(timelineClient.getDelegationToken(any())).thenReturn(dToken);
        return timelineClient;
      }",1
"@Test
  public void testListClusterNodes() throws Exception {
    List<NodeReport> nodeReports = new ArrayList<NodeReport>();
    nodeReports.addAll(getNodeReports(1, NodeState.NEW));
    nodeReports.addAll(getNodeReports(2, NodeState.RUNNING));
    nodeReports.addAll(getNodeReports(1, NodeState.UNHEALTHY));
    nodeReports.addAll(getNodeReports(1, NodeState.DECOMMISSIONED));
    nodeReports.addAll(getNodeReports(1, NodeState.REBOOTED));
    nodeReports.addAll(getNodeReports(1, NodeState.LOST));

    NodeCLI cli = createAndGetNodeCLI();

    Set<NodeState> nodeStates = new HashSet<NodeState>();
    nodeStates.add(NodeState.NEW);
    NodeState[] states = nodeStates.toArray(new NodeState[0]);
    when(client.getNodeReports(states))
        .thenReturn(getNodeReports(nodeReports, nodeStates));
    int result = cli.run(new String[] {""-list"", ""-states"", ""NEW""}",1
"@Test
  public void testIntegerAssignment() throws YarnException {
    float[] weights =
        new float[] {0, 0.1f, 0.2f, 0.2f, -0.1f, 0.1f, 0.2f, 0.1f, 0.1f}",1
"@Test
  public void testGetSubCluster() throws YarnException {
    for (int i = 0; i < numSubClusters; i++) {
      SubClusterId subClusterId =
          SubClusterId.newInstance(FederationStateStoreTestUtil.SC_PREFIX + i);
      Assert.assertEquals(stateStoreTestUtil.querySubClusterInfo(subClusterId),
          facade.getSubCluster(subClusterId));
    }",1
"@Test
  public void testGetSubClusterFlushCache() throws YarnException {
    for (int i = 0; i < numSubClusters; i++) {
      SubClusterId subClusterId =
          SubClusterId.newInstance(FederationStateStoreTestUtil.SC_PREFIX + i);
      Assert.assertEquals(stateStoreTestUtil.querySubClusterInfo(subClusterId),
          facade.getSubCluster(subClusterId, true));
    }",1
"@Test
  public void testAllocateAndReleaseContainersForMultipleAM()
      throws Exception {
    int numberOfApps = 5;
    for (int testAppId = 0; testAppId < numberOfApps; testAppId++) {
      RegisterApplicationMasterResponse registerResponse =
          registerApplicationMaster(testAppId);
      Assert.assertNotNull(registerResponse);
      List<Container> containers = getContainersAndAssert(testAppId, 10);
      releaseContainersAndAssert(testAppId, containers);
    }",1
"@Test
  public void parsingProcNetFile() throws IOException {
    long numBytesReadIntf1 = 2097172468L;
    long numBytesWrittenIntf1 = 1355620114L;
    long numBytesReadIntf2 = 1097172460L;
    long numBytesWrittenIntf2 = 1055620110L;
    File tempFile = new File(FAKE_NETFILE);
    tempFile.deleteOnExit();
    FileWriter fWriter = new FileWriter(FAKE_NETFILE);
    fWriter.write(String.format(NETINFO_FORMAT,
                            numBytesReadIntf1, numBytesWrittenIntf1,
                            numBytesReadIntf2, numBytesWrittenIntf2));
    fWriter.close();
    assertEquals(plugin.getNetworkBytesRead(), numBytesReadIntf1 + numBytesReadIntf2);
    assertEquals(plugin.getNetworkBytesWritten(), numBytesWrittenIntf1 + numBytesWrittenIntf2);
  }",1
"@Test
  public void parsingProcStatAndCpuFile() throws IOException {
    // Write fake /proc/cpuinfo file.
    long numProcessors = 8;
    long cpuFrequencyKHz = 2392781;
    String fileContent = """";
    for (int i = 0; i < numProcessors; i++) {
      fileContent +=
          String.format(CPUINFO_FORMAT, i, cpuFrequencyKHz / 1000D, 0, 0)
              + ""\n"";
    }",1
"@Test
  public void testAsyncAPIPollTimeout() {
    testAsyncAPIPollTimeoutHelper(null, false);
    testAsyncAPIPollTimeoutHelper(0L, true);
    testAsyncAPIPollTimeoutHelper(1L, true);
  }",1
"@Test
  public void testSplitBasedOnHeadroom() throws Exception {

    // Tests how the headroom info are used to split based on the capacity
    // each RM claims to give us.
    // Configure policy to be 100% headroom based
    getPolicyInfo().setHeadroomAlpha(1.0f);

    initializePolicy();
    List<ResourceRequest> resourceRequests = createSimpleRequest();

    prepPolicyWithHeadroom(true);

    Map<SubClusterId, List<ResourceRequest>> response =
        ((FederationAMRMProxyPolicy) getPolicy()).splitResourceRequests(
            resourceRequests, new HashSet<SubClusterId>());

    // pretty print requests
    LOG.info(""Initial headroom"");
    prettyPrintRequests(response);

    validateSplit(response, resourceRequests);

    /*
     * based on headroom, we expect 75 containers to got to subcluster0 (60) and
     * subcluster2 (15) according to the advertised headroom (40 and 10), no
     * containers for sublcuster1 as it advertise zero headroom, and 25 to
     * subcluster5 which has unknown headroom, and so it gets 1/4th of the load
     */
    checkExpectedAllocation(response, ""subcluster0"", 1, 60);
    checkExpectedAllocation(response, ""subcluster1"", 1, -1);
    checkExpectedAllocation(response, ""subcluster2"", 1, 15);
    checkExpectedAllocation(response, ""subcluster5"", 1, 25);
    checkTotalContainerAllocation(response, 100);

    // notify a change in headroom and try again
    AllocateResponse ar = getAllocateResponseWithTargetHeadroom(40);
    ((FederationAMRMProxyPolicy) getPolicy())
        .notifyOfResponse(SubClusterId.newInstance(""subcluster2""), ar);
    response = ((FederationAMRMProxyPolicy) getPolicy())
        .splitResourceRequests(resourceRequests, new HashSet<SubClusterId>());

    LOG.info(""After headroom update"");
    prettyPrintRequests(response);
    validateSplit(response, resourceRequests);

    /*
     * we simulated a change in headroom for subcluster2, which will now have
     * the same headroom of subcluster0, so each 37.5, note that the odd one
     * will be assigned to either one of the two subclusters
     */
    checkExpectedAllocation(response, ""subcluster0"", 1, 37);
    checkExpectedAllocation(response, ""subcluster1"", 1, -1);
    checkExpectedAllocation(response, ""subcluster2"", 1, 37);
    checkExpectedAllocation(response, ""subcluster5"", 1, 25);
    checkTotalContainerAllocation(response, 100);
  }",1
"@Test
  public void testNormalCase() throws IOException {
    ApplicationId appId = ApplicationId.newInstance(1, 1);
    ApplicationAttemptId attemptId = ApplicationAttemptId.newInstance(appId, 1);

    Token<AMRMTokenIdentifier> localToken =
        secretManager.createAndGetAMRMToken(attemptId);

    AMRMTokenIdentifier identifier = secretManager.createIdentifier();
    identifier.readFields(new DataInputStream(
        new ByteArrayInputStream(localToken.getIdentifier())));

    secretManager.retrievePassword(identifier);

    secretManager.applicationMasterFinished(attemptId);

    try {
      secretManager.retrievePassword(identifier);
      Assert.fail(""Expect InvalidToken exception"");
    }",1
"@Test
  public void testMultipleSubClusters() throws Exception {
    UserGroupInformation ugi =
        interceptor.getUGIWithToken(interceptor.getAttemptId());
    ugi.doAs((PrivilegedExceptionAction<Object>) () -> {
      // Register the application
      RegisterApplicationMasterRequest registerReq =
          Records.newRecord(RegisterApplicationMasterRequest.class);
      registerReq.setHost(Integer.toString(testAppId));
      registerReq.setRpcPort(0);
      registerReq.setTrackingUrl("""");

      RegisterApplicationMasterResponse registerResponse =
          interceptor.registerApplicationMaster(registerReq);
      Assert.assertNotNull(registerResponse);
      lastResponseId = 0;

      Assert.assertEquals(0, interceptor.getUnmanagedAMPoolSize());

      // Allocate the first batch of containers, with sc1 and sc2 active
      registerSubCluster(SubClusterId.newInstance(""SC-1""));
      registerSubCluster(SubClusterId.newInstance(""SC-2""));

      int numberOfContainers = 3;
      List<Container> containers =
          getContainersAndAssert(numberOfContainers, numberOfContainers * 2);
      Assert.assertEquals(2, interceptor.getUnmanagedAMPoolSize());

      // Allocate the second batch of containers, with sc1 and sc3 active
      deRegisterSubCluster(SubClusterId.newInstance(""SC-2""));
      registerSubCluster(SubClusterId.newInstance(""SC-3""));

      numberOfContainers = 1;
      containers.addAll(
          getContainersAndAssert(numberOfContainers, numberOfContainers * 2));
      Assert.assertEquals(3, interceptor.getUnmanagedAMPoolSize());

      // Allocate the third batch of containers with only in home sub-cluster
      // active
      deRegisterSubCluster(SubClusterId.newInstance(""SC-1""));
      deRegisterSubCluster(SubClusterId.newInstance(""SC-3""));
      registerSubCluster(SubClusterId.newInstance(HOME_SC_ID));

      numberOfContainers = 2;
      containers.addAll(
          getContainersAndAssert(numberOfContainers, numberOfContainers));
      Assert.assertEquals(3, interceptor.getUnmanagedAMPoolSize());

      // Release all containers
      releaseContainersAndAssert(containers);

      // Finish the application
      FinishApplicationMasterRequest finishReq =
          Records.newRecord(FinishApplicationMasterRequest.class);
      finishReq.setDiagnostics("""");
      finishReq.setTrackingUrl("""");
      finishReq.setFinalApplicationStatus(FinalApplicationStatus.SUCCEEDED);

      FinishApplicationMasterResponse finishResponse =
          interceptor.finishApplicationMaster(finishReq);
      Assert.assertNotNull(finishResponse);
      Assert.assertTrue(finishResponse.getIsUnregistered());

      return null;
    }",1
"@Test
  public void testConvertProtoToDeletionTask() throws Exception {
    DeletionService deletionService = mock(DeletionService.class);
    DeletionServiceDeleteTaskProto.Builder protoBuilder =
        DeletionServiceDeleteTaskProto.newBuilder();
    int id = 0;
    protoBuilder.setId(id);
    DeletionServiceDeleteTaskProto proto = protoBuilder.build();
    DeletionTask deletionTask =
        NMProtoUtils.convertProtoToDeletionTask(proto, deletionService);
    assertEquals(DeletionTaskType.FILE, deletionTask.getDeletionTaskType());
    assertEquals(id, deletionTask.getTaskId());
  }",1
"@Test
  public void testConvertProtoToDeletionTaskRecoveryInfo() throws Exception {
    long delTime = System.currentTimeMillis();
    List<Integer> successorTaskIds = Arrays.asList(1);
    DeletionTask deletionTask = mock(DeletionTask.class);
    DeletionTaskRecoveryInfo info =
        new DeletionTaskRecoveryInfo(deletionTask, successorTaskIds, delTime);
    assertEquals(deletionTask, info.getTask());
    assertEquals(successorTaskIds, info.getSuccessorTaskIds());
    assertEquals(delTime, info.getDeletionTimestamp());
  }",1
"@Test
  public void testConvertProtoToDockerContainerDeletionTask() throws Exception {
    DeletionService deletionService = mock(DeletionService.class);
    int id = 0;
    String user = ""user"";
    String dockerContainerId = ""container_e123_12321231_00001"";
    DeletionServiceDeleteTaskProto.Builder protoBuilder =
        DeletionServiceDeleteTaskProto.newBuilder();
    protoBuilder
        .setId(id)
        .setUser(user)
        .setDockerContainerId(dockerContainerId);
    DeletionServiceDeleteTaskProto proto = protoBuilder.build();
    DeletionTask deletionTask =
        NMProtoUtils.convertProtoToDockerContainerDeletionTask(proto,
            deletionService, id);
    assertEquals(DeletionTaskType.DOCKER_CONTAINER.name(),
        deletionTask.getDeletionTaskType().name());
    assertEquals(id, deletionTask.getTaskId());
    assertEquals(dockerContainerId,
        ((DockerContainerDeletionTask) deletionTask).getContainerId());
  }",1
"@Test
  public void testApplicationInit2() {
    WrappedApplication wa = null;
    try {
      wa = new WrappedApplication(2, 314159265358979L, ""yak"", 3);
      wa.initApplication();
      wa.initContainer(0);
      assertEquals(ApplicationState.INITING, wa.app.getApplicationState());
      assertEquals(1, wa.app.getContainers().size());

      wa.applicationInited();
      assertEquals(ApplicationState.RUNNING, wa.app.getApplicationState());
      verify(wa.containerBus).handle(
          argThat(new ContainerInitMatcher(wa.containers.get(0)
              .getContainerId())));

      wa.initContainer(1);
      wa.initContainer(2);
      assertEquals(ApplicationState.RUNNING, wa.app.getApplicationState());
      assertEquals(3, wa.app.getContainers().size());

      for (int i = 1; i < wa.containers.size(); i++) {
        verify(wa.containerBus).handle(
            argThat(new ContainerInitMatcher(wa.containers.get(i)
                .getContainerId())));
      }",1
"@Test
  public void testApplicationOnAppLogHandlingInitedEvtShouldStoreLogInitedTime()
      throws IOException {
    WrappedApplication wa = new WrappedApplication(5,  314159265358979L,
        ""yak"", 0);
    wa.initApplication();

    ArgumentCaptor<ContainerManagerApplicationProto> applicationProto =
        ArgumentCaptor.forClass(ContainerManagerApplicationProto.class);

    final long timestamp = wa.applicationLogInited();

    verify(wa.stateStoreService).storeApplication(any(ApplicationId.class),
        applicationProto.capture());

    assertEquals(applicationProto.getValue().getAppLogAggregationInitedTime()
        , timestamp);
  }",1
"@Test
  public void testLocalizationRequest() throws Exception {
    WrappedContainer wc = null;
    try {
      wc = new WrappedContainer(7, 314159265358979L, 4344, ""yak"");
      assertEquals(ContainerState.NEW, wc.c.getContainerState());
      wc.initContainer();

      // Verify request for public/private resources to localizer
      ResourcesRequestedMatcher matchesReq =
          new ResourcesRequestedMatcher(wc.localResources, EnumSet.of(
              LocalResourceVisibility.PUBLIC, LocalResourceVisibility.PRIVATE,
              LocalResourceVisibility.APPLICATION));
      verify(wc.localizerBus).handle(argThat(matchesReq));
      assertEquals(ContainerState.LOCALIZING, wc.c.getContainerState());
    }",1
"@Test
  public void testSpecialCharSymlinks() throws IOException  {

    File shellFile = null;
    File tempFile = null;
    String badSymlink = Shell.WINDOWS ? ""foo@zz_#!-+bar.cmd"" :
      ""-foo@zz%_#*&!-+= bar()"";
    File symLinkFile = null;

    try {
      shellFile = Shell.appendScriptExtension(tmpDir, ""hello"");
      tempFile = Shell.appendScriptExtension(tmpDir, ""temp"");
      String timeoutCommand = Shell.WINDOWS ? ""@echo \""hello\"""" :
        ""echo \""hello\"""";
      PrintWriter writer = new PrintWriter(new FileOutputStream(shellFile));
      FileUtil.setExecutable(shellFile, true);
      writer.println(timeoutCommand);
      writer.close();

      Map<Path, List<String>> resources =
          new HashMap<Path, List<String>>();
      Path path = new Path(shellFile.getAbsolutePath());
      resources.put(path, Arrays.asList(badSymlink));

      FileOutputStream fos = new FileOutputStream(tempFile);

      Map<String, String> env = new HashMap<String, String>();
      List<String> commands = new ArrayList<String>();
      if (Shell.WINDOWS) {
        commands.add(""cmd"");
        commands.add(""/c"");
        commands.add(""\"""" + badSymlink + ""\"""");
      }",1
"@Test
  public void testExecutorPath() {
    String containerExePath = PrivilegedOperationExecutor
        .getContainerExecutorExecutablePath(nullConf);

    //In case HADOOP_YARN_HOME isn't set, CWD is used. If conf is null or
    //NM_LINUX_CONTAINER_EXECUTOR_PATH is not set, then a defaultPath is
    //constructed.
    String yarnHomeEnvVar = System.getenv(""HADOOP_YARN_HOME"");
    String yarnHome = yarnHomeEnvVar != null ? yarnHomeEnvVar
        : new File("""").getAbsolutePath();
    String expectedPath = yarnHome + ""/bin/container-executor"";

    Assert.assertEquals(expectedPath, containerExePath);

    containerExePath = PrivilegedOperationExecutor
        .getContainerExecutorExecutablePath(emptyConf);
    Assert.assertEquals(expectedPath, containerExePath);

    //if NM_LINUX_CONTAINER_EXECUTOR_PATH is set, this must be returned
    expectedPath = customExecutorPath;
    containerExePath = PrivilegedOperationExecutor
        .getContainerExecutorExecutablePath(confWithExecutorPath);
    Assert.assertEquals(expectedPath, containerExePath);
  }",1
"@Test
  public void testAllocateNumaNodeWithRoundRobinFashionAssignment()
      throws Exception {
    NumaResourceAllocation nodeInfo1 = numaResourceAllocator
        .allocateNumaNodes(getContainer(
            ContainerId.fromString(""container_1481156246874_0001_01_000001""),
            Resource.newInstance(2048, 2)));
    Assert.assertEquals(""0"", String.join("","", nodeInfo1.getMemNodes()));
    Assert.assertEquals(""0"", String.join("","", nodeInfo1.getCpuNodes()));

    NumaResourceAllocation nodeInfo2 = numaResourceAllocator
        .allocateNumaNodes(getContainer(
            ContainerId.fromString(""container_1481156246874_0001_01_000002""),
            Resource.newInstance(2048, 2)));
    Assert.assertEquals(""1"", String.join("","", nodeInfo2.getMemNodes()));
    Assert.assertEquals(""1"", String.join("","", nodeInfo2.getCpuNodes()));

    NumaResourceAllocation nodeInfo3 = numaResourceAllocator
        .allocateNumaNodes(getContainer(
            ContainerId.fromString(""container_1481156246874_0001_01_000003""),
            Resource.newInstance(2048, 2)));
    Assert.assertEquals(""0"", String.join("","", nodeInfo3.getMemNodes()));
    Assert.assertEquals(""0"", String.join("","", nodeInfo3.getCpuNodes()));

    NumaResourceAllocation nodeInfo4 = numaResourceAllocator
        .allocateNumaNodes(getContainer(
            ContainerId.fromString(""container_1481156246874_0001_01_000003""),
            Resource.newInstance(2048, 2)));
    Assert.assertEquals(""1"", String.join("","", nodeInfo4.getMemNodes()));
    Assert.assertEquals(""1"", String.join("","", nodeInfo4.getCpuNodes()));
  }",1
"@Test
  public void testReadNumaTopologyFromCmdOutput() throws Exception {
    conf.setBoolean(YarnConfiguration.NM_NUMA_AWARENESS_READ_TOPOLOGY, true);
    String cmdOutput = ""available: 2 nodes (0-1)\n\t""
        + ""node 0 cpus: 0 2 4 6\n\t""
        + ""node 0 size: 73717 MB\n\t""
        + ""node 0 free: 17272 MB\n\t""
        + ""node 1 cpus: 1 3 5 7\n\t""
        + ""node 1 size: 73727 MB\n\t""
        + ""node 1 free: 10699 MB\n\t""
        + ""node distances:\n\t""
        + ""node 0 1\n\t""
        + ""0: 10 20\n\t""
        + ""1: 20 10"";
    numaResourceAllocator = new NumaResourceAllocator(mock(Context.class)) {
      @Override
      public String executeNGetCmdOutput(Configuration config)
          throws YarnRuntimeException {
        return cmdOutput;
      }",1
"@Test
  public void testRecoverNumaResource() throws Exception {
    @SuppressWarnings(""unchecked"")
    ConcurrentHashMap<ContainerId, Container> mockContainers = mock(
        ConcurrentHashMap.class);
    Context mockContext = mock(Context.class);
    Container mockContainer = mock(Container.class);
    ResourceMappings value = new ResourceMappings();
    AssignedResources assignedResources = new AssignedResources();
    assignedResources.updateAssignedResources(
        Arrays.asList(new NumaResourceAllocation(""0"", 70000, ""0"", 4)));
    value.addAssignedResources(""numa"", assignedResources);
    when(mockContainer.getResourceMappings()).thenReturn(value);
    when(mockContainers.get(any())).thenReturn(mockContainer);
    when(mockContext.getContainers()).thenReturn(mockContainers);
    NMStateStoreService mock = mock(NMStateStoreService.class);
    when(mockContext.getNMStateStore()).thenReturn(mock);
    numaResourceAllocator = new NumaResourceAllocator(mockContext);
    numaResourceAllocator.init(conf);
    // Recover the resources
    numaResourceAllocator.recoverNumaResource(
        ContainerId.fromString(""container_1481156246874_0001_01_000001""));

    // Request resources based on the availability
    NumaResourceAllocation numaNode = numaResourceAllocator
        .allocateNumaNodes(getContainer(
            ContainerId.fromString(""container_1481156246874_0001_01_000005""),
            Resource.newInstance(2048, 1)));
    assertEquals(""1"", String.join("","", numaNode.getMemNodes()));
    assertEquals(""1"", String.join("","", numaNode.getCpuNodes()));

    // Request resources more than the available
    numaNode = numaResourceAllocator.allocateNumaNodes(getContainer(
        ContainerId.fromString(""container_1481156246874_0001_01_000006""),
        Resource.newInstance(2048, 4)));
    assertNull(numaNode);
  }",1
"@Test
  public void testReleaseNumaResourcess() throws Exception {
    NumaResourceAllocation nodeInfo = numaResourceAllocator
        .allocateNumaNodes(getContainer(
            ContainerId.fromString(""container_1481156246874_0001_01_000001""),
            Resource.newInstance(2048, 8)));
    Assert.assertEquals(""0"", String.join("","", nodeInfo.getMemNodes()));
    Assert.assertEquals(""0,1"", String.join("","", nodeInfo.getCpuNodes()));

    // Request the resource when all cpu nodes occupied
    nodeInfo = numaResourceAllocator.allocateNumaNodes(getContainer(
        ContainerId.fromString(""container_1481156246874_0001_01_000002""),
        Resource.newInstance(2048, 4)));
    Assert.assertNull(""Should not assign numa nodes when there""
        + "" are no sufficient cpu resources available."", nodeInfo);

    // Release the resources
    numaResourceAllocator.releaseNumaResource(
        ContainerId.fromString(""container_1481156246874_0001_01_000001""));
    // Request the resources
    nodeInfo = numaResourceAllocator.allocateNumaNodes(getContainer(
        ContainerId.fromString(""container_1481156246874_0001_01_000003""),
        Resource.newInstance(1024, 2)));
    Assert.assertEquals(""0"", String.join("","", nodeInfo.getMemNodes()));
    Assert.assertEquals(""0"", String.join("","", nodeInfo.getCpuNodes()));
  }",1
"@Test
  public void testReacquireContainer() throws Exception {
    @SuppressWarnings(""unchecked"")
    ConcurrentHashMap<ContainerId, Container> mockContainers = mock(
        ConcurrentHashMap.class);
    Context mockContext = mock(Context.class);
    NMStateStoreService mock = mock(NMStateStoreService.class);
    when(mockContext.getNMStateStore()).thenReturn(mock);
    ResourceMappings resourceMappings = new ResourceMappings();
    AssignedResources assignedRscs = new AssignedResources();
    NumaResourceAllocation numaResourceAllocation = new NumaResourceAllocation(
        ""0"", 70000, ""0"", 4);
    assignedRscs.updateAssignedResources(Arrays.asList(numaResourceAllocation));
    resourceMappings.addAssignedResources(""numa"", assignedRscs);
    when(mockContainer.getResourceMappings()).thenReturn(resourceMappings);
    when(mockContainers.get(any())).thenReturn(mockContainer);
    when(mockContext.getContainers()).thenReturn(mockContainers);
    numaResourceHandler = new NumaResourceHandlerImpl(conf, mockContext);
    numaResourceHandler.bootstrap(conf);
    // recovered numa resources should be added to the used resources and
    // remaining will be available for further allocation.
    numaResourceHandler.reacquireContainer(
        ContainerId.fromString(""container_1481156246874_0001_01_000001""));

    testAllocateNumaResource(""container_1481156246874_0001_01_000005"",
        Resource.newInstance(2048, 1), ""1"", ""1"");
    when(mockContainer.getContainerId()).thenReturn(
        ContainerId.fromString(""container_1481156246874_0001_01_000005""));
    when(mockContainer.getResource()).thenReturn(Resource.newInstance(2048, 4));
    List<PrivilegedOperation> preStart = numaResourceHandler
        .preStart(mockContainer);
    assertNull(preStart);
  }",1
"@Test
  public void testPreStart() throws Exception {
    String id = ""container_01_01"";
    String path = ""test-path/"" + id;
    ContainerId mockContainerId = mock(ContainerId.class);
    when(mockContainerId.toString()).thenReturn(id);
    Container mockContainer = mock(Container.class);
    when(mockContainer.getContainerId()).thenReturn(mockContainerId);
    when(mockCGroupsHandler
        .getPathForCGroupTasks(CGroupsHandler.CGroupController.CPU, id))
        .thenReturn(path);
    when(mockContainer.getResource()).thenReturn(Resource.newInstance(1024, 2));

    List<PrivilegedOperation> ret =
        cGroupsCpuResourceHandler.preStart(mockContainer);
    verify(mockCGroupsHandler, times(1))
        .createCGroup(CGroupsHandler.CGroupController.CPU, id);
    verify(mockCGroupsHandler, times(1))
        .updateCGroupParam(CGroupsHandler.CGroupController.CPU, id,
            CGroupsHandler.CGROUP_CPU_SHARES, String
                .valueOf(CGroupsCpuResourceHandlerImpl.CPU_DEFAULT_WEIGHT * 2));

    // don't set quota or period
    verify(mockCGroupsHandler, never())
        .updateCGroupParam(eq(CGroupsHandler.CGroupController.CPU), eq(id),
            eq(CGroupsHandler.CGROUP_CPU_PERIOD_US), anyString());
    verify(mockCGroupsHandler, never())
        .updateCGroupParam(eq(CGroupsHandler.CGroupController.CPU), eq(id),
            eq(CGroupsHandler.CGROUP_CPU_QUOTA_US), anyString());
    Assert.assertNotNull(ret);
    Assert.assertEquals(1, ret.size());
    PrivilegedOperation op = ret.get(0);
    Assert.assertEquals(PrivilegedOperation.OperationType.ADD_PID_TO_CGROUP,
        op.getOperationType());
    List<String> args = op.getArguments();
    Assert.assertEquals(1, args.size());
    Assert.assertEquals(PrivilegedOperation.CGROUP_ARG_PREFIX + path,
        args.get(0));
  }",1
"@Test
  public void testPreStartRestrictedContainers() throws Exception {
    String id = ""container_01_01"";
    String path = ""test-path/"" + id;
    int defaultVCores = 8;
    Configuration conf = new YarnConfiguration();
    conf.setBoolean(
        YarnConfiguration.NM_LINUX_CONTAINER_CGROUPS_STRICT_RESOURCE_USAGE,
        true);
    int cpuPerc = 75;
    conf.setInt(YarnConfiguration.NM_RESOURCE_PERCENTAGE_PHYSICAL_CPU_LIMIT,
        cpuPerc);
    cGroupsCpuResourceHandler.bootstrap(plugin, conf);
    InOrder cpuLimitOrder = inOrder(mockCGroupsHandler);
    cpuLimitOrder.verify(mockCGroupsHandler, times(1))
        .updateCGroupParam(CGroupsHandler.CGroupController.CPU, """",
            CGroupsHandler.CGROUP_CPU_PERIOD_US, String.valueOf(""333333""));
    cpuLimitOrder.verify(mockCGroupsHandler, times(1))
        .updateCGroupParam(CGroupsHandler.CGroupController.CPU, """",
            CGroupsHandler.CGROUP_CPU_QUOTA_US,
            String.valueOf(CGroupsCpuResourceHandlerImpl.MAX_QUOTA_US));
    float yarnCores = (cpuPerc * numProcessors) / 100;
    int[] containerVCores = { 2, 4 }",1
"@Test
  public void testPreMountedControllerEmpty() throws Exception {
    testPreMountedControllerInitialization("""");
  }",1
"@Test
  public void testOpportunistic() throws Exception {
    Configuration conf = new YarnConfiguration();
    conf.setBoolean(YarnConfiguration.NM_PMEM_CHECK_ENABLED, false);
    conf.setBoolean(YarnConfiguration.NM_VMEM_CHECK_ENABLED, false);

    cGroupsMemoryResourceHandler.bootstrap(conf);
    ContainerTokenIdentifier tokenId = mock(ContainerTokenIdentifier.class);
    when(tokenId.getExecutionType()).thenReturn(ExecutionType.OPPORTUNISTIC);
    Container container = mock(Container.class);
    String id = ""container_01_01"";
    ContainerId mockContainerId = mock(ContainerId.class);
    when(mockContainerId.toString()).thenReturn(id);
    when(container.getContainerId()).thenReturn(mockContainerId);
    when(container.getContainerTokenIdentifier()).thenReturn(tokenId);
    when(container.getResource()).thenReturn(Resource.newInstance(1024, 2));
    cGroupsMemoryResourceHandler.preStart(container);
    verify(mockCGroupsHandler, times(1))
        .updateCGroupParam(CGroupsHandler.CGroupController.MEMORY, id,
            CGroupsHandler.CGROUP_PARAM_MEMORY_SOFT_LIMIT_BYTES, ""0M"");
    verify(mockCGroupsHandler, times(1))
        .updateCGroupParam(CGroupsHandler.CGroupController.MEMORY, id,
            CGroupsHandler.CGROUP_PARAM_MEMORY_SWAPPINESS, ""100"");
    verify(mockCGroupsHandler, times(1))
        .updateCGroupParam(CGroupsHandler.CGroupController.MEMORY, id,
            CGroupsHandler.CGROUP_PARAM_MEMORY_HARD_LIMIT_BYTES, ""1024M"");
  }",1
"@Test
  public void testCGgroupNotFound() throws Exception {
    writeToFile(""proc/41/cgroup"",
        ""7:devices:/yarn/container_1"",
        ""6:cpuacct,cpu:/yarn/container_1"",
        ""5:pids:/yarn/container_1"",
        ""4:memory:/yarn/container_1""
    );

    CGroupsResourceCalculator calculator = createCalculator();
    calculator.updateProcessTree();
    assertEquals(-1, calculator.getCumulativeCpuTime());
  }",1
"@Test
  public void testKillAllContainersUponOOM() throws Exception {
    int currentContainerId = 0;

    ConcurrentHashMap<ContainerId, Container> containers =
        new ConcurrentHashMap<>();
    Container c1 = createContainer(currentContainerId++, false, 1, true);
    containers.put(c1.getContainerId(), c1);
    Container c2 = createContainer(currentContainerId++, false, 2, true);
    containers.put(c2.getContainerId(), c2);
    Container c3 = createContainer(currentContainerId++, true, 1, true);
    containers.put(c3.getContainerId(), c3);

    ContainerExecutor ex = createContainerExecutor(containers);
    Context context = mock(Context.class);
    when(context.getContainers()).thenReturn(containers);
    when(context.getContainerExecutor()).thenReturn(ex);

    CGroupsHandler cGroupsHandler = mock(CGroupsHandler.class);
    when(cGroupsHandler.getCGroupParam(
        CGroupsHandler.CGroupController.MEMORY,
        """",
        CGROUP_PARAM_MEMORY_OOM_CONTROL))
        .thenReturn(""under_oom 1"")
        .thenReturn(""under_oom 1"")
        .thenReturn(""under_oom 1"")
        .thenReturn(""under_oom 0"");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1234"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1235"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c3.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1236"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c3.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c3.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(9));

    DefaultOOMHandler handler =
        new DefaultOOMHandler(context, false) {
          @Override
          protected CGroupsHandler getCGroupsHandler() {
            return cGroupsHandler;
          }",1
"@Test
  public void testKillOneOverLimitOpportunisticContainerUponOOM()
      throws Exception {
    ConcurrentHashMap<ContainerId, Container> containers =
        new ConcurrentHashMap<>();
    int currentContainerId = 0;
    Container c1 = createContainer(currentContainerId++, false, 2, true);
    containers.put(c1.getContainerId(), c1);
    Container c2 = createContainer(currentContainerId++, false, 1, true);
    containers.put(c2.getContainerId(), c2);
    Container c3 = createContainer(currentContainerId++, true, 1, true);
    containers.put(c3.getContainerId(), c3);

    ContainerExecutor ex = createContainerExecutor(containers);
    Context context = mock(Context.class);
    when(context.getContainers()).thenReturn(containers);
    when(context.getContainerExecutor()).thenReturn(ex);

    CGroupsHandler cGroupsHandler = mock(CGroupsHandler.class);
    when(cGroupsHandler.getCGroupParam(
        CGroupsHandler.CGroupController.MEMORY,
        """",
        CGROUP_PARAM_MEMORY_OOM_CONTROL))
        .thenReturn(""under_oom 1"")
        .thenReturn(""under_oom 0"");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1234"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(9));

    // container c2 is out of its limit
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1235"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(11));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(11));

    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c3.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1236"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c3.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c3.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(9));

    DefaultOOMHandler handler =
        new DefaultOOMHandler(context, false) {
          @Override
          protected CGroupsHandler getCGroupsHandler() {
            return cGroupsHandler;
          }",1
"@Test
  public void testNoGuaranteedContainerOverLimitOOM() throws Exception {
    ConcurrentHashMap<ContainerId, Container> containers =
        new ConcurrentHashMap<>();
    Container c1 = createContainer(1, true, 1L, true);
    containers.put(c1.getContainerId(), c1);
    Container c2 = createContainer(2, true, 2L, true);
    containers.put(c2.getContainerId(), c2);

    ContainerExecutor ex = createContainerExecutor(containers);
    Context context = mock(Context.class);
    when(context.getContainers()).thenReturn(containers);
    when(context.getContainerExecutor()).thenReturn(ex);

    CGroupsHandler cGroupsHandler = mock(CGroupsHandler.class);
    when(cGroupsHandler.getCGroupParam(
        CGroupsHandler.CGroupController.MEMORY,
        """",
        CGROUP_PARAM_MEMORY_OOM_CONTROL))
        .thenReturn(""under_oom 1"").thenReturn(""under_oom 0"");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1234"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c1.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PROCS_FILE))
        .thenReturn(""1235"").thenReturn("""");
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PARAM_MEMORY_USAGE_BYTES))
        .thenReturn(getMB(9));
    when(cGroupsHandler.getCGroupParam(CGroupsHandler.CGroupController.MEMORY,
        c2.getContainerId().toString(), CGROUP_PARAM_MEMORY_MEMSW_USAGE_BYTES))
        .thenReturn(getMB(9));

    DefaultOOMHandler handler =
        new DefaultOOMHandler(context, false) {
          @Override
          protected CGroupsHandler getCGroupsHandler() {
            return cGroupsHandler;
          }",1
"@Test
  public void testLifeCycle() {
    NetworkPacketTaggingHandlerImpl handlerImpl =
        createNetworkPacketTaggingHandlerImpl();
    try {
      handlerImpl.bootstrap(conf);
      testPreStart(handlerImpl);
      testPostComplete(handlerImpl);
    }",1
"@Test
  public void testLifeCycle() {
    TrafficController trafficControllerSpy = spy(new TrafficController(conf,
        privilegedOperationExecutorMock));
    TrafficControlBandwidthHandlerImpl handlerImpl = new
        TrafficControlBandwidthHandlerImpl(privilegedOperationExecutorMock,
        cGroupsHandlerMock, trafficControllerSpy);

    try {
      handlerImpl.bootstrap(conf);
      testPreStart(trafficControllerSpy, handlerImpl);
      testPostComplete(trafficControllerSpy, handlerImpl);
    }",1
"@Test
  public void testLifeCycle() {
    TrafficController trafficControllerSpy = spy(new TrafficController(conf,
        privilegedOperationExecutorMock));
    TrafficControlBandwidthHandlerImpl handlerImpl = new
        TrafficControlBandwidthHandlerImpl(privilegedOperationExecutorMock,
        cGroupsHandlerMock, trafficControllerSpy);

    try {
      handlerImpl.bootstrap(conf);
      testPreStart(trafficControllerSpy, handlerImpl);
      testPostComplete(trafficControllerSpy, handlerImpl);
    }",1
"@Test
  public void testBootstrapRecoveryEnabled() {
    conf.setBoolean(YarnConfiguration.NM_RECOVERY_ENABLED, true);

    TrafficController trafficController = new TrafficController(conf,
        privilegedOperationExecutorMock);

    try {
      //Return a default tc state when attempting to read state
      when(privilegedOperationExecutorMock.executePrivilegedOperation(
          any(PrivilegedOperation.class), eq(true)))
          .thenReturn(DEFAULT_TC_STATE_EXAMPLE);

      trafficController
          .bootstrap(DEVICE, ROOT_BANDWIDTH_MBIT, YARN_BANDWIDTH_MBIT);

      ArgumentCaptor<PrivilegedOperation> readOpCaptor = ArgumentCaptor.forClass
          (PrivilegedOperation.class);

      //NM_RECOVERY_ENABLED - so we expect three privileged operation executions
      //1) read tc state 2) wipe tc state 3) init tc state
      //one for wiping tc state - a second for initializing state
      //First, verify read op
      verify(privilegedOperationExecutorMock, times(1))
          .executePrivilegedOperation(readOpCaptor.capture(), eq(true));
      List<PrivilegedOperation> readOps = readOpCaptor.getAllValues();
      verifyTrafficControlOperation(readOps.get(0),
          PrivilegedOperation.OperationType.TC_READ_STATE,
          Arrays.asList(READ_QDISC_CMD, READ_FILTER_CMD, READ_CLASS_CMD));

      ArgumentCaptor<PrivilegedOperation> writeOpCaptor = ArgumentCaptor
          .forClass(PrivilegedOperation.class);
      verify(privilegedOperationExecutorMock, times(2))
          .executePrivilegedOperation(writeOpCaptor.capture(), eq(false));
      //Now verify that the two write operations were correct
      List<PrivilegedOperation> writeOps = writeOpCaptor.getAllValues();
      verifyTrafficControlOperation(writeOps.get(0),
          PrivilegedOperation.OperationType.TC_MODIFY_STATE,
          Arrays.asList(WIPE_STATE_CMD));

      verifyTrafficControlOperation(writeOps.get(1),
          PrivilegedOperation.OperationType.TC_MODIFY_STATE,
          Arrays.asList(ADD_ROOT_QDISC_CMD, ADD_CGROUP_FILTER_CMD,
              ADD_ROOT_CLASS_CMD, ADD_DEFAULT_CLASS_CMD, ADD_YARN_CLASS_CMD));
    }",1
"@Test
  public void testInvalidBuilder() {
    conf.setBoolean(YarnConfiguration.NM_RECOVERY_ENABLED, false);

    TrafficController trafficController = new TrafficController(conf,
        privilegedOperationExecutorMock);
    try {
      trafficController
          .bootstrap(DEVICE, ROOT_BANDWIDTH_MBIT, YARN_BANDWIDTH_MBIT);

      try {
        //Invalid op type for TC batch builder
        TrafficController.BatchBuilder invalidBuilder = trafficController.
            new BatchBuilder(
            PrivilegedOperation.OperationType.ADD_PID_TO_CGROUP);
        Assert.fail(""Invalid builder check failed!"");
      }",1
"@Test
  public void testExecuteDockerCommand() throws Exception {
    DockerStopCommand dockerStopCommand =
        new DockerStopCommand(MOCK_CONTAINER_ID);
    DockerCommandExecutor.executeDockerCommand(dockerStopCommand,
        cId.toString(), env, mockExecutor, false, nmContext);
    List<PrivilegedOperation> ops = MockPrivilegedOperationCaptor
        .capturePrivilegedOperations(mockExecutor, 1, true);
    assertEquals(1, ops.size());
    assertEquals(PrivilegedOperation.OperationType.RUN_DOCKER_CMD.name(),
        ops.get(0).getOperationType().name());
  }",1
"@Test
  public void testExecuteDockerKillSIGKILL() throws Exception {
    DockerKillCommand dockerKillCommand =
        new DockerKillCommand(MOCK_CONTAINER_ID)
            .setSignal(ContainerExecutor.Signal.KILL.name());
    DockerCommandExecutor.executeDockerCommand(dockerKillCommand,
        MOCK_CONTAINER_ID, env, mockExecutor, false, nmContext);
    List<PrivilegedOperation> ops = MockPrivilegedOperationCaptor
        .capturePrivilegedOperations(mockExecutor, 1, true);
    List<String> dockerCommands = getValidatedDockerCommands(ops);
    assertEquals(1, ops.size());
    assertEquals(PrivilegedOperation.OperationType.RUN_DOCKER_CMD.name(),
        ops.get(0).getOperationType().name());
    assertEquals(4, dockerCommands.size());
    assertEquals(""[docker-command-execution]"", dockerCommands.get(0));
    assertEquals(""  docker-command=kill"", dockerCommands.get(1));
    assertEquals(""  name="" + MOCK_CONTAINER_ID, dockerCommands.get(2));
    assertEquals(""  signal="" + ContainerExecutor.Signal.KILL.name(),
        dockerCommands.get(3));
  }",1
"@Test
  public void testExecuteDockerRmWithCgroup() throws Exception {
    DockerRmCommand dockerCommand =
        new DockerRmCommand(MOCK_CONTAINER_ID, MOCK_CGROUP_HIERARCHY);
    DockerCommandExecutor.executeDockerCommand(dockerCommand, MOCK_CONTAINER_ID,
        env, mockExecutor, false, nmContext);
    List<PrivilegedOperation> ops = MockPrivilegedOperationCaptor
        .capturePrivilegedOperations(mockExecutor, 1, true);
    PrivilegedOperation privOp = ops.get(0);
    List<String> args = privOp.getArguments();
    assertEquals(1, ops.size());
    assertEquals(PrivilegedOperation.OperationType.
            REMOVE_DOCKER_CONTAINER.name(),
        privOp.getOperationType().name());
    assertEquals(2, args.size());
    assertEquals(MOCK_CGROUP_HIERARCHY, args.get(0));
    assertEquals(MOCK_CONTAINER_ID, args.get(1));
  }",1
"@Test
  public void testExecuteDockerStop() throws Exception {
    DockerStopCommand dockerCommand = new DockerStopCommand(MOCK_CONTAINER_ID);
    DockerCommandExecutor.executeDockerCommand(dockerCommand, MOCK_CONTAINER_ID,
        env, mockExecutor, false, nmContext);
    List<PrivilegedOperation> ops = MockPrivilegedOperationCaptor
        .capturePrivilegedOperations(mockExecutor, 1, true);
    List<String> dockerCommands = getValidatedDockerCommands(ops);
    assertEquals(1, ops.size());
    assertEquals(PrivilegedOperation.OperationType.RUN_DOCKER_CMD.name(),
        ops.get(0).getOperationType().name());
    assertEquals(3, dockerCommands.size());
    assertEquals(""[docker-command-execution]"", dockerCommands.get(0));
    assertEquals(""  docker-command=stop"", dockerCommands.get(1));
    assertEquals(""  name="" + MOCK_CONTAINER_ID, dockerCommands.get(2));
  }",1
"@Test
  public void testJavaSandboxNotAllowedButPermissiveDockerRequested()
      throws Exception {
    env.put(ContainerRuntimeConstants.ENV_CONTAINER_TYPE,
        ContainerRuntimeConstants.CONTAINER_RUNTIME_DOCKER);
    conf.set(YarnConfiguration.LINUX_CONTAINER_RUNTIME_ALLOWED_RUNTIMES,
        ""default,docker"");
    conf.set(YarnConfiguration.YARN_CONTAINER_SANDBOX, ""permissive"");
    delegatingLinuxContainerRuntime.initialize(conf, null);
    ContainerRuntime runtime =
        delegatingLinuxContainerRuntime.pickContainerRuntime(env);
    assertTrue(runtime instanceof DockerLinuxContainerRuntime);
  }",1
"@Test
  public void testNotifySCMFail() throws Exception {
    Configuration conf = new Configuration();
    conf.setBoolean(YarnConfiguration.SHARED_CACHE_ENABLED, true);
    LocalResource resource = mock(LocalResource.class);
    Path localPath = mock(Path.class);
    when(localPath.getName()).thenReturn(""foo.jar"");
    String user = ""joe"";
    FileSystem fs = mock(FileSystem.class);
    // return false when rename is called
    when(fs.rename(isA(Path.class), isA(Path.class))).thenReturn(true);
    FileSystem localFs = FileSystem.getLocal(conf);
    SharedCacheUploader spied =
        createSpiedUploader(resource, localPath, user, conf, null, fs,
            localFs);
    // stub verifyAccess() to return true
    doReturn(true).when(spied).verifyAccess();
    // stub getActualPath()
    doReturn(localPath).when(spied).getActualPath();
    // stub computeChecksum()
    doReturn(""abcdef0123456789"").when(spied).computeChecksum(isA(Path.class));
    // stub uploadFile() to return true
    doReturn(true).when(spied).uploadFile(isA(Path.class), isA(Path.class));
    // stub notifySharedCacheManager to return true
    doReturn(false).when(spied).notifySharedCacheManager(isA(String.class),
        isA(String.class));

    assertFalse(spied.call());
    verify(fs).delete(isA(Path.class), anyBoolean());
  }",1
"@Test
  public void testSuccess() throws Exception {
    Configuration conf = new Configuration();
    conf.setBoolean(YarnConfiguration.SHARED_CACHE_ENABLED, true);
    LocalResource resource = mock(LocalResource.class);
    Path localPath = mock(Path.class);
    when(localPath.getName()).thenReturn(""foo.jar"");
    String user = ""joe"";
    SCMUploaderProtocol scmClient = mock(SCMUploaderProtocol.class);
    SCMUploaderNotifyResponse response = mock(SCMUploaderNotifyResponse.class);
    when(response.getAccepted()).thenReturn(true);
    when(scmClient.notify(isA(SCMUploaderNotifyRequest.class))).
        thenReturn(response);
    FileSystem fs = mock(FileSystem.class);
    // return false when rename is called
    when(fs.rename(isA(Path.class), isA(Path.class))).thenReturn(true);
    FileSystem localFs = FileSystem.getLocal(conf);
    SharedCacheUploader spied =
        createSpiedUploader(resource, localPath, user, conf, scmClient, fs,
            localFs);
    // stub verifyAccess() to return true
    doReturn(true).when(spied).verifyAccess();
    // stub getActualPath()
    doReturn(localPath).when(spied).getActualPath();
    // stub computeChecksum()
    doReturn(""abcdef0123456789"").when(spied).computeChecksum(isA(Path.class));
    // stub uploadFile() to return true
    doReturn(true).when(spied).uploadFile(isA(Path.class), isA(Path.class));
    // stub notifySharedCacheManager to return true
    doReturn(true).when(spied).notifySharedCacheManager(isA(String.class),
        isA(String.class));

    assertTrue(spied.call());
  }",1
"@Test
  public void testMain() throws Exception {
    ContainerLocalizerWrapper wrapper = new ContainerLocalizerWrapper();
    ContainerLocalizer localizer =
        wrapper.setupContainerLocalizerForTest();
    Random random = wrapper.random;
    List<Path> localDirs = wrapper.localDirs;
    Path tokenPath = wrapper.tokenPath;
    LocalizationProtocol nmProxy = wrapper.nmProxy;
    AbstractFileSystem spylfs = wrapper.spylfs;
    mockOutDownloads(localizer);

    // verify created cache
    List<Path> privCacheList = new ArrayList<Path>();
    List<Path> appCacheList = new ArrayList<Path>();
    for (Path p : localDirs) {
      Path base = new Path(new Path(p, ContainerLocalizer.USERCACHE), appUser);
      Path privcache = new Path(base, ContainerLocalizer.FILECACHE);
      privCacheList.add(privcache);
      Path appDir =
          new Path(base, new Path(ContainerLocalizer.APPCACHE, appId));
      Path appcache = new Path(appDir, ContainerLocalizer.FILECACHE);
      appCacheList.add(appcache);
    }",1
"@Test
  public void testMultipleLocalizers() throws Exception {
    FakeContainerLocalizerWrapper testA = new FakeContainerLocalizerWrapper();
    FakeContainerLocalizerWrapper testB = new FakeContainerLocalizerWrapper();

    FakeContainerLocalizer localizerA = testA.init();
    FakeContainerLocalizer localizerB = testB.init();

    // run localization
    Thread threadA = new Thread() {
      @Override
      public void run() {
        try {
          localizerA.runLocalization(nmAddr);
        }",1
"@Test
  public void testAggregatorWhenAllFilesOlderThanRetentionShouldUploadNone()
      throws IOException {

    final ApplicationId applicationId =
        ApplicationId.newInstance(System.currentTimeMillis(), 0);
    final ApplicationAttemptId attemptId =
        ApplicationAttemptId.newInstance(applicationId, 0);
    final ContainerId containerId = ContainerId.newContainerId(attemptId, 0);

    // create artificial log files
    final File appLogDir = new File(LOCAL_LOG_DIR,
        applicationId.toString());
    final File containerLogDir = new File(appLogDir,
        containerId.toString());
    containerLogDir.mkdirs();
    final Set<File> logFiles = createContainerLogFiles(containerLogDir, 3);


    final long week = 7 * 24 * 60 * 60;
    final long recoveredLogInitedTimeMillis = System.currentTimeMillis() -
        2 * week * 1000;
    verifyLogAggregationWithExpectedFiles2DeleteAndUpload(
        applicationId, containerId, week, recoveredLogInitedTimeMillis,
        logFiles, new HashSet<File>());
  }",1
"@Test
  public void testLogAggregationCreateDirsFailsWithoutKillingNM()
      throws Exception {

    this.conf.set(YarnConfiguration.NM_LOG_DIRS,
        localLogDir.getAbsolutePath());
    this.conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,
        this.remoteRootLogDir.getAbsolutePath());

    DeletionService spyDelSrvc = spy(this.delSrvc);
    LogAggregationFileControllerFactory factory
        = new LogAggregationFileControllerFactory(conf);
    LogAggregationFileController logAggregationFileFormat = factory
        .getFileControllerForWrite();
    LogAggregationFileController spyLogAggregationFileFormat =
        spy(logAggregationFileFormat);
    Exception e =
        new YarnRuntimeException(new SecretManager.InvalidToken(""KABOOM!""));
    doThrow(e).when(spyLogAggregationFileFormat)
        .createAppDir(any(String.class), any(ApplicationId.class),
            any(UserGroupInformation.class));
    LogAggregationService logAggregationService = spy(
        new LogAggregationService(dispatcher, this.context, spyDelSrvc,
            super.dirsHandler){
        @Override
        public LogAggregationFileController getLogAggregationFileController(
            Configuration conf) {
          return spyLogAggregationFileFormat;
        }",1
"@Test
  public void testLogAggregatorCleanup() throws Exception {
    DeletionService delSrvc = mock(DeletionService.class);

    // get the AppLogAggregationImpl thread to crash
    LocalDirsHandlerService mockedDirSvc = mock(LocalDirsHandlerService.class);

    LogAggregationService logAggregationService =
        new LogAggregationService(dispatcher, this.context, delSrvc,
                                  mockedDirSvc);
    logAggregationService.init(this.conf);
    logAggregationService.start();

    ApplicationId application1 = BuilderUtils.newApplicationId(1234, 1);
    logAggregationService.handle(new LogHandlerAppStartedEvent(
            application1, this.user, null, this.acls));

    logAggregationService.handle(new LogHandlerAppFinishedEvent(application1));
    dispatcher.await();
    int timeToWait = 20 * 1000;
    while (timeToWait > 0 && logAggregationService.getNumAggregators() > 0) {
      Thread.sleep(100);
      timeToWait -= 100;
    }",1
"@Test
  public void testNoContainerOnNode() throws Exception {
    this.conf.set(YarnConfiguration.NM_LOG_DIRS, localLogDir.getAbsolutePath());
    this.conf.set(YarnConfiguration.NM_REMOTE_APP_LOG_DIR,
        this.remoteRootLogDir.getAbsolutePath());
    
    LogAggregationService logAggregationService =
        new LogAggregationService(dispatcher, this.context, this.delSrvc,
                                  super.dirsHandler);
    logAggregationService.init(this.conf);
    logAggregationService.start();

    ApplicationId application1 = BuilderUtils.newApplicationId(1234, 1);

    // AppLogDir should be created
    File app1LogDir =
      new File(localLogDir, application1.toString());
    app1LogDir.mkdir();
    logAggregationService
        .handle(new LogHandlerAppStartedEvent(
            application1, this.user, null, this.acls));

    logAggregationService.handle(new LogHandlerAppFinishedEvent(
        application1));

    logAggregationService.stop();
    assertEquals(0, logAggregationService.getNumAggregators());
    LogAggregationFileController format1 =
        logAggregationService.getLogAggregationFileController(conf);
    Assert.assertFalse(new File(format1.getRemoteNodeLogFileForApp(
        application1, this.user, this.nodeId).toUri().getPath())
        .exists());

    dispatcher.await();
    
    ApplicationEvent expectedEvents[] = new ApplicationEvent[]{
        new ApplicationEvent(
            application1,
            ApplicationEventType.APPLICATION_LOG_HANDLING_INITED),
        new ApplicationEvent(
            application1,
            ApplicationEventType.APPLICATION_LOG_HANDLING_FINISHED)
    }",1
"@Test
  public void testContainerMetricsFlow() throws InterruptedException {
    final String ERR = ""Error in number of records"";

    MetricsCollectorImpl collector = new MetricsCollectorImpl();
    ContainerId containerId = mock(ContainerId.class);
    ContainerMetrics metrics = ContainerMetrics.forContainer(containerId,
        100, 1);

    metrics.recordMemoryUsage(1024);
    metrics.getMetrics(collector, true);
    assertEquals(ERR, 0, collector.getRecords().size());

    Thread.sleep(110);
    metrics.getMetrics(collector, true);
    assertEquals(ERR, 1, collector.getRecords().size());
    collector.clear();

    Thread.sleep(110);
    metrics.getMetrics(collector, true);
    assertEquals(ERR, 1, collector.getRecords().size());
    collector.clear();

    metrics.finished(false);
    metrics.getMetrics(collector, true);
    assertEquals(ERR, 1, collector.getRecords().size());
    collector.clear();

    metrics.getMetrics(collector, true);
    assertEquals(ERR, 1, collector.getRecords().size());
    collector.clear();

    Thread.sleep(110);
    metrics.getMetrics(collector, true);
    assertEquals(ERR, 1, collector.getRecords().size());
  }",1
"@Test
  public void testAuxServicesMeta() throws IOException {
    Configuration conf = getABConf();
    final AuxServices aux = new AuxServices(MOCK_AUX_PATH_HANDLER,
        MOCK_CONTEXT, MOCK_DEL_SERVICE);
    aux.init(conf);

    int latch = 1;
    for (Service s : aux.getServices()) {
      assertEquals(INITED, s.getServiceState());
      if (s instanceof ServiceA) { latch *= 2; }",1
"@Test
  public void testChangeContainerResource() throws Exception {
    containerManager.start();
    File scriptFile = Shell.appendScriptExtension(tmpDir, ""scriptFile"");
    PrintWriter fileWriter = new PrintWriter(scriptFile);
    // Construct the Container-id
    ContainerId cId = createContainerId(0);
    if (Shell.WINDOWS) {
      fileWriter.println(""@ping -n 100 127.0.0.1 >nul"");
    }",1
"@Test
  public void testMultipleContainersLaunch() throws Exception {
    containerManager.start();

    List<StartContainerRequest> list = new ArrayList<>();
    for (int i = 0; i < 10; i++) {
      ContainerId cId = createContainerId(i);
      long identifier = 0;
      if ((i & 1) == 0)
        // container with even id fail
        identifier = ResourceManagerConstants.RM_INVALID_IDENTIFIER;
      else
        identifier = DUMMY_RM_IDENTIFIER;
      Token containerToken =
          createContainerToken(cId, identifier, context.getNodeId(), user,
            context.getContainerTokenSecretManager());
      StartContainerRequest request =
          StartContainerRequest.newInstance(
              recordFactory.newRecordInstance(ContainerLaunchContext.class),
              containerToken);
      list.add(request);
    }",1
"@Test
  public void testStartContainerFailureWithNullTypeLocalResource()
      throws Exception {
    containerManager.start();
    LocalResource rsrc_alpha =
        recordFactory.newRecordInstance(LocalResource.class);
    rsrc_alpha.setResource(URL.fromPath(new Path(""./"")));
    rsrc_alpha.setSize(-1);
    rsrc_alpha.setVisibility(LocalResourceVisibility.APPLICATION);
    rsrc_alpha.setType(null);
    rsrc_alpha.setTimestamp(System.currentTimeMillis());
    Map<String, LocalResource> localResources =
        new HashMap<String, LocalResource>();
    localResources.put(""null_type_resource"", rsrc_alpha);
    ContainerLaunchContext containerLaunchContext =
        recordFactory.newRecordInstance(ContainerLaunchContext.class);
    ContainerLaunchContext spyContainerLaunchContext =
        spy(containerLaunchContext);
    Mockito.when(spyContainerLaunchContext.getLocalResources())
        .thenReturn(localResources);

    ContainerId cId = createContainerId(0);
    String user = ""start_container_fail"";
    Token containerToken =
        createContainerToken(cId, DUMMY_RM_IDENTIFIER, context.getNodeId(),
            user, context.getContainerTokenSecretManager());
    StartContainerRequest request = StartContainerRequest
        .newInstance(spyContainerLaunchContext, containerToken);

    // start containers
    List<StartContainerRequest> startRequest =
        new ArrayList<StartContainerRequest>();
    startRequest.add(request);
    StartContainersRequest requestList =
        StartContainersRequest.newInstance(startRequest);

    StartContainersResponse response =
        containerManager.startContainers(requestList);
    Assert.assertTrue(response.getFailedRequests().size() == 1);
    Assert.assertTrue(response.getSuccessfullyStartedContainers().size() == 0);
    Assert.assertTrue(response.getFailedRequests().containsKey(cId));
    Assert.assertTrue(response.getFailedRequests().get(cId).getMessage()
        .contains(""Null resource type for local resource""));
  }",1
"@Test
  public void testStartContainerFailureWithUnknownAuxService() throws Exception {
    conf.setStrings(YarnConfiguration.NM_AUX_SERVICES,
        new String[] { ""existService"" }",1
"@Test
  public void testParseConfiguration() throws IOException {
    // ATTRIBUTE_NAME,ATTRIBUTE_TYPE,ATTRIBUTE_VALUE
    String attributesStr = ""hostname,STRING,host1234:uptime,STRING,321543"";
    Set<NodeAttribute> attributes = nodeAttributesProvider
        .parseAttributes(attributesStr);
    Assert.assertEquals(2, attributes.size());
    Iterator<NodeAttribute> ait = attributes.iterator();

    while(ait.hasNext()) {
      NodeAttribute attr = ait.next();
      NodeAttributeKey at = attr.getAttributeKey();
      if (at.getAttributeName().equals(""hostname"")) {
        Assert.assertEquals(""hostname"", at.getAttributeName());
        Assert.assertEquals(NodeAttribute.PREFIX_DISTRIBUTED,
            at.getAttributePrefix());
        Assert.assertEquals(NodeAttributeType.STRING,
            attr.getAttributeType());
        Assert.assertEquals(""host1234"", attr.getAttributeValue());
      }",1
"@Test
  public void testFetchInterval() throws Exception {
    // The script returns the pid (as an attribute) each time runs this script
    String simpleScript = ""echo NODE_ATTRIBUTE:pid,STRING,$$"";
    writeNodeAttributeScriptFile(simpleScript, true);

    nodeAttributesProvider.init(getConfForNodeAttributeScript());
    nodeAttributesProvider.start();

    // Wait for at most 3 seconds until we get at least 1
    // different attribute value.
    Set<String> resultSet = new HashSet<>();
    GenericTestUtils.waitFor(() -> {
      Set<NodeAttribute> attributes =
          nodeAttributesProvider.getDescriptors();
      if (attributes != null) {
        Assert.assertEquals(1, attributes.size());
        resultSet.add(attributes.iterator().next().getAttributeValue());
        return resultSet.size() > 1;
      }",1
"@Test
  public void testContainerTokenStorage() throws IOException {
    // test empty when no state
    RecoveredContainerTokensState state =
        stateStore.loadContainerTokensState();
    Map<ContainerId, Long> loadedActiveTokens = loadContainerTokens(state.it);
    assertNull(state.getCurrentMasterKey());
    assertNull(state.getPreviousMasterKey());
    assertTrue(loadedActiveTokens.isEmpty());

    // store a master key and verify recovered
    ContainerTokenKeyGeneratorForTest keygen =
        new ContainerTokenKeyGeneratorForTest(new YarnConfiguration());
    MasterKey currentKey = keygen.generateKey();
    stateStore.storeContainerTokenCurrentMasterKey(currentKey);
    restartStateStore();
    state = stateStore.loadContainerTokensState();
    loadedActiveTokens = loadContainerTokens(state.it);
    assertEquals(currentKey, state.getCurrentMasterKey());
    assertNull(state.getPreviousMasterKey());
    assertTrue(loadedActiveTokens.isEmpty());

    // store a previous key and verify recovered
    MasterKey prevKey = keygen.generateKey();
    stateStore.storeContainerTokenPreviousMasterKey(prevKey);
    restartStateStore();
    state = stateStore.loadContainerTokensState();
    loadedActiveTokens = loadContainerTokens(state.it);
    assertEquals(currentKey, state.getCurrentMasterKey());
    assertEquals(prevKey, state.getPreviousMasterKey());
    assertTrue(loadedActiveTokens.isEmpty());

    // store a few container tokens and verify recovered
    ContainerId cid1 = BuilderUtils.newContainerId(1, 1, 1, 1);
    Long expTime1 = 1234567890L;
    ContainerId cid2 = BuilderUtils.newContainerId(2, 2, 2, 2);
    Long expTime2 = 9876543210L;
    stateStore.storeContainerToken(cid1, expTime1);
    stateStore.storeContainerToken(cid2, expTime2);
    restartStateStore();
    state = stateStore.loadContainerTokensState();
    loadedActiveTokens = loadContainerTokens(state.it);
    assertEquals(currentKey, state.getCurrentMasterKey());
    assertEquals(prevKey, state.getPreviousMasterKey());
    assertEquals(2, loadedActiveTokens.size());
    assertEquals(expTime1, loadedActiveTokens.get(cid1));
    assertEquals(expTime2, loadedActiveTokens.get(cid2));

    // add/update/remove tokens and verify recovered
    ContainerId cid3 = BuilderUtils.newContainerId(3, 3, 3, 3);
    Long expTime3 = 135798642L;
    stateStore.storeContainerToken(cid3, expTime3);
    stateStore.removeContainerToken(cid1);
    expTime2 += 246897531L;
    stateStore.storeContainerToken(cid2, expTime2);
    prevKey = currentKey;
    stateStore.storeContainerTokenPreviousMasterKey(prevKey);
    currentKey = keygen.generateKey();
    stateStore.storeContainerTokenCurrentMasterKey(currentKey);
    restartStateStore();
    state = stateStore.loadContainerTokensState();
    loadedActiveTokens = loadContainerTokens(state.it);
    assertEquals(currentKey, state.getCurrentMasterKey());
    assertEquals(prevKey, state.getPreviousMasterKey());
    assertEquals(2, loadedActiveTokens.size());
    assertNull(loadedActiveTokens.get(cid1));
    assertEquals(expTime2, loadedActiveTokens.get(cid2));
    assertEquals(expTime3, loadedActiveTokens.get(cid3));
  }",1
"@Test
  public void testFinishResourceLocalizationForApplicationResource()
      throws IOException {
    String user = ""somebody"";
    ApplicationId appId = ApplicationId.newInstance(1, 1);

    // start and finish a local resource for an application
    Path appRsrcPath = new Path(""hdfs://some/app/resource"");
    LocalResourcePBImpl rsrcPb = (LocalResourcePBImpl)
        LocalResource.newInstance(
            URL.fromPath(appRsrcPath),
            LocalResourceType.ARCHIVE, LocalResourceVisibility.APPLICATION,
            123L, 456L);
    LocalResourceProto appRsrcProto = rsrcPb.getProto();
    Path appRsrcLocalPath = new Path(""/some/local/dir/for/apprsrc"");
    stateStore.startResourceLocalization(user, appId, appRsrcProto,
        appRsrcLocalPath);
    LocalizedResourceProto appLocalizedProto =
        LocalizedResourceProto.newBuilder()
          .setResource(appRsrcProto)
          .setLocalPath(appRsrcLocalPath.toString())
          .setSize(1234567L)
          .build();
    stateStore.finishResourceLocalization(user, appId, appLocalizedProto);

    List<LocalizedResourceProto> completedResources =
        new ArrayList<LocalizedResourceProto>();
    Map<LocalResourceProto, Path> startedResources =
        new HashMap<LocalResourceProto, Path>();

    // restart and verify only app resource is completed
    restartStateStore();
    RecoveredLocalizationState state = stateStore.loadLocalizationState();
    LocalResourceTrackerState pubts = state.getPublicTrackerState();
    completedResources = loadCompletedResources(
        pubts.getCompletedResourcesIterator());
    startedResources = loadStartedResources(
        pubts.getStartedResourcesIterator());
    assertTrue(completedResources.isEmpty());
    assertTrue(startedResources.isEmpty());
    Map<String, RecoveredUserResources> userResources =
        loadUserResources(state.getIterator());
    assertEquals(1, userResources.size());
    RecoveredUserResources rur = userResources.get(user);
    LocalResourceTrackerState privts = rur.getPrivateTrackerState();
    assertNotNull(privts);
    completedResources = loadCompletedResources(
        privts.getCompletedResourcesIterator());
    startedResources = loadStartedResources(
        privts.getStartedResourcesIterator());
    assertTrue(completedResources.isEmpty());
    assertTrue(startedResources.isEmpty());
    assertEquals(1, rur.getAppTrackerStates().size());
    LocalResourceTrackerState appts = rur.getAppTrackerStates().get(appId);
    assertNotNull(appts);
    completedResources = loadCompletedResources(
        appts.getCompletedResourcesIterator());
    startedResources = loadStartedResources(
        appts.getStartedResourcesIterator());
    assertTrue(startedResources.isEmpty());
    assertEquals(1, completedResources.size());
    assertEquals(appLocalizedProto,
        completedResources.iterator().next());
  }",1
"@Test
  public void testLogDeleterStorage() throws IOException {
    // test empty when no state
    RecoveredLogDeleterState state = stateStore.loadLogDeleterState();
    assertTrue(state.getLogDeleterMap().isEmpty());

    // store log deleter state
    final ApplicationId appId1 = ApplicationId.newInstance(1, 1);
    LogDeleterProto proto1 = LogDeleterProto.newBuilder()
        .setUser(""user1"")
        .setDeletionTime(1234)
        .build();
    stateStore.storeLogDeleter(appId1, proto1);

    // restart state store and verify recovered
    restartStateStore();
    state = stateStore.loadLogDeleterState();
    assertEquals(1, state.getLogDeleterMap().size());
    assertEquals(proto1, state.getLogDeleterMap().get(appId1));

    // store another log deleter
    final ApplicationId appId2 = ApplicationId.newInstance(2, 2);
    LogDeleterProto proto2 = LogDeleterProto.newBuilder()
        .setUser(""user2"")
        .setDeletionTime(5678)
        .build();
    stateStore.storeLogDeleter(appId2, proto2);

    // restart state store and verify recovered
    restartStateStore();
    state = stateStore.loadLogDeleterState();
    assertEquals(2, state.getLogDeleterMap().size());
    assertEquals(proto1, state.getLogDeleterMap().get(appId1));
    assertEquals(proto2, state.getLogDeleterMap().get(appId2));

    // remove a deleter and verify removed after restart and recovery
    stateStore.removeLogDeleter(appId1);
    restartStateStore();
    state = stateStore.loadLogDeleterState();
    assertEquals(1, state.getLogDeleterMap().size());
    assertEquals(proto2, state.getLogDeleterMap().get(appId2));

    // remove last deleter and verify empty after restart and recovery
    stateStore.removeLogDeleter(appId2);
    restartStateStore();
    state = stateStore.loadLogDeleterState();
    assertTrue(state.getLogDeleterMap().isEmpty());
  }",1
"@Test
  public void testRemoveLocalizedResourceForApplicationResource()
      throws IOException {
    String user = ""somebody"";
    ApplicationId appId = ApplicationId.newInstance(1, 1);

    // go through the complete lifecycle for an application local resource
    Path appRsrcPath = new Path(""hdfs://some/app/resource"");
    LocalResourcePBImpl rsrcPb = (LocalResourcePBImpl)
        LocalResource.newInstance(
            URL.fromPath(appRsrcPath),
            LocalResourceType.ARCHIVE, LocalResourceVisibility.APPLICATION,
            123L, 456L);
    LocalResourceProto appRsrcProto = rsrcPb.getProto();
    Path appRsrcLocalPath = new Path(""/some/local/dir/for/apprsrc"");
    stateStore.startResourceLocalization(user, appId, appRsrcProto,
        appRsrcLocalPath);
    LocalizedResourceProto appLocalizedProto =
        LocalizedResourceProto.newBuilder()
          .setResource(appRsrcProto)
          .setLocalPath(appRsrcLocalPath.toString())
          .setSize(1234567L)
          .build();
    stateStore.finishResourceLocalization(user, appId, appLocalizedProto);
    stateStore.removeLocalizedResource(user, appId, appRsrcLocalPath);

    restartStateStore();
    verifyEmptyState();

    // remove an app resource that didn't finish
    stateStore.startResourceLocalization(user, appId, appRsrcProto,
        appRsrcLocalPath);
    stateStore.removeLocalizedResource(user, appId, appRsrcLocalPath);

    restartStateStore();
    verifyEmptyState();
  }",1
"@Test
  public void testUnexpectedKeyDoesntThrowException() throws IOException {
    // test empty when no state
    List<RecoveredContainerState> recoveredContainers =
        loadContainersState(stateStore.getContainerStateIterator());
    assertTrue(recoveredContainers.isEmpty());

    ApplicationId appId = ApplicationId.newInstance(1234, 3);
    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(appId,
        4);
    ContainerId containerId = ContainerId.newContainerId(appAttemptId, 5);
    StartContainerRequest startContainerRequest = storeMockContainer(
        containerId);

    // add a invalid key
    byte[] invalidKey = (""ContainerManager/containers/""
    + containerId.toString() + ""/invalidKey1234"").getBytes();
    stateStore.getDB().put(invalidKey, new byte[1]);
    restartStateStore();
    recoveredContainers =
        loadContainersState(stateStore.getContainerStateIterator());
    assertEquals(1, recoveredContainers.size());
    RecoveredContainerState rcs = recoveredContainers.get(0);
    assertEquals(RecoveredContainerStatus.REQUESTED, rcs.getStatus());
    assertEquals(ContainerExitStatus.INVALID, rcs.getExitCode());
    assertEquals(false, rcs.getKilled());
    assertEquals(startContainerRequest, rcs.getStartRequest());
    assertTrue(rcs.getDiagnostics().isEmpty());
    assertEquals(RecoveredContainerType.KILL, rcs.getRecoveryType());
    // assert unknown keys are cleaned up finally
    assertNotNull(stateStore.getDB().get(invalidKey));
    stateStore.removeContainer(containerId);
    assertNull(stateStore.getDB().get(invalidKey));
  }",1
"@Test
  public void testPickDirectory() throws Exception {
    Configuration conf = new Configuration();
    FileContext lfs = FileContext.getLocalFSFileContext(conf);
    DefaultContainerExecutor executor = new DefaultContainerExecutor(lfs);

    long[] availableOnDisk = new long[2];
    availableOnDisk[0] = 100;
    availableOnDisk[1] = 100;
    assertEquals(0, executor.pickDirectory(0L, availableOnDisk));
    assertEquals(0, executor.pickDirectory(99L, availableOnDisk));
    assertEquals(1, executor.pickDirectory(100L, availableOnDisk));
    assertEquals(1, executor.pickDirectory(101L, availableOnDisk));
    assertEquals(1, executor.pickDirectory(199L, availableOnDisk));

    long[] availableOnDisk2 = new long[5];
    availableOnDisk2[0] = 100;
    availableOnDisk2[1] = 10;
    availableOnDisk2[2] = 400;
    availableOnDisk2[3] = 200;
    availableOnDisk2[4] = 350;
    assertEquals(0, executor.pickDirectory(0L, availableOnDisk2));
    assertEquals(0, executor.pickDirectory(99L, availableOnDisk2));
    assertEquals(1, executor.pickDirectory(100L, availableOnDisk2));
    assertEquals(1, executor.pickDirectory(105L, availableOnDisk2));
    assertEquals(2, executor.pickDirectory(110L, availableOnDisk2));
    assertEquals(2, executor.pickDirectory(259L, availableOnDisk2));
    assertEquals(3, executor.pickDirectory(700L, availableOnDisk2));
    assertEquals(4, executor.pickDirectory(710L, availableOnDisk2));
    assertEquals(4, executor.pickDirectory(910L, availableOnDisk2));
  }",1
"@Test
  public void testRecovery() throws Exception {
    Random r = new Random();
    long seed = r.nextLong();
    r.setSeed(seed);
    System.out.println(""SEED: "" + seed);
    List<Path> baseDirs = buildDirs(r, base, 4);
    createDirs(new Path("".""), baseDirs);
    List<Path> content = buildDirs(r, new Path("".""), 10);
    for (Path b : baseDirs) {
      createDirs(b, content);
    }",1
"@Test
  public void testConcurrentAccess() throws IOException {
    // Initialize DirectoryCollection with a file instead of a directory
    
    String[] dirs = {testFile.getPath()}",1
"@Test
  public void testNonsecureUsernamePattern() throws Exception {
    Assume.assumeTrue(shouldRun());
    try {
      // nonsecure default
      Configuration conf = new YarnConfiguration();
      conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION,
        ""simple"");
      UserGroupInformation.setConfiguration(conf);
      LinuxContainerExecutor lce = new LinuxContainerExecutor();
      lce.setConf(conf);
      lce.verifyUsernamePattern(""foo"");
      try {
        lce.verifyUsernamePattern(""foo/x"");
        fail();
      }",1
"@Test  
  public void testKeyValLogFormat() throws Exception {
    StringBuilder actLog = new StringBuilder();
    StringBuilder expLog = new StringBuilder();
    // add the first k=v pair and check
    NMAuditLogger.start(Keys.USER, USER, actLog);
    expLog.append(""USER=test"");
    assertEquals(expLog.toString(), actLog.toString());

    // append another k1=v1 pair to already added k=v and test
    NMAuditLogger.add(Keys.OPERATION, OPERATION, actLog);
    expLog.append(""\tOPERATION=oper"");
    assertEquals(expLog.toString(), actLog.toString());

    // append another k1=null pair and test
    NMAuditLogger.add(Keys.APPID, (String)null, actLog);
    expLog.append(""\tAPPID=null"");
    assertEquals(expLog.toString(), actLog.toString());

    // now add the target and check of the final string
    NMAuditLogger.add(Keys.TARGET, TARGET, actLog);
    expLog.append(""\tTARGET=tgt"");
    assertEquals(expLog.toString(), actLog.toString());
  }",1
"@Test  
  public void testNMAuditLoggerWithoutIP() throws Exception {
    // test without ip
    testSuccessLogFormat(false);
    testFailureLogFormat(false);
  }",1
"@Test
  public void testCreationOfNodeLabelsProviderService()
      throws InterruptedException {
    try {
      NodeManager nodeManager = new NodeManager();
      Configuration conf = new Configuration();
      NodeLabelsProvider labelsProviderService =
          nodeManager.createNodeLabelsProvider(conf);
      Assert
          .assertNull(
              ""LabelsProviderService should not be initialized in default configuration"",
              labelsProviderService);

      // With valid className
      conf.set(
          YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG,
          ""org.apache.hadoop.yarn.server.nodemanager.nodelabels.ConfigurationNodeLabelsProvider"");
      labelsProviderService = nodeManager.createNodeLabelsProvider(conf);
      Assert.assertNotNull(""LabelsProviderService should be initialized When ""
          + ""node labels provider class is configured"", labelsProviderService);

      // With invalid className
      conf.set(YarnConfiguration.NM_NODE_LABELS_PROVIDER_CONFIG,
          ""org.apache.hadoop.yarn.server.nodemanager.NodeManager"");
      try {
        labelsProviderService = nodeManager.createNodeLabelsProvider(conf);
        Assert.fail(""Expected to throw IOException on Invalid configuration"");
      }",1
"@Test public void testContainerResourceUsage() {
    ApplicationId appId = ApplicationId.newInstance(0, 1);
    publisher.createTimelineClient(appId);
    Container aContainer = mock(Container.class);
    when(aContainer.getContainerId()).thenReturn(ContainerId
        .newContainerId(ApplicationAttemptId.newInstance(appId, 1), 0L));
    long idPrefix = TimelineServiceHelper.invertLong(
        aContainer.getContainerId().getContainerId());
    publisher.reportContainerResourceUsage(aContainer, 1024L, 8F);
    verifyPublishedResourceUsageMetrics(timelineClient, 1024L, 8, idPrefix);
    timelineClient.reset();

    publisher.reportContainerResourceUsage(aContainer, 1024L, 0.8F);
    verifyPublishedResourceUsageMetrics(timelineClient, 1024L, 1, idPrefix);
    timelineClient.reset();

    publisher.reportContainerResourceUsage(aContainer, 1024L, 0.49F);
    verifyPublishedResourceUsageMetrics(timelineClient, 1024L, 0, idPrefix);
    timelineClient.reset();

    publisher.reportContainerResourceUsage(aContainer, 1024L,
        (float) ResourceCalculatorProcessTree.UNAVAILABLE);
    verifyPublishedResourceUsageMetrics(timelineClient, 1024L,
        ResourceCalculatorProcessTree.UNAVAILABLE, idPrefix);
  }",1
"@Test
  public void testSelectCgroup() {
    File cpu = new File(cgroupDir, ""cpu"");
    File cpuNoExist = new File(cgroupDir, ""cpuNoExist"");
    File memory = new File(cgroupDir, ""memory"");
    try {
      CgroupsLCEResourcesHandler handler = new CgroupsLCEResourcesHandler();
      Map<String, Set<String>> cgroups = new LinkedHashMap<>();

      Assert.assertTrue(""temp dir should be created"", cpu.mkdirs());
      Assert.assertTrue(""temp dir should be created"", memory.mkdirs());
      Assert.assertFalse(""temp dir should not be created"", cpuNoExist.exists());

      cgroups.put(
          memory.getAbsolutePath(), Collections.singleton(""memory""));
      cgroups.put(
          cpuNoExist.getAbsolutePath(), Collections.singleton(""cpu""));
      cgroups.put(cpu.getAbsolutePath(), Collections.singleton(""cpu""));
      String selectedCPU = handler.findControllerInMtab(""cpu"", cgroups);
      Assert.assertEquals(""Wrong CPU mount point selected"",
          cpu.getAbsolutePath(), selectedCPU);
    }",1
"@Test
  public void testGetContainerMemoryMB() throws Exception {

    ResourceCalculatorPlugin plugin = new TestResourceCalculatorPlugin();
    long physicalMemMB = plugin.getPhysicalMemorySize() / (1024 * 1024);
    YarnConfiguration conf = new YarnConfiguration();
    conf.setBoolean(YarnConfiguration.NM_ENABLE_HARDWARE_CAPABILITY_DETECTION,
        true);
    long mem = NodeManagerHardwareUtils.getContainerMemoryMB(null, conf);
    Assert.assertEquals(YarnConfiguration.DEFAULT_NM_PMEM_MB, mem);

    mem = NodeManagerHardwareUtils.getContainerMemoryMB(plugin, conf);
    int hadoopHeapSizeMB =
        (int) (Runtime.getRuntime().maxMemory() / (1024 * 1024));
    int calculatedMemMB =
        (int) (0.8 * (physicalMemMB - (2 * hadoopHeapSizeMB)));
    Assert.assertEquals(calculatedMemMB, mem);

    conf.setInt(YarnConfiguration.NM_PMEM_MB, 1024);
    mem = NodeManagerHardwareUtils.getContainerMemoryMB(conf);
    Assert.assertEquals(1024, mem);

    conf = new YarnConfiguration();
    conf.setBoolean(YarnConfiguration.NM_ENABLE_HARDWARE_CAPABILITY_DETECTION,
        false);
    mem = NodeManagerHardwareUtils.getContainerMemoryMB(conf);
    Assert.assertEquals(YarnConfiguration.DEFAULT_NM_PMEM_MB, mem);
    conf.setInt(YarnConfiguration.NM_PMEM_MB, 10 * 1024);
    mem = NodeManagerHardwareUtils.getContainerMemoryMB(conf);
    Assert.assertEquals(10 * 1024, mem);
  }",1
"@Test
  public void testLogFileWithDriveLetter() throws Exception {
    
    ContainerImpl container = mock(ContainerImpl.class);
    
    ApplicationIdPBImpl appId = mock(ApplicationIdPBImpl.class);
    when(appId.toString()).thenReturn(""appId"");
    
    Application app = mock(Application.class);
    when(app.getAppId()).thenReturn(appId);
    
    ApplicationAttemptIdPBImpl appAttemptId =
               mock(ApplicationAttemptIdPBImpl.class);
    when(appAttemptId.getApplicationId()).thenReturn(appId); 
    
    ConcurrentMap<ApplicationId, Application> applications = 
      new ConcurrentHashMap<ApplicationId, Application>();
    applications.put(appId, app);
    
    ContainerId containerId = mock(ContainerIdPBImpl.class);
    when(containerId.toString()).thenReturn(""containerId"");
    when(containerId.getApplicationAttemptId()).thenReturn(appAttemptId);
    
    ConcurrentMap<ContainerId, Container> containers = 
      new ConcurrentHashMap<ContainerId, Container>();
    
    containers.put(containerId, container);
    
    LocalDirsHandlerService localDirs = mock(LocalDirsHandlerService.class);
    when(localDirs.getLogPathToRead(""appId"" + Path.SEPARATOR + ""containerId"" +
      Path.SEPARATOR + ""fileName""))
      .thenReturn(new Path(""F:/nmlogs/appId/containerId/fileName""));
    
    NMContext context = mock(NMContext.class);
    when(context.getLocalDirsHandler()).thenReturn(localDirs);
    when(context.getApplications()).thenReturn(applications);
    when(context.getContainers()).thenReturn(containers);
    
    File logFile = ContainerLogsUtils.getContainerLogFile(containerId,
      ""fileName"", null, context);
      
    Assert.assertTrue(""logFile lost drive letter "" +
      logFile,
      logFile.toString().indexOf(""F:"" + File.separator + ""nmlogs"") > -1);
    
  }",1
"@Test
  public void testWriteApplication() throws Exception {
    RMApp app = createRMApp(ApplicationId.newInstance(0, 1));

    writer.applicationStarted(app);
    ApplicationHistoryData appHD = null;
    for (int i = 0; i < MAX_RETRIES; ++i) {
      appHD = store.getApplication(ApplicationId.newInstance(0, 1));
      if (appHD != null) {
        break;
      }",1
"@Test
  public void testWriteApplicationAttempt() throws Exception {
    RMAppAttempt appAttempt =
        createRMAppAttempt(ApplicationAttemptId.newInstance(
          ApplicationId.newInstance(0, 1), 1));
    writer.applicationAttemptStarted(appAttempt);
    ApplicationAttemptHistoryData appAttemptHD = null;
    for (int i = 0; i < MAX_RETRIES; ++i) {
      appAttemptHD =
          store.getApplicationAttempt(ApplicationAttemptId.newInstance(
            ApplicationId.newInstance(0, 1), 1));
      if (appAttemptHD != null) {
        break;
      }",1
"@Test
  public void testSimpleBlacklistAboveFailureThreshold() {
    // Create a threshold of 0.5 * 3 i.e at 1.5 node failures.
    BlacklistManager manager = new SimpleBlacklistManager(3, 0.5);
    String anyNode = ""foo"";
    String anyNode2 = ""bar"";
    manager.addNode(anyNode);
    ResourceBlacklistRequest blacklist = manager
        .getBlacklistUpdates();

    List<String> blacklistAdditions = blacklist.getBlacklistAdditions();
    Collections.sort(blacklistAdditions);
    List<String> blacklistRemovals = blacklist.getBlacklistRemovals();
    String[] expectedBlacklistAdditions = new String[]{anyNode}",1
"@Test
  public void testContainerOrdering(){

    List<RMContainer> containers = new ArrayList<RMContainer>();

    ApplicationAttemptId appAttId = ApplicationAttemptId.newInstance(
        ApplicationId.newInstance(TS, 10), 0);

    // create a set of containers
    RMContainer rm1 = mockContainer(appAttId, 5, mock(Resource.class), 3);
    RMContainer rm2 = mockContainer(appAttId, 3, mock(Resource.class), 3);
    RMContainer rm3 = mockContainer(appAttId, 2, mock(Resource.class), 2);
    RMContainer rm4 = mockContainer(appAttId, 1, mock(Resource.class), 2);
    RMContainer rm5 = mockContainer(appAttId, 4, mock(Resource.class), 1);

    // insert them in non-sorted order
    containers.add(rm3);
    containers.add(rm2);
    containers.add(rm1);
    containers.add(rm5);
    containers.add(rm4);

    // sort them
    FifoCandidatesSelector.sortContainers(containers);

    // verify the ""priority""-first, ""reverse container-id""-second
    // ordering is enforced correctly
    assert containers.get(0).equals(rm1);
    assert containers.get(1).equals(rm2);
    assert containers.get(2).equals(rm3);
    assert containers.get(3).equals(rm4);
    assert containers.get(4).equals(rm5);

  }",1
"@Test
  public void testBuilderWithSpecifiedNodeResources() throws Exception {
    String labelsConfig =
        ""=200,true;"" + // default partition
            ""red=100,false;"" + // partition=red
            ""blue=200,true""; // partition=blue
    String nodesConfig =
        ""n1=red res=100;"" + // n1 has partition=red
            ""n2=blue;"" + // n2 has partition=blue
            ""n3= res=30""; // n3 doesn't have partition
    String queuesConfig =
        // guaranteed,max,used,pending
        ""root(=[200 200 100 100 100],red=[100 100 100 100 90],blue=[200 200 200 200 80]);"" + //root
            ""-a(=[100 200 100 100 50],red=[0 0 0 0 40],blue=[200 200 200 200 30]);"" + // a
            ""--a1(=[50 100 50 100 40],red=[0 0 0 0 20],blue=[100 200 200 0]);"" + // a1
            ""--a2(=[50 200 50 0 10],red=[0 0 0 0 20],blue=[100 200 0 200]);"" + // a2
            ""-b(=[100 200 0 0],red=[100 100 100 100],blue=[0 0 0 0])"";
    String appsConfig=
        //queueName\t(priority,resource,host,expression,#repeat,reserved)
        // app1 in a1, , 50 in n2 (reserved), 50 in n2 (allocated)
        ""a1\t"" // app1 in a1
            + ""(1,1,n3,red,50,false);"" + // 50 * default in n3

            ""a1\t"" // app2 in a1
            + ""(2,1,n2,,50,true)(2,1,n2,,50,false)"" // 50 * ignore-exclusivity (reserved),
            // 50 * ignore-exclusivity (allocated)
            + ""(2,1,n2,blue,50,true)(2,1,n2,blue,50,true);"" + // 50 in n2 (reserved),
            // 50 in n2 (allocated)
            ""a2\t"" // app3 in a2
            + ""(1,1,n3,red,50,false);"" + // 50 * default in n3

            ""b\t"" // app4 in b
            + ""(1,1,n1,red,100,false);"";

    buildEnv(labelsConfig, nodesConfig, queuesConfig, appsConfig);

    // Check host resources
    Assert.assertEquals(3, this.cs.getAllNodes().size());
    SchedulerNode node1 = cs.getSchedulerNode(NodeId.newInstance(""n1"", 1));
    Assert.assertEquals(100, node1.getTotalResource().getMemorySize());
    Assert.assertEquals(100, node1.getCopiedListOfRunningContainers().size());
    Assert.assertNull(node1.getReservedContainer());

    SchedulerNode node2 = cs.getSchedulerNode(NodeId.newInstance(""n2"", 1));
    Assert.assertEquals(0, node2.getTotalResource().getMemorySize());
    Assert.assertEquals(50, node2.getCopiedListOfRunningContainers().size());
    Assert.assertNotNull(node2.getReservedContainer());

    SchedulerNode node3 = cs.getSchedulerNode(NodeId.newInstance(""n3"", 1));
    Assert.assertEquals(30, node3.getTotalResource().getMemorySize());
    Assert.assertEquals(100, node3.getCopiedListOfRunningContainers().size());
    Assert.assertNull(node3.getReservedContainer());
  }",1
"@Test
  public void testAddNodeAttributes() throws IOException {
    Map<String, Set<NodeAttribute>> toAddAttributes = new HashMap<>();
    Map<NodeAttribute, AttributeValue> nodeAttributes;

    // Add 3 attributes to host1
    //  yarn.test1.io/A1=host1_v1_1
    //  yarn.test1.io/A2=host1_v1_2
    //  yarn.test1.io/A3=host1_v1_3
    toAddAttributes.put(HOSTNAMES[0],
        createAttributesForTest(PREFIXES[0], 3, ""A"", ""host1_v1""));

    attributesManager.addNodeAttributes(toAddAttributes);
    nodeAttributes = attributesManager.getAttributesForNode(HOSTNAMES[0]);

    Assert.assertEquals(3, nodeAttributes.size());
    Assert.assertTrue(sameAttributeSet(toAddAttributes.get(HOSTNAMES[0]),
        nodeAttributes.keySet()));

    // Add 2 attributes to host2
    //  yarn.test1.io/A1=host2_v1_1
    //  yarn.test1.io/A2=host2_v1_2
    toAddAttributes.clear();
    toAddAttributes.put(HOSTNAMES[1],
        createAttributesForTest(PREFIXES[0], 2, ""A"", ""host2_v1""));
    attributesManager.addNodeAttributes(toAddAttributes);

    // Verify host1 attributes are still valid.
    nodeAttributes = attributesManager.getAttributesForNode(HOSTNAMES[0]);
    Assert.assertEquals(3, nodeAttributes.size());

    // Verify new added host2 attributes are correctly updated.
    nodeAttributes = attributesManager.getAttributesForNode(HOSTNAMES[1]);
    Assert.assertEquals(2, nodeAttributes.size());
    Assert.assertTrue(sameAttributeSet(toAddAttributes.get(HOSTNAMES[1]),
        nodeAttributes.keySet()));

    // Cluster wide, it only has 3 attributes.
    //  yarn.test1.io/A1
    //  yarn.test1.io/A2
    //  yarn.test1.io/A3
    Set<NodeAttribute> clusterAttributes = attributesManager
        .getClusterNodeAttributes(Sets.newHashSet(PREFIXES[0]));
    Assert.assertEquals(3, clusterAttributes.size());

    // Query for attributes under a non-exist prefix,
    // ensure it returns an empty set.
    clusterAttributes = attributesManager
        .getClusterNodeAttributes(Sets.newHashSet(""non_exist_prefix""));
    Assert.assertEquals(0, clusterAttributes.size());

    // Not provide any prefix, ensure it returns all attributes.
    clusterAttributes = attributesManager.getClusterNodeAttributes(null);
    Assert.assertEquals(3, clusterAttributes.size());

    // Add some other attributes with different prefixes on host1 and host2.
    toAddAttributes.clear();

    // Host1
    //  yarn.test2.io/A_1=host1_v2_1
    //  ...
    //  yarn.test2.io/A_10=host1_v2_10
    toAddAttributes.put(HOSTNAMES[0],
        createAttributesForTest(PREFIXES[1], 10, ""C"", ""host1_v2""));
    // Host2
    //  yarn.test2.io/C_1=host1_v2_1
    //  ...
    //  yarn.test2.io/C_20=host1_v2_20
    toAddAttributes.put(HOSTNAMES[1],
        createAttributesForTest(PREFIXES[1], 20, ""C"", ""host1_v2""));
    attributesManager.addNodeAttributes(toAddAttributes);

    nodeAttributes = attributesManager.getAttributesForNode(HOSTNAMES[0]);
    Assert.assertEquals(13, nodeAttributes.size());

    nodeAttributes = attributesManager.getAttributesForNode(HOSTNAMES[1]);
    Assert.assertEquals(22, nodeAttributes.size());
  }",1
"@Test
  public void testAppNodeSplit() throws Exception {
    TestZKRMStateStoreTester zkTester = new TestZKRMStateStoreTester();
    long submitTime = System.currentTimeMillis();
    long startTime = submitTime + 1234;
    Configuration conf = new YarnConfiguration();

    // Get store with app node split config set as 1.
    RMStateStore store = zkTester.getRMStateStore(createConfForAppNodeSplit(1));
    TestDispatcher dispatcher = new TestDispatcher();
    store.setRMDispatcher(dispatcher);

    // Create RM Context and app token manager.
    RMContext rmContext = mock(RMContext.class);
    when(rmContext.getStateStore()).thenReturn(store);
    AMRMTokenSecretManager appTokenMgr =
        spy(new AMRMTokenSecretManager(conf, rmContext));
    MasterKeyData masterKeyData = appTokenMgr.createNewMasterKey();
    when(appTokenMgr.getMasterKey()).thenReturn(masterKeyData);
    ClientToAMTokenSecretManagerInRM clientToAMTokenMgr =
        new ClientToAMTokenSecretManagerInRM();

    // Store app1.
    ApplicationId appId1 = ApplicationId.newInstance(1352994193343L, 1);
    ApplicationAttemptId attemptId1 =
        ApplicationAttemptId.newInstance(appId1, 1);
    ApplicationAttemptId attemptId2 =
        ApplicationAttemptId.newInstance(appId1, 2);
    storeAppWithAttempts(store, dispatcher, submitTime, startTime,
        appTokenMgr, clientToAMTokenMgr, attemptId1, attemptId2);

    // Store app2 with app id application_1352994193343_120213.
    ApplicationId appId21 = ApplicationId.newInstance(1352994193343L, 120213);
    storeApp(store, appId21, submitTime, startTime);
    waitNotify(dispatcher);

    // Store another app which will be removed.
    ApplicationId appIdRemoved = ApplicationId.newInstance(1352994193343L, 2);
    ApplicationAttemptId attemptIdRemoved =
        ApplicationAttemptId.newInstance(appIdRemoved, 1);
    storeAppWithAttempts(store, dispatcher, submitTime, startTime,
        null, null, attemptIdRemoved);
    // Remove the app.
    RMApp mockRemovedApp =
        createMockAppForRemove(appIdRemoved, attemptIdRemoved);
    store.removeApplication(mockRemovedApp);
    // Close state store
    store.close();

    // Load state store
    store = zkTester.getRMStateStore(createConfForAppNodeSplit(1));
    store.setRMDispatcher(dispatcher);
    RMState state = store.loadState();
    // Check if application_1352994193343_120213 (i.e. app2) exists in state
    // store as per split index.
    verifyAppPathPath(store, appId21, 1);

    // Verify loaded apps and attempts based on the operations we did before
    // reloading the state store.
    verifyLoadedApp(state, appId1, submitTime, startTime, 0, false,
        Lists.newArrayList(attemptId1, attemptId2), Lists.newArrayList(-1000,
        -1000), Lists.newArrayList((FinalApplicationStatus) null, null));

    // Update app state for app1.
    finishAppWithAttempts(state, store, dispatcher, attemptId2, submitTime,
        startTime, 100, 1234, false);

    // Test updating app/attempt for app whose initial state is not saved
    ApplicationId dummyAppId = ApplicationId.newInstance(1234, 10);
    ApplicationAttemptId dummyAttemptId =
        ApplicationAttemptId.newInstance(dummyAppId, 6);
    finishAppWithAttempts(state, store, dispatcher, dummyAttemptId, submitTime,
        startTime, 111, 1234, true);
    // Close the store
    store.close();

    // Check updated application state.
    store = zkTester.getRMStateStore(createConfForAppNodeSplit(1));
    store.setRMDispatcher(dispatcher);
    RMState newRMState = store.loadState();
    verifyLoadedApp(newRMState, dummyAppId, submitTime, startTime, 1234, true,
        Lists.newArrayList(dummyAttemptId), Lists.newArrayList(111),
        Lists.newArrayList(FinalApplicationStatus.SUCCEEDED));
    verifyLoadedApp(newRMState, appId1, submitTime, startTime, 1234, true,
        Lists.newArrayList(attemptId1, attemptId2),
        Lists.newArrayList(-1000, 100), Lists.newArrayList(null,
        FinalApplicationStatus.SUCCEEDED));

    // assert store is in expected state after everything is cleaned
    assertTrue(""Store is not in expected state"", zkTester.isFinalStateValid());
    store.close();
  }",1
"@Test
  public void testDuplicateRMAppDeletion() throws Exception {
    TestZKRMStateStoreTester zkTester = new TestZKRMStateStoreTester();
    long submitTime = System.currentTimeMillis();
    long startTime = System.currentTimeMillis() + 1234;
    RMStateStore store = zkTester.getRMStateStore();
    TestDispatcher dispatcher = new TestDispatcher();
    store.setRMDispatcher(dispatcher);

    ApplicationAttemptId attemptIdRemoved = ApplicationAttemptId.fromString(
        ""appattempt_1352994193343_0002_000001"");
    ApplicationId appIdRemoved = attemptIdRemoved.getApplicationId();
    storeApp(store, appIdRemoved, submitTime, startTime);
    storeAttempt(store, attemptIdRemoved,
        ""container_1352994193343_0002_01_000001"", null, null, dispatcher);

    ApplicationSubmissionContext context =
        new ApplicationSubmissionContextPBImpl();
    context.setApplicationId(appIdRemoved);

    ApplicationStateData appStateRemoved =
        ApplicationStateData.newInstance(
            submitTime, startTime, context, ""user1"");
    appStateRemoved.attempts.put(attemptIdRemoved, null);
    store.removeApplicationStateInternal(appStateRemoved);
    try {
      store.removeApplicationStateInternal(appStateRemoved);
    }",1
"@Test
  public void testAll() throws PlanningException {
    prepareBasicPlan();
    // create an ALL request
    ReservationDefinition rr = new ReservationDefinitionPBImpl();
    rr.setArrival(100 * step);
    rr.setDeadline(120 * step);
    rr.setRecurrenceExpression(recurrenceExpression);
    ReservationRequests reqs = new ReservationRequestsPBImpl();
    reqs.setInterpreter(ReservationRequestInterpreter.R_ALL);
    ReservationRequest r = ReservationRequest.newInstance(
        Resource.newInstance(1024, 1), 5, 5, 10 * step);
    ReservationRequest r2 = ReservationRequest.newInstance(
        Resource.newInstance(2048, 2), 10, 10, 20 * step);

    List<ReservationRequest> list = new ArrayList<ReservationRequest>();
    list.add(r);
    list.add(r2);
    reqs.setReservationResources(list);
    rr.setReservationRequests(reqs);

    // submit to agent
    ReservationId reservationID = ReservationSystemTestUtil
        .getNewReservationId();
    agent.createReservation(reservationID, ""u1"", plan, rr);

    // validate results, we expect the second one to be accepted
    assertTrue(""Agent-based allocation failed"", reservationID != null);
    assertTrue(""Agent-based allocation failed"", plan.getAllReservations()
        .size() == 3);

    ReservationAllocation cs = plan.getReservationById(reservationID);

    if (allocateLeft) {
      assertTrue(cs.toString(), check(cs, 100 * step, 110 * step, 25, 1024, 1));
      assertTrue(cs.toString(), check(cs, 110 * step, 120 * step, 20, 1024, 1));
    }",1
"@Test
  public void testAnyImpossible() throws PlanningException {
    prepareBasicPlan();
    // create an ANY request, with all impossible alternatives
    ReservationDefinition rr = new ReservationDefinitionPBImpl();
    rr.setArrival(100L);
    rr.setDeadline(120L);
    rr.setRecurrenceExpression(recurrenceExpression);
    ReservationRequests reqs = new ReservationRequestsPBImpl();
    reqs.setInterpreter(ReservationRequestInterpreter.R_ANY);

    // longer than arrival-deadline
    ReservationRequest r1 = ReservationRequest.newInstance(
        Resource.newInstance(1024, 1), 35, 5, 30);
    // above max cluster size
    ReservationRequest r2 = ReservationRequest.newInstance(
        Resource.newInstance(1024, 1), 110, 110, 10);

    List<ReservationRequest> list = new ArrayList<ReservationRequest>();
    list.add(r1);
    list.add(r2);
    reqs.setReservationResources(list);
    rr.setReservationRequests(reqs);

    ReservationId reservationID = ReservationSystemTestUtil
        .getNewReservationId();
    boolean result = false;
    try {
      // submit to agent
      result = agent.createReservation(reservationID, ""u1"", plan, rr);
      fail();
    }",1
"@Test
  public void testOrderNoGapImpossible() throws PlanningException {
    prepareBasicPlan();
    // create a completely utilized segment at time 30
    int[] f = { 100, 100 }",1
"@Test
  public void testSimple() throws PlanningException {

    prepareBasicPlan();

    // create a request with a single atomic ask
    ReservationDefinition rr = new ReservationDefinitionPBImpl();
    rr.setArrival(5 * step);
    rr.setDeadline(20 * step);
    rr.setRecurrenceExpression(recurrenceExpression);
    ReservationRequest r = ReservationRequest.newInstance(
        Resource.newInstance(2048, 2), 10, 5, 10 * step);
    ReservationRequests reqs = new ReservationRequestsPBImpl();
    reqs.setReservationResources(Collections.singletonList(r));
    rr.setReservationRequests(reqs);

    ReservationId reservationID = ReservationSystemTestUtil
        .getNewReservationId();
    agent.createReservation(reservationID, ""u1"", plan, rr);

    assertTrue(""Agent-based allocation failed"", reservationID != null);
    assertTrue(""Agent-based allocation failed"", plan.getAllReservations()
        .size() == 3);

    ReservationAllocation cs = plan.getReservationById(reservationID);

    System.out.println(""--------AFTER SIMPLE ALLOCATION (queue: ""
        + reservationID + "")----------"");
    System.out.println(plan.toString());
    System.out.println(plan.toCumulativeString());

    if(allocateLeft){
      for (long i = 5 * step; i < 15 * step; i++) {
        assertTrue(
            ""Agent-based allocation unexpected"",
            Resources.equals(cs.getResourcesAtTime(i),
                Resource.newInstance(2048 * 10, 2 * 10)));
      }",1
"@Test
  public void testSingleSliding() throws PlanningException {
    prepareBasicPlan();

    // create a single request for which we need subsequent (tight) packing.
    ReservationDefinition rr = new ReservationDefinitionPBImpl();
    rr.setArrival(100 * step);
    rr.setDeadline(120 * step);
    rr.setRecurrenceExpression(recurrenceExpression);
    ReservationRequests reqs = new ReservationRequestsPBImpl();
    reqs.setInterpreter(ReservationRequestInterpreter.R_ALL);
    ReservationRequest r = ReservationRequest.newInstance(
        Resource.newInstance(1024, 1), 200, 10, 10 * step);

    List<ReservationRequest> list = new ArrayList<ReservationRequest>();
    list.add(r);
    reqs.setReservationResources(list);
    rr.setReservationRequests(reqs);

    // submit to agent
    ReservationId reservationID = ReservationSystemTestUtil
        .getNewReservationId();
    agent.createReservation(reservationID, ""u1"", plan, rr);

    // validate results, we expect the second one to be accepted
    assertTrue(""Agent-based allocation failed"", reservationID != null);
    assertTrue(""Agent-based allocation failed"", plan.getAllReservations()
        .size() == 3);

    ReservationAllocation cs = plan.getReservationById(reservationID);

    assertTrue(cs.toString(), check(cs, 100 * step, 120 * step, 100, 1024, 1));

    System.out.println(""--------AFTER packed ALLOCATION (queue: ""
        + reservationID + "")----------"");
    System.out.println(plan.toString());
    System.out.println(plan.toCumulativeString());

  }",1
"@Test
  public void testReplanningPlanCapacityLoss() throws PlanningException {

    Resource clusterCapacity = Resource.newInstance(100 * 1024, 100);
    Resource minAlloc = Resource.newInstance(1024, 1);
    Resource maxAlloc = Resource.newInstance(1024 * 8, 8);

    ResourceCalculator res = new DefaultResourceCalculator();
    long step = 1L;
    Clock clock = mock(Clock.class);
    ReservationAgent agent = mock(ReservationAgent.class);

    SharingPolicy policy = new NoOverCommitPolicy();
    policy.init(""root.dedicated"", null);

    QueueMetrics queueMetrics = mock(QueueMetrics.class);

    when(clock.getTime()).thenReturn(0L);
    SimpleCapacityReplanner enf = new SimpleCapacityReplanner(clock);

    RMContext context = ReservationSystemTestUtil.createMockRMContext();
    ReservationSchedulerConfiguration conf =
        mock(ReservationSchedulerConfiguration.class);
    when(conf.getEnforcementWindow(any(QueuePath.class))).thenReturn(6L);

    enf.init(""blah"", conf);

    // Initialize the plan with more resources
    InMemoryPlan plan = new InMemoryPlan(queueMetrics, policy, agent,
        clusterCapacity, step, res, minAlloc, maxAlloc, ""dedicated"", enf, true,
        YarnConfiguration.DEFAULT_RM_RESERVATION_SYSTEM_MAX_PERIODICITY,
        context, clock);

    // add reservation filling the plan (separating them 1ms, so we are sure
    // s2 follows s1 on acceptance
    long ts = System.currentTimeMillis();
    ReservationId r1 = ReservationId.newInstance(ts, 1);
    int[] f5 = { 20, 20, 20, 20, 20 }",1
"@Test
  public void testNegativeGetReservationSearchIntervalCloseToEndTime() {
    // Reservation duration is 10 minutes
    long reservationStart = Timestamp.valueOf(""2050-12-03 10:37:37"").getTime();
    long reservationEnd = Timestamp.valueOf(""2050-12-03 10:47:37"").getTime();

    // Reservation does not fit within search interval, but is close to the end
    // time.
    long searchStart = Timestamp.valueOf(""2050-12-03 10:48:37"").getTime();
    long searchEnd = Timestamp.valueOf(""2050-12-03 10:50:37"").getTime();

    // 60 minute period in milliseconds.
    long period = 60 * 60 * 1000;

    testNegativeGetRecurringReservationsHelper(reservationStart,
        reservationEnd, searchStart, searchEnd, 100, period, 10);
  }",1
"@Test
  public void testZeroAlloaction() {
    ReservationId reservationID =
        ReservationId.newInstance(rand.nextLong(), rand.nextLong());
    int[] alloc = {}",1
"@Test
  public void testInitialize() throws IOException {
    try {
      reservationSystem.reinitialize(scheduler.getConfig(), rmContext);
    }",1
"@Test
  public void testConvertAllocationsToReservationInfoEmptyAllocations() {
    long startTime = new Date().getTime();
    long step = 10000;
    int[] alloc = {}",1
"@Test
  public void testMergeMin() throws PlanningException {

    TreeMap<Long, Resource> a = new TreeMap<>();
    TreeMap<Long, Resource> b = new TreeMap<>();

    setupArrays(a, b);

    RLESparseResourceAllocation rleA =
        new RLESparseResourceAllocation(a, new DefaultResourceCalculator());
    RLESparseResourceAllocation rleB =
        new RLESparseResourceAllocation(b, new DefaultResourceCalculator());

    RLESparseResourceAllocation out =
        RLESparseResourceAllocation.merge(new DefaultResourceCalculator(),
            Resource.newInstance(100 * 128 * 1024, 100 * 32), rleA, rleB,
            RLEOperator.min, 0, 60);

    System.out.println(out);

    long[] time = { 10, 22, 33, 40, 43, 50, 60 }",1
"@Test
  public void testCachedResolverWithEvent() throws Exception {
    GenericTestUtils.setRootLogLevel(Level.DEBUG);

    YarnConfiguration conf = new YarnConfiguration();
    conf.setInt(YarnConfiguration.RM_NODE_IP_CACHE_EXPIRY_INTERVAL_SECS, 30);

    MockRM rm = new MockRM(conf);
    rm.init(conf);
    NodesListManager nodesListManager = rm.getNodesListManager();
    nodesListManager.init(conf);
    nodesListManager.start();

    NodesListManager.CachedResolver resolver =
        (NodesListManager.CachedResolver)nodesListManager.getResolver();

    resolver.addToCache(""testCachedResolverHost1"", ""1.1.1.1"");
    resolver.addToCache(""testCachedResolverHost2"", ""1.1.1.2"");
    Assert.assertEquals(""1.1.1.1"",
        resolver.resolve(""testCachedResolverHost1""));
    Assert.assertEquals(""1.1.1.2"",
        resolver.resolve(""testCachedResolverHost2""));

    RMNode rmnode1 = MockNodes.newNodeInfo(1, Resource.newInstance(28000, 8),
        1, ""testCachedResolverHost1"", 1234);
    RMNode rmnode2 = MockNodes.newNodeInfo(1, Resource.newInstance(28000, 8),
        1, ""testCachedResolverHost2"", 1234);

    nodesListManager.handle(
        new NodesListManagerEvent(NodesListManagerEventType.NODE_USABLE,
            rmnode1));
    Assert.assertNotEquals(""1.1.1.1"",
        resolver.resolve(""testCachedResolverHost1""));
    Assert.assertEquals(""1.1.1.2"",
        resolver.resolve(""testCachedResolverHost2""));

    nodesListManager.handle(
        new NodesListManagerEvent(NodesListManagerEventType.NODE_USABLE,
            rmnode2));
    Assert.assertNotEquals(""1.1.1.1"",
        resolver.resolve(""testCachedResolverHost1""));
    Assert.assertNotEquals(""1.1.1.2"",
        resolver.resolve(""testCachedResolverHost2""));

  }",1
"@Test
  public void testExistenceOfResourceRequestInRMContainer() throws Exception {
    Configuration conf = new Configuration();
    MockRM rm1 = new MockRM(conf);
    rm1.start();
    MockNM nm1 = rm1.registerNode(""unknownhost:1234"", 8000);
    RMApp app1 = MockRMAppSubmitter.submitWithMemory(1024, rm1);
    MockAM am1 = MockRM.launchAndRegisterAM(app1, rm1, nm1);
    ResourceScheduler scheduler = rm1.getResourceScheduler();

    // request a container.
    am1.allocate(""127.0.0.1"", 1024, 1, new ArrayList<ContainerId>());
    ContainerId containerId2 = ContainerId.newContainerId(
        am1.getApplicationAttemptId(), 2);
    rm1.waitForState(nm1, containerId2, RMContainerState.ALLOCATED);

    // Verify whether list of ResourceRequest is present in RMContainer
    // while moving to ALLOCATED state
    Assert.assertNotNull(
        scheduler.getRMContainer(containerId2).getContainerRequest());

    // Allocate container
    am1.allocate(new ArrayList<ResourceRequest>(), new ArrayList<ContainerId>())
        .getAllocatedContainers();
    rm1.waitForState(nm1, containerId2, RMContainerState.ACQUIRED);

    // After RMContainer moving to ACQUIRED state, list of ResourceRequest will
    // be empty
    Assert.assertNull(
        scheduler.getRMContainer(containerId2).getContainerRequest());
  }",1
"@Test
  public void testHDFSBackedProvider() throws Exception {
    File testSchedulerConfigurationDir = new File(
        TestMutableCSConfigurationProvider.class.getResource("""").getPath()
            + TestMutableCSConfigurationProvider.class.getSimpleName());
    FileUtils.deleteDirectory(testSchedulerConfigurationDir);
    testSchedulerConfigurationDir.mkdirs();

    Configuration conf = new Configuration(false);
    conf.set(YarnConfiguration.SCHEDULER_CONFIGURATION_STORE_CLASS,
        YarnConfiguration.FS_CONFIGURATION_STORE);
    conf.set(YarnConfiguration.SCHEDULER_CONFIGURATION_FS_PATH,
        testSchedulerConfigurationDir.getAbsolutePath());
    writeConf(conf, testSchedulerConfigurationDir.getAbsolutePath());

    confProvider.init(conf);
    assertNull(confProvider.loadConfiguration(conf)
        .get(""yarn.scheduler.capacity.root.a.goodKey""));

    LogMutation log = confProvider.logAndApplyMutation(TEST_USER, goodUpdate);
    confProvider.confirmPendingMutation(log, true);
    assertEquals(""goodVal"", confProvider.loadConfiguration(conf)
        .get(""yarn.scheduler.capacity.root.a.goodKey""));

    assertNull(confProvider.loadConfiguration(conf).get(
        ""yarn.scheduler.capacity.root.a.badKey""));
    log = confProvider.logAndApplyMutation(TEST_USER, badUpdate);
    confProvider.confirmPendingMutation(log, false);
    assertNull(confProvider.loadConfiguration(conf).get(
        ""yarn.scheduler.capacity.root.a.badKey""));

    confProvider.formatConfigurationInStore(conf);
    assertNull(confProvider.loadConfiguration(conf)
        .get(""yarn.scheduler.capacity.root.a.goodKey""));

  }",1
"@Test
  public void testPriorityUtilizationOrdering() {
    PriorityUtilizationQueueOrderingPolicy policy =
        new PriorityUtilizationQueueOrderingPolicy(true);

    // Case 1, one queue
    policy.setQueues(mockCSQueues(new String[] { ""a"" }",1
"@Test
  public void testUtilizationOrdering() {
    PriorityUtilizationQueueOrderingPolicy policy =
        new PriorityUtilizationQueueOrderingPolicy(false);

    // Case 1, one queue
    policy.setQueues(mockCSQueues(new String[] { ""a"" }",1
"@Test
  public void testAllocateReorder() throws Exception {

    //Confirm that allocation (resource request) alone will trigger a change in
    //application ordering where appropriate

    Configuration conf = new Configuration();
    conf.setClass(YarnConfiguration.RM_SCHEDULER, CapacityScheduler.class,
        ResourceScheduler.class);
    MockRM rm = new MockRM(conf);
    rm.start();
    CapacityScheduler cs = (CapacityScheduler) rm.getResourceScheduler();

    LeafQueue q = (LeafQueue) cs.getQueue(""default"");
    Assert.assertNotNull(q);

    FairOrderingPolicy fop = new FairOrderingPolicy();
    fop.setSizeBasedWeight(true);
    q.setOrderingPolicy(fop);

    String host = ""127.0.0.1"";
    RMNode node =
        MockNodes.newNodeInfo(0, MockNodes.newResource(4 * GB), 1, host);
    cs.handle(new NodeAddedSchedulerEvent(node));

    ApplicationAttemptId appAttemptId1 = appHelper(rm, cs, 100, 1, ""default"", ""user"");
    ApplicationAttemptId appAttemptId2 = appHelper(rm, cs, 100, 2, ""default"", ""user"");

    RecordFactory recordFactory =
      RecordFactoryProvider.getRecordFactory(null);

    Priority priority = TestUtils.createMockPriority(1);
    ResourceRequest r1 = TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 1, true, priority, recordFactory);

    //This will allocate for app1
    cs.allocate(appAttemptId1,
        Collections.<ResourceRequest>singletonList(r1), null, Collections.<ContainerId>emptyList(),
        null, null, NULL_UPDATE_REQUESTS);

    //And this will result in container assignment for app1
    CapacityScheduler.schedule(cs);

    //Verify that app1 is still first in assignment order
    //This happens because app2 has no demand/a magnitude of NaN, which
    //results in app1 and app2 being equal in the fairness comparison and
    //failling back to fifo (start) ordering
    assertEquals(q.getOrderingPolicy().getAssignmentIterator(
        IteratorSelector.EMPTY_ITERATOR_SELECTOR).next().getId(),
        appAttemptId1.getApplicationId().toString());

    //Now, allocate for app2 (this would be the first/AM allocation)
    ResourceRequest r2 = TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 1, true, priority, recordFactory);
    cs.allocate(appAttemptId2,
        Collections.<ResourceRequest>singletonList(r2), null, Collections.<ContainerId>emptyList(),
        null, null, NULL_UPDATE_REQUESTS);

    //In this case we do not perform container assignment because we want to
    //verify re-ordering based on the allocation alone

    //Now, the first app for assignment is app2
    assertEquals(q.getOrderingPolicy().getAssignmentIterator(
        IteratorSelector.EMPTY_ITERATOR_SELECTOR).next().getId(),
        appAttemptId2.getApplicationId().toString());

    rm.stop();
  }",1
"@Test
  public void testApplicationHeadRoom() throws Exception {
    Configuration conf = new Configuration();
    conf.setClass(YarnConfiguration.RM_SCHEDULER, CapacityScheduler.class,
        ResourceScheduler.class);
    MockRM rm = new MockRM(conf);
    rm.start();
    CapacityScheduler cs = (CapacityScheduler) rm.getResourceScheduler();

    ApplicationId appId = BuilderUtils.newApplicationId(100, 1);
    ApplicationAttemptId appAttemptId =
        BuilderUtils.newApplicationAttemptId(appId, 1);

    RMAppAttemptMetrics attemptMetric =
        new RMAppAttemptMetrics(appAttemptId, rm.getRMContext());
    RMAppImpl app = mock(RMAppImpl.class);
    when(app.getApplicationId()).thenReturn(appId);
    RMAppAttemptImpl attempt = mock(RMAppAttemptImpl.class);
    Container container = mock(Container.class);
    when(attempt.getMasterContainer()).thenReturn(container);
    ApplicationSubmissionContext submissionContext = mock(
        ApplicationSubmissionContext.class);
    when(attempt.getSubmissionContext()).thenReturn(submissionContext);
    when(attempt.getAppAttemptId()).thenReturn(appAttemptId);
    when(attempt.getRMAppAttemptMetrics()).thenReturn(attemptMetric);
    when(app.getCurrentAppAttempt()).thenReturn(attempt);

    rm.getRMContext().getRMApps().put(appId, app);

    SchedulerEvent addAppEvent =
        new AppAddedSchedulerEvent(appId, ""default"", ""user"");
    cs.handle(addAppEvent);
    SchedulerEvent addAttemptEvent =
        new AppAttemptAddedSchedulerEvent(appAttemptId, false);
    cs.handle(addAttemptEvent);

    Allocation allocate =
        cs.allocate(appAttemptId, Collections.<ResourceRequest> emptyList(),
            null, Collections.<ContainerId> emptyList(), null, null,
            NULL_UPDATE_REQUESTS);

    Assert.assertNotNull(attempt);

    Assert
        .assertEquals(Resource.newInstance(0, 0), allocate.getResourceLimit());
    Assert.assertEquals(Resource.newInstance(0, 0),
        attemptMetric.getApplicationAttemptHeadroom());

    // Add a node to cluster
    Resource newResource = Resource.newInstance(4 * GB, 1);
    RMNode node = MockNodes.newNodeInfo(0, newResource, 1, ""127.0.0.1"");
    cs.handle(new NodeAddedSchedulerEvent(node));

    allocate =
        cs.allocate(appAttemptId, Collections.<ResourceRequest> emptyList(),
            null, Collections.<ContainerId> emptyList(), null, null,
            NULL_UPDATE_REQUESTS);

    // All resources should be sent as headroom
    Assert.assertEquals(newResource, allocate.getResourceLimit());
    Assert.assertEquals(newResource,
        attemptMetric.getApplicationAttemptHeadroom());

    rm.stop();
  }",1
"@Test
  public void testCapacityScheduler() throws Exception {

    LOG.info(""--- START: testCapacityScheduler ---"");

    NodeStatus mockNodeStatus = createMockNodeStatus();

    // Register node1
    String host_0 = ""host_0"";
    NodeManager nm_0 =
        registerNode(resourceManager, host_0, 1234, 2345, NetworkTopology.DEFAULT_RACK,
            Resources.createResource(4 * GB, 1), mockNodeStatus);

    // Register node2
    String host_1 = ""host_1"";
    NodeManager nm_1 =
        registerNode(resourceManager, host_1, 1234, 2345, NetworkTopology.DEFAULT_RACK,
            Resources.createResource(2 * GB, 1), mockNodeStatus);

    // ResourceRequest priorities
    Priority priority_0 = Priority.newInstance(0);
    Priority priority_1 = Priority.newInstance(1);

    // Submit an application
    Application application_0 = new Application(""user_0"", ""a1"", resourceManager);
    application_0.submit();

    application_0.addNodeManager(host_0, 1234, nm_0);
    application_0.addNodeManager(host_1, 1234, nm_1);

    Resource capability_0_0 = Resources.createResource(1 * GB, 1);
    application_0.addResourceRequestSpec(priority_1, capability_0_0);

    Resource capability_0_1 = Resources.createResource(2 * GB, 1);
    application_0.addResourceRequestSpec(priority_0, capability_0_1);

    Task task_0_0 = new Task(application_0, priority_1,
        new String[] {host_0, host_1}",1
"@Test
  public void testCapacitySchedulerInfo() throws Exception {
    QueueInfo queueInfo = resourceManager.getResourceScheduler().getQueueInfo(""a"", true, true);
    Assert.assertEquals(""Queue Name should be a"", ""a"",
        queueInfo.getQueueName());
    Assert.assertEquals(""Queue Path should be root.a"", ""root.a"",
        queueInfo.getQueuePath());
    Assert.assertEquals(""Child Queues size should be 2"", 2,
        queueInfo.getChildQueues().size());

    List<QueueUserACLInfo> userACLInfo = resourceManager.getResourceScheduler().getQueueUserAclInfo();
    Assert.assertNotNull(userACLInfo);
    for (QueueUserACLInfo queueUserACLInfo : userACLInfo) {
      Assert.assertEquals(1, getQueueCount(userACLInfo,
          queueUserACLInfo.getQueueName()));
    }",1
"@Test
  public void testCSQueueBlocked() throws Exception {
    CapacitySchedulerConfiguration conf = new CapacitySchedulerConfiguration();
    setupBlockedQueueConfiguration(conf);
    conf.setClass(YarnConfiguration.RM_SCHEDULER, CapacityScheduler.class,
        ResourceScheduler.class);
    MockRM rm = new MockRM(conf);
    rm.start();
    CapacityScheduler cs = (CapacityScheduler) rm.getResourceScheduler();
    LeafQueue q = (LeafQueue) cs.getQueue(""a"");

    Assert.assertNotNull(q);
    String host = ""127.0.0.1"";
    String host1 = ""test"";
    RMNode node =
        MockNodes.newNodeInfo(0, Resource.newInstance(8 * GB, 8), 1, host);
    RMNode node1 =
        MockNodes.newNodeInfo(0, Resource.newInstance(8 * GB, 8), 2, host1);
    cs.handle(new NodeAddedSchedulerEvent(node));
    cs.handle(new NodeAddedSchedulerEvent(node1));
    //add app begin
    ApplicationAttemptId appAttemptId1 =
        appHelper(rm, cs, 100, 1, ""a"", ""user1"");
    ApplicationAttemptId appAttemptId2 =
        appHelper(rm, cs, 100, 2, ""b"", ""user2"");
    //add app end

    RecordFactory recordFactory =
        RecordFactoryProvider.getRecordFactory(null);

    Priority priority = TestUtils.createMockPriority(1);
    ResourceRequest r1 = TestUtils.createResourceRequest(
        ResourceRequest.ANY, 2 * GB, 1, true, priority, recordFactory);
    //This will allocate for app1
    cs.allocate(appAttemptId1, Collections.<ResourceRequest>singletonList(r1),
        null, Collections.<ContainerId>emptyList(),
        null, null, NULL_UPDATE_REQUESTS).getContainers().size();
    CapacityScheduler.schedule(cs);
    ResourceRequest r2 = null;
    for (int i =0; i < 13; i++) {
      r2 = TestUtils.createResourceRequest(
          ResourceRequest.ANY, 1 * GB, 1, true, priority, recordFactory);
      cs.allocate(appAttemptId2,
          Collections.<ResourceRequest>singletonList(r2), null, Collections.<ContainerId>emptyList(),
          null, null, NULL_UPDATE_REQUESTS);
      CapacityScheduler.schedule(cs);
    }",1
"@Test
  public void testNormalContainerAllocationWhenDNSUnavailable() throws Exception{
    MockRM rm1 = new MockRM(conf);
    rm1.start();
    MockNM nm1 = rm1.registerNode(""unknownhost:1234"", 8000);
    RMApp app1 = MockRMAppSubmitter.submitWithMemory(200, rm1);
    MockAM am1 = MockRM.launchAndRegisterAM(app1, rm1, nm1);

    // request a container.
    am1.allocate(""127.0.0.1"", 1024, 1, new ArrayList<ContainerId>());
    ContainerId containerId2 =
        ContainerId.newContainerId(am1.getApplicationAttemptId(), 2);
    rm1.waitForState(nm1, containerId2, RMContainerState.ALLOCATED);

    // acquire the container.
    SecurityUtilTestHelper.setTokenServiceUseIp(true);
    List<Container> containers;
    try {
      containers =
          am1.allocate(new ArrayList<ResourceRequest>(),
              new ArrayList<ContainerId>()).getAllocatedContainers();
      // not able to fetch the container;
      Assert.assertEquals(0, containers.size());
    }",1
"@Test
  public void testAppAttemptMetrics() throws Exception {
    CSMaxRunningAppsEnforcer enforcer = mock(CSMaxRunningAppsEnforcer.class);
    cs.setMaxRunningAppsEnforcer(enforcer);
    ApplicationSubmissionContext applicationSubmissionContext =
        mock(ApplicationSubmissionContext.class);
    when(applicationSubmissionContext.getUnmanagedAM()).thenReturn(false);
    when(rmApp.getApplicationSubmissionContext())
        .thenReturn(applicationSubmissionContext);
    when(rmApp.getCurrentAppAttempt()).thenReturn(mock(RMAppAttempt.class));
    // Manipulate queue 'a'
    LeafQueue a = stubLeafQueue((LeafQueue) queues.get(B));

    // Users
    final String user_0 = ""user_0"";

    // Submit applications
    final ApplicationAttemptId appAttemptId_0 = TestUtils
        .getMockApplicationAttemptId(0, 1);

    AppAddedSchedulerEvent addAppEvent =
        new AppAddedSchedulerEvent(appAttemptId_0.getApplicationId(),
          a.getQueuePath(), user_0);
    cs.handle(addAppEvent);
    AppAttemptAddedSchedulerEvent addAttemptEvent = 
        new AppAttemptAddedSchedulerEvent(appAttemptId_0, false);
    cs.handle(addAttemptEvent);

    AppAttemptRemovedSchedulerEvent event = new AppAttemptRemovedSchedulerEvent(
        appAttemptId_0, RMAppAttemptState.FAILED, false);
    cs.handle(event);
    
    assertEquals(0, a.getMetrics().getAppsPending());
    assertEquals(0, a.getMetrics().getAppsFailed());

    // Attempt the same application again
    final ApplicationAttemptId appAttemptId_1 = TestUtils
        .getMockApplicationAttemptId(0, 2);
    FiCaSchedulerApp app1 = new FiCaSchedulerApp(appAttemptId_1, user_0, a,
        null, spyRMContext);
    app1.getAppSchedulingInfo().setUnmanagedAM(false);
    app1.setAMResource(Resource.newInstance(100, 1));
    a.submitApplicationAttempt(app1, user_0); // same user

    assertEquals(1, a.getMetrics().getAppsSubmitted());
    assertEquals(1, a.getMetrics().getAppsPending());
    assertEquals(1, a.getUser(user_0).getActiveApplications());
    assertEquals(app1.getAMResource().getMemorySize(), a.getMetrics()
        .getUsedAMResourceMB());
    assertEquals(app1.getAMResource().getVirtualCores(), a.getMetrics()
        .getUsedAMResourceVCores());
    
    event = new AppAttemptRemovedSchedulerEvent(appAttemptId_0,
        RMAppAttemptState.FINISHED, false);
    cs.handle(event);
    AppRemovedSchedulerEvent rEvent = new AppRemovedSchedulerEvent(
        appAttemptId_0.getApplicationId(), RMAppState.FINISHED);
    cs.handle(rEvent);
    
    assertEquals(1, a.getMetrics().getAppsSubmitted());
    assertEquals(0, a.getMetrics().getAppsPending());
    assertEquals(0, a.getMetrics().getAppsFailed());
    assertEquals(1, a.getMetrics().getAppsCompleted());

    QueueMetrics userMetrics = a.getMetrics().getUserMetrics(user_0);
    assertEquals(1, userMetrics.getAppsSubmitted());
  }",1
"@Test
  public void testDRFUserLimits() throws Exception {
    setUpWithDominantResourceCalculator();

    // Mock the queue
    LeafQueue b = stubLeafQueue((LeafQueue) queues.get(B));
    // unset maxCapacity
    b.setMaxCapacity(1.0f);

    // Users
    final String user0 = ""user_0"";
    final String user1 = ""user_1"";

    // Submit applications
    final ApplicationAttemptId appAttemptId0 =
        TestUtils.getMockApplicationAttemptId(0, 0);
    FiCaSchedulerApp app0 =
        new FiCaSchedulerApp(appAttemptId0, user0, b,
            b.getAbstractUsersManager(), spyRMContext);
    b.submitApplicationAttempt(app0, user0);

    final ApplicationAttemptId appAttemptId2 =
        TestUtils.getMockApplicationAttemptId(2, 0);
    FiCaSchedulerApp app2 =
        new FiCaSchedulerApp(appAttemptId2, user1, b,
            b.getAbstractUsersManager(), spyRMContext);
    b.submitApplicationAttempt(app2, user1);

    // Setup some nodes
    String host0 = ""127.0.0.1"";
    FiCaSchedulerNode node0 =
        TestUtils.getMockNode(host0, DEFAULT_RACK, 0, 8 * GB, 100);
    String host1 = ""127.0.0.2"";
    FiCaSchedulerNode node1 =
        TestUtils.getMockNode(host1, DEFAULT_RACK, 0, 8 * GB, 100);

    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node0.getNodeID(),
        node0, node1.getNodeID(), node1);
    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app0.getApplicationAttemptId(), app0, app2.getApplicationAttemptId(),
        app2);

    int numNodes = 2;
    Resource clusterResource =
        Resources.createResource(numNodes * (8 * GB), numNodes * 100);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    when(csContext.getClusterResource()).thenReturn(clusterResource);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Setup resource-requests so that one application is memory dominant
    // and other application is vcores dominant
    Priority priority = TestUtils.createMockPriority(1);
    app0.updateResourceRequests(Collections.singletonList(TestUtils
        .createResourceRequest(ResourceRequest.ANY, 1 * GB, 40, 10, true,
            priority, recordFactory, NO_LABEL)));

    app2.updateResourceRequests(Collections.singletonList(TestUtils
        .createResourceRequest(ResourceRequest.ANY, 2 * GB, 10, 10, true,
            priority, recordFactory, NO_LABEL)));

    /**
     * Start testing...
     */

    // Set user-limit
    b.setUserLimit(50);
    b.setUserLimitFactor(2);
    User queueUser0 = b.getUser(user0);
    User queueUser1 = b.getUser(user1);

    assertEquals(""There should 2 active users!"", 2, b
        .getAbstractUsersManager().getNumActiveUsers());
    // Fill both Nodes as far as we can
    CSAssignment assign;
    do {
      assign =
          b.assignContainers(clusterResource, node0, new ResourceLimits(
              clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
      LOG.info(assign.toString());
      applyCSAssignment(clusterResource, assign, b, nodes, apps);
    }",1
"@Test
  public void testGetTotalPendingResourcesConsideringUserLimitOneUser()
      throws Exception {
    // Manipulate queue 'e'
    LeafQueue e = stubLeafQueue((LeafQueue)queues.get(E));
    // Allow queue 'e' to use 100% of cluster resources (max capacity).
    e.setMaxCapacity(1.0f);
    // When used queue resources goes above capacity (in this case, 1%), user
    // resource limit (used in calculating headroom) is calculated in small
    // increments to ensure that user-limit-percent can be met for all users in
    // a queue. Take user-limit-percent out of the equation so that user
    // resource limit will always be calculated to its max possible value.
    e.setUserLimit(1000);

    final String user_0 = ""user_0"";

    // Submit 2 applications for user_0
    final ApplicationAttemptId appAttemptId_0 =
        TestUtils.getMockApplicationAttemptId(0, 0);
    FiCaSchedulerApp app_0 =
        new FiCaSchedulerApp(appAttemptId_0, user_0, e,
            mock(ActiveUsersManager.class), spyRMContext);
    e.submitApplicationAttempt(app_0, user_0);

    final ApplicationAttemptId appAttemptId_1 =
        TestUtils.getMockApplicationAttemptId(1, 0);
    FiCaSchedulerApp app_1 =
        new FiCaSchedulerApp(appAttemptId_1, user_0, e,
            mock(ActiveUsersManager.class), spyRMContext);
    e.submitApplicationAttempt(app_1, user_0);  // same user

    // Setup 1 node with 100GB of memory resources.
    String host_0 = ""127.0.0.1"";
    FiCaSchedulerNode node_0 = TestUtils.getMockNode(host_0, DEFAULT_RACK, 0,
        100*GB);

    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app_0.getApplicationAttemptId(), app_0, app_1.getApplicationAttemptId(),
        app_1);
    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node_0.getNodeID(),
        node_0);

    final int numNodes = 1;
    Resource clusterResource =
        Resources.createResource(numNodes * (100*GB), numNodes * 128);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Pending resource requests for app_0 and app_1 total 5GB.
    Priority priority = TestUtils.createMockPriority(1);
    app_0.updateResourceRequests(Collections.singletonList(
            TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 3, true,
                priority, recordFactory)));

    app_1.updateResourceRequests(Collections.singletonList(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 2, true,
            priority, recordFactory)));

    // Start testing...

    // Assign 1st Container of 1GB
    applyCSAssignment(clusterResource,
        e.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), e, nodes, apps);
    // With queue capacity set at 1% of 100GB and user-limit-factor set to 1.0,
    // all users (only user_0) queue 'e' should be able to consume 1GB.
    // The first container should be assigned to app_0 with no headroom left
    // even though user_0's apps are still asking for a total of 4GB.
    assertEquals(1*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0 * GB,
        e.getTotalPendingResourcesConsideringUserLimit(clusterResource,
            NO_LABEL, false).getMemorySize());

    // Assign 2nd container of 1GB
    applyCSAssignment(clusterResource,
        e.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), e, nodes, apps);
    // user_0 has no headroom due to user-limit-factor of 1.0. However capacity
    // scheduler will assign one container more than user-limit-factor.
    // This container also went to app_0. Still with no neadroom even though
    // app_0 and app_1 are asking for a cumulative 3GB.
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, e.getTotalPendingResourcesConsideringUserLimit(
        clusterResource, NO_LABEL, false).getMemorySize());

    // Can't allocate 3rd container due to user-limit. Headroom still 0.
    applyCSAssignment(clusterResource,
        e.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), e, nodes, apps);
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, e.getTotalPendingResourcesConsideringUserLimit(
        clusterResource, NO_LABEL, false).getMemorySize());

    // Increase user-limit-factor from 1GB to 10GB (1% * 10 * 100GB = 10GB).
    // Pending for both app_0 and app_1 are still 3GB, so user-limit-factor
    // is no longer limiting the return value of
    // getTotalPendingResourcesConsideringUserLimit()
    e.setUserLimitFactor(10.0f);
    assertEquals(3*GB, e.getTotalPendingResourcesConsideringUserLimit(
        clusterResource, NO_LABEL, false).getMemorySize());

    applyCSAssignment(clusterResource,
        e.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), e, nodes, apps);
    // app_0 is now satisified, app_1 is still asking for 2GB.
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(2*GB, e.getTotalPendingResourcesConsideringUserLimit(
        clusterResource, NO_LABEL, false).getMemorySize());

    // Get the last 2 containers for app_1, no more pending requests.
    applyCSAssignment(clusterResource,
        e.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), e, nodes, apps);
    applyCSAssignment(clusterResource,
        e.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), e, nodes, apps);
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(2*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, e.getTotalPendingResourcesConsideringUserLimit(
        clusterResource, NO_LABEL, false).getMemorySize());

    // Release each container from app_0
    for (RMContainer rmContainer : app_0.getLiveContainers()) {
      e.completedContainer(clusterResource, app_0, node_0, rmContainer,
          ContainerStatus.newInstance(rmContainer.getContainerId(),
              ContainerState.COMPLETE, """",
              ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),
          RMContainerEventType.KILL, null, true);
    }",1
"@Test
  public void testLocalityConstraints() throws Exception {

    // Manipulate queue 'a'
    LeafQueue a = stubLeafQueue((LeafQueue)queues.get(A));

    // User
    String user_0 = ""user_0"";
    
    // Submit applications
    final ApplicationAttemptId appAttemptId_0 = 
        TestUtils.getMockApplicationAttemptId(0, 0); 
    FiCaSchedulerApp app_0 =
        new FiCaSchedulerApp(appAttemptId_0, user_0, a,
            mock(ActiveUsersManager.class), spyRMContext);
    a.submitApplicationAttempt(app_0, user_0);

    final ApplicationAttemptId appAttemptId_1 = 
        TestUtils.getMockApplicationAttemptId(1, 0); 
    FiCaSchedulerApp app_1 =
        new FiCaSchedulerApp(appAttemptId_1, user_0, a,
            mock(ActiveUsersManager.class), spyRMContext);
    a.submitApplicationAttempt(app_1, user_0);

    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app_0.getApplicationAttemptId(), app_0, app_1.getApplicationAttemptId(),
        app_1);

    // Setup some nodes and racks
    String host_0_0 = ""127.0.0.1"";
    String rack_0 = ""rack_0"";
    String host_0_1 = ""127.0.0.2"";
    FiCaSchedulerNode node_0_1 = TestUtils.getMockNode(host_0_1, rack_0, 0, 8*GB);

    String host_1_0 = ""127.0.0.3"";
    String rack_1 = ""rack_1"";
    FiCaSchedulerNode node_1_0 = TestUtils.getMockNode(host_1_0, rack_1, 0, 8*GB);
    String host_1_1 = ""127.0.0.4"";
    FiCaSchedulerNode node_1_1 = TestUtils.getMockNode(host_1_1, rack_1, 0, 8*GB);

    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node_0_1.getNodeID(),
        node_0_1, node_1_0.getNodeID(), node_1_0, node_1_1.getNodeID(),
        node_1_1);
    
    final int numNodes = 4;
    Resource clusterResource = Resources.createResource(
        numNodes * (8*GB), numNodes * 1);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);

    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Setup resource-requests
    // resourceName: <priority, memory, #containers, relaxLocality>
    // host_0_0: < 1, 1GB, 1, true >
    // host_0_1: < null >
    // rack_0:   < null >                     <----
    // host_1_0: < 1, 1GB, 1, true >
    // host_1_1: < null >
    // rack_1:   < 1, 1GB, 1, false >         <----
    // ANY:      < 1, 1GB, 1, false >         <----
    // Availability:
    // host_0_0: 8G
    // host_0_1: 8G
    // host_1_0: 8G
    // host_1_1: 8G
    // Blacklist: <host_0_0>
    Priority priority = TestUtils.createMockPriority(1);
    SchedulerRequestKey schedulerKey = toSchedulerKey(priority);
    List<ResourceRequest> app_0_requests_0 = new ArrayList<ResourceRequest>();
    app_0_requests_0.add(
        TestUtils.createResourceRequest(host_0_0, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(host_1_0, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(rack_1, 1*GB, 1, 
            false, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 1, // only one
            false, priority, recordFactory));
    app_0.updateResourceRequests(app_0_requests_0);
    app_0.updateBlacklist(Collections.singletonList(host_0_0), null);
    app_0_requests_0.clear();

    //
    // Start testing...
    //
    
    // node_0_1  
    // Shouldn't allocate since RR(rack_0) = null && RR(ANY) = relax: false
    CSAssignment assignment =
        a.assignContainers(clusterResource, node_0_1, new ResourceLimits(
            clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyNoContainerAllocated(assignment);
    // should be 0
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    
    // resourceName: <priority, memory, #containers, relaxLocality>
    // host_0_0: < 1, 1GB, 1, true >
    // host_0_1: < null >
    // rack_0:   < null >                     <----
    // host_1_0: < 1, 1GB, 1, true >
    // host_1_1: < null >
    // rack_1:   < 1, 1GB, 1, false >         <----
    // ANY:      < 1, 1GB, 1, false >         <----
    // Availability:
    // host_0_0: 8G
    // host_0_1: 8G
    // host_1_0: 8G
    // host_1_1: 8G
    // Blacklist: <host_0_0>

    // node_1_1  
    // Shouldn't allocate since RR(rack_1) = relax: false
    assignment = a.assignContainers(clusterResource, node_1_1, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyNoContainerAllocated(assignment);
    // should be 0
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    
    // Allow rack-locality for rack_1, but blacklist node_1_1
    app_0_requests_0.add(
        TestUtils.createResourceRequest(rack_1, 1*GB, 1, 
            true, priority, recordFactory));
    app_0.updateResourceRequests(app_0_requests_0);
    app_0.updateBlacklist(Collections.singletonList(host_1_1), null);
    app_0_requests_0.clear();

    // resourceName: <priority, memory, #containers, relaxLocality>
    // host_0_0: < 1, 1GB, 1, true >
    // host_0_1: < null >
    // rack_0:   < null >                     
    // host_1_0: < 1, 1GB, 1, true >
    // host_1_1: < null >
    // rack_1:   < 1, 1GB, 1, true >         
    // ANY:      < 1, 1GB, 1, false >         
    // Availability:
    // host_0_0: 8G
    // host_0_1: 8G
    // host_1_0: 8G
    // host_1_1: 8G
    // Blacklist: < host_0_0 , host_1_1 >       <----

    // node_1_1  
    // Shouldn't allocate since node_1_1 is blacklisted
    assignment = a.assignContainers(clusterResource, node_1_1, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyNoContainerAllocated(assignment);
    // should be 0
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));

    // Now, remove node_1_1 from blacklist, but add rack_1 to blacklist
    app_0.updateResourceRequests(app_0_requests_0);
    app_0.updateBlacklist(
        Collections.singletonList(rack_1), Collections.singletonList(host_1_1));
    app_0_requests_0.clear();

    // resourceName: <priority, memory, #containers, relaxLocality>
    // host_0_0: < 1, 1GB, 1, true >
    // host_0_1: < null >
    // rack_0:   < null >                     
    // host_1_0: < 1, 1GB, 1, true >
    // host_1_1: < null >
    // rack_1:   < 1, 1GB, 1, true >         
    // ANY:      < 1, 1GB, 1, false >         
    // Availability:
    // host_0_0: 8G
    // host_0_1: 8G
    // host_1_0: 8G
    // host_1_1: 8G
    // Blacklist: < host_0_0 , rack_1 >       <----

    // node_1_1  
    // Shouldn't allocate since rack_1 is blacklisted
    assignment = a.assignContainers(clusterResource, node_1_1,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyNoContainerAllocated(assignment);
    // should be 0
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    
    // Now remove rack_1 from blacklist
    app_0.updateResourceRequests(app_0_requests_0);
    app_0.updateBlacklist(null, Collections.singletonList(rack_1));
    app_0_requests_0.clear();
    
    // resourceName: <priority, memory, #containers, relaxLocality>
    // host_0_0: < 1, 1GB, 1, true >
    // host_0_1: < null >
    // rack_0:   < null >                     
    // host_1_0: < 1, 1GB, 1, true >
    // host_1_1: < null >
    // rack_1:   < 1, 1GB, 1, true >         
    // ANY:      < 1, 1GB, 1, false >         
    // Availability:
    // host_0_0: 8G
    // host_0_1: 8G
    // host_1_0: 8G
    // host_1_1: 8G
    // Blacklist: < host_0_0 >       <----

    // Now, should allocate since RR(rack_1) = relax: true
    assignment = a.assignContainers(clusterResource, node_1_1, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyNoContainerAllocated(assignment);
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    assertEquals(1, app_0.getOutstandingAsksCount(schedulerKey));

    // Now sanity-check node_local
    app_0_requests_0.add(
        TestUtils.createResourceRequest(rack_1, 1*GB, 1, 
            false, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 1, // only one
            false, priority, recordFactory));
    app_0.updateResourceRequests(app_0_requests_0);
    app_0_requests_0.clear();
    
    // resourceName: <priority, memory, #containers, relaxLocality>
    // host_0_0: < 1, 1GB, 1, true >
    // host_0_1: < null >
    // rack_0:   < null >                     
    // host_1_0: < 1, 1GB, 1, true >
    // host_1_1: < null >
    // rack_1:   < 1, 1GB, 1, false >          <----
    // ANY:      < 1, 1GB, 1, false >          <----
    // Availability:
    // host_0_0: 8G
    // host_0_1: 8G
    // host_1_0: 8G
    // host_1_1: 7G

    assignment = a.assignContainers(clusterResource, node_1_0, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyContainerAllocated(assignment, NodeType.NODE_LOCAL);
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    assertEquals(0, app_0.getOutstandingAsksCount(schedulerKey));

  }",1
"@Test
  public void testLocalityDelaySkipsApplication() throws Exception {

    // Manipulate queue 'a'
    LeafQueue a = stubLeafQueue((LeafQueue)queues.get(A));

    // User
    String user_0 = ""user_0"";
    
    // Submit applications
    final ApplicationAttemptId appAttemptId_0 = 
        TestUtils.getMockApplicationAttemptId(0, 0); 
    FiCaSchedulerApp app_0 =
        new FiCaSchedulerApp(appAttemptId_0, user_0, a,
            mock(ActiveUsersManager.class), spyRMContext);
    a.submitApplicationAttempt(app_0, user_0);
    final ApplicationAttemptId appAttemptId_1 = 
        TestUtils.getMockApplicationAttemptId(1, 0);
    FiCaSchedulerApp app_1 =
        new FiCaSchedulerApp(appAttemptId_1, user_0, a,
            mock(ActiveUsersManager.class), spyRMContext);
    a.submitApplicationAttempt(app_1, user_0);

    // Setup some nodes and racks
    String host_0 = ""127.0.0.1"";
    String rack_0 = ""rack_0"";
    FiCaSchedulerNode node_0 = TestUtils.getMockNode(host_0, rack_0, 0, 8*GB);
    
    String host_1 = ""127.0.0.2"";
    String rack_1 = ""rack_1"";
    FiCaSchedulerNode node_1 = TestUtils.getMockNode(host_1, rack_1, 0, 8*GB);
    
    String host_2 = ""127.0.0.3"";
    String rack_2 = ""rack_2"";
    FiCaSchedulerNode node_2 = TestUtils.getMockNode(host_2, rack_2, 0, 8*GB);

    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app_0.getApplicationAttemptId(), app_0, app_1.getApplicationAttemptId(),
        app_1);
    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node_0.getNodeID(),
        node_0, node_1.getNodeID(), node_1, node_2.getNodeID(), node_2);

    final int numNodes = 3;
    Resource clusterResource = 
        Resources.createResource(numNodes * (8*GB), numNodes * 16);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));
    
    // Setup resource-requests and submit
    // App0 has node local request for host_0/host_1, and app1 has node local
    // request for host2.
    Priority priority = TestUtils.createMockPriority(1);
    SchedulerRequestKey schedulerKey = toSchedulerKey(priority);
    List<ResourceRequest> app_0_requests_0 = new ArrayList<ResourceRequest>();
    app_0_requests_0.add(
        TestUtils.createResourceRequest(host_0, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(rack_0, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(host_1, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(rack_1, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 3, // one extra
            true, priority, recordFactory));
    app_0.updateResourceRequests(app_0_requests_0);

    List<ResourceRequest> app_1_requests_0 = new ArrayList<ResourceRequest>();
    app_1_requests_0.add(
        TestUtils.createResourceRequest(host_2, 1*GB, 1, 
            true, priority, recordFactory));
    app_1_requests_0.add(
        TestUtils.createResourceRequest(rack_2, 1*GB, 1, 
            true, priority, recordFactory));
    app_1_requests_0.add(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 1, // one extra
            true, priority, recordFactory));
    app_1.updateResourceRequests(app_1_requests_0);

    // Start testing...
    // When doing allocation, even if app_0 submit earlier than app_1, app_1 can
    // still get allocated because app_0 is waiting for node-locality-delay
    CSAssignment assignment = null;
    
    // Check app_0's scheduling opportunities increased and app_1 get allocated
    assignment = a.assignContainers(clusterResource, node_2,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyContainerAllocated(assignment, NodeType.NODE_LOCAL);
    assertEquals(1, app_0.getSchedulingOpportunities(schedulerKey));
    assertEquals(3, app_0.getOutstandingAsksCount(schedulerKey));
    assertEquals(0, app_0.getLiveContainers().size());
    assertEquals(1, app_1.getLiveContainers().size());
  }",1
"@Test
  public void testPolicyConfiguration() throws Exception {
    
    CapacitySchedulerConfiguration testConf = 
        new CapacitySchedulerConfiguration();
    
    String tproot = ROOT + ""."" +
      ""testPolicyRoot"" + System.currentTimeMillis();

    OrderingPolicy<FiCaSchedulerApp> comPol =    
        testConf.<FiCaSchedulerApp>getAppOrderingPolicy(new QueuePath(tproot));
    
    
  }",1
"@Test
  public void testReservation() throws Exception {

    // Manipulate queue 'a'
    LeafQueue a = stubLeafQueue((LeafQueue)queues.get(A));
    //unset maxCapacity
    a.setMaxCapacity(1.0f);

    // Users
    final String user_0 = ""user_0"";
    final String user_1 = ""user_1"";

    // Submit applications
    final ApplicationAttemptId appAttemptId_0 = 
        TestUtils.getMockApplicationAttemptId(0, 0); 
    FiCaSchedulerApp app_0 = 
        new FiCaSchedulerApp(appAttemptId_0, user_0, a, 
            mock(ActiveUsersManager.class), spyRMContext);
    a.submitApplicationAttempt(app_0, user_0);

    final ApplicationAttemptId appAttemptId_1 = 
        TestUtils.getMockApplicationAttemptId(1, 0); 
    FiCaSchedulerApp app_1 = 
        new FiCaSchedulerApp(appAttemptId_1, user_1, a, 
            mock(ActiveUsersManager.class), spyRMContext);
    a.submitApplicationAttempt(app_1, user_1);  

    // Setup some nodes
    String host_0 = ""127.0.0.1"";
    FiCaSchedulerNode node_0 = TestUtils.getMockNode(host_0, DEFAULT_RACK, 0, 4*GB);

    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app_0.getApplicationAttemptId(), app_0, app_1.getApplicationAttemptId(),
        app_1);
    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node_0.getNodeID(),
        node_0);
    
    final int numNodes = 2;
    Resource clusterResource = 
        Resources.createResource(numNodes * (4*GB), numNodes * 16);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));
    
    // Setup resource-requests
    Priority priority = TestUtils.createMockPriority(1);
    app_0.updateResourceRequests(Collections.singletonList(
            TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 2, true,
                priority, recordFactory)));

    app_1.updateResourceRequests(Collections.singletonList(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 4*GB, 1, true,
            priority, recordFactory)));

    // Start testing...
    
    // Only 1 container
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(1*GB, a.getUsedResources().getMemorySize());
    assertEquals(1*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(1*GB, a.getMetrics().getAllocatedMB());
    assertEquals(0*GB, a.getMetrics().getAvailableMB());

    // Also 2nd -> minCapacity = 1024 since (.1 * 8G) < minAlloc, also
    // you can get one container more than user-limit
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(2*GB, a.getUsedResources().getMemorySize());
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(2*GB, a.getMetrics().getAllocatedMB());
    
    // Now, reservation should kick in for app_1
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(6*GB, a.getUsedResources().getMemorySize());
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(4*GB, app_1.getCurrentReservation().getMemorySize());
    assertEquals(2*GB, node_0.getAllocatedResource().getMemorySize());
    assertEquals(4*GB, a.getMetrics().getReservedMB());
    assertEquals(2*GB, a.getMetrics().getAllocatedMB());
    
    // Now free 1 container from app_0 i.e. 1G
    RMContainer rmContainer = app_0.getLiveContainers().iterator().next();
    a.completedContainer(clusterResource, app_0, node_0, rmContainer,
        ContainerStatus.newInstance(rmContainer.getContainerId(),
            ContainerState.COMPLETE, """",
            ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),
        RMContainerEventType.KILL, null, true);
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(5*GB, a.getUsedResources().getMemorySize());
    assertEquals(1*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(4*GB, app_1.getCurrentReservation().getMemorySize());
    assertEquals(1*GB, node_0.getAllocatedResource().getMemorySize());
    assertEquals(4*GB, a.getMetrics().getReservedMB());
    assertEquals(1*GB, a.getMetrics().getAllocatedMB());

    // Now finish another container from app_0 and fulfill the reservation
    rmContainer = app_0.getLiveContainers().iterator().next();
    a.completedContainer(clusterResource, app_0, node_0, rmContainer,
        ContainerStatus.newInstance(rmContainer.getContainerId(),
            ContainerState.COMPLETE, """",
            ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),
        RMContainerEventType.KILL, null, true);
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
            new ResourceLimits(clusterResource),
            SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(4*GB, a.getUsedResources().getMemorySize());
    assertEquals(0*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(4*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentReservation().getMemorySize());
    assertEquals(4*GB, node_0.getAllocatedResource().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(4*GB, a.getMetrics().getAllocatedMB());
  }",1
"@Test
  public void testSchedulingConstraints() throws Exception {

    // Manipulate queue 'a'
    LeafQueue a = stubLeafQueue((LeafQueue)queues.get(A));

    // User
    String user_0 = ""user_0"";
    
    // Submit applications
    final ApplicationAttemptId appAttemptId_0 = 
        TestUtils.getMockApplicationAttemptId(0, 0); 
    FiCaSchedulerApp app_0 = 
        new FiCaSchedulerApp(appAttemptId_0, user_0, a, 
            mock(ActiveUsersManager.class), spyRMContext);
    a.submitApplicationAttempt(app_0, user_0);
    
    // Setup some nodes and racks
    String host_0_0 = ""127.0.0.1"";
    String rack_0 = ""rack_0"";
    FiCaSchedulerNode node_0_0 = TestUtils.getMockNode(host_0_0, rack_0, 0, 8*GB);
    String host_0_1 = ""127.0.0.2"";
    FiCaSchedulerNode node_0_1 = TestUtils.getMockNode(host_0_1, rack_0, 0, 8*GB);
    
    
    String host_1_0 = ""127.0.0.3"";
    String rack_1 = ""rack_1"";
    FiCaSchedulerNode node_1_0 = TestUtils.getMockNode(host_1_0, rack_1, 0, 8*GB);

    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app_0.getApplicationAttemptId(), app_0);
    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node_0_0.getNodeID(),
        node_0_0, node_0_1.getNodeID(), node_0_1, node_1_0.getNodeID(),
        node_1_0);
    
    final int numNodes = 3;
    Resource clusterResource = Resources.createResource(
        numNodes * (8*GB), numNodes * 16);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Setup resource-requests and submit
    Priority priority = TestUtils.createMockPriority(1);
    SchedulerRequestKey schedulerKey = toSchedulerKey(priority);
    List<ResourceRequest> app_0_requests_0 = new ArrayList<ResourceRequest>();
    app_0_requests_0.add(
        TestUtils.createResourceRequest(host_0_0, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(host_0_1, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(rack_0, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(host_1_0, 1*GB, 1, 
            true, priority, recordFactory));
    app_0_requests_0.add(
        TestUtils.createResourceRequest(rack_1, 1*GB, 1, 
            true, priority, recordFactory));
    app_0.updateResourceRequests(app_0_requests_0);

    // Start testing...
    
    // Add one request
    app_0_requests_0.clear();
    app_0_requests_0.add(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 1, // only 1
            true, priority, recordFactory));
    app_0.updateResourceRequests(app_0_requests_0);
    
    // NODE_LOCAL - node_0_1
    CSAssignment assignment = a.assignContainers(clusterResource, node_0_0,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyContainerAllocated(assignment, NodeType.NODE_LOCAL);
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    // should reset
    assertEquals(0, app_0.getOutstandingAsksCount(schedulerKey));

    // No allocation on node_1_0 even though it's node/rack local since
    // required(ANY) == 0
    assignment = a.assignContainers(clusterResource, node_1_0,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyNoContainerAllocated(assignment);
    // Still zero
    // since #req=0
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    assertEquals(0, app_0.getOutstandingAsksCount(schedulerKey));
    
    // Add one request
    app_0_requests_0.clear();
    app_0_requests_0.add(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 1, // only one
            true, priority, recordFactory));
    app_0.updateResourceRequests(app_0_requests_0);

    // No allocation on node_0_1 even though it's node/rack local since
    // required(rack_1) == 0
    assignment = a.assignContainers(clusterResource, node_0_1,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyNoContainerAllocated(assignment);
    assertEquals(1, app_0.getSchedulingOpportunities(schedulerKey));
    assertEquals(1, app_0.getOutstandingAsksCount(schedulerKey));
    
    // NODE_LOCAL - node_1
    assignment = a.assignContainers(clusterResource, node_1_0,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyCSAssignment(clusterResource, assignment, a, nodes, apps);
    verifyContainerAllocated(assignment, NodeType.NODE_LOCAL);
    // should reset
    assertEquals(0, app_0.getSchedulingOpportunities(schedulerKey));
    assertEquals(0, app_0.getOutstandingAsksCount(schedulerKey));
  }",1
"@Test
  public void testSingleQueueWithMultipleUsers() throws Exception {
    
    // Mock the queue
    LeafQueue a = stubLeafQueue((LeafQueue)queues.get(A));
    //unset maxCapacity
    a.setMaxCapacity(1.0f);
    
    // Users
    final String user_0 = ""user_0"";
    final String user_1 = ""user_1"";
    final String user_2 = ""user_2"";

    // Submit applications
    final ApplicationAttemptId appAttemptId_0 = 
        TestUtils.getMockApplicationAttemptId(0, 0); 
    FiCaSchedulerApp app_0 = 
        new FiCaSchedulerApp(appAttemptId_0, user_0, a, 
            a.getAbstractUsersManager(), spyRMContext);
    a.submitApplicationAttempt(app_0, user_0);

    final ApplicationAttemptId appAttemptId_1 = 
        TestUtils.getMockApplicationAttemptId(1, 0); 
    FiCaSchedulerApp app_1 = 
        new FiCaSchedulerApp(appAttemptId_1, user_0, a, 
            a.getAbstractUsersManager(), spyRMContext);
    a.submitApplicationAttempt(app_1, user_0);  // same user

    final ApplicationAttemptId appAttemptId_2 = 
        TestUtils.getMockApplicationAttemptId(2, 0); 
    FiCaSchedulerApp app_2 = 
        new FiCaSchedulerApp(appAttemptId_2, user_1, a, 
            a.getAbstractUsersManager(), spyRMContext);
    a.submitApplicationAttempt(app_2, user_1);

    final ApplicationAttemptId appAttemptId_3 = 
        TestUtils.getMockApplicationAttemptId(3, 0); 
    FiCaSchedulerApp app_3 = 
        new FiCaSchedulerApp(appAttemptId_3, user_2, a, 
            a.getAbstractUsersManager(), spyRMContext);
    a.submitApplicationAttempt(app_3, user_2);

    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app_0.getApplicationAttemptId(), app_0, app_1.getApplicationAttemptId(),
        app_1, app_2.getApplicationAttemptId(), app_2,
        app_3.getApplicationAttemptId(), app_3);
    
    // Setup some nodes
    String host_0 = ""127.0.0.1"";
    FiCaSchedulerNode node_0 = TestUtils.getMockNode(host_0, DEFAULT_RACK, 0, 8*GB);
    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node_0.getNodeID(),
        node_0);
    
    final int numNodes = 1;
    Resource clusterResource = 
        Resources.createResource(numNodes * (8*GB), numNodes * 16);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    when(csContext.getClusterResource()).thenReturn(clusterResource);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Setup resource-requests
    Priority priority = TestUtils.createMockPriority(1);
    app_0.updateResourceRequests(Collections.singletonList(
            TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 10, true,
                priority, recordFactory)));

    app_1.updateResourceRequests(Collections.singletonList(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 10, true,
            priority, recordFactory)));

    /** 
     * Start testing... 
     */
    
    // Only 1 container
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(1*GB, a.getUsedResources().getMemorySize());
    assertEquals(1*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());

    // Also 2nd -> minCapacity = 1024 since (.1 * 8G) < minAlloc, also
    // you can get one container more than user-limit
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(2*GB, a.getUsedResources().getMemorySize());
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    
    // Can't allocate 3rd due to user-limit
    a.setUserLimit(25);
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(2*GB, a.getUsedResources().getMemorySize());
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    
    // Submit resource requests for other apps now to 'activate' them
    
    app_2.updateResourceRequests(Collections.singletonList(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 3*GB, 1, true,
            priority, recordFactory)));

    app_3.updateResourceRequests(Collections.singletonList(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 2, true,
            priority, recordFactory)));

    // Now allocations should goto app_2 since 
    // user_0 is at limit inspite of high user-limit-factor
    a.setUserLimitFactor(10);
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(5*GB, a.getUsedResources().getMemorySize());
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(3*GB, app_2.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_3.getCurrentConsumption().getMemorySize());

    // Now allocations should goto app_0 since 
    // user_0 is at user-limit not above it
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(6*GB, a.getUsedResources().getMemorySize());
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(3*GB, app_2.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_3.getCurrentConsumption().getMemorySize());
    
    // Test max-capacity
    // Now - no more allocs since we are at max-cap
    a.setMaxCapacity(0.5f);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(6*GB, a.getUsedResources().getMemorySize());
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(3*GB, app_2.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_3.getCurrentConsumption().getMemorySize());
    
    // Revert max-capacity and user-limit-factor
    // Now, allocations should goto app_3 since it's under user-limit 
    a.setMaxCapacity(1.0f);
    a.setUserLimitFactor(1);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(7*GB, a.getUsedResources().getMemorySize());
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(3*GB, app_2.getCurrentConsumption().getMemorySize());
    assertEquals(1*GB, app_3.getCurrentConsumption().getMemorySize());

    // Now we should assign to app_3 again since user_2 is under user-limit
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(8*GB, a.getUsedResources().getMemorySize());
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(3*GB, app_2.getCurrentConsumption().getMemorySize());
    assertEquals(2*GB, app_3.getCurrentConsumption().getMemorySize());

    // 8. Release each container from app_0
    for (RMContainer rmContainer : app_0.getLiveContainers()) {
      a.completedContainer(clusterResource, app_0, node_0, rmContainer,
          ContainerStatus.newInstance(rmContainer.getContainerId(),
              ContainerState.COMPLETE, """",
              ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),
          RMContainerEventType.KILL, null, true);
    }",1
"@Test
  public void testSingleQueueWithOneUser() throws Exception {

    // Manipulate queue 'a'
    LeafQueue a = stubLeafQueue((LeafQueue)queues.get(A));
    //unset maxCapacity
    a.setMaxCapacity(1.0f);

    // Users
    final String user_0 = ""user_0"";

    // Active Users Manager
    AbstractUsersManager activeUserManager = a.getAbstractUsersManager();

    // Submit applications
    final ApplicationAttemptId appAttemptId_0 = 
        TestUtils.getMockApplicationAttemptId(0, 0); 
    FiCaSchedulerApp app_0 = 
        new FiCaSchedulerApp(appAttemptId_0, user_0, a, 
            activeUserManager, spyRMContext);
    a.submitApplicationAttempt(app_0, user_0);

    final ApplicationAttemptId appAttemptId_1 = 
        TestUtils.getMockApplicationAttemptId(1, 0); 
    FiCaSchedulerApp app_1 = 
        new FiCaSchedulerApp(appAttemptId_1, user_0, a, 
            activeUserManager, spyRMContext);
    a.submitApplicationAttempt(app_1, user_0);  // same user

    
    // Setup some nodes
    String host_0 = ""127.0.0.1"";
    FiCaSchedulerNode node_0 = TestUtils.getMockNode(host_0, DEFAULT_RACK, 0,
        8*GB);

    Map<ApplicationAttemptId, FiCaSchedulerApp> apps = ImmutableMap.of(
        app_0.getApplicationAttemptId(), app_0, app_1.getApplicationAttemptId(),
        app_1);
    Map<NodeId, FiCaSchedulerNode> nodes = ImmutableMap.of(node_0.getNodeID(),
        node_0);

    final int numNodes = 1;
    Resource clusterResource = 
        Resources.createResource(numNodes * (8*GB), numNodes * 16);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Setup resource-requests
    Priority priority = TestUtils.createMockPriority(1);
    app_0.updateResourceRequests(Collections.singletonList(
            TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 3, true,
                priority, recordFactory)));

    app_1.updateResourceRequests(Collections.singletonList(
        TestUtils.createResourceRequest(ResourceRequest.ANY, 1*GB, 2, true,
            priority, recordFactory)));

    // Start testing...
    
    // Only 1 container
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(1*GB, a.getUsedResources().getMemorySize());
    assertEquals(1*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(1*GB, a.getMetrics().getAllocatedMB());
    assertEquals(0*GB, a.getMetrics().getAvailableMB());

    // Also 2nd -> minCapacity = 1024 since (.1 * 8G) < minAlloc, also
    // you can get one container more than user-limit
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(2*GB, a.getUsedResources().getMemorySize());
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(2*GB, a.getMetrics().getAllocatedMB());
    
    // Can't allocate 3rd due to user-limit
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(2*GB, a.getUsedResources().getMemorySize());
    assertEquals(2*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(2*GB, a.getMetrics().getAllocatedMB());
    
    // Bump up user-limit-factor, now allocate should work
    a.setUserLimitFactor(10);
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(3*GB, a.getUsedResources().getMemorySize());
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(3*GB, a.getMetrics().getAllocatedMB());

    // One more should work, for app_1, due to user-limit-factor
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(4*GB, a.getUsedResources().getMemorySize());
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(1*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(4*GB, a.getMetrics().getAllocatedMB());

    // Test max-capacity
    // Now - no more allocs since we are at max-cap
    a.setMaxCapacity(0.5f);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));
    applyCSAssignment(clusterResource,
        a.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY), a, nodes, apps);
    assertEquals(4*GB, a.getUsedResources().getMemorySize());
    assertEquals(3*GB, app_0.getCurrentConsumption().getMemorySize());
    assertEquals(1*GB, app_1.getCurrentConsumption().getMemorySize());
    assertEquals(0*GB, a.getMetrics().getReservedMB());
    assertEquals(4*GB, a.getMetrics().getAllocatedMB());
    
    // Release each container from app_0
    for (RMContainer rmContainer : app_0.getLiveContainers()) {
      a.completedContainer(clusterResource, app_0, node_0, rmContainer,
          ContainerStatus.newInstance(rmContainer.getContainerId(),
              ContainerState.COMPLETE, """",
              ContainerExitStatus.KILLED_BY_RESOURCEMANAGER),
          RMContainerEventType.KILL, null, true);
    }",1
"@Test
  public void testMultiLevelQueues() throws Exception {
    /*
     * Structure of queue:
     *            Root
     *           ____________
     *          /    |   \   \
     *         A     B    C   D
     *       / |   / | \   \
     *      A1 A2 B1 B2 B3  C1
     *                        \
     *                         C11
     *                           \
     *                           C111
     *                             \
     *                              C1111
     */
    
    // Setup queue configs
    setupMultiLevelQueues(csConf);

    CSQueueStore queues = new CSQueueStore();
    CSQueue root =
        CapacitySchedulerQueueManager.parseQueue(queueContext, csConf, null,
            CapacitySchedulerConfiguration.ROOT, queues, queues,
            TestUtils.spyHook);
    
    // Setup some nodes
    final int memoryPerNode = 10;
    final int coresPerNode = 16;
    final int numNodes = 3;
    
    FiCaSchedulerNode node_0 = 
        TestUtils.getMockNode(""host_0"", DEFAULT_RACK, 0, memoryPerNode*GB);
    FiCaSchedulerNode node_1 = 
        TestUtils.getMockNode(""host_1"", DEFAULT_RACK, 0, memoryPerNode*GB);
    FiCaSchedulerNode node_2 = 
        TestUtils.getMockNode(""host_2"", DEFAULT_RACK, 0, memoryPerNode*GB);
    
    final Resource clusterResource = 
        Resources.createResource(numNodes * (memoryPerNode*GB), 
            numNodes * coresPerNode);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Start testing
    CSQueue a = queues.get(A);
    a.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    CSQueue b = queues.get(B);
    b.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    CSQueue c = queues.get(C);
    c.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    CSQueue d = queues.get(D);
    d.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));

    CSQueue a1 = queues.get(A1);
    a1.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    CSQueue a2 = queues.get(A2);
    a2.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));

    CSQueue b1 = queues.get(B1);
    b1.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    CSQueue b2 = queues.get(B2);
    b2.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    CSQueue b3 = queues.get(B3);
    b3.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    queues.get(CapacitySchedulerConfiguration.ROOT).getQueueResourceUsage()
    .incPending(Resources.createResource(1 * GB));

    // Simulate C returning a container on node_0
    stubQueueAllocation(a, clusterResource, node_0, 0*GB);
    stubQueueAllocation(b, clusterResource, node_0, 0*GB);
    stubQueueAllocation(c, clusterResource, node_0, 1*GB);
    stubQueueAllocation(d, clusterResource, node_0, 0*GB);
    root.assignContainers(clusterResource, node_0, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    verifyQueueMetrics(a, 0*GB, clusterResource);
    verifyQueueMetrics(b, 0*GB, clusterResource);
    verifyQueueMetrics(c, 1*GB, clusterResource);
    verifyQueueMetrics(d, 0*GB, clusterResource);
    reset(a); reset(b); reset(c);

    // Now get B2 to allocate
    // A = 0/3, B = 0/15, C = 1/6, D=0/6
    stubQueueAllocation(a, clusterResource, node_1, 0*GB);
    stubQueueAllocation(b2, clusterResource, node_1, 4*GB);
    stubQueueAllocation(c, clusterResource, node_1, 0*GB);
    root.assignContainers(clusterResource, node_1, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    applyAllocationToQueue(clusterResource, 4*GB,
        b);
    verifyQueueMetrics(a, 0*GB, clusterResource);
    verifyQueueMetrics(b, 4*GB, clusterResource);
    verifyQueueMetrics(c, 1*GB, clusterResource);
    reset(a); reset(b); reset(c);
    
    // Now get both A1, C & B3 to allocate in right order
    // A = 0/3, B = 4/15, C = 1/6, D=0/6
    stubQueueAllocation(a1, clusterResource, node_0, 1*GB);
    stubQueueAllocation(b3, clusterResource, node_0, 2*GB);
    stubQueueAllocation(c, clusterResource, node_0, 2*GB);

    root.assignContainers(clusterResource, node_0, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    InOrder allocationOrder = inOrder(a, c, b);
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    applyAllocationToQueue(clusterResource, 1 * GB, a);

    root.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder.verify(c).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    applyAllocationToQueue(clusterResource, 2 * GB, root);

    root.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    applyAllocationToQueue(clusterResource, 2*GB, b);
    verifyQueueMetrics(a, 1*GB, clusterResource);
    verifyQueueMetrics(b, 6*GB, clusterResource);
    verifyQueueMetrics(c, 3*GB, clusterResource);
    reset(a); reset(b); reset(c);
    
    // Now verify max-capacity
    // A = 1/3, B = 6/15, C = 3/6, D=0/6
    // Ensure a1 won't alloc above max-cap although it should get 
    // scheduling opportunity now, right after a2
    LOG.info(""here"");
    ((ParentQueue)a).setMaxCapacity(.1f);  // a should be capped at 3/30
    stubQueueAllocation(a1, clusterResource, node_2, 1*GB); // shouldn't be 
                                                            // allocated due 
                                                            // to max-cap
    stubQueueAllocation(a2, clusterResource, node_2, 2*GB);
    stubQueueAllocation(b3, clusterResource, node_2, 1*GB);
    stubQueueAllocation(b1, clusterResource, node_2, 1*GB);
    stubQueueAllocation(c, clusterResource, node_2, 1*GB);
    root.assignContainers(clusterResource, node_2,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder = inOrder(a, a2, a1, b, c);
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    allocationOrder.verify(a2).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    applyAllocationToQueue(clusterResource, 2*GB, a);

    root.assignContainers(clusterResource, node_2,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    applyAllocationToQueue(clusterResource, 2*GB, b);

    root.assignContainers(clusterResource, node_2,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder.verify(c).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    verifyQueueMetrics(a, 3*GB, clusterResource);
    verifyQueueMetrics(b, 8*GB, clusterResource);
    verifyQueueMetrics(c, 4*GB, clusterResource);
    reset(a); reset(b); reset(c);
  }",1
"@Test
  public void testOffSwitchScheduling() throws Exception {
    // Setup queue configs
    setupSingleLevelQueues(csConf);

    CSQueueStore queues = new CSQueueStore();
    CSQueue root =
        CapacitySchedulerQueueManager.parseQueue(queueContext, csConf, null,
            CapacitySchedulerConfiguration.ROOT, queues, queues,
            TestUtils.spyHook);

    // Setup some nodes
    final int memoryPerNode = 10;
    final int coresPerNode = 16;
    final int numNodes = 2;

    FiCaSchedulerNode node_0 =
        TestUtils.getMockNode(""host_0"", DEFAULT_RACK, 0, memoryPerNode*GB);
    FiCaSchedulerNode node_1 =
        TestUtils.getMockNode(""host_1"", DEFAULT_RACK, 0, memoryPerNode*GB);

    final Resource clusterResource =
        Resources.createResource(numNodes * (memoryPerNode*GB),
            numNodes * coresPerNode);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Start testing
    LeafQueue a = (LeafQueue)queues.get(A);
    LeafQueue b = (LeafQueue)queues.get(B);
    a.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    b.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    queues.get(CapacitySchedulerConfiguration.ROOT).getQueueResourceUsage()
        .incPending(Resources.createResource(1 * GB));

    // Simulate B returning a container on node_0
    stubQueueAllocation(a, clusterResource, node_0, 0*GB, NodeType.OFF_SWITCH);
    stubQueueAllocation(b, clusterResource, node_0, 1*GB, NodeType.OFF_SWITCH);
    root.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    verifyQueueMetrics(a, 0*GB, clusterResource);
    verifyQueueMetrics(b, 1*GB, clusterResource);

    // Now, A should get the scheduling opportunity since A=0G/6G, B=1G/14G
    // also, B gets a scheduling opportunity since A allocates RACK_LOCAL
    stubQueueAllocation(a, clusterResource, node_1, 2*GB, NodeType.RACK_LOCAL);
    stubQueueAllocation(b, clusterResource, node_1, 1*GB, NodeType.OFF_SWITCH);
    root.assignContainers(clusterResource, node_1,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    InOrder allocationOrder = inOrder(a);
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    root.assignContainers(clusterResource, node_1,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder = inOrder(b);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    verifyQueueMetrics(a, 2*GB, clusterResource);
    verifyQueueMetrics(b, 2*GB, clusterResource);

    // Now, B should get the scheduling opportunity
    // since A has 2/6G while B has 2/14G,
    // However, since B returns off-switch, A won't get an opportunity
    stubQueueAllocation(a, clusterResource, node_0, 1*GB, NodeType.NODE_LOCAL);
    stubQueueAllocation(b, clusterResource, node_0, 2*GB, NodeType.OFF_SWITCH);
    root.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder = inOrder(b, a);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    verifyQueueMetrics(a, 2*GB, clusterResource);
    verifyQueueMetrics(b, 4*GB, clusterResource);

  }",1
"@Test
  public void testQueueAcl() throws Exception {
 
    setupMultiLevelQueues(csConf);
    csConf.setAcl(ROOT, QueueACL.SUBMIT_APPLICATIONS, "" "");
    csConf.setAcl(ROOT, QueueACL.ADMINISTER_QUEUE, "" "");

    csConf.setAcl(Q_C, QueueACL.ADMINISTER_QUEUE, ""*"");
    csConf.setAcl(Q_C11, QueueACL.SUBMIT_APPLICATIONS, ""*"");
    queueContext.reinitialize();

    CSQueueStore queues = new CSQueueStore();
    CSQueue root = 
        CapacitySchedulerQueueManager.parseQueue(queueContext, csConf, null,
            CapacitySchedulerConfiguration.ROOT, queues, queues,
            TestUtils.spyHook);
    YarnAuthorizationProvider authorizer =
        YarnAuthorizationProvider.getInstance(conf);
    AppPriorityACLsManager appPriorityACLManager = new AppPriorityACLsManager(
        conf);
    CapacitySchedulerQueueManager.setQueueAcls(authorizer,
        appPriorityACLManager, queues);

    UserGroupInformation user = UserGroupInformation.getCurrentUser();
    // Setup queue configs
    ParentQueue c = (ParentQueue)queues.get(C);
    ParentQueue c1 = (ParentQueue)queues.get(C1);
    ParentQueue c11 = (ParentQueue)queues.get(C11);
    ParentQueue c111 = (ParentQueue)queues.get(C111);

    assertFalse(root.hasAccess(QueueACL.ADMINISTER_QUEUE, user));
    List<QueueUserACLInfo> aclInfos = root.getQueueUserAclInfo(user);
    assertFalse(hasQueueACL(aclInfos, QueueACL.ADMINISTER_QUEUE, ""root""));
    
    assertFalse(root.hasAccess(QueueACL.SUBMIT_APPLICATIONS, user));
    assertFalse(hasQueueACL(aclInfos, QueueACL.SUBMIT_APPLICATIONS, ""root""));

    // c has no SA, but QA
    assertTrue(c.hasAccess(QueueACL.ADMINISTER_QUEUE, user));
    assertTrue(hasQueueACL(aclInfos,  QueueACL.ADMINISTER_QUEUE, ""root.c""));
    assertFalse(c.hasAccess(QueueACL.SUBMIT_APPLICATIONS, user));
    assertFalse(hasQueueACL(aclInfos, QueueACL.SUBMIT_APPLICATIONS, ""root.c""));

    //Queue c1 has QA, no SA (gotten perm from parent)
    assertTrue(c1.hasAccess(QueueACL.ADMINISTER_QUEUE, user)); 
    assertTrue(hasQueueACL(aclInfos,  QueueACL.ADMINISTER_QUEUE, ""root.c.c1""));
    assertFalse(c1.hasAccess(QueueACL.SUBMIT_APPLICATIONS, user)); 
    assertFalse(hasQueueACL(
        aclInfos, QueueACL.SUBMIT_APPLICATIONS, ""root.c.c1""));

    //Queue c11 has permissions from parent queue and SA
    assertTrue(c11.hasAccess(QueueACL.ADMINISTER_QUEUE, user));
    assertTrue(hasQueueACL(
        aclInfos,  QueueACL.ADMINISTER_QUEUE, ""root.c.c1.c11""));
    assertTrue(c11.hasAccess(QueueACL.SUBMIT_APPLICATIONS, user));
    assertTrue(
        hasQueueACL(aclInfos, QueueACL.SUBMIT_APPLICATIONS, ""root.c.c1.c11""));

    //Queue c111 has SA and AQ, both from parent
    assertTrue(c111.hasAccess(QueueACL.ADMINISTER_QUEUE, user));
    assertTrue(hasQueueACL(
        aclInfos,  QueueACL.ADMINISTER_QUEUE, ""root.c.c1.c11.c111""));
    assertTrue(c111.hasAccess(QueueACL.SUBMIT_APPLICATIONS, user));
    assertTrue(hasQueueACL(
        aclInfos, QueueACL.SUBMIT_APPLICATIONS, ""root.c.c1.c11.c111""));

    reset(c);
  }",1
"@Test
  public void testSingleLevelQueues() throws Exception {
    // Setup queue configs
    setupSingleLevelQueues(csConf);

    CSQueueStore queues = new CSQueueStore();
    CSQueue root =
        CapacitySchedulerQueueManager.parseQueue(queueContext, csConf, null,
            CapacitySchedulerConfiguration.ROOT, queues, queues, 
            TestUtils.spyHook);

    // Setup some nodes
    final int memoryPerNode = 10;
    final int coresPerNode = 16;
    final int numNodes = 2;
    
    FiCaSchedulerNode node_0 = 
        TestUtils.getMockNode(""host_0"", DEFAULT_RACK, 0, memoryPerNode*GB);
    FiCaSchedulerNode node_1 = 
        TestUtils.getMockNode(""host_1"", DEFAULT_RACK, 0, memoryPerNode*GB);
    
    final Resource clusterResource = 
        Resources.createResource(numNodes * (memoryPerNode*GB),
            numNodes * coresPerNode);
    when(csContext.getNumClusterNodes()).thenReturn(numNodes);
    root.updateClusterResource(clusterResource,
        new ResourceLimits(clusterResource));

    // Start testing
    LeafQueue a = (LeafQueue)queues.get(A);
    LeafQueue b = (LeafQueue)queues.get(B);
    
    a.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    b.getQueueResourceUsage().incPending(Resources.createResource(1 * GB));
    queues.get(CapacitySchedulerConfiguration.ROOT).getQueueResourceUsage()
    .incPending(Resources.createResource(1 * GB));
    
    // Simulate B returning a container on node_0
    stubQueueAllocation(a, clusterResource, node_0, 0*GB);
    stubQueueAllocation(b, clusterResource, node_0, 1*GB);
    root.assignContainers(clusterResource, node_0, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    verifyQueueMetrics(a, 0*GB, clusterResource);
    verifyQueueMetrics(b, 1*GB, clusterResource);
    
    // Now, A should get the scheduling opportunity since A=0G/6G, B=1G/14G
    stubQueueAllocation(a, clusterResource, node_1, 2*GB);
    stubQueueAllocation(b, clusterResource, node_1, 1*GB);
    root.assignContainers(clusterResource, node_1,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    InOrder allocationOrder = inOrder(a, b);
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    root.assignContainers(clusterResource, node_1,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    verifyQueueMetrics(a, 2*GB, clusterResource);
    verifyQueueMetrics(b, 2*GB, clusterResource);

    // Now, B should get the scheduling opportunity 
    // since A has 2/6G while B has 2/14G
    stubQueueAllocation(a, clusterResource, node_0, 1*GB);
    stubQueueAllocation(b, clusterResource, node_0, 2*GB);
    root.assignContainers(clusterResource, node_0, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    root.assignContainers(clusterResource, node_0,
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder = inOrder(b, a);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    verifyQueueMetrics(a, 3*GB, clusterResource);
    verifyQueueMetrics(b, 4*GB, clusterResource);

    // Now, B should still get the scheduling opportunity 
    // since A has 3/6G while B has 4/14G
    stubQueueAllocation(a, clusterResource, node_0, 0*GB);
    stubQueueAllocation(b, clusterResource, node_0, 4*GB);
    root.assignContainers(clusterResource, node_0, 
        new ResourceLimits(clusterResource), SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder = inOrder(b, a);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    verifyQueueMetrics(a, 3*GB, clusterResource);
    verifyQueueMetrics(b, 8*GB, clusterResource);

    // Now, A should get the scheduling opportunity 
    // since A has 3/6G while B has 8/14G
    stubQueueAllocation(a, clusterResource, node_1, 1*GB);
    stubQueueAllocation(b, clusterResource, node_1, 1*GB);
    root.assignContainers(clusterResource, node_1,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    root.assignContainers(clusterResource, node_1,
        new ResourceLimits(clusterResource),
        SchedulingMode.RESPECT_PARTITION_EXCLUSIVITY);
    allocationOrder = inOrder(a, b);
    allocationOrder.verify(b).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    allocationOrder.verify(a).assignContainers(eq(clusterResource),
        any(CandidateNodeSet.class), anyResourceLimits(),
        any(SchedulingMode.class));
    verifyQueueMetrics(a, 4*GB, clusterResource);
    verifyQueueMetrics(b, 9*GB, clusterResource);
  }",1
"@Test
  public void testTempContainerAllocations()
      throws InvalidAllocationTagsQueryException {
    /**
     * Construct both TEMP and normal containers: Node1: TEMP container_1_1
     * (mapper/reducer/app_1) container_1_2 (service/app_1)
     *
     * Node2: container_1_3 (reducer/app_1) TEMP container_2_1 (service/app_2)
     */

    AllocationTagsManager atm = new AllocationTagsManager(rmContext);
    LocalAllocationTagsManager ephAtm =
        new LocalAllocationTagsManager(atm);

    // 3 Containers from app1
    ephAtm.addTempTags(NodeId.fromString(""host1:123""),
        TestUtils.getMockApplicationId(1),
        ImmutableSet.of(""mapper"", ""reducer""));

    atm.addContainer(NodeId.fromString(""host1:123""),
        TestUtils.getMockContainerId(1, 2), ImmutableSet.of(""service""));

    atm.addContainer(NodeId.fromString(""host2:123""),
        TestUtils.getMockContainerId(1, 3), ImmutableSet.of(""reducer""));

    // 1 Container from app2
    ephAtm.addTempTags(NodeId.fromString(""host2:123""),
        TestUtils.getMockApplicationId(2), ImmutableSet.of(""service""));

    // Expect tag mappings to be present including temp Tags
    Assert.assertEquals(1,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host1:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(1),
                ImmutableSet.of(""mapper"")),
            Long::sum));

    Assert.assertEquals(1,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host1:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(1),
                ImmutableSet.of(""service"")),
            Long::sum));

    Assert.assertEquals(1,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host2:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(2),
                ImmutableSet.of(""service"")),
            Long::sum));

    // Do a temp Tag cleanup on app2
    ephAtm.cleanTempContainers(TestUtils.getMockApplicationId(2));
    Assert.assertEquals(0,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host2:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(2),
                ImmutableSet.of(""service"")),
            Long::sum));
    // Expect app1 to be unaffected
    Assert.assertEquals(1,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host1:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(1),
                ImmutableSet.of(""mapper"")),
            Long::sum));
    // Do a cleanup on app1 as well
    ephAtm.cleanTempContainers(TestUtils.getMockApplicationId(1));
    Assert.assertEquals(0,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host1:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(1),
                ImmutableSet.of(""mapper"")),
            Long::sum));

    // Non temp-tags should be unaffected
    Assert.assertEquals(1,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host1:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(1),
                ImmutableSet.of(""service"")),
            Long::sum));

    Assert.assertEquals(0,
        atm.getNodeCardinalityByOp(NodeId.fromString(""host2:123""),
            AllocationTags.createSingleAppAllocationTags(
                TestUtils.getMockApplicationId(2),
                ImmutableSet.of(""service"")),
            Long::sum));

    // Expect app2 with no containers, and app1 with 2 containers across 2 nodes
    Assert.assertEquals(2,
        atm.getPerAppNodeMappings().get(TestUtils.getMockApplicationId(1))
            .getTypeToTagsWithCount().size());

    Assert.assertNull(
        atm.getPerAppNodeMappings().get(TestUtils.getMockApplicationId(2)));
  }",1
"@Test
  public void testInvalidAllocationTagNamespace() {
    AllocationTagsManager tm = new AllocationTagsManager(rmContext);
    PlacementConstraintManagerService pcm =
        new MemoryPlacementConstraintManager();
    rmContext.setAllocationTagsManager(tm);
    rmContext.setPlacementConstraintManager(pcm);

    long ts = System.currentTimeMillis();
    ApplicationId application1 = BuilderUtils.newApplicationId(ts, 123);
    RMNode n0r1 = rmNodes.get(0);
    SchedulerNode schedulerNode0 = newSchedulerNode(n0r1.getHostName(),
        n0r1.getRackName(), n0r1.getNodeID());

    PlacementConstraint constraint1 = PlacementConstraints
        .targetNotIn(NODE, allocationTagWithNamespace(""unknown_namespace"",
            ""hbase-m""))
        .build();
    Set<String> srcTags1 = new HashSet<>();
    srcTags1.add(""app1"");

    try {
      PlacementConstraintsUtil.canSatisfyConstraints(application1,
          createSchedulingRequest(srcTags1, constraint1), schedulerNode0,
          pcm, tm);
      Assert.fail(""This should fail because we gave an invalid namespace"");
    }",1
"@Test
  public void testNodeAntiAffinityAssignment()
      throws InvalidAllocationTagsQueryException {
    PlacementConstraintManagerService pcm =
        new MemoryPlacementConstraintManager();
    AllocationTagsManager tm = new AllocationTagsManager(rmContext);
    // Register App1 with anti-affinity constraint map
    pcm.registerApplication(appId1, constraintMap2);
    /**
     * place container:
     * Node0:123 (Rack1):
     *    container_app1_1 (hbase-m)
     */
    RMNode n0_r1 = rmNodes.get(0);
    RMNode n1_r1 = rmNodes.get(1);
    RMNode n2_r2 = rmNodes.get(2);
    RMNode n3_r2 = rmNodes.get(3);

    SchedulerNode schedulerNode0 =newSchedulerNode(n0_r1.getHostName(),
        n0_r1.getRackName(), n0_r1.getNodeID());
    SchedulerNode schedulerNode1 =newSchedulerNode(n1_r1.getHostName(),
        n1_r1.getRackName(), n1_r1.getNodeID());
    SchedulerNode schedulerNode2 =newSchedulerNode(n2_r2.getHostName(),
        n2_r2.getRackName(), n2_r2.getNodeID());
    SchedulerNode schedulerNode3 =newSchedulerNode(n3_r2.getHostName(),
        n3_r2.getRackName(), n3_r2.getNodeID());

    // 1 Containers on node 0 with allocationTag 'hbase-m'
    ContainerId hbase_m = ContainerId
        .newContainerId(ApplicationAttemptId.newInstance(appId1, 0), 0);
    tm.addContainer(n0_r1.getNodeID(), hbase_m, ImmutableSet.of(""hbase-m""));

    // 'spark' placement on Node0 should now FAIL
    Assert.assertFalse(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode0, pcm, tm));
    // SUCCEED on the rest of the nodes
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode1, pcm, tm));
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode2, pcm, tm));
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode3, pcm, tm));
  }",1
"@Test
  public void testORConstraintAssignment()
      throws InvalidAllocationTagsQueryException {
    AllocationTagsManager tm = new AllocationTagsManager(rmContext);
    PlacementConstraintManagerService pcm =
        new MemoryPlacementConstraintManager();
    // Register App1 with anti-affinity constraint map.
    pcm.registerApplication(appId1, constraintMap4);
    RMNode n0r1 = rmNodes.get(0);
    RMNode n1r1 = rmNodes.get(1);
    RMNode n2r2 = rmNodes.get(2);
    RMNode n3r2 = rmNodes.get(3);

    /**
     * Place container:
     *  n0: hbase-m(1)
     *  n1: """"
     *  n2: hbase-rs(1)
     *  n3: """"
     */
    tm.addContainer(n0r1.getNodeID(),
        newContainerId(appId1, 1), ImmutableSet.of(""hbase-m""));
    tm.addContainer(n2r2.getNodeID(),
        newContainerId(appId1, 2), ImmutableSet.of(""hbase-rs""));
    Assert.assertEquals(1L, tm.getAllocationTagsWithCount(n0r1.getNodeID())
        .get(""hbase-m"").longValue());
    Assert.assertEquals(1L, tm.getAllocationTagsWithCount(n2r2.getNodeID())
        .get(""hbase-rs"").longValue());

    SchedulerNode schedulerNode0 =newSchedulerNode(n0r1.getHostName(),
        n0r1.getRackName(), n0r1.getNodeID());
    SchedulerNode schedulerNode1 =newSchedulerNode(n1r1.getHostName(),
        n1r1.getRackName(), n1r1.getNodeID());
    SchedulerNode schedulerNode2 =newSchedulerNode(n2r2.getHostName(),
        n2r2.getRackName(), n2r2.getNodeID());
    SchedulerNode schedulerNode3 =newSchedulerNode(n3r2.getHostName(),
        n3r2.getRackName(), n3r2.getNodeID());

    // n0 and n2 should be qualified for allocation as
    // they either have hbase-m or hbase-rs tag
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode0, pcm, tm));
    Assert.assertFalse(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode1, pcm, tm));
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode2, pcm, tm));
    Assert.assertFalse(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode3, pcm, tm));

    /**
     * Place container:
     *  n0: hbase-m(1)
     *  n1: """"
     *  n2: hbase-rs(1)
     *  n3: hbase-rs(1)
     */
    tm.addContainer(n3r2.getNodeID(),
        newContainerId(appId1, 2), ImmutableSet.of(""hbase-rs""));
    // n3 is qualified now because it is allocated with hbase-rs tag
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag1), schedulerNode3, pcm, tm));

    /**
     * Place container:
     *  n0: hbase-m(1)
     *  n1: """"
     *  n2: hbase-rs(1), spark(1)
     *  n3: hbase-rs(1)
     */
    // Place
    tm.addContainer(n2r2.getNodeID(),
        newContainerId(appId1, 3), ImmutableSet.of(""spark""));
    // According to constraint, ""zk"" is allowed to be placed on a node
    // has ""hbase-m"" tag OR a node has both ""hbase-rs"" and ""spark"" tags.
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag2), schedulerNode0, pcm, tm));
    Assert.assertFalse(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag2), schedulerNode1, pcm, tm));
    Assert.assertTrue(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag2), schedulerNode2, pcm, tm));
    Assert.assertFalse(PlacementConstraintsUtil.canSatisfyConstraints(appId1,
        createSchedulingRequest(sourceTag2), schedulerNode3, pcm, tm));
  }",1
"@Test
  public void testCalculateMinShareRatios() {
    Map<String, Integer> index = ResourceUtils.getResourceTypeIndex();
    Resource used = Resources.createResource(10, 5);
    Resource minShares = Resources.createResource(5, 10);
    float[][] ratios = new float[3][3];
    DominantResourceFairnessComparatorN comparator =
        new DominantResourceFairnessComparatorN();

    used.setResourceValue(""test"", 2L);
    minShares.setResourceValue(""test"", 0L);

    comparator.calculateMinShareRatios(used, minShares, ratios);

    assertEquals(""Calculated min share ratio for memory (10MB out of 5MB) is ""
        + ""incorrect"", 2.0,
        ratios[index.get(ResourceInformation.MEMORY_MB.getName())][2], .00001f);
    assertEquals(""Calculated min share ratio for vcores (5 out of 10) is ""
        + ""incorrect"", 0.5,
        ratios[index.get(ResourceInformation.VCORES.getName())][2], .00001f);
    assertEquals(""Calculated min share ratio for test resource (0 out of 5) is ""
        + ""incorrect"", Float.POSITIVE_INFINITY, ratios[index.get(""test"")][2],
        0.00001f);
  }",1
"@Test
  public void testBackwardsCompatibleAllocationFileParsing() throws Exception {
    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);
    AllocationFileLoaderService allocLoader =
        new AllocationFileLoaderService(scheduler);

    AllocationFileWriter.create()
        .useLegacyTagNameForQueues()
        // Give queue A a minimum of 1024 M
        .addQueue(new AllocationFileQueue.Builder(""queueA"")
            .minResources(""1024mb,0vcores"")
            .build())
        // Give queue B a minimum of 2048 M
        .addQueue(new AllocationFileQueue.Builder(""queueB"")
            .minResources(""2048mb,0vcores"")
            .aclAdministerApps(""alice,bob admins"")
            .build())
        // Give queue C no minimum
        .addQueue(new AllocationFileQueue.Builder(""queueC"")
            .aclAdministerApps(""alice,bob admins"")
            .build())
        // Give queue D a limit of 3 running apps
        .addQueue(new AllocationFileQueue.Builder(""queueD"")
            .maxRunningApps(3)
            .build())
        // Give queue E a preemption timeout of one minute and 0.3f threshold
        .addQueue(new AllocationFileQueue.Builder(""queueE"")
            .minSharePreemptionTimeout(60)
            .fairSharePreemptionThreshold(0.3)
            .build())
        // Set default limit of apps per queue to 15
        .queueMaxAppsDefault(15)
        // Set default limit of apps per user to 5
        .userMaxAppsDefault(5)
        // Set default limit of max resource per queue to 4G and 100 cores
        .queueMaxResourcesDefault(""4096mb,100vcores"")
        // Set default limit of AMResourceShare to 0.5f
        .queueMaxAMShareDefault(0.5)
        // Set default min share preemption timeout to 2 minutes
        .defaultMinSharePreemptionTimeout(120)
        // Set default fair share preemption timeout to 5 minutes
        .defaultFairSharePreemptionTimeout(300)
        // Set default fair share preemption threshold to 0.6
        .defaultFairSharePreemptionThreshold(0.6)
        // Set default scheduling policy to DRF
        .drfDefaultQueueSchedulingPolicy()
        // Give user1 a limit of 10 jobs
        .userSettings(new UserSettings.Builder(""user1"")
            .maxRunningApps(10)
            .build())
        .writeToFile(ALLOC_FILE);

    allocLoader.init(conf);
    ReloadListener confHolder = new ReloadListener();
    allocLoader.setReloadListener(confHolder);
    allocLoader.reloadAllocations();
    AllocationConfiguration queueConf = confHolder.allocConf;

    assertEquals(5, queueConf.getConfiguredQueues().get(FSQueueType.LEAF).size());
    assertEquals(Resources.createResource(0),
        queueConf.getMinResources(""root."" + YarnConfiguration.DEFAULT_QUEUE_NAME));
    assertEquals(Resources.createResource(0),
        queueConf.getMinResources(""root."" + YarnConfiguration.DEFAULT_QUEUE_NAME));

    assertEquals(Resources.createResource(1024, 0),
        queueConf.getMinResources(""root.queueA""));
    assertEquals(Resources.createResource(2048, 0),
        queueConf.getMinResources(""root.queueB""));
    assertEquals(Resources.createResource(0),
        queueConf.getMinResources(""root.queueC""));
    assertEquals(Resources.createResource(0),
        queueConf.getMinResources(""root.queueD""));
    assertEquals(Resources.createResource(0),
        queueConf.getMinResources(""root.queueE""));

    assertEquals(15, queueConf.getQueueMaxApps(""root."" + YarnConfiguration.DEFAULT_QUEUE_NAME));
    assertEquals(15, queueConf.getQueueMaxApps(""root.queueA""));
    assertEquals(15, queueConf.getQueueMaxApps(""root.queueB""));
    assertEquals(15, queueConf.getQueueMaxApps(""root.queueC""));
    assertEquals(3, queueConf.getQueueMaxApps(""root.queueD""));
    assertEquals(15, queueConf.getQueueMaxApps(""root.queueE""));
    assertEquals(10, queueConf.getUserMaxApps(""user1""));
    assertEquals(5, queueConf.getUserMaxApps(""user2""));

    assertEquals(120000, queueConf.getMinSharePreemptionTimeout(""root""));
    assertEquals(-1, queueConf.getMinSharePreemptionTimeout(""root."" +
        YarnConfiguration.DEFAULT_QUEUE_NAME));
    assertEquals(-1, queueConf.getMinSharePreemptionTimeout(""root.queueA""));
    assertEquals(-1, queueConf.getMinSharePreemptionTimeout(""root.queueB""));
    assertEquals(-1, queueConf.getMinSharePreemptionTimeout(""root.queueC""));
    assertEquals(-1, queueConf.getMinSharePreemptionTimeout(""root.queueD""));
    assertEquals(60000, queueConf.getMinSharePreemptionTimeout(""root.queueE""));

    assertEquals(300000, queueConf.getFairSharePreemptionTimeout(""root""));
    assertEquals(-1, queueConf.getFairSharePreemptionTimeout(""root."" +
        YarnConfiguration.DEFAULT_QUEUE_NAME));
    assertEquals(-1, queueConf.getFairSharePreemptionTimeout(""root.queueA""));
    assertEquals(-1, queueConf.getFairSharePreemptionTimeout(""root.queueB""));
    assertEquals(-1, queueConf.getFairSharePreemptionTimeout(""root.queueC""));
    assertEquals(-1, queueConf.getFairSharePreemptionTimeout(""root.queueD""));
    assertEquals(-1, queueConf.getFairSharePreemptionTimeout(""root.queueE""));

    assertEquals(.6f, queueConf.getFairSharePreemptionThreshold(""root""), 0.01);
    assertEquals(-1, queueConf.getFairSharePreemptionThreshold(""root.""
        + YarnConfiguration.DEFAULT_QUEUE_NAME), 0.01);
    assertEquals(-1,
        queueConf.getFairSharePreemptionThreshold(""root.queueA""), 0.01);
    assertEquals(-1,
        queueConf.getFairSharePreemptionThreshold(""root.queueB""), 0.01);
    assertEquals(-1,
        queueConf.getFairSharePreemptionThreshold(""root.queueC""), 0.01);
    assertEquals(-1,
        queueConf.getFairSharePreemptionThreshold(""root.queueD""), 0.01);
    assertEquals(.3f,
        queueConf.getFairSharePreemptionThreshold(""root.queueE""), 0.01);
  }",1
"@Test
  public void testParentTagWithReservation() throws Exception {
    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);

    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""parent"")
            .parent(true)
            .reservation()
            .build())
        .writeToFile(ALLOC_FILE);

    AllocationFileLoaderService allocLoader =
        new AllocationFileLoaderService(scheduler);
    allocLoader.init(conf);
    ReloadListener confHolder = new ReloadListener();
    allocLoader.setReloadListener(confHolder);
    try {
      allocLoader.reloadAllocations();
    }",1
"@Test
  public void testAclSubmitApplication() throws Exception {
    // Set acl's
    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);

    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""root"")
            .aclSubmitApps("" "")
            .aclAdministerApps("" "")
            .subQueue(new AllocationFileQueue.Builder(""queue1"")
                .aclSubmitApps(""norealuserhasthisname"")
                .aclAdministerApps(""norealuserhasthisname"")
                .build())
            .build())
        .writeToFile(ALLOC_FILE);

    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    ApplicationAttemptId attId1 = createSchedulingRequest(1024, ""queue1"",
        ""norealuserhasthisname"", 1);
    ApplicationAttemptId attId2 = createSchedulingRequest(1024, ""queue1"",
        ""norealuserhasthisname2"", 1);

    FSAppAttempt app1 = scheduler.getSchedulerApp(attId1);
    assertNotNull(""The application was not allowed"", app1);
    FSAppAttempt app2 = scheduler.getSchedulerApp(attId2);
    assertNull(""The application was allowed"", app2);
  }",1
"@Test
  public void testAggregateCapacityTracking() throws Exception {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    // Add a node
    RMNode node1 =
        MockNodes
            .newNodeInfo(1, Resources.createResource(1024), 1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);
    assertEquals(1024, scheduler.getClusterResource().getMemorySize());

    // Add another node
    RMNode node2 =
        MockNodes.newNodeInfo(1, Resources.createResource(512), 2, ""127.0.0.2"");
    NodeAddedSchedulerEvent nodeEvent2 = new NodeAddedSchedulerEvent(node2);
    scheduler.handle(nodeEvent2);
    assertEquals(1536, scheduler.getClusterResource().getMemorySize());

    // Remove the first node
    NodeRemovedSchedulerEvent nodeEvent3 = new NodeRemovedSchedulerEvent(node1);
    scheduler.handle(nodeEvent3);
    assertEquals(512, scheduler.getClusterResource().getMemorySize());
  }",1
"@Test
  public void testBasicDRFAssignment() throws Exception {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    RMNode node = MockNodes.newNodeInfo(1, Resources.createResource(8192, 5));
    NodeAddedSchedulerEvent nodeEvent = new NodeAddedSchedulerEvent(node);
    scheduler.handle(nodeEvent);

    ApplicationAttemptId appAttId1 = createSchedulingRequest(2048, 1, ""queue1"",
        ""user1"", 2);
    FSAppAttempt app1 = scheduler.getSchedulerApp(appAttId1);
    ApplicationAttemptId appAttId2 = createSchedulingRequest(1024, 2, ""queue1"",
        ""user1"", 2);
    FSAppAttempt app2 = scheduler.getSchedulerApp(appAttId2);

    DominantResourceFairnessPolicy drfPolicy = new DominantResourceFairnessPolicy();
    drfPolicy.initialize(scheduler.getContext());
    scheduler.getQueueManager().getQueue(""queue1"").setPolicy(drfPolicy);
    scheduler.update();

    // First both apps get a container
    // Then the first gets another container because its dominant share of
    // 2048/8192 is less than the other's of 2/5
    NodeUpdateSchedulerEvent updateEvent = new NodeUpdateSchedulerEvent(node);
    scheduler.handle(updateEvent);
    Assert.assertEquals(1, app1.getLiveContainers().size());
    Assert.assertEquals(0, app2.getLiveContainers().size());

    scheduler.handle(updateEvent);
    Assert.assertEquals(1, app1.getLiveContainers().size());
    Assert.assertEquals(1, app2.getLiveContainers().size());

    scheduler.handle(updateEvent);
    Assert.assertEquals(2, app1.getLiveContainers().size());
    Assert.assertEquals(1, app2.getLiveContainers().size());
  }",1
"@Test
  public void testBasicDRFWithQueues() throws Exception {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    RMNode node = MockNodes.newNodeInfo(1, Resources.createResource(8192, 7),
        1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent = new NodeAddedSchedulerEvent(node);
    scheduler.handle(nodeEvent);

    ApplicationAttemptId appAttId1 = createSchedulingRequest(3072, 1, ""queue1"",
        ""user1"", 2);
    FSAppAttempt app1 = scheduler.getSchedulerApp(appAttId1);
    ApplicationAttemptId appAttId2 = createSchedulingRequest(2048, 2, ""queue1"",
        ""user1"", 2);
    FSAppAttempt app2 = scheduler.getSchedulerApp(appAttId2);
    ApplicationAttemptId appAttId3 = createSchedulingRequest(1024, 2, ""queue2"",
        ""user1"", 2);
    FSAppAttempt app3 = scheduler.getSchedulerApp(appAttId3);
    
    DominantResourceFairnessPolicy drfPolicy = new DominantResourceFairnessPolicy();
    drfPolicy.initialize(scheduler.getContext());
    scheduler.getQueueManager().getQueue(""root"").setPolicy(drfPolicy);
    scheduler.getQueueManager().getQueue(""queue1"").setPolicy(drfPolicy);
    scheduler.update();

    NodeUpdateSchedulerEvent updateEvent = new NodeUpdateSchedulerEvent(node);
    scheduler.handle(updateEvent);
    Assert.assertEquals(1, app1.getLiveContainers().size());
    scheduler.handle(updateEvent);
    Assert.assertEquals(1, app3.getLiveContainers().size());
    scheduler.handle(updateEvent);
    Assert.assertEquals(2, app3.getLiveContainers().size());
    scheduler.handle(updateEvent);
    Assert.assertEquals(1, app2.getLiveContainers().size());
  }",1
"@Test
  public void testCancelStrictLocality() throws IOException {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(1024), 1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);

    RMNode node2 = MockNodes.newNodeInfo(1, Resources.createResource(1024), 2, ""127.0.0.2"");
    NodeAddedSchedulerEvent nodeEvent2 = new NodeAddedSchedulerEvent(node2);
    scheduler.handle(nodeEvent2);

    ApplicationAttemptId attId1 = createSchedulingRequest(1024, ""queue1"",
        ""user1"", 0);
    
    ResourceRequest nodeRequest = createResourceRequest(1024, node1.getHostName(), 1, 1, true);
    ResourceRequest rackRequest = createResourceRequest(1024, ""rack1"", 1, 1, false);
    ResourceRequest anyRequest = createResourceRequest(1024, ResourceRequest.ANY,
        1, 1, false);
    createSchedulingRequestExistingApplication(nodeRequest, attId1);
    createSchedulingRequestExistingApplication(rackRequest, attId1);
    createSchedulingRequestExistingApplication(anyRequest, attId1);

    scheduler.update();

    NodeUpdateSchedulerEvent node2UpdateEvent = new NodeUpdateSchedulerEvent(node2);

    // no matter how many heartbeats, node2 should never get a container
    FSAppAttempt app = scheduler.getSchedulerApp(attId1);
    for (int i = 0; i < 10; i++) {
      scheduler.handle(node2UpdateEvent);
      assertEquals(0, app.getLiveContainers().size());
    }",1
"@Test
  public void testChildMaxResources() throws IOException {
    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""queueA"")
            .parent(true)
            .maxChildResources(""2048mb,2vcores"")
            .build())
        .writeToFile(ALLOC_FILE);

    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    // Add one big node (only care about aggregate capacity)
    RMNode node1 =
        MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1,
            ""127.0.0.1"");

    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);

    ApplicationAttemptId attId1 =
        createSchedulingRequest(1024, 1, ""queueA.queueB"", ""user1"", 8);
    ApplicationAttemptId attId2 =
        createSchedulingRequest(1024, 1, ""queueA.queueC"", ""user1"", 8);

    scheduler.update();

    NodeUpdateSchedulerEvent nodeEvent = new NodeUpdateSchedulerEvent(node1);

    // Send 4 node heartbeats, this should be enough to allocate 4 containers
    // As we have 2 queues with capacity: 2GB,2cores, we could only have
    // 4 containers at most
    scheduler.handle(nodeEvent);
    scheduler.handle(nodeEvent);
    scheduler.handle(nodeEvent);
    scheduler.handle(nodeEvent);
    drainEventsOnRM();

    // Apps should be running with 2 containers
    assertEquals(""App 1 is not running with the correct number of containers"",
        2, scheduler.getSchedulerApp(attId1).getLiveContainers().size());
    assertEquals(""App 2 is not running with the correct number of containers"",
        2, scheduler.getSchedulerApp(attId2).getLiveContainers().size());

    //ensure that a 5th node heartbeat does not allocate more containers
    scheduler.handle(nodeEvent);
    drainEventsOnRM();

    // Apps should be running with 2 containers
    assertEquals(""App 1 is not running with the correct number of containers"",
        2, scheduler.getSchedulerApp(attId1).getLiveContainers().size());
    assertEquals(""App 2 is not running with the correct number of containers"",
        2, scheduler.getSchedulerApp(attId2).getLiveContainers().size());

    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""queueA"")
            .parent(true)
            .maxChildResources(""3072mb,3vcores"")
            .build())
        .writeToFile(ALLOC_FILE);

    scheduler.reinitialize(conf, resourceManager.getRMContext());
    scheduler.update();

    // Send 2 node heartbeats, this should be enough to allocate 2
    // more containers.
    // As we have 2 queues with capacity: 3GB,3cores, we could only have
    // 6 containers at most
    scheduler.handle(nodeEvent);
    scheduler.handle(nodeEvent);
    drainEventsOnRM();

    // Apps should be running with 3 containers now
    assertEquals(""App 1 is not running with the correct number of containers"",
        3, scheduler.getSchedulerApp(attId1).getLiveContainers().size());
    assertEquals(""App 2 is not running with the correct number of containers"",
        3, scheduler.getSchedulerApp(attId2).getLiveContainers().size());

    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""queueA"")
            .parent(true)
            .maxChildResources(""1024mb,1vcores"")
            .build())
        .writeToFile(ALLOC_FILE);

    //ensure that a 7th node heartbeat does not allocate more containers
    scheduler.handle(nodeEvent);
    drainEventsOnRM();
    assertEquals(6, scheduler.getRootQueueMetrics().getAllocatedContainers());

    scheduler.reinitialize(conf, resourceManager.getRMContext());

    scheduler.update();
    scheduler.handle(nodeEvent);
    drainEventsOnRM();

    // Apps still should be running with 3 containers because we don't preempt
    assertEquals(""App 1 is not running with the correct number of containers"",
        3, scheduler.getSchedulerApp(attId1).getLiveContainers().size());
    assertEquals(""App 2 is not running with the correct number of containers"",
        3, scheduler.getSchedulerApp(attId2).getLiveContainers().size());
  }",1
"@Test
  public void testEmptyQueueNameInConfigFile() {
    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);
    // set empty queue name
    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder("""").build())
        .writeToFile(ALLOC_FILE);

    try {
      scheduler.init(conf);
      Assert.fail(""scheduler init should fail because"" +
          "" empty queue name."");
    }",1
"@Test
  public void testFairShareWithLowMaxResources() throws IOException {
    PrintWriter out = new PrintWriter(new FileWriter(ALLOC_FILE));

    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""queueA"")
            .maxResources(""1024 mb 1 vcores"")
            .weight(.75f)
            .build())
        .addQueue(new AllocationFileQueue.Builder(""queueB"")
            .maxResources(""3072 mb 3 vcores"")
            .weight(.25f)
            .build())
        .writeToFile(ALLOC_FILE);

    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    // Add one big node (only care about aggregate capacity)
    RMNode node1 =
        MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1,
            ""127.0.0.1"");

    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);

    ApplicationAttemptId attId1 =
        createSchedulingRequest(1024, 1, ""queueA"", ""user1"", 2);
    ApplicationAttemptId attId2 =
        createSchedulingRequest(1024, 1, ""queueB"", ""user1"", 4);

    scheduler.update();

    FSLeafQueue queue =
        scheduler.getQueueManager().getLeafQueue(""queueA"", false);
    // queueA's weight is 0.5, so its fair share should be 6GB, but it's
    // capped at 1GB.
    assertEquals(""Queue A did not get its expected fair share"",
        1 * 1024, queue.getFairShare().getMemorySize());
    // queueB's weight is 0.5, so its fair share should be 2GB, but the
    // other queue is capped at 1GB, so queueB's share is 7GB,
    // capped at 3GB.
    queue = scheduler.getQueueManager().getLeafQueue(
        ""queueB"", false);
    assertEquals(""Queue B did not get its expected fair share"",
        3 * 1024, queue.getFairShare().getMemorySize());

    NodeUpdateSchedulerEvent updateEvent = new NodeUpdateSchedulerEvent(node1);
    scheduler.handle(updateEvent);
    scheduler.handle(updateEvent);
    scheduler.handle(updateEvent);
    scheduler.handle(updateEvent);
    scheduler.handle(updateEvent);
    scheduler.handle(updateEvent);

    // App 1 should be running with 1 container
    assertEquals(""App 1 is not running with the correct number of containers"",
        1, scheduler.getSchedulerApp(attId1).getLiveContainers().size());
    // App 2 should be running with 3 containers
    assertEquals(""App 2 is not running with the correct number of containers"",
        3, scheduler.getSchedulerApp(attId2).getLiveContainers().size());
  }",1
"@Test
  public void testFairShareWithNoneZeroWeightNoneZeroMinRes()
      throws IOException {
    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);
    // set queueA and queueB weight 0.5.
    // set queueA and queueB minResources 1024.
    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""queueA"")
            .weight(0.5f)
            .minResources(""1024 mb 1 vcores"")
            .build())
        .addQueue(new AllocationFileQueue.Builder(""queueB"")
            .weight(0.5f)
            .minResources(""1024 mb 1 vcores"")
            .build())
        .writeToFile(ALLOC_FILE);

    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    // Add one big node (only care about aggregate capacity)
    RMNode node1 =
        MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1,
            ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);

    // Queue A wants 4 * 1024.
    createSchedulingRequest(4 * 1024, ""queueA"", ""user1"");
    // Queue B wants 4 * 1024
    createSchedulingRequest(4 * 1024, ""queueB"", ""user1"");

    scheduler.update();

    FSLeafQueue queue = scheduler.getQueueManager().getLeafQueue(
        ""queueA"", false);
    // queueA's weight is 0.5 and minResources is 1024,
    // so its fair share should be 4096.
    assertEquals(4096, queue.getFairShare().getMemorySize());
    // queueB's weight is 0.5 and minResources is 1024,
    // so its fair share should be 4096.
    queue = scheduler.getQueueManager().getLeafQueue(
        ""queueB"", false);
    assertEquals(4096, queue.getFairShare().getMemorySize());
  }",1
"@Test
  public void testQueueMaxAMShareDefault() throws Exception {
    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);
    conf.setInt(YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_VCORES, 6);

    AllocationFileWriter.create()
        .fairDefaultQueueSchedulingPolicy()
        .addQueue(new AllocationFileQueue.Builder(""queue1"").build())
        .addQueue(new AllocationFileQueue.Builder(""queue2"")
            .maxAMShare(0.4f)
            .build())
        .addQueue(new AllocationFileQueue.Builder(""queue3"")
            .maxResources(""10240 mb 4 vcores"")
            .build())
        .addQueue(new AllocationFileQueue.Builder(""queue4"").build())
        .addQueue(new AllocationFileQueue.Builder(""queue5"").build())
        .writeToFile(ALLOC_FILE);

    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    RMNode node =
        MockNodes.newNodeInfo(1, Resources.createResource(8192, 10),
            0, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent = new NodeAddedSchedulerEvent(node);
    NodeUpdateSchedulerEvent updateEvent = new NodeUpdateSchedulerEvent(node);
    scheduler.handle(nodeEvent);
    scheduler.update();

    FSLeafQueue queue1 =
        scheduler.getQueueManager().getLeafQueue(""queue1"", true);
    assertEquals(""Queue queue1's fair share should be 0"", 0, queue1
        .getFairShare().getMemorySize());
    FSLeafQueue queue2 =
        scheduler.getQueueManager().getLeafQueue(""queue2"", true);
    assertEquals(""Queue queue2's fair share should be 0"", 0, queue2
        .getFairShare().getMemorySize());
    FSLeafQueue queue3 =
        scheduler.getQueueManager().getLeafQueue(""queue3"", true);
    assertEquals(""Queue queue3's fair share should be 0"", 0, queue3
        .getFairShare().getMemorySize());
    FSLeafQueue queue4 =
        scheduler.getQueueManager().getLeafQueue(""queue4"", true);
    assertEquals(""Queue queue4's fair share should be 0"", 0, queue4
        .getFairShare().getMemorySize());
    FSLeafQueue queue5 =
        scheduler.getQueueManager().getLeafQueue(""queue5"", true);
    assertEquals(""Queue queue5's fair share should be 0"", 0, queue5
        .getFairShare().getMemorySize());

    List<String> queues = Arrays.asList(""root.queue3"", ""root.queue4"",
        ""root.queue5"");
    for (String queue : queues) {
      createSchedulingRequest(1 * 1024, queue, ""user1"");
      scheduler.update();
      scheduler.handle(updateEvent);
    }",1
"@Test
  public void testQueueMaxAMShareWithContainerReservation() throws Exception {
    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);
    conf.setFloat(FairSchedulerConfiguration.RESERVABLE_NODES, 1f);
    AllocationFileWriter.create()
        .addQueue(new AllocationFileQueue.Builder(""queue1"")
            .maxAMShare(0.5).build())
        .writeToFile(ALLOC_FILE);

    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    RMNode node1 = MockNodes.newNodeInfo(1,
        Resources.createResource(RM_SCHEDULER_MAXIMUM_ALLOCATION_MB_VALUE, 10),
        1, ""127.0.0.1"");
    RMNode node2 = MockNodes.newNodeInfo(1,
        Resources.createResource(RM_SCHEDULER_MAXIMUM_ALLOCATION_MB_VALUE, 10),
        2, ""127.0.0.2"");
    RMNode node3 =
        MockNodes.newNodeInfo(1, Resources.createResource(5120, 5),
            3, ""127.0.0.3"");
    NodeAddedSchedulerEvent nodeE1 = new NodeAddedSchedulerEvent(node1);
    NodeUpdateSchedulerEvent updateE1 = new NodeUpdateSchedulerEvent(node1);
    NodeAddedSchedulerEvent nodeE2 = new NodeAddedSchedulerEvent(node2);
    NodeUpdateSchedulerEvent updateE2 = new NodeUpdateSchedulerEvent(node2);
    NodeAddedSchedulerEvent nodeE3 = new NodeAddedSchedulerEvent(node3);
    NodeUpdateSchedulerEvent updateE3 = new NodeUpdateSchedulerEvent(node3);
    scheduler.handle(nodeE1);
    scheduler.handle(nodeE2);
    scheduler.handle(nodeE3);
    scheduler.update();
    FSLeafQueue queue1 = scheduler.getQueueManager().getLeafQueue(""queue1"",
        true);
    Resource amResource1 = Resource.newInstance(1024, 1);
    Resource amResource2 = Resource.newInstance(1024, 1);
    Resource amResource3 =
        Resource.newInstance(RM_SCHEDULER_MAXIMUM_ALLOCATION_MB_VALUE, 1);
    Resource amResource4 = Resource.newInstance(5120, 1);
    Resource amResource5 = Resource.newInstance(1024, 1);
    Resource amResource6 =
        Resource.newInstance(RM_SCHEDULER_MAXIMUM_ALLOCATION_MB_VALUE, 1);
    Resource amResource7 = Resource.newInstance(1024, 1);
    Resource amResource8 = Resource.newInstance(1024, 1);
    int amPriority = RMAppAttemptImpl.AM_CONTAINER_PRIORITY.getPriority();
    ApplicationAttemptId attId1 = createAppAttemptId(1, 1);
    createApplicationWithAMResource(attId1, ""queue1"", ""user1"", amResource1);
    createSchedulingRequestExistingApplication(1024, 1, amPriority, attId1);
    FSAppAttempt app1 = scheduler.getSchedulerApp(attId1);
    scheduler.update();
    // Allocate app1's AM container on node1.
    scheduler.handle(updateE1);
    assertEquals(""Application1's AM requests 1024 MB memory"",
        1024, app1.getAMResource().getMemorySize());
    assertEquals(""Application1's AM should be running"",
        1, app1.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 1024 MB memory"",
        1024, queue1.getAmResourceUsage().getMemorySize());

    ApplicationAttemptId attId2 = createAppAttemptId(2, 1);
    createApplicationWithAMResource(attId2, ""queue1"", ""user1"", amResource2);
    createSchedulingRequestExistingApplication(1024, 1, amPriority, attId2);
    FSAppAttempt app2 = scheduler.getSchedulerApp(attId2);
    scheduler.update();
    // Allocate app2's AM container on node2.
    scheduler.handle(updateE2);
    assertEquals(""Application2's AM requests 1024 MB memory"",
        1024, app2.getAMResource().getMemorySize());
    assertEquals(""Application2's AM should be running"",
        1, app2.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 2048 MB memory"",
        2048, queue1.getAmResourceUsage().getMemorySize());

    ApplicationAttemptId attId3 = createAppAttemptId(3, 1);
    createApplicationWithAMResource(attId3, ""queue1"", ""user1"", amResource3);
    createSchedulingRequestExistingApplication(
        RM_SCHEDULER_MAXIMUM_ALLOCATION_MB_VALUE, 1, amPriority, attId3);
    FSAppAttempt app3 = scheduler.getSchedulerApp(attId3);
    scheduler.update();
    // app3 reserves a container on node1 because node1's available resource
    // is less than app3's AM container resource.
    scheduler.handle(updateE1);
    // Similarly app3 reserves a container on node2.
    scheduler.handle(updateE2);
    assertEquals(""Application3's AM resource shouldn't be updated"",
        0, app3.getAMResource().getMemorySize());
    assertEquals(""Application3's AM should not be running"",
        0, app3.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 2048 MB memory"",
        2048, queue1.getAmResourceUsage().getMemorySize());

    ApplicationAttemptId attId4 = createAppAttemptId(4, 1);
    createApplicationWithAMResource(attId4, ""queue1"", ""user1"", amResource4);
    createSchedulingRequestExistingApplication(5120, 1, amPriority, attId4);
    FSAppAttempt app4 = scheduler.getSchedulerApp(attId4);
    scheduler.update();
    // app4 can't allocate its AM container on node1 because
    // app3 already reserved its container on node1.
    scheduler.handle(updateE1);
    assertEquals(""Application4's AM resource shouldn't be updated"",
        0, app4.getAMResource().getMemorySize());
    assertEquals(""Application4's AM should not be running"",
        0, app4.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 2048 MB memory"",
        2048, queue1.getAmResourceUsage().getMemorySize());

    scheduler.update();
    // Allocate app4's AM container on node3.
    scheduler.handle(updateE3);
    assertEquals(""Application4's AM requests 5120 MB memory"",
        5120, app4.getAMResource().getMemorySize());
    assertEquals(""Application4's AM should be running"",
        1, app4.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 7168 MB memory"",
        7168, queue1.getAmResourceUsage().getMemorySize());

    AppAttemptRemovedSchedulerEvent appRemovedEvent1 =
        new AppAttemptRemovedSchedulerEvent(attId1,
            RMAppAttemptState.FINISHED, false);
    // Release app1's AM container on node1.
    scheduler.handle(appRemovedEvent1);
    assertEquals(""Queue1's AM resource usage should be 6144 MB memory"",
        6144, queue1.getAmResourceUsage().getMemorySize());

    ApplicationAttemptId attId5 = createAppAttemptId(5, 1);
    createApplicationWithAMResource(attId5, ""queue1"", ""user1"", amResource5);
    createSchedulingRequestExistingApplication(1024, 1, amPriority, attId5);
    FSAppAttempt app5 = scheduler.getSchedulerApp(attId5);
    scheduler.update();
    // app5 can allocate its AM container on node1 after
    // app3 unreserve its container on node1 due to
    // exceeding queue MaxAMShare limit.
    scheduler.handle(updateE1);
    assertEquals(""Application5's AM requests 1024 MB memory"",
        1024, app5.getAMResource().getMemorySize());
    assertEquals(""Application5's AM should be running"",
        1, app5.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 7168 MB memory"",
        7168, queue1.getAmResourceUsage().getMemorySize());

    AppAttemptRemovedSchedulerEvent appRemovedEvent3 =
        new AppAttemptRemovedSchedulerEvent(attId3,
            RMAppAttemptState.FINISHED, false);
    // Remove app3.
    scheduler.handle(appRemovedEvent3);
    assertEquals(""Queue1's AM resource usage should be 7168 MB memory"",
        7168, queue1.getAmResourceUsage().getMemorySize());

    ApplicationAttemptId attId6 = createAppAttemptId(6, 1);
    createApplicationWithAMResource(attId6, ""queue1"", ""user1"", amResource6);
    createSchedulingRequestExistingApplication(
        RM_SCHEDULER_MAXIMUM_ALLOCATION_MB_VALUE, 1, amPriority, attId6);
    FSAppAttempt app6 = scheduler.getSchedulerApp(attId6);
    scheduler.update();
    // app6 can't reserve a container on node1 because
    // it exceeds queue MaxAMShare limit.
    scheduler.handle(updateE1);
    assertEquals(""Application6's AM resource shouldn't be updated"",
        0, app6.getAMResource().getMemorySize());
    assertEquals(""Application6's AM should not be running"",
        0, app6.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 7168 MB memory"",
        7168, queue1.getAmResourceUsage().getMemorySize());

    ApplicationAttemptId attId7 = createAppAttemptId(7, 1);
    createApplicationWithAMResource(attId7, ""queue1"", ""user1"", amResource7);
    createSchedulingRequestExistingApplication(1024, 1, amPriority, attId7);
    FSAppAttempt app7 = scheduler.getSchedulerApp(attId7);
    scheduler.update();
    // Allocate app7's AM container on node1 to prove
    // app6 didn't reserve a container on node1.
    scheduler.handle(updateE1);
    assertEquals(""Application7's AM requests 1024 MB memory"",
        1024, app7.getAMResource().getMemorySize());
    assertEquals(""Application7's AM should be running"",
        1, app7.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 8192 MB memory"",
        8192, queue1.getAmResourceUsage().getMemorySize());

    AppAttemptRemovedSchedulerEvent appRemovedEvent4 =
        new AppAttemptRemovedSchedulerEvent(attId4,
            RMAppAttemptState.FINISHED, false);
    // Release app4's AM container on node3.
    scheduler.handle(appRemovedEvent4);
    assertEquals(""Queue1's AM resource usage should be 3072 MB memory"",
        3072, queue1.getAmResourceUsage().getMemorySize());

    AppAttemptRemovedSchedulerEvent appRemovedEvent5 =
        new AppAttemptRemovedSchedulerEvent(attId5,
            RMAppAttemptState.FINISHED, false);
    // Release app5's AM container on node1.
    scheduler.handle(appRemovedEvent5);
    assertEquals(""Queue1's AM resource usage should be 2048 MB memory"",
              2048, queue1.getAmResourceUsage().getMemorySize());

    scheduler.update();
    // app6 reserves a container on node1 because node1's available resource
    // is less than app6's AM container resource and
    // app6 is not over AMShare limit.
    scheduler.handle(updateE1);
    // Similarly app6 reserves a container on node2.
    scheduler.handle(updateE2);

    ApplicationAttemptId attId8 = createAppAttemptId(8, 1);
    createApplicationWithAMResource(attId8, ""queue1"", ""user1"", amResource8);
    createSchedulingRequestExistingApplication(1024, 1, amPriority, attId8);
    FSAppAttempt app8 = scheduler.getSchedulerApp(attId8);
    scheduler.update();
    // app8 can't allocate a container on node1 because
    // app6 already reserved a container on node1.
    scheduler.handle(updateE1);
    assertEquals(""Application8's AM resource shouldn't be updated"",
        0, app8.getAMResource().getMemorySize());
    assertEquals(""Application8's AM should not be running"",
        0, app8.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 2048 MB memory"",
        2048, queue1.getAmResourceUsage().getMemorySize());
    scheduler.update();
    // app8 can't allocate a container on node2 because
    // app6 already reserved a container on node2.
    scheduler.handle(updateE2);
    assertEquals(""Application8's AM resource shouldn't be updated"",
        0, app8.getAMResource().getMemorySize());
    assertEquals(""Application8's AM should not be running"",
        0, app8.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 2048 MB memory"",
        2048, queue1.getAmResourceUsage().getMemorySize());

    AppAttemptRemovedSchedulerEvent appRemovedEvent2 =
        new AppAttemptRemovedSchedulerEvent(attId2,
            RMAppAttemptState.FINISHED, false);
    // Release app2's AM container on node2.
    scheduler.handle(appRemovedEvent2);
    assertEquals(""Queue1's AM resource usage should be 1024 MB memory"",
        1024, queue1.getAmResourceUsage().getMemorySize());

    scheduler.update();
    // app6 turns the reservation into an allocation on node2.
    scheduler.handle(updateE2);
    assertEquals(""Application6's AM requests 10240 MB memory"",
        RM_SCHEDULER_MAXIMUM_ALLOCATION_MB_VALUE,
        app6.getAMResource().getMemorySize());
    assertEquals(""Application6's AM should be running"",
        1, app6.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 11264 MB memory"",
        11264, queue1.getAmResourceUsage().getMemorySize());

    scheduler.update();
    // app6 unreserve its container on node1 because
    // it already got a container on node2.
    // Now app8 can allocate its AM container on node1.
    scheduler.handle(updateE1);
    assertEquals(""Application8's AM requests 1024 MB memory"",
        1024, app8.getAMResource().getMemorySize());
    assertEquals(""Application8's AM should be running"",
        1, app8.getLiveContainers().size());
    assertEquals(""Queue1's AM resource usage should be 12288 MB memory"",
        12288, queue1.getAmResourceUsage().getMemorySize());
  }",1
"@Test
  public void testQueueuNameWithPeriods() throws Exception {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    // no queue by default
    assertEquals(0, scheduler.getQueueManager().getLeafQueues().size());

    // Submit app with queue name (.A)
    // Submit fails before we reach the placement check.
    ApplicationAttemptId appAttemptId1 = createAppAttemptId(1, 1);
    AppAddedSchedulerEvent appAddedEvent1 =
        new AppAddedSchedulerEvent(appAttemptId1.getApplicationId(), "".A"",
            ""user1"");
    scheduler.handle(appAddedEvent1);
    // submission rejected
    assertEquals(0, scheduler.getQueueManager().getLeafQueues().size());
    assertNull(scheduler.getSchedulerApp(appAttemptId1));
    assertEquals(0, resourceManager.getRMContext().getRMApps().size());

    // Submit app with queue name (A.)
    // Submit fails before we reach the placement check.
    ApplicationAttemptId appAttemptId2 = createAppAttemptId(2, 1);
    AppAddedSchedulerEvent appAddedEvent2 =
        new AppAddedSchedulerEvent(appAttemptId2.getApplicationId(), ""A."",
            ""user1"");
    scheduler.handle(appAddedEvent2);
    // submission rejected
    assertEquals(0, scheduler.getQueueManager().getLeafQueues().size());
    assertNull(scheduler.getSchedulerApp(appAttemptId2));
    assertEquals(0, resourceManager.getRMContext().getRMApps().size());

    // submit app with queue name (A.B)
    // Submit does not fail we must have a placement context.
    ApplicationAttemptId appAttemptId3 = createAppAttemptId(3, 1);
    AppAddedSchedulerEvent appAddedEvent3 =
        new AppAddedSchedulerEvent(appAttemptId3.getApplicationId(), ""A.B"",
            ""user1"", new ApplicationPlacementContext(""A.B""));
    scheduler.handle(appAddedEvent3);
    // submission accepted
    assertEquals(1, scheduler.getQueueManager().getLeafQueues().size());
    assertNull(scheduler.getSchedulerApp(appAttemptId3));
    assertEquals(0, resourceManager.getRMContext().getRMApps().size());
  }",1
"@Test
  public void testSchedulerRootQueueMetrics() throws Exception {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    // Add a node
    RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(1024));
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);

    // Queue 1 requests full capacity of node
    createSchedulingRequest(1024, ""queue1"", ""user1"", 1);
    scheduler.update();
    NodeUpdateSchedulerEvent updateEvent = new NodeUpdateSchedulerEvent(node1);
    scheduler.handle(updateEvent);

    // Now queue 2 requests likewise
    createSchedulingRequest(1024, ""queue2"", ""user1"", 1);
    scheduler.update();
    scheduler.handle(updateEvent);

    // Make sure reserved memory gets updated correctly
    assertEquals(1024, scheduler.rootMetrics.getReservedMB());
    
    // Now another node checks in with capacity
    RMNode node2 = MockNodes.newNodeInfo(1, Resources.createResource(1024));
    NodeAddedSchedulerEvent nodeEvent2 = new NodeAddedSchedulerEvent(node2);
    NodeUpdateSchedulerEvent updateEvent2 = new NodeUpdateSchedulerEvent(node2);
    scheduler.handle(nodeEvent2);
    scheduler.handle(updateEvent2);


    // The old reservation should still be there...
    assertEquals(1024, scheduler.rootMetrics.getReservedMB());

    // ... but it should disappear when we update the first node.
    scheduler.handle(updateEvent);
    assertEquals(0, scheduler.rootMetrics.getReservedMB());
  }",1
"@Test
  public void testSimpleHierarchicalFairShareCalculation() throws IOException {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    // Add one big node (only care about aggregate capacity)
    int capacity = 10 * 24;
    RMNode node1 =
        MockNodes.newNodeInfo(1, Resources.createResource(capacity), 1,
            ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);

    // Have two queues which want entire cluster capacity
    createSchedulingRequest(10 * 1024, ""parent.queue2"", ""user1"");
    createSchedulingRequest(10 * 1024, ""parent.queue3"", ""user1"");
    createSchedulingRequest(10 * 1024, ""root.default"", ""user1"");

    scheduler.update();
    scheduler.getQueueManager().getRootQueue()
        .setSteadyFairShare(scheduler.getClusterResource());
    scheduler.getQueueManager().getRootQueue().recomputeSteadyShares();

    QueueManager queueManager = scheduler.getQueueManager();
    Collection<FSLeafQueue> queues = queueManager.getLeafQueues();
    assertEquals(3, queues.size());
    
    FSLeafQueue queue1 = queueManager.getLeafQueue(""default"", true);
    FSLeafQueue queue2 = queueManager.getLeafQueue(""parent.queue2"", true);
    FSLeafQueue queue3 = queueManager.getLeafQueue(""parent.queue3"", true);
    assertEquals(capacity / 2, queue1.getFairShare().getMemorySize());
    assertEquals(capacity / 2, queue1.getMetrics().getFairShareMB());
    assertEquals(capacity / 2, queue1.getSteadyFairShare().getMemorySize());
    assertEquals(capacity / 2, queue1.getMetrics().getSteadyFairShareMB());
    assertEquals(capacity / 4, queue2.getFairShare().getMemorySize());
    assertEquals(capacity / 4, queue2.getMetrics().getFairShareMB());
    assertEquals(capacity / 4, queue2.getSteadyFairShare().getMemorySize());
    assertEquals(capacity / 4, queue2.getMetrics().getSteadyFairShareMB());
    assertEquals(capacity / 4, queue3.getFairShare().getMemorySize());
    assertEquals(capacity / 4, queue3.getMetrics().getFairShareMB());
    assertEquals(capacity / 4, queue3.getSteadyFairShare().getMemorySize());
    assertEquals(capacity / 4, queue3.getMetrics().getSteadyFairShareMB());
  }",1
"@Test
  public void testStrictLocality() throws IOException {
    scheduler.init(conf);
    scheduler.start();
    scheduler.reinitialize(conf, resourceManager.getRMContext());

    RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(1024), 1, ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);

    RMNode node2 = MockNodes.newNodeInfo(1, Resources.createResource(1024), 2, ""127.0.0.2"");
    NodeAddedSchedulerEvent nodeEvent2 = new NodeAddedSchedulerEvent(node2);
    scheduler.handle(nodeEvent2);

    ApplicationAttemptId attId1 = createSchedulingRequest(1024, ""queue1"",
        ""user1"", 0);
    
    ResourceRequest nodeRequest = createResourceRequest(1024, node1.getHostName(), 1, 1, true);
    ResourceRequest rackRequest = createResourceRequest(1024, node1.getRackName(), 1, 1, false);
    ResourceRequest anyRequest = createResourceRequest(1024, ResourceRequest.ANY,
        1, 1, false);
    createSchedulingRequestExistingApplication(nodeRequest, attId1);
    createSchedulingRequestExistingApplication(rackRequest, attId1);
    createSchedulingRequestExistingApplication(anyRequest, attId1);

    scheduler.update();

    NodeUpdateSchedulerEvent node1UpdateEvent = new NodeUpdateSchedulerEvent(node1);
    NodeUpdateSchedulerEvent node2UpdateEvent = new NodeUpdateSchedulerEvent(node2);

    // no matter how many heartbeats, node2 should never get a container
    FSAppAttempt app = scheduler.getSchedulerApp(attId1);
    for (int i = 0; i < 10; i++) {
      scheduler.handle(node2UpdateEvent);
      assertEquals(0, app.getLiveContainers().size());
      assertEquals(0, app.getReservedContainers().size());
    }",1
"@Test
  public void testParseResourceConfigValue() throws Exception {
    Resource expected = Resources.createResource(5 * 1024, 2);
    Resource clusterResource = Resources.createResource(10 * 1024, 4);

    assertEquals(expected,
        parseResourceConfigValue(""5120 mb 2 vcores"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""2 vcores, 5120 mb"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""5120 mb, 2 vcores"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""2vcores,5120mb"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""5120mb,2vcores"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""5120mb   mb, 2    vcores"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""5120 Mb, 2 vCores"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""  5120 mb, 2 vcores  "").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""  5120.3 mb, 2.35 vcores  "").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""  5120. mb, 2. vcores  "").getResource());

    assertEquals(expected,
        parseResourceConfigValue(""50% memory, 50% cpu"").
            getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""50% Memory, 50% CpU"").
            getResource(clusterResource));
    assertEquals(Resources.createResource(5 * 1024, 4),
        parseResourceConfigValue(""50% memory, 100% cpu"").
        getResource(clusterResource));
    assertEquals(Resources.createResource(5 * 1024, 4),
        parseResourceConfigValue("" 100% cpu, 50% memory"").
        getResource(clusterResource));
    assertEquals(Resources.createResource(5 * 1024, 0),
        parseResourceConfigValue(""50% memory, 0% cpu"").
            getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""50 % memory, 50 % cpu"").
            getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""50%memory,50%cpu"").
            getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""  50  %  memory,  50  %  cpu  "").
            getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""50.% memory, 50.% cpu"").
            getResource(clusterResource));
    assertEquals(Resources.createResource((int)(1024 * 10 * 0.109), 2),
        parseResourceConfigValue(""10.9% memory, 50.6% cpu"").
            getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""50%"").getResource(clusterResource));

    Configuration conf = new Configuration();

    conf.set(YarnConfiguration.RESOURCE_TYPES, ""test1"");
    ResourceUtils.resetResourceTypes(conf);

    clusterResource = Resources.createResource(10 * 1024, 4);
    expected = Resources.createResource(5 * 1024, 2);
    expected.setResourceValue(""test1"", Long.MAX_VALUE);

    assertEquals(expected,
        parseResourceConfigValue(""vcores=2, memory-mb=5120"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""memory-mb=5120, vcores=2"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""vcores=2,memory-mb=5120"").getResource());
    assertEquals(expected, parseResourceConfigValue("" vcores = 2 , ""
            + ""memory-mb = 5120 "").getResource());

    expected.setResourceValue(""test1"", 0L);

    assertEquals(expected,
        parseResourceConfigValue(""vcores=2, memory-mb=5120"", 0L).getResource());
    assertEquals(expected,
        parseResourceConfigValue(""memory-mb=5120, vcores=2"", 0L).getResource());
    assertEquals(expected,
        parseResourceConfigValue(""vcores=2,memory-mb=5120"", 0L).getResource());
    assertEquals(expected,
        parseResourceConfigValue("" vcores = 2 , memory-mb = 5120 "",
            0L).getResource());

    clusterResource.setResourceValue(""test1"", 8L);
    expected.setResourceValue(""test1"", 4L);

    assertEquals(expected,
        parseResourceConfigValue(""50%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""vcores=2, memory-mb=5120, ""
            + ""test1=4"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""test1=4, vcores=2, ""
            + ""memory-mb=5120"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""memory-mb=5120, test1=4, ""
            + ""vcores=2"").getResource());
    assertEquals(expected,
        parseResourceConfigValue(""vcores=2,memory-mb=5120,""
            + ""test1=4"").getResource());
    assertEquals(expected,
        parseResourceConfigValue("" vcores = 2 , memory-mb = 5120 , ""
            + ""test1 = 4 "").getResource());

    expected = Resources.createResource(4 * 1024, 3);
    expected.setResourceValue(""test1"", 8L);

    assertEquals(expected,
        parseResourceConfigValue(""vcores=75%, ""
            + ""memory-mb=40%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""memory-mb=40%, ""
            + ""vcores=75%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""vcores=75%,""
            + ""memory-mb=40%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue("" vcores = 75 % , ""
            + ""memory-mb = 40 % "").getResource(clusterResource));

    expected.setResourceValue(""test1"", 4L);

    assertEquals(expected,
        parseResourceConfigValue(""vcores=75%, memory-mb=40%, ""
            + ""test1=50%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""test1=50%, vcores=75%, ""
            + ""memory-mb=40%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""memory-mb=40%, test1=50%, ""
            + ""vcores=75%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue(""vcores=75%,memory-mb=40%,""
            + ""test1=50%"").getResource(clusterResource));
    assertEquals(expected,
        parseResourceConfigValue("" vcores = 75 % , memory-mb = 40 % , ""
            + ""test1 = 50 % "").getResource(clusterResource));
  }",1
"@Test
  public void testTrimQueueNameEquals() throws Exception {
    final String[] equalsStrings = {
        // no spaces
        ""a"",
        // leading spaces
        "" a"",
        "" \u3000a"",
        ""\u2002\u3000\r\u0085\u200A\u2005\u2000\u3000a"",
        ""\u2029\u000B\u3000\u2008\u2003\u205F\u3000\u1680a"",
        ""\u0009\u0020\u2006\u2001\u202F\u00A0\u000C\u2009a"",
        ""\u3000\u2004\u3000\u3000\u2028\n\u2007\u3000a"",
        // trailing spaces
        ""a\u200A"",
        ""a  \u0085 "",
        // spaces on both sides
        "" a "",
        ""  a\u00A0"",
        ""\u0009\u0020\u2006\u2001\u202F\u00A0\u000C\u2009a"" +
            ""\u3000\u2004\u3000\u3000\u2028\n\u2007\u3000"",
    }",1
"@Test
  public void testHeadroom() {
    final FairScheduler mockScheduler = Mockito.mock(FairScheduler.class);
    Mockito.when(mockScheduler.getClock()).thenReturn(scheduler.getClock());

    final FSLeafQueue mockQueue = Mockito.mock(FSLeafQueue.class);

    final Resource queueMaxResources = Resource.newInstance(5 * 1024, 3);
    final Resource queueFairShare = Resources.createResource(4096, 2);
    final Resource queueUsage = Resource.newInstance(2048, 2);

    final Resource queueStarvation =
        Resources.subtract(queueFairShare, queueUsage);
    final Resource queueMaxResourcesAvailable =
        Resources.subtract(queueMaxResources, queueUsage);

    final Resource clusterResource = Resources.createResource(8192, 8);
    final Resource clusterUsage = Resources.createResource(2048, 2);
    final Resource clusterAvailable =
        Resources.subtract(clusterResource, clusterUsage);

    final QueueMetrics fakeRootQueueMetrics = Mockito.mock(QueueMetrics.class);

    Mockito.when(mockQueue.getMaxShare()).thenReturn(queueMaxResources);
    Mockito.when(mockQueue.getFairShare()).thenReturn(queueFairShare);
    Mockito.when(mockQueue.getResourceUsage()).thenReturn(queueUsage);
    Mockito.when(mockScheduler.getClusterResource()).thenReturn
        (clusterResource);
    Mockito.when(fakeRootQueueMetrics.getAllocatedResources()).thenReturn
        (clusterUsage);
    Mockito.when(mockScheduler.getRootQueueMetrics()).thenReturn
        (fakeRootQueueMetrics);
    Mockito.when(mockScheduler.getConf()).thenReturn
        (Mockito.mock(FairSchedulerConfiguration.class));

    ApplicationAttemptId applicationAttemptId = createAppAttemptId(1, 1);
    RMContext rmContext = resourceManager.getRMContext();
    FSAppAttempt schedulerApp =
        new FSAppAttempt(mockScheduler, applicationAttemptId, ""user1"", mockQueue ,
            null, rmContext);

    // Min of Memory and CPU across cluster and queue is used in
    // DominantResourceFairnessPolicy
    Mockito.when(mockQueue.getPolicy()).thenReturn(SchedulingPolicy
        .getInstance(DominantResourceFairnessPolicy.class));
    verifyHeadroom(schedulerApp,
        min(queueStarvation.getMemorySize(),
            clusterAvailable.getMemorySize(),
            queueMaxResourcesAvailable.getMemorySize()),
        min(queueStarvation.getVirtualCores(),
            clusterAvailable.getVirtualCores(),
            queueMaxResourcesAvailable.getVirtualCores())
    );

    // Fair and Fifo ignore CPU of queue, so use cluster available CPU
    Mockito.when(mockQueue.getPolicy()).thenReturn(SchedulingPolicy
        .getInstance(FairSharePolicy.class));
    verifyHeadroom(schedulerApp,
        min(queueStarvation.getMemorySize(),
            clusterAvailable.getMemorySize(),
            queueMaxResourcesAvailable.getMemorySize()),
        Math.min(
            clusterAvailable.getVirtualCores(),
            queueMaxResourcesAvailable.getVirtualCores())
    );

    Mockito.when(mockQueue.getPolicy()).thenReturn(SchedulingPolicy
        .getInstance(FifoPolicy.class));
    verifyHeadroom(schedulerApp,
        min(queueStarvation.getMemorySize(),
            clusterAvailable.getMemorySize(),
            queueMaxResourcesAvailable.getMemorySize()),
        Math.min(
            clusterAvailable.getVirtualCores(),
            queueMaxResourcesAvailable.getVirtualCores())
    );
  }",1
"@Test
  public void testHeadroomWithBlackListedNodes() {
    // Add two nodes
    RMNode node1 =
        MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1,
            ""127.0.0.1"");
    NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1);
    scheduler.handle(nodeEvent1);
    RMNode node2 =
        MockNodes.newNodeInfo(1, Resources.createResource(4 * 1024, 4), 2,
            ""127.0.0.2"");
    NodeAddedSchedulerEvent nodeEvent2 = new NodeAddedSchedulerEvent(node2);
    scheduler.handle(nodeEvent2);
    assertEquals(""We should have two alive nodes."",
        2, scheduler.getNumClusterNodes());
    Resource clusterResource = scheduler.getClusterResource();
    Resource clusterUsage = scheduler.getRootQueueMetrics()
        .getAllocatedResources();
    assertEquals(12 * 1024, clusterResource.getMemorySize());
    assertEquals(12, clusterResource.getVirtualCores());
    assertEquals(0, clusterUsage.getMemorySize());
    assertEquals(0, clusterUsage.getVirtualCores());
    ApplicationAttemptId id11 = createAppAttemptId(1, 1);
    createMockRMApp(id11);
    ApplicationPlacementContext placementCtx =
        new ApplicationPlacementContext(""default"");
    scheduler.addApplication(id11.getApplicationId(),
            ""default"", ""user1"", false, placementCtx);
    scheduler.addApplicationAttempt(id11, false, false);
    assertNotNull(scheduler.getSchedulerApplications().get(id11.
            getApplicationId()));
    FSAppAttempt app = scheduler.getSchedulerApp(id11);
    assertNotNull(app);
    Resource queueUsage = app.getQueue().getResourceUsage();
    assertEquals(0, queueUsage.getMemorySize());
    assertEquals(0, queueUsage.getVirtualCores());
    SchedulerNode n1 = scheduler.getSchedulerNode(node1.getNodeID());
    SchedulerNode n2 = scheduler.getSchedulerNode(node2.getNodeID());
    assertNotNull(n1);
    assertNotNull(n2);
    List<String> blacklistAdditions = new ArrayList<String>(1);
    List<String> blacklistRemovals = new ArrayList<String>(1);
    blacklistAdditions.add(n1.getNodeName());
    FSAppAttempt spyApp = spy(app);
    doReturn(false)
        .when(spyApp).isWaitingForAMContainer();
    spyApp.updateBlacklist(blacklistAdditions, blacklistRemovals);
    spyApp.getQueue().setFairShare(clusterResource);
    assertTrue(spyApp.isPlaceBlacklisted(n1.getNodeName()));
    assertFalse(spyApp.isPlaceBlacklisted(n2.getNodeName()));
    assertEquals(n2.getUnallocatedResource(), spyApp.getHeadroom());

    blacklistAdditions.clear();
    blacklistAdditions.add(n2.getNodeName());
    blacklistRemovals.add(n1.getNodeName());
    spyApp.updateBlacklist(blacklistAdditions, blacklistRemovals);
    assertFalse(spyApp.isPlaceBlacklisted(n1.getNodeName()));
    assertTrue(spyApp.isPlaceBlacklisted(n2.getNodeName()));
    assertEquals(n1.getUnallocatedResource(), spyApp.getHeadroom());

    blacklistAdditions.clear();
    blacklistRemovals.clear();
    blacklistRemovals.add(n2.getNodeName());
    spyApp.updateBlacklist(blacklistAdditions, blacklistRemovals);
    assertFalse(spyApp.isPlaceBlacklisted(n1.getNodeName()));
    assertFalse(spyApp.isPlaceBlacklisted(n2.getNodeName()));
    assertEquals(clusterResource, spyApp.getHeadroom());
  }",1
"@Test
  public void testConcurrentChangeToGetChildQueue() {

    queueManager.getLeafQueue(""parent.child"", true);
    queueManager.getLeafQueue(""parent.child2"", true);
    FSParentQueue test = queueManager.getParentQueue(""parent"", false);
    assertEquals(2, test.getChildQueues().size());

    boolean first = true;
    int childQueuesFound = 0;
    for (FSQueue childQueue:test.getChildQueues()) {
      if (first) {
        first = false;
        queueManager.getLeafQueue(""parent.child3"", true);
      }",1
"@Test
  public void testSimpleAllocation() {
    RMNode node = createNode();
    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, false);

    createDefaultContainer();
    assertEquals(""Nothing should have been allocated, yet"",
        Resources.none(), schedulerNode.getAllocatedResource());
    schedulerNode.allocateContainer(containers.get(0));
    assertEquals(""Container should be allocated"",
        containers.get(0).getContainer().getResource(),
        schedulerNode.getAllocatedResource());
    schedulerNode.releaseContainer(containers.get(0).getContainerId(), true);
    assertEquals(""Everything should have been released"",
        Resources.none(), schedulerNode.getAllocatedResource());

    // Check that we are error prone
    schedulerNode.releaseContainer(containers.get(0).getContainerId(), true);
    finalValidation(schedulerNode);
  }",1
"@Test
  public void testMultiplePreemptionEvents() {
    RMNode node = createNode();
    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, false);

    // Launch containers and saturate the cluster
    saturateCluster(schedulerNode);
    assertEquals(""Container should be allocated"",
        Resources.multiply(containers.get(0).getContainer().getResource(),
            containers.size()),
        schedulerNode.getAllocatedResource());

    // Preempt a container
    FSAppAttempt starvingApp1 = createStarvingApp(schedulerNode,
        Resource.newInstance(2048, 2));
    FSAppAttempt starvingApp2 = createStarvingApp(schedulerNode,
        Resource.newInstance(1024, 1));

    // Preemption thread kicks in
    schedulerNode.addContainersForPreemption(
        Collections.singletonList(containers.get(0)), starvingApp1);
    schedulerNode.addContainersForPreemption(
        Collections.singletonList(containers.get(1)), starvingApp1);
    schedulerNode.addContainersForPreemption(
        Collections.singletonList(containers.get(2)), starvingApp2);

    // Preemption happens
    schedulerNode.releaseContainer(containers.get(1).getContainerId(), true);
    allocateContainers(schedulerNode);

    schedulerNode.releaseContainer(containers.get(2).getContainerId(), true);
    schedulerNode.releaseContainer(containers.get(0).getContainerId(), true);
    allocateContainers(schedulerNode);

    assertEquals(""Container should be allocated"",
        schedulerNode.getTotalResource(),
        schedulerNode.getAllocatedResource());

    // Release all containers
    for (int i = 3; i < containers.size(); ++i) {
      schedulerNode.releaseContainer(containers.get(i).getContainerId(), true);
    }",1
"@Test
  public void testPartialReservedPreemption() {
    RMNode node = createNode();
    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, false);

    // Launch containers and saturate the cluster
    saturateCluster(schedulerNode);
    assertEquals(""Container should be allocated"",
        Resources.multiply(containers.get(0).getContainer().getResource(),
            containers.size()),
        schedulerNode.getAllocatedResource());

    // Preempt a container
    Resource originalStarvingAppDemand = Resource.newInstance(512, 1);
    FSAppAttempt starvingApp = createStarvingApp(schedulerNode,
        originalStarvingAppDemand);
    schedulerNode.addContainersForPreemption(
        Collections.singletonList(containers.get(0)), starvingApp);

    // Preemption occurs
    schedulerNode.releaseContainer(containers.get(0).getContainerId(), true);

    // Container partially reassigned
    allocateContainers(schedulerNode);
    assertEquals(""Container should be allocated"",
        Resources.subtract(schedulerNode.getTotalResource(),
            Resource.newInstance(512, 0)),
        schedulerNode.getAllocatedResource());

    // Cleanup simulating node update
    schedulerNode.getPreemptionList();

    // Release all containers
    for (int i = 1; i < containers.size(); ++i) {
      schedulerNode.releaseContainer(containers.get(i).getContainerId(), true);
    }",1
"@Test
  public void testPreemptionToCompletedApp() {
    RMNode node = createNode();
    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, false);

    // Launch containers and saturate the cluster
    saturateCluster(schedulerNode);
    assertEquals(""Container should be allocated"",
        Resources.multiply(containers.get(0).getContainer().getResource(),
            containers.size()),
        schedulerNode.getAllocatedResource());

    // Preempt a container
    FSAppAttempt starvingApp = createStarvingApp(schedulerNode,
        Resource.newInstance(1024, 1));
    schedulerNode.addContainersForPreemption(
        Collections.singletonList(containers.get(0)), starvingApp);

    schedulerNode.releaseContainer(containers.get(0).getContainerId(), true);

    // Stop the application then try to satisfy the reservation
    // and observe that there are still free resources not allocated to
    // the deleted app
    when(starvingApp.isStopped()).thenReturn(true);
    allocateContainers(schedulerNode);
    assertNotEquals(""Container should be allocated"",
        schedulerNode.getTotalResource(),
        schedulerNode.getAllocatedResource());

    // Release all containers
    for (int i = 1; i < containers.size(); ++i) {
      schedulerNode.releaseContainer(containers.get(i).getContainerId(), true);
    }",1
"@Test
  public void testSimplePreemption() {
    RMNode node = createNode();
    FSSchedulerNode schedulerNode = new FSSchedulerNode(node, false);

    // Launch containers and saturate the cluster
    saturateCluster(schedulerNode);
    assertEquals(""Container should be allocated"",
        Resources.multiply(containers.get(0).getContainer().getResource(),
            containers.size()),
        schedulerNode.getAllocatedResource());

    // Request preemption
    FSAppAttempt starvingApp = createStarvingApp(schedulerNode,
        Resource.newInstance(1024, 1));
    schedulerNode.addContainersForPreemption(
        Collections.singletonList(containers.get(0)), starvingApp);
    assertEquals(
        ""No resource amount should be reserved for preemptees"",
        containers.get(0).getAllocatedResource(),
        schedulerNode.getTotalReserved());

    // Preemption occurs release one container
    schedulerNode.releaseContainer(containers.get(0).getContainerId(), true);
    allocateContainers(schedulerNode);
    assertEquals(""Container should be allocated"",
        schedulerNode.getTotalResource(),
        schedulerNode.getAllocatedResource());

    // Release all remaining containers
    for (int i = 1; i < containers.size(); ++i) {
      schedulerNode.releaseContainer(containers.get(i).getContainerId(), true);
    }",1
"@Test
  public void testNonEmptyStaticQueueBecomingDynamicQueue() {
    FSLeafQueue q1 = queueManager.getLeafQueue(""root.test.childA"", false);

    assertNotNull(""Queue root.test.childA does not exist"", q1);
    assertEquals(""createQueue() returned wrong queue"",
        ""root.test.childA"", q1.getName());
    assertFalse(""root.test.childA is not a static queue"", q1.isDynamic());

    // we submitted an app to the queue
    ApplicationId appId = ApplicationId.newInstance(0, 0);
    q1.addAssignedApp(appId);

    // the next removeEmptyDynamicQueues() call should not modify
    // root.test.childA
    queueManager.removePendingIncompatibleQueues();
    queueManager.removeEmptyDynamicQueues();
    q1 = queueManager.getLeafQueue(""root.test.childA"", false);
    assertNotNull(""Queue root.test.childA was deleted"", q1);
    assertFalse(""root.test.childA is not a dynamic queue"", q1.isDynamic());

    // next we remove all queues from the allocation config,
    // this causes all queues to change to dynamic
    AllocationConfiguration allocConf = scheduler.getAllocationConfiguration();
    for (Set<String> queueNames : allocConf.configuredQueues.values()) {
      queueManager.setQueuesToDynamic(queueNames);
      queueNames.clear();
    }",1
"@Test
  public void testRemovalOfDynamicParentQueue() {
    FSQueue q1 = queueManager.getLeafQueue(""root.parent1.dynamic1"", true);

    assertNotNull(""Queue root.parent1.dynamic1 was not created"", q1);
    assertEquals(""createQueue() returned wrong queue"",
        ""root.parent1.dynamic1"", q1.getName());
    assertTrue(""root.parent1.dynamic1 is not a dynamic queue"", q1.isDynamic());

    FSQueue p1 = queueManager.getParentQueue(""root.parent1"", false);
    assertNotNull(""Queue root.parent1 was not created"", p1);
    assertTrue(""root.parent1 is not a dynamic queue"", p1.isDynamic());

    queueManager.removePendingIncompatibleQueues();
    queueManager.removeEmptyDynamicQueues();
    q1 = queueManager.getLeafQueue(""root.parent1.dynamic1"", false);
    p1 = queueManager.getParentQueue(""root.parent1"", false);

    assertNull(""Queue root.parent1.dynamic1 was not deleted"", q1);
    assertNull(""Queue root.parent1 was not deleted"", p1);
  }",1
"@Test
  public void testResourceUpdateDecommissioningNode() throws Exception {
    // Mock the RMNodeResourceUpdate event handler to update SchedulerNode
    // to have 0 available resource
    RMContext spyContext = Mockito.spy(resourceManager.getRMContext());
    Dispatcher mockDispatcher = mock(AsyncDispatcher.class);
    when(mockDispatcher.getEventHandler()).thenReturn(new EventHandler<Event>() {
      @Override
      public void handle(Event event) {
        if (event instanceof RMNodeResourceUpdateEvent) {
          RMNodeResourceUpdateEvent resourceEvent =
              (RMNodeResourceUpdateEvent) event;
          resourceManager
              .getResourceScheduler()
              .getSchedulerNode(resourceEvent.getNodeId())
              .updateTotalResource(resourceEvent.getResourceOption().getResource());
        }",1
"@Test
  public void testNodeAttributesFunctionality() {
    // 1. Simple java=1.8 validation
    SchedulingRequest schedulingRequest =
        SchedulingRequest.newBuilder().executionType(
            ExecutionTypeRequest.newInstance(ExecutionType.GUARANTEED))
            .allocationRequestId(10L).priority(Priority.newInstance(1))
            .placementConstraintExpression(PlacementConstraints
                .targetNodeAttribute(PlacementConstraints.NODE,
                    NodeAttributeOpCode.EQ,
                    PlacementConstraints.PlacementTargets
                        .nodeAttribute(""java"", ""1.8""),
                    PlacementConstraints.PlacementTargets.nodePartition(""""))
                .build()).resourceSizing(
            ResourceSizing.newInstance(1, Resource.newInstance(1024, 1)))
            .build();
    allocator.updatePendingAsk(schedulerRequestKey, schedulingRequest, false);
    Set<NodeAttribute> attributes = new HashSet<>();
    attributes.add(
        NodeAttribute.newInstance(""java"", NodeAttributeType.STRING, ""1.8""));
    boolean result = allocator.canAllocate(NodeType.NODE_LOCAL,
        TestUtils.getMockNodeWithAttributes(""host1"", ""/rack1"", 123, 1024,
            attributes));
    Assert.assertTrue(""Allocation should be success for java=1.8"", result);

    // 2. verify python!=3 validation
    SchedulingRequest schedulingRequest2 =
        SchedulingRequest.newBuilder().executionType(
            ExecutionTypeRequest.newInstance(ExecutionType.GUARANTEED))
            .allocationRequestId(10L).priority(Priority.newInstance(1))
            .placementConstraintExpression(PlacementConstraints
                .targetNodeAttribute(PlacementConstraints.NODE,
                    NodeAttributeOpCode.NE,
                    PlacementConstraints.PlacementTargets
                        .nodeAttribute(""python"", ""3""),
                    PlacementConstraints.PlacementTargets.nodePartition(""""))
                .build()).resourceSizing(
            ResourceSizing.newInstance(1, Resource.newInstance(1024, 1)))
            .build();
    // Create allocator
    allocator = new SingleConstraintAppPlacementAllocator();
    allocator.initialize(appSchedulingInfo, schedulerRequestKey, rmContext);
    allocator.updatePendingAsk(schedulerRequestKey, schedulingRequest2, false);
    attributes = new HashSet<>();
    result = allocator.canAllocate(NodeType.NODE_LOCAL,
        TestUtils.getMockNodeWithAttributes(""host1"", ""/rack1"", 123, 1024,
            attributes));
    Assert.assertTrue(""Allocation should be success as python doesn't exist"",
        result);

    // 3. verify python!=3 validation when node has python=2
    allocator = new SingleConstraintAppPlacementAllocator();
    allocator.initialize(appSchedulingInfo, schedulerRequestKey, rmContext);
    allocator.updatePendingAsk(schedulerRequestKey, schedulingRequest2, false);
    attributes = new HashSet<>();
    attributes.add(
        NodeAttribute.newInstance(""python"", NodeAttributeType.STRING, ""2""));
    result = allocator.canAllocate(NodeType.NODE_LOCAL,
        TestUtils.getMockNodeWithAttributes(""host1"", ""/rack1"", 123, 1024,
            attributes));
    Assert.assertTrue(
        ""Allocation should be success as python=3 doesn't exist in node"",
        result);

    // 4. verify python!=3 validation when node has python=3
    allocator = new SingleConstraintAppPlacementAllocator();
    allocator.initialize(appSchedulingInfo, schedulerRequestKey, rmContext);
    allocator.updatePendingAsk(schedulerRequestKey, schedulingRequest2, false);
    attributes = new HashSet<>();
    attributes.add(
        NodeAttribute.newInstance(""python"", NodeAttributeType.STRING, ""3""));
    result = allocator.canAllocate(NodeType.NODE_LOCAL,
        TestUtils.getMockNodeWithAttributes(""host1"", ""/rack1"", 123, 1024,
            attributes));
    Assert.assertFalse(""Allocation should fail as python=3 exist in node"",
        result);
  }",1
"@Test
  public void testSizeBasedWeightNotAffectAppActivation() throws Exception {
    CapacitySchedulerConfiguration csConf =
        new CapacitySchedulerConfiguration();

    // Define top-level queues
    String defaultPath = CapacitySchedulerConfiguration.ROOT + "".default"";
    QueuePath queuePath = new QueuePath(defaultPath);
    csConf.set(YarnConfiguration.RM_SCHEDULER,
        CapacityScheduler.class.getCanonicalName());
    csConf.setOrderingPolicy(queuePath,
        CapacitySchedulerConfiguration.FAIR_APP_ORDERING_POLICY);
    csConf.setOrderingPolicyParameter(queuePath,
        FairOrderingPolicy.ENABLE_SIZE_BASED_WEIGHT, ""true"");
    csConf.setMaximumApplicationMasterResourcePerQueuePercent(queuePath, 0.1f);

    // inject node label manager
    MockRM rm = new MockRM(csConf);
    rm.start();

    CapacityScheduler cs = (CapacityScheduler) rm.getResourceScheduler();

    // Get LeafQueue
    LeafQueue lq = (LeafQueue) cs.getQueue(""default"");
    OrderingPolicy<FiCaSchedulerApp> policy = lq.getOrderingPolicy();
    Assert.assertTrue(policy instanceof FairOrderingPolicy);
    Assert.assertTrue(((FairOrderingPolicy<FiCaSchedulerApp>)policy).getSizeBasedWeight());

    rm.registerNode(""h1:1234"", 10 * GB);

    // Submit 4 apps
    MockRMAppSubmissionData data3 =
        MockRMAppSubmissionData.Builder.createWithMemory(1 * GB, rm)
            .withAppName(""app"")
            .withUser(""user"")
            .withAcls(null)
            .withQueue(""default"")
            .withUnmanagedAM(false)
            .build();
    MockRMAppSubmitter.submit(rm, data3);
    MockRMAppSubmissionData data2 =
        MockRMAppSubmissionData.Builder.createWithMemory(1 * GB, rm)
            .withAppName(""app"")
            .withUser(""user"")
            .withAcls(null)
            .withQueue(""default"")
            .withUnmanagedAM(false)
            .build();
    MockRMAppSubmitter.submit(rm, data2);
    MockRMAppSubmissionData data1 =
        MockRMAppSubmissionData.Builder.createWithMemory(1 * GB, rm)
            .withAppName(""app"")
            .withUser(""user"")
            .withAcls(null)
            .withQueue(""default"")
            .withUnmanagedAM(false)
            .build();
    MockRMAppSubmitter.submit(rm, data1);
    MockRMAppSubmissionData data =
        MockRMAppSubmissionData.Builder.createWithMemory(1 * GB, rm)
            .withAppName(""app"")
            .withUser(""user"")
            .withAcls(null)
            .withQueue(""default"")
            .withUnmanagedAM(false)
            .build();
    MockRMAppSubmitter.submit(rm, data);

    Assert.assertEquals(1, lq.getNumActiveApplications());
    Assert.assertEquals(3, lq.getNumPendingApplications());

    // Try allocate once, #active-apps and #pending-apps should be still correct
    cs.handle(new NodeUpdateSchedulerEvent(
        rm.getRMContext().getRMNodes().get(NodeId.newInstance(""h1"", 1234))));
    Assert.assertEquals(1, lq.getNumActiveApplications());
    Assert.assertEquals(3, lq.getNumPendingApplications());
  }",1
"@Test
  public void testIterators() {
    OrderingPolicy<MockSchedulableEntity> schedOrder =
     new FifoOrderingPolicy<MockSchedulableEntity>();
    
    MockSchedulableEntity msp1 = new MockSchedulableEntity();
    MockSchedulableEntity msp2 = new MockSchedulableEntity();
    MockSchedulableEntity msp3 = new MockSchedulableEntity();
    
    msp1.setSerial(3);
    msp2.setSerial(2);
    msp3.setSerial(1);
    
    schedOrder.addSchedulableEntity(msp1);
    schedOrder.addSchedulableEntity(msp2);
    schedOrder.addSchedulableEntity(msp3);
    
    //Assignment, oldest to youngest
    checkSerials(Arrays.asList(1L, 2L, 3L), schedOrder.getAssignmentIterator(
        IteratorSelector.EMPTY_ITERATOR_SELECTOR));
    
    //Preemption, youngest to oldest
    checkSerials(Arrays.asList(3L, 2L, 1L), schedOrder.getPreemptionIterator());
  }",1
"@Test
  public void testNodeTypeMetrics() {
    String parentQueueName = ""root"";
    String leafQueueName = ""root.leaf"";

    QueueMetrics parentMetrics =
      QueueMetrics.forQueue(ms, parentQueueName, null, true, conf);
    Queue parentQueue = mock(Queue.class);
    when(parentQueue.getMetrics()).thenReturn(parentMetrics);
    QueueMetrics metrics =
      QueueMetrics.forQueue(ms, leafQueueName, parentQueue, true, conf);
    MetricsSource parentQueueSource = queueSource(ms, parentQueueName);
    MetricsSource queueSource = queueSource(ms, leafQueueName);
    //AppSchedulingInfo app = mockApp(user);

    metrics.submitApp(USER, false);
    MetricsSource userSource = userSource(ms, leafQueueName, USER);
    MetricsSource parentUserSource = userSource(ms, parentQueueName, USER);

    metrics.incrNodeTypeAggregations(USER, NodeType.NODE_LOCAL);
    checkAggregatedNodeTypes(queueSource, 1L, 0L, 0L);
    checkAggregatedNodeTypes(parentQueueSource, 1L, 0L, 0L);
    checkAggregatedNodeTypes(userSource, 1L, 0L, 0L);
    checkAggregatedNodeTypes(parentUserSource, 1L, 0L, 0L);

    metrics.incrNodeTypeAggregations(USER, NodeType.RACK_LOCAL);
    checkAggregatedNodeTypes(queueSource, 1L, 1L, 0L);
    checkAggregatedNodeTypes(parentQueueSource, 1L, 1L, 0L);
    checkAggregatedNodeTypes(userSource, 1L, 1L, 0L);
    checkAggregatedNodeTypes(parentUserSource, 1L, 1L, 0L);

    metrics.incrNodeTypeAggregations(USER, NodeType.OFF_SWITCH);
    checkAggregatedNodeTypes(queueSource, 1L, 1L, 1L);
    checkAggregatedNodeTypes(parentQueueSource, 1L, 1L, 1L);
    checkAggregatedNodeTypes(userSource, 1L, 1L, 1L);
    checkAggregatedNodeTypes(parentUserSource, 1L, 1L, 1L);

    metrics.incrNodeTypeAggregations(USER, NodeType.OFF_SWITCH);
    checkAggregatedNodeTypes(queueSource, 1L, 1L, 2L);
    checkAggregatedNodeTypes(parentQueueSource, 1L, 1L, 2L);
    checkAggregatedNodeTypes(userSource, 1L, 1L, 2L);
    checkAggregatedNodeTypes(parentUserSource, 1L, 1L, 2L);
  }",1
"@Test
  public void testActiveUsersWhenMove() {
    final String user = ""user1"";
    Queue parentQueue = createQueue(""parent"", null);
    Queue queue1 = createQueue(""queue1"", parentQueue);
    Queue queue2 = createQueue(""queue2"", parentQueue);
    Queue queue3 = createQueue(""queue3"", parentQueue);

    ApplicationAttemptId appAttId = createAppAttemptId(0, 0);
    RMContext rmContext = mock(RMContext.class);
    when(rmContext.getEpoch()).thenReturn(3L);
    when(rmContext.getYarnConfiguration()).thenReturn(conf);
    SchedulerApplicationAttempt app = new SchedulerApplicationAttempt(appAttId,
        user, queue1, queue1.getAbstractUsersManager(), rmContext);

    // Resource request
    Resource requestedResource = Resource.newInstance(1536, 2);
    Priority requestedPriority = Priority.newInstance(2);
    ResourceRequest request = ResourceRequest.newInstance(requestedPriority,
        ResourceRequest.ANY, requestedResource, 1);
    app.updateResourceRequests(Arrays.asList(request));

    assertEquals(1, queue1.getAbstractUsersManager().getNumActiveUsers());
    // move app from queue1 to queue2
    app.move(queue2);
    // Active user count has to decrease from queue1
    assertEquals(0, queue1.getAbstractUsersManager().getNumActiveUsers());
    // Increase the active user count in queue2 if the moved app has pending requests
    assertEquals(1, queue2.getAbstractUsersManager().getNumActiveUsers());

    // Allocated container
    RMContainer container1 = createRMContainer(appAttId, 1, requestedResource);
    app.liveContainers.put(container1.getContainerId(), container1);
    SchedulerNode node = createNode();
    app.appSchedulingInfo.allocate(NodeType.OFF_SWITCH, node,
        toSchedulerKey(requestedPriority), container1);

    // Active user count has to decrease from queue2 due to app has NO pending requests
    assertEquals(0, queue2.getAbstractUsersManager().getNumActiveUsers());
    // move app from queue2 to queue3
    app.move(queue3);
    // Active user count in queue3 stays same if the moved app has NO pending requests
    assertEquals(0, queue3.getAbstractUsersManager().getNumActiveUsers());
  }",1
"@Test
  public void testAppPercentages() throws Exception {
    FifoScheduler scheduler = mock(FifoScheduler.class);
    when(scheduler.getClusterResource())
        .thenReturn(Resource.newInstance(10 * 1024, 10));
    when(scheduler.getResourceCalculator())
        .thenReturn(new DefaultResourceCalculator());

    ApplicationAttemptId appAttId = createAppAttemptId(0, 0);
    RMContext rmContext = mock(RMContext.class);
    when(rmContext.getEpoch()).thenReturn(3L);
    when(rmContext.getScheduler()).thenReturn(scheduler);
    when(rmContext.getYarnConfiguration()).thenReturn(conf);

    final String user = ""user1"";
    Queue queue = createQueue(""test"", null);
    SchedulerApplicationAttempt app =
        new SchedulerApplicationAttempt(appAttId, user, queue,
            queue.getAbstractUsersManager(), rmContext);

    // Resource request
    Resource requestedResource = Resource.newInstance(1536, 2);
    app.attemptResourceUsage.incUsed(requestedResource);

    assertEquals(15.0f, app.getResourceUsageReport().getQueueUsagePercentage(),
        0.01f);
    assertEquals(15.0f,
        app.getResourceUsageReport().getClusterUsagePercentage(), 0.01f);

    queue = createQueue(""test2"", null, 0.5f);
    app = new SchedulerApplicationAttempt(appAttId, user, queue,
        queue.getAbstractUsersManager(), rmContext);
    app.attemptResourceUsage.incUsed(requestedResource);
    assertEquals(30.0f, app.getResourceUsageReport().getQueueUsagePercentage(),
        0.01f);
    assertEquals(15.0f,
        app.getResourceUsageReport().getClusterUsagePercentage(), 0.01f);

    app.attemptResourceUsage.incUsed(requestedResource);
    app.attemptResourceUsage.incUsed(requestedResource);
    app.attemptResourceUsage.incUsed(requestedResource);

    assertEquals(120.0f, app.getResourceUsageReport().getQueueUsagePercentage(),
        0.01f);
    assertEquals(60.0f,
        app.getResourceUsageReport().getClusterUsagePercentage(), 0.01f);

    queue = createQueue(""test3"", null, Float.MIN_VALUE);
    app = new SchedulerApplicationAttempt(appAttId, user, queue,
        queue.getAbstractUsersManager(), rmContext);

    // Resource request
    app.attemptResourceUsage.incUsed(requestedResource);

    assertEquals(0.0f, app.getResourceUsageReport().getQueueUsagePercentage(),
        0.01f);
    assertEquals(15.0f,
        app.getResourceUsageReport().getClusterUsagePercentage(), 0.01f);
  }",1
"@Test
  public void testValidateResourceBlacklistRequest() throws Exception {

    MyContainerManager containerManager = new MyContainerManager();
    final MockRMWithAMS rm =
            new MockRMWithAMS(new YarnConfiguration(), containerManager);
    rm.start();

    MockNM nm1 = rm.registerNode(""localhost:1234"", 5120);

    Map<ApplicationAccessType, String> acls =
            new HashMap<ApplicationAccessType, String>(2);
    acls.put(ApplicationAccessType.VIEW_APP, ""*"");
    MockRMAppSubmissionData data =
        MockRMAppSubmissionData.Builder.createWithMemory(1024, rm)
            .withAppName(""appname"")
            .withUser(""appuser"")
            .withAcls(acls)
            .build();
    RMApp app = MockRMAppSubmitter.submit(rm, data);

    nm1.nodeHeartbeat(true);

    RMAppAttempt attempt = app.getCurrentAppAttempt();
    ApplicationAttemptId applicationAttemptId = attempt.getAppAttemptId();
    waitForLaunchedState(attempt);

    // Create a client to the RM.
    final Configuration yarnConf = rm.getConfig();
    final YarnRPC rpc = YarnRPC.create(yarnConf);

    UserGroupInformation currentUser =
            UserGroupInformation.createRemoteUser(applicationAttemptId.toString());
    Credentials credentials = containerManager.getContainerCredentials();
    final InetSocketAddress rmBindAddress =
            rm.getApplicationMasterService().getBindAddress();
    Token<? extends TokenIdentifier> amRMToken =
            MockRMWithAMS.setupAndReturnAMRMToken(rmBindAddress,
                    credentials.getAllTokens());
    currentUser.addToken(amRMToken);
    ApplicationMasterProtocol client =
            currentUser.doAs(new PrivilegedAction<ApplicationMasterProtocol>() {
              @Override
              public ApplicationMasterProtocol run() {
                return (ApplicationMasterProtocol) rpc.getProxy(
                        ApplicationMasterProtocol.class, rmBindAddress, yarnConf);
              }",1
"@Test
  public void testForceKillNonExistingApplication() throws YarnException {
    RMContext rmContext = mock(RMContext.class);
    when(rmContext.getRMApps()).thenReturn(
        new ConcurrentHashMap<ApplicationId, RMApp>());
    ClientRMService rmService = new ClientRMService(rmContext, null, null,
        null, null, null);
    ApplicationId applicationId =
        BuilderUtils.newApplicationId(System.currentTimeMillis(), 0);
    KillApplicationRequest request =
        KillApplicationRequest.newInstance(applicationId);
    try {
      rmService.forceKillApplication(request);
      Assert.fail();
    }",1
"@Test
  public void testMoveApplicationAdminTargetQueue() throws Exception {
    ApplicationId applicationId = getApplicationId(1);
    UserGroupInformation aclUGI = UserGroupInformation.getCurrentUser();
    QueueACLsManager queueAclsManager = getQueueAclManager(""allowed_queue"",
        QueueACL.ADMINISTER_QUEUE, aclUGI);
    ApplicationACLsManager appAclsManager = getAppAclManager();
    ClientRMService rmService =
        createClientRMServiceForMoveApplicationRequest(applicationId,
            aclUGI.getShortUserName(), appAclsManager, queueAclsManager);

    // user is admin move to queue in acl
    MoveApplicationAcrossQueuesRequest moveAppRequest =
        MoveApplicationAcrossQueuesRequest.newInstance(applicationId,
            ""allowed_queue"");
    rmService.moveApplicationAcrossQueues(moveAppRequest);

    // user is admin move to queue not in acl
    moveAppRequest = MoveApplicationAcrossQueuesRequest.newInstance(
        applicationId, ""not_allowed"");

    try {
      rmService.moveApplicationAcrossQueues(moveAppRequest);
      Assert.fail(""The request should fail with an AccessControlException"");
    }",1
"@Test
  public void testRMStartWithDecommissionedNode() throws Exception {
    File testDir = GenericTestUtils.getRandomizedTestDir();
    assertTrue(""Failed to create test directory: "" + testDir.getAbsolutePath(), testDir.mkdirs());
    try {
      File excludeFile = createExcludeFile(testDir);
      conf = new YarnConfiguration();
      conf.set(YarnConfiguration.RM_NODES_EXCLUDE_FILE_PATH,
          excludeFile.getAbsolutePath());
      MockRM rm = new MockRM(conf) {
        protected ClientRMService createClientRMService() {
          return new ClientRMService(this.rmContext, scheduler,
              this.rmAppManager, this.applicationACLsManager, this.queueACLsManager,
              this.getRMContext().getRMDelegationTokenSecretManager());
        }",1
"@Test
  public void testNMExpiryAndHeartbeatIntervalsValidation() throws Exception {
    Configuration conf = new YarnConfiguration();
    conf.setLong(YarnConfiguration.RM_NM_EXPIRY_INTERVAL_MS, 1000);
    conf.setLong(YarnConfiguration.RM_NM_HEARTBEAT_INTERVAL_MS, 1001);
    try {
      resourceManager = new MockRM(conf);
    }",1
"@Test
  public void testIncorrectRecommission() throws Exception {
    //Check decommissioned node not get recommissioned with graceful refresh
    Configuration conf = new Configuration();
    rm = new MockRM(conf);
    rm.start();
    MockNM nm1 = rm.registerNode(""host1:1234"", 5120);
    MockNM nm2 = rm.registerNode(""host2:5678"", 10240);
    nm1.nodeHeartbeat(true);
    nm2.nodeHeartbeat(true);
    writeToHostsFile(excludeHostFile, ""host3"", ""host2"");
    conf.set(YarnConfiguration.RM_NODES_EXCLUDE_FILE_PATH,
        excludeHostFile.getAbsolutePath());
    writeToHostsFile(hostFile, ""host1"", ""host2"");
    writeToHostsFile(excludeHostFile, ""host1"");
    rm.getNodesListManager().refreshNodesGracefully(conf, null);
    rm.drainEvents();
    nm1.nodeHeartbeat(true);
    rm.drainEvents();
    Assert.assertTrue(""Node "" + nm1.getNodeId().getHost() +
        "" should be Decommissioned"", rm.getRMContext()
        .getInactiveRMNodes().get(nm1.getNodeId()).getState() == NodeState
        .DECOMMISSIONED);
    writeToHostsFile(excludeHostFile, """");
    rm.getNodesListManager().refreshNodesGracefully(conf, null);
    rm.drainEvents();
    Assert.assertTrue(""Node "" + nm1.getNodeId().getHost() +
        "" should be Decommissioned"", rm.getRMContext()
        .getInactiveRMNodes().get(nm1.getNodeId()).getState() == NodeState
        .DECOMMISSIONED);
    rm.stop();
  }",1
"@Test
  public void testNodeHeartBeatWithInvalidLabels() throws Exception {
    writeToHostsFile(""host2"");
    Configuration conf = new Configuration();
    conf.set(YarnConfiguration.RM_NODES_INCLUDE_FILE_PATH,
        hostFile.getAbsolutePath());
    conf.set(YarnConfiguration.NODELABEL_CONFIGURATION_TYPE,
        YarnConfiguration.DISTRIBUTED_NODELABEL_CONFIGURATION_TYPE);

    final RMNodeLabelsManager nodeLabelsMgr = new NullRMNodeLabelsManager();

    rm = new MockRM(conf) {
      @Override
      protected RMNodeLabelsManager createNodeLabelManager() {
        return nodeLabelsMgr;
      }",1
"@Test
  public void testNodeHeartBeatWithLabels() throws Exception {
    writeToHostsFile(""host2"");
    Configuration conf = new Configuration();
    conf.set(YarnConfiguration.RM_NODES_INCLUDE_FILE_PATH,
        hostFile.getAbsolutePath());
    conf.set(YarnConfiguration.NODELABEL_CONFIGURATION_TYPE,
        YarnConfiguration.DISTRIBUTED_NODELABEL_CONFIGURATION_TYPE);

    final RMNodeLabelsManager nodeLabelsMgr = new NullRMNodeLabelsManager();

    rm = new MockRM(conf) {
      @Override
      protected RMNodeLabelsManager createNodeLabelManager() {
        return nodeLabelsMgr;
      }",1
"@Test
  public void testNodeHeartbeatWithNodeAttributes() throws Exception {
    writeToHostsFile(""host2"");
    Configuration conf = new Configuration();
    conf.set(YarnConfiguration.RM_NODES_INCLUDE_FILE_PATH,
        hostFile.getAbsolutePath());
    conf.setClass(YarnConfiguration.FS_NODE_ATTRIBUTE_STORE_IMPL_CLASS,
        FileSystemNodeAttributeStore.class, NodeAttributeStore.class);
    conf.set(YarnConfiguration.FS_NODE_ATTRIBUTE_STORE_ROOT_DIR,
        TEMP_DIR.getAbsolutePath());
    rm = new MockRM(conf);
    rm.start();

    // Register to RM
    ResourceTrackerService resourceTrackerService =
        rm.getResourceTrackerService();
    RegisterNodeManagerRequest registerReq =
        Records.newRecord(RegisterNodeManagerRequest.class);
    NodeId nodeId = NodeId.newInstance(""host2"", 1234);
    Resource capability = Resources.createResource(1024);
    registerReq.setResource(capability);
    registerReq.setNodeId(nodeId);
    registerReq.setHttpPort(1234);
    registerReq.setNMVersion(YarnVersionInfo.getVersion());
    RegisterNodeManagerResponse registerResponse =
        resourceTrackerService.registerNodeManager(registerReq);

    Set<NodeAttribute> nodeAttributes = new HashSet<>();
    nodeAttributes.add(NodeAttribute.newInstance(
        NodeAttribute.PREFIX_DISTRIBUTED, ""host"",
        NodeAttributeType.STRING, ""host2""));

    // Set node attributes in HB.
    NodeHeartbeatRequest heartbeatReq =
        Records.newRecord(NodeHeartbeatRequest.class);
    NodeStatus nodeStatusObject = getNodeStatusObject(nodeId);
    int responseId = nodeStatusObject.getResponseId();
    heartbeatReq.setNodeStatus(nodeStatusObject);
    heartbeatReq.setLastKnownNMTokenMasterKey(registerResponse
        .getNMTokenMasterKey());
    heartbeatReq.setLastKnownContainerTokenMasterKey(registerResponse
        .getContainerTokenMasterKey());
    heartbeatReq.setNodeAttributes(nodeAttributes);
    resourceTrackerService.nodeHeartbeat(heartbeatReq);

    // Ensure RM gets correct node attributes update.
    NodeAttributesManager attributeManager =
        rm.getRMContext().getNodeAttributesManager();
    Map<NodeAttribute, AttributeValue> attrs = attributeManager
        .getAttributesForNode(nodeId.getHost());
    Assert.assertEquals(1, attrs.size());
    NodeAttribute na = attrs.keySet().iterator().next();
    Assert.assertEquals(""host"", na.getAttributeKey().getAttributeName());
    Assert.assertEquals(""host2"", na.getAttributeValue());
    Assert.assertEquals(NodeAttributeType.STRING, na.getAttributeType());


    // Send another HB to RM with updated node atrribute
    nodeAttributes.clear();
    nodeAttributes.add(NodeAttribute.newInstance(
        NodeAttribute.PREFIX_DISTRIBUTED, ""host"",
        NodeAttributeType.STRING, ""host3""));
    nodeStatusObject = getNodeStatusObject(nodeId);
    nodeStatusObject.setResponseId(++responseId);
    heartbeatReq.setNodeStatus(nodeStatusObject);
    heartbeatReq.setNodeAttributes(nodeAttributes);
    resourceTrackerService.nodeHeartbeat(heartbeatReq);

    // Make sure RM gets the updated attribute
    attrs = attributeManager.getAttributesForNode(nodeId.getHost());
    Assert.assertEquals(1, attrs.size());
    na = attrs.keySet().iterator().next();
    Assert.assertEquals(""host"", na.getAttributeKey().getAttributeName());
    Assert.assertEquals(""host3"", na.getAttributeValue());
    Assert.assertEquals(NodeAttributeType.STRING, na.getAttributeType());
  }",1
"@Test
  public void testNodeRegistrationWithInvalidLabels() throws Exception {
    writeToHostsFile(""host2"");
    Configuration conf = new Configuration();
    conf.set(YarnConfiguration.RM_NODES_INCLUDE_FILE_PATH,
        hostFile.getAbsolutePath());
    conf.set(YarnConfiguration.NODELABEL_CONFIGURATION_TYPE,
        YarnConfiguration.DISTRIBUTED_NODELABEL_CONFIGURATION_TYPE);

    final RMNodeLabelsManager nodeLabelsMgr = new NullRMNodeLabelsManager();

    rm = new MockRM(conf) {
      @Override
      protected RMNodeLabelsManager createNodeLabelManager() {
        return nodeLabelsMgr;
      }",1
"@Test
  public void testUnhealthyNodeStatus() throws Exception {
    Configuration conf = new Configuration();
    conf.set(YarnConfiguration.RM_NODES_EXCLUDE_FILE_PATH, hostFile
        .getAbsolutePath());

    rm = new MockRM(conf);
    rm.start();

    MockNM nm1 = rm.registerNode(""host1:1234"", 5120);
    Assert.assertEquals(0, ClusterMetrics.getMetrics().getUnhealthyNMs());
    // node healthy
    nm1.nodeHeartbeat(true);

    // node unhealthy
    nm1.nodeHeartbeat(false);
    checkUnhealthyNMCount(rm, nm1, true, 1);

    // node healthy again
    nm1.nodeHeartbeat(true);
    checkUnhealthyNMCount(rm, nm1, false, 0);
  }",1
"@Test  
  public void testKeyValLogFormat() throws Exception {
    StringBuilder actLog = new StringBuilder();
    StringBuilder expLog = new StringBuilder();
    // add the first k=v pair and check
    RMAuditLogger.start(Keys.USER, USER, actLog);
    expLog.append(""USER=test"");
    assertEquals(expLog.toString(), actLog.toString());

    // append another k1=v1 pair to already added k=v and test
    RMAuditLogger.add(Keys.OPERATION, OPERATION, actLog);
    expLog.append(""\tOPERATION=oper"");
    assertEquals(expLog.toString(), actLog.toString());

    // append another k1=null pair and test
    RMAuditLogger.add(Keys.APPID, (String)null, actLog);
    expLog.append(""\tAPPID=null"");
    assertEquals(expLog.toString(), actLog.toString());

    // now add the target and check of the final string
    RMAuditLogger.add(Keys.TARGET, TARGET, actLog);
    expLog.append(""\tTARGET=tgt"");
    assertEquals(expLog.toString(), actLog.toString());
  }",1
"@Test
  public void testValidateAndSplitUpdateResourceRequests() {
    List<UpdateContainerRequest> updateRequests = new ArrayList<>();
    int containerVersion = 10;
    int resource = 10;
    Resource maxAllocation = Resource.newInstance(resource, resource);

    UpdateContainerRequestPBImpl updateContainerRequestPBFail =
        new UpdateContainerRequestPBImpl();
    updateContainerRequestPBFail.setContainerVersion(containerVersion);
    updateContainerRequestPBFail
        .setCapability(Resource.newInstance(resource + 1, resource + 1));
    updateContainerRequestPBFail
        .setContainerId(Mockito.mock(ContainerId.class));

    ContainerId containerIdOk = Mockito.mock(ContainerId.class);
    Resource capabilityOk = Resource.newInstance(resource - 1, resource - 1);
    UpdateContainerRequestPBImpl updateContainerRequestPBOk =
        new UpdateContainerRequestPBImpl();
    updateContainerRequestPBOk.setContainerVersion(containerVersion);
    updateContainerRequestPBOk.setCapability(capabilityOk);
    updateContainerRequestPBOk.setContainerUpdateType(INCREASE_RESOURCE);
    updateContainerRequestPBOk.setContainerId(containerIdOk);

    updateRequests.add(updateContainerRequestPBOk);
    updateRequests.add(updateContainerRequestPBFail);

    Dispatcher dispatcher = Mockito.mock(Dispatcher.class);
    RMContext rmContext = Mockito.mock(RMContext.class);
    ResourceScheduler scheduler = Mockito.mock(ResourceScheduler.class);

    Mockito.when(rmContext.getScheduler()).thenReturn(scheduler);
    Mockito.when(rmContext.getDispatcher()).thenReturn(dispatcher);

    RMContainer rmContainer = Mockito.mock(RMContainer.class);
    Mockito.when(scheduler.getRMContainer(Mockito.any()))
        .thenReturn(rmContainer);
    Container container = Mockito.mock(Container.class);
    Mockito.when(container.getVersion()).thenReturn(containerVersion);
    Mockito.when(rmContainer.getContainer()).thenReturn(container);
    Mockito.when(scheduler.getNormalizedResource(capabilityOk, maxAllocation))
        .thenReturn(capabilityOk);

    AllocateRequest allocateRequest =
        AllocateRequest.newInstance(1, 0.5f, new ArrayList<ResourceRequest>(),
            new ArrayList<ContainerId>(), updateRequests, null);

    List<UpdateContainerError> updateErrors = new ArrayList<>();
    ContainerUpdates containerUpdates =
        RMServerUtils.validateAndSplitUpdateResourceRequests(rmContext,
            allocateRequest, maxAllocation, updateErrors);
    Assert.assertEquals(1, updateErrors.size());
    Assert.assertEquals(resource + 1, updateErrors.get(0)
        .getUpdateContainerRequest().getCapability().getMemorySize());
    Assert.assertEquals(resource + 1, updateErrors.get(0)
        .getUpdateContainerRequest().getCapability().getVirtualCores());
    Assert.assertEquals(RESOURCE_OUTSIDE_ALLOWED_RANGE,
        updateErrors.get(0).getReason());

    Assert.assertEquals(1, containerUpdates.getIncreaseRequests().size());
    UpdateContainerRequest increaseRequest =
        containerUpdates.getIncreaseRequests().get(0);
    Assert.assertEquals(capabilityOk.getVirtualCores(),
        increaseRequest.getCapability().getVirtualCores());
    Assert.assertEquals(capabilityOk.getMemorySize(),
        increaseRequest.getCapability().getMemorySize());
    Assert.assertEquals(containerIdOk, increaseRequest.getContainerId());
  }",1
"@Test
  public void testDumpingSchedulerLogs() throws Exception {

    ResourceManager mockRM = mock(ResourceManager.class);
    Configuration conf = new YarnConfiguration();
    HttpServletRequest mockHsr = mockHttpServletRequestByUserName(""non-admin"");
    ApplicationACLsManager aclsManager = new ApplicationACLsManager(conf);
    when(mockRM.getApplicationACLsManager()).thenReturn(aclsManager);
    RMWebServices webSvc =
        new RMWebServices(mockRM, conf, mock(HttpServletResponse.class));

    // nothing should happen
    webSvc.dumpSchedulerLogs(""1"", mockHsr);
    waitforLogDump(50);
    checkSchedulerLogFileAndCleanup();

    conf.setBoolean(YarnConfiguration.YARN_ACL_ENABLE, true);
    conf.setStrings(YarnConfiguration.YARN_ADMIN_ACL, ""admin"");
    aclsManager = new ApplicationACLsManager(conf);
    when(mockRM.getApplicationACLsManager()).thenReturn(aclsManager);
    webSvc = new RMWebServices(mockRM, conf, mock(HttpServletResponse.class));
    boolean exceptionThrown = false;
    try {
      webSvc.dumpSchedulerLogs(""1"", mockHsr);
      fail(""Dumping logs should fail"");
    }",1
"@Test
  public void testRouterClientRMServiceE2E() throws Exception {

    String user = ""test1"";

    LOG.info(""testRouterClientRMServiceE2E - Get New Application"");

    GetNewApplicationResponse responseGetNewApp = getNewApplication(user);
    Assert.assertNotNull(responseGetNewApp);

    LOG.info(""testRouterClientRMServiceE2E - Submit Application"");

    SubmitApplicationResponse responseSubmitApp =
        submitApplication(responseGetNewApp.getApplicationId(), user);
    Assert.assertNotNull(responseSubmitApp);

    LOG.info(""testRouterClientRMServiceE2E - Get Cluster Metrics"");

    GetClusterMetricsResponse responseGetClusterMetrics =
        getClusterMetrics(user);
    Assert.assertNotNull(responseGetClusterMetrics);

    LOG.info(""testRouterClientRMServiceE2E - Get Cluster Nodes"");

    GetClusterNodesResponse responseGetClusterNodes = getClusterNodes(user);
    Assert.assertNotNull(responseGetClusterNodes);

    LOG.info(""testRouterClientRMServiceE2E - Get Queue Info"");

    GetQueueInfoResponse responseGetQueueInfo = getQueueInfo(user);
    Assert.assertNotNull(responseGetQueueInfo);

    LOG.info(""testRouterClientRMServiceE2E - Get Queue User"");

    GetQueueUserAclsInfoResponse responseGetQueueUser = getQueueUserAcls(user);
    Assert.assertNotNull(responseGetQueueUser);

    LOG.info(""testRouterClientRMServiceE2E - Get Cluster Node"");

    GetClusterNodeLabelsResponse responseGetClusterNode =
        getClusterNodeLabels(user);
    Assert.assertNotNull(responseGetClusterNode);

    LOG.info(""testRouterClientRMServiceE2E - Move Application Across Queues"");

    MoveApplicationAcrossQueuesResponse responseMoveApp =
        moveApplicationAcrossQueues(user, responseGetNewApp.getApplicationId());
    Assert.assertNotNull(responseMoveApp);

    LOG.info(""testRouterClientRMServiceE2E - Get New Reservation"");

    GetNewReservationResponse getNewReservationResponse =
        getNewReservation(user);

    LOG.info(""testRouterClientRMServiceE2E - Submit Reservation"");

    ReservationSubmissionResponse responseSubmitReser =
        submitReservation(user, getNewReservationResponse.getReservationId());
    Assert.assertNotNull(responseSubmitReser);

    LOG.info(""testRouterClientRMServiceE2E - Update Reservation"");

    ReservationUpdateResponse responseUpdateReser =
        updateReservation(user, getNewReservationResponse.getReservationId());
    Assert.assertNotNull(responseUpdateReser);

    LOG.info(""testRouterClientRMServiceE2E - Delete Reservation"");

    ReservationDeleteResponse responseDeleteReser =
        deleteReservation(user, getNewReservationResponse.getReservationId());
    Assert.assertNotNull(responseDeleteReser);

    LOG.info(""testRouterClientRMServiceE2E - Kill Application"");

    KillApplicationResponse responseKillApp =
        forceKillApplication(responseGetNewApp.getApplicationId(), user);
    Assert.assertNotNull(responseKillApp);
  }",1
"@Test
  public void testGetClusterMetrics() {

    ClusterMetricsInfo responseGet = interceptor.getClusterMetricsInfo();

    Assert.assertNotNull(responseGet);
    int expectedAppSubmitted = 0;
    for (int i = 0; i < NUM_SUBCLUSTER; i++) {
      expectedAppSubmitted += i;
    }",1
"@Test
  public void testMerge4DifferentApps() {

    AppsInfo apps = new AppsInfo();
    int value = 1000;

    AppInfo app1 = new AppInfo();
    app1.setAppId(APPID1.toString());
    app1.setAMHostHttpAddress(""http://i_am_the_AM1:1234"");
    app1.setState(YarnApplicationState.FINISHED);
    app1.setNumAMContainerPreempted(value);
    apps.add(app1);

    AppInfo app2 = new AppInfo();
    app2.setAppId(APPID2.toString());
    app2.setAMHostHttpAddress(""http://i_am_the_AM2:1234"");
    app2.setState(YarnApplicationState.ACCEPTED);
    app2.setAllocatedVCores(2 * value);

    apps.add(app2);

    AppInfo app3 = new AppInfo();
    app3.setAppId(APPID3.toString());
    app3.setAMHostHttpAddress(""http://i_am_the_AM3:1234"");
    app3.setState(YarnApplicationState.RUNNING);
    app3.setReservedMB(3 * value);
    apps.add(app3);

    AppInfo app4 = new AppInfo();
    app4.setAppId(APPID4.toString());
    app4.setAMHostHttpAddress(""http://i_am_the_AM4:1234"");
    app4.setState(YarnApplicationState.NEW);
    app4.setAllocatedMB(4 * value);
    apps.add(app4);

    AppsInfo result = RouterWebServiceUtil.mergeAppsInfo(apps.getApps(), false);
    Assert.assertNotNull(result);
    Assert.assertEquals(4, result.getApps().size());

    List<String> appIds = new ArrayList<String>();
    AppInfo appInfo1 = null, appInfo2 = null, appInfo3 = null, appInfo4 = null;
    for (AppInfo app : result.getApps()) {
      appIds.add(app.getAppId());
      if (app.getAppId().equals(APPID1.toString())) {
        appInfo1 = app;
      }",1
"@Test
  public void testGetEntitiesWithPrimaryFilters() throws IOException {
    super.testGetEntitiesWithPrimaryFilters();
  }",1
"@Test
  public void testActionServiceUpgrade() throws Exception {
    Service service = createService();
    ServiceClient client = MockServiceClient.create(rule, service, true);

    //upgrade the service
    service.setVersion(""v2"");
    client.initiateUpgrade(service);

    Service fromFs = ServiceApiUtil.loadServiceUpgrade(rule.getFs(),
        service.getName(), service.getVersion());
    Assert.assertEquals(service.getName(), fromFs.getName());
    Assert.assertEquals(service.getVersion(), fromFs.getVersion());
    client.stop();
  }",1
"@Test
  public void testCancelNothingToUpgrade() throws Exception {
    ServiceContext context = TestComponent.createTestContext(rule,
        ""testCancelUpgradeWhenContainerReady"");
    Component component = context.scheduler.getAllComponents().entrySet()
        .iterator().next().getValue();
    cancelCompUpgrade(component);

    ComponentInstance instance = component.getAllComponentInstances().iterator()
        .next();

    ComponentInstanceEvent cancelEvent = new ComponentInstanceEvent(
        instance.getContainer().getId(),
        ComponentInstanceEventType.CANCEL_UPGRADE);
    instance.handle(cancelEvent);

    Assert.assertEquals(""instance not ready"", ContainerState.READY,
        component.getComponentSpec().getContainer(instance.getContainer()
            .getId().toString()).getState());
  }",1
"@Test
  public void testContainerUpgrade() throws Exception {
    ServiceContext context = TestComponent.createTestContext(rule,
        ""testContainerUpgrade"");
    Component component = context.scheduler.getAllComponents().entrySet()
        .iterator().next().getValue();
    upgradeComponent(component);

    ComponentInstance instance = component.getAllComponentInstances().iterator()
        .next();
    ComponentInstanceEvent instanceEvent = new ComponentInstanceEvent(
        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE);
    instance.handle(instanceEvent);
    Container containerSpec = component.getComponentSpec().getContainer(
        instance.getContainer().getId().toString());
    Assert.assertEquals(""instance not upgrading"", ContainerState.UPGRADING,
        containerSpec.getState());
  }",1
"@Test
  public void testComponentDependency() throws Exception{
    ApplicationId applicationId = ApplicationId.newInstance(123456, 1);
    Service exampleApp = new Service();
    exampleApp.setVersion(""v1"");
    exampleApp.setId(applicationId.toString());
    exampleApp.setName(""testComponentDependency"");
    exampleApp.addComponent(createComponent(""compa"", 1, ""sleep 1000""));
    // Let compb depends on compa;
    Component compb = createComponent(""compb"", 1, ""sleep 1000"", Component
        .RestartPolicyEnum.ON_FAILURE, Collections.singletonList(""compa""));
    // Let compb depends on compb;
    Component compc = createComponent(""compc"", 1, ""sleep 1000"", Component
        .RestartPolicyEnum.NEVER, Collections.singletonList(""compb""));

    exampleApp.addComponent(compb);
    exampleApp.addComponent(compc);

    MockServiceAM am = new MockServiceAM(exampleApp);
    am.init(conf);
    am.start();

    // compa ready
    Assert.assertTrue(am.getComponent(""compa"").areDependenciesReady());
    //compb not ready
    Assert.assertFalse(am.getComponent(""compb"").areDependenciesReady());

    // feed 1 container to compa,
    am.feedContainerToComp(exampleApp, 1, ""compa"");
    // waiting for compb's dependencies are satisfied
    am.waitForDependenciesSatisfied(""compb"");

    // feed 1 container to compb,
    am.feedContainerToComp(exampleApp, 2, ""compb"");
    // waiting for compc's dependencies are satisfied
    am.waitForDependenciesSatisfied(""compc"");

    // feed 1 container to compb
    am.feedContainerToComp(exampleApp, 2, ""compb"");
    am.flexComponent(""compa"", 2);
    am.waitForNumDesiredContainers(""compa"", 2);

    // compb dependencies not satisfied again.
    Assert.assertFalse(am.getComponent(""compb"").areDependenciesReady());
    am.stop();
  }",1
"@Test
  public void testBuildContainerLaunchCommand() throws Exception {
    AbstractProviderService providerService = new DockerProviderService();
    Component component = serviceContext.scheduler.getAllComponents().entrySet()
        .iterator().next().getValue();
    ContainerLaunchService.ComponentLaunchContext clc =
        createEntryPointCLCFor(testService, component, ""sleep,9000"");

    ComponentInstance instance = component.getAllComponentInstances().iterator()
        .next();
    Container container = mock(Container.class);
    providerService.buildContainerLaunchCommand(launcher, testService, instance,
        rule.getFs(), serviceContext.scheduler.getConfig(), container, clc,
        null);

    Assert.assertEquals(""commands"", Lists.newArrayList(clc.getLaunchCommand()),
        launcher.getCommands());
  }",1
"@Test
  public void testExternalComponent() throws IOException {
    Service ext = createValidApplication(""comp1"");
    SliderFileSystem sfs = ServiceTestUtils.initMockFs(ext);

    Service app = createValidApplication(""comp2"");
    Artifact artifact = new Artifact();
    artifact.setType(Artifact.TypeEnum.SERVICE);
    artifact.setId(""id"");
    app.setArtifact(artifact);

    try {
      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
    }",1
"@Test
  public void testResolveCompsCircularDependency() {
    Service service = createExampleApplication();
    List<String> dependencies = new ArrayList<String>();
    List<String> dependencies2 = new ArrayList<String>();
    dependencies.add(""compb"");
    dependencies2.add(""compa"");
    Component compa = createComponent(""compa"");
    compa.setDependencies(dependencies);
    Component compb = createComponent(""compb"");
    compa.setDependencies(dependencies2);
    service.addComponent(compa);
    service.addComponent(compb);
    List<String> order = ServiceApiUtil.resolveCompsDependency(service);
    List<String> expected = new ArrayList<String>();
    expected.add(""compa"");
    expected.add(""compb"");
    for (int i = 0; i < expected.size(); i++) {
      Assert.assertEquals(""Components are not equal."", expected.get(i),
          order.get(i));
    }",1
"@Test
  public void testServiceDependencies() {
    Thread thread = new Thread() {
      @Override
      public void run() {
        Service service = createExampleApplication();
        Component compa = createComponent(""compa"");
        Component compb = createComponent(""compb"");
        service.addComponent(compa);
        service.addComponent(compb);
        List<String> dependencies = new ArrayList<String>();
        dependencies.add(""abc"");
        service.setDependencies(dependencies);
        Service dependent = createExampleApplication();
        dependent.setState(ServiceState.STOPPED);
        ServiceApiUtil.checkServiceDependencySatisified(service);
      }",1
"@Test
  public void testAMSimulatorWithNodeLabels() throws Exception {
    if (scheduler.equals(CapacityScheduler.class)) {
      // add label to the cluster
      RMAdminCLI rmAdminCLI = new RMAdminCLI(conf);
      String[] args = {""-addToClusterNodeLabels"", ""label1""}",1
"@Test
  public void testTrackPageHtmlTemplate() throws Exception {
    String trackTemplate = FileUtils.readFileToString(
            new File(""src/main/html/track.html.template""), StandardCharsets.UTF_8);
    String trackedQueueInfo = """";
    Set<String> trackedQueues = new HashSet<String>();
    trackedQueues.add(""sls_queue_1"");
    trackedQueues.add(""sls_queue_2"");
    trackedQueues.add(""sls_queue_3"");
    for(String queue : trackedQueues) {
      trackedQueueInfo += ""<option value='Queue "" + queue + ""'>""
              + queue + ""</option>"";
    }",1
"@Test
    public void testCreateSubscriptionWithInvalidSessionIdAndNonAnonymousAccess() throws Exception {
        ctx.channel().attr(SubscriptionConstants.SESSION_ID_ATTR).set(URLEncoder.encode(UUID.randomUUID().toString(), StandardCharsets.UTF_8.name()));
        decoder = new WebSocketRequestDecoder(authenticationService, requireUserSecurity);
    // @formatter:off
        String request = ""{ ""+
          ""\""operation\"" : \""create\"", "" +
          ""\""subscriptionId\"" : \""1234\"""" +
        "" }",1
"@Test
    public void testCreateSubscriptionWithValidSessionIdAndNonAnonymousAccess() throws Exception {
        ctx.channel().attr(SubscriptionConstants.SESSION_ID_ATTR).set(cookie);
        decoder = new WebSocketRequestDecoder(authenticationService, requireUserSecurity);
    // @formatter:off
        String request = ""{ "" +
          ""\""operation\"" : \""create\"","" +
          ""\""subscriptionId\"" : \"""" + cookie + ""\"""" +
        ""}",1
"@Test
    public void testMetrics() throws Exception {
        decoder = new WebSocketRequestDecoder(authenticationService, anonymousSecurity);
        String request = ""{ \""operation\"" : \""metrics\"", \""sessionId\"" : \""1234\"" }",1
"@Test
    public void testRemoveSubscription() throws Exception {
        decoder = new WebSocketRequestDecoder(authenticationService, anonymousSecurity);
        String request = ""{ \""operation\"" : \""remove\"", \""subscriptionId\"" : \""1234\"" }",1
