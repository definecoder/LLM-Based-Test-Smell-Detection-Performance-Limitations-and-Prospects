test_method,isResourceOptimism
"@Test
    public void testGetFromUserResources() throws Throwable {
        Path testXenonImagesPath = Files.createTempDirectory(""test-xenon-images"");

        HostInitCommonServiceConfig.startServices(host);
        waitForServiceAvailability(ConfigurationFactoryService.SELF_LINK);
        waitForServiceAvailability(UriUtils.buildUriPath(UriUtils.buildUriPath(
                ConfigurationFactoryService.SELF_LINK, FileUtil.USER_RESOURCES_PATH_VARIABLE)));

        // Set expected configuration
        ConfigurationState config = new ConfigurationState();
        config.documentSelfLink = UriUtils.buildUriPath(ConfigurationFactoryService.SELF_LINK,
                FileUtil.USER_RESOURCES_PATH_VARIABLE);
        config.key = FileUtil.USER_RESOURCES_PATH_VARIABLE;
        config.value = testXenonImagesPath.toAbsolutePath().toString();

        doPut(config);

        File imageDir = new File(UriUtils.buildUriPath(testXenonImagesPath.toString(),
                SystemImageRetrievalManager.SYSTEM_IMAGES_PATH));
        imageDir.mkdir();

        byte[] content = IOUtils.toByteArray(Thread.currentThread().getContextClassLoader()
                .getResourceAsStream(TEST_IMAGE));
        // Basically, rename it so it must be loaded from user resources for sure
        File tmpFile = new File(
                UriUtils.buildUriPath(imageDir.getAbsolutePath(), TEST_IMAGE_RES));
        tmpFile.createNewFile();
        try (OutputStream os = new FileOutputStream(tmpFile)) {
            os.write(content);
        }",1
"@Test
    public void testValidateServicesAreDeployedFirst() throws Throwable {
        String wordpressTemplate = CommonTestStateFactory
                .getFileContent(""WordPress_with_MySQL_kubernetes.yaml"");

        String compositeDescriptionLink = importTemplate(wordpressTemplate);

        CompositeDescription compositeDescription = getCompositeDescription(
                compositeDescriptionLink);

        CompositeComponent compositeComponent = new CompositeComponent();
        compositeComponent.name = compositeDescription.name + ""-mcm-102"";
        compositeComponent.compositeDescriptionLink = compositeDescription.documentSelfLink;
        compositeComponent.customProperties = new HashMap<>();
        compositeComponent.customProperties.put(CUSTOM_PROPERTY_HOST_LINK,
                kubernetesHostState.documentSelfLink);
        compositeComponent = doPost(compositeComponent, CompositeComponentFactoryService.SELF_LINK);

        addPodsAndReplicaSetsForWordpressApp(extractId(compositeComponent.documentSelfLink));

        provisioningTaskLink = createProvisioningTask();

        ApplicationRequest appRequest = createApplicationRequest(
                compositeComponent.documentSelfLink);

        doOperation(ManagementUriParts.ADAPTER_KUBERNETES_APPLICATION, appRequest);

        // wait for provisioning task stage to change to finish
        waitForPropertyValue(provisioningTaskLink, MockTaskState.class, ""taskInfo.stage"",
                TaskState.TaskStage.FINISHED);

        assertEquals(10, service.deployedElements.size());

        List<BaseKubernetesObject> kubernetesElements = new ArrayList<>();
        service.deployedElements.forEach(e -> kubernetesElements.add(e));

        // Assert that services are deployed first.
        assertEquals(KubernetesUtil.SERVICE_TYPE, kubernetesElements.get(4).kind);
        assertEquals(KubernetesUtil.SERVICE_TYPE, kubernetesElements.get(5).kind);

        // Assert that states are created and they have correct compositeComponentLink.
        CompositeComponent finalCompositeComponent = compositeComponent;

        List<String> resourceLinks = getDocumentLinksOfType(ServiceState.class);
        assertEquals(2, resourceLinks.size());
        resourceLinks.forEach(link -> doOperation(Operation.createGet(host, link)
                .setCompletion((o, ex) -> {
                    if (ex != null) {
                        host.failIteration(ex);
                    }",1
"@Test
    public void testDefaultProjectCreatedOnStartUp() throws Throwable {
        waitForServiceAvailability(ProjectService.DEFAULT_PROJECT_LINK);

        ProjectState project = getDocument(ProjectState.class,
                ProjectService.DEFAULT_PROJECT_LINK);

        assertNotNull(project);
        assertEquals(ProjectService.DEFAULT_PROJECT_ID, project.name);
        assertEquals(ProjectService.DEFAULT_PROJECT_ID, project.id);
    }",1
"@Test
    public void testImportContentWithProjectAndUsers() throws Throwable {
        AuthContentBody body = Utils.fromJson(authContent, AuthContentBody.class);
        loadAuthContent(body);

        List<String> projectLinks = getDocumentLinksOfType(ProjectState.class);
        projectLinks.remove(ProjectService.DEFAULT_PROJECT_LINK);

        assertEquals(body.projects.size(), projectLinks.size());

        List<String> projectToImportNames = body.projects.stream()
                .map(p -> p.name)
                .collect(Collectors.toList());

        for (String link : projectLinks) {
            ProjectState state = getDocument(ProjectState.class, link);
            assertTrue(projectToImportNames.contains(state.name));
        }",1
"@Test
    public void testDeletePrincipalShouldDeleteUserState() throws Throwable {
        String fritzEmail = ""fritz@admiral.com"";
        String fritzSelfLink = LocalPrincipalFactoryService.SELF_LINK + ""/"" + encode(fritzEmail);

        doDelete(UriUtils.buildUri(host, fritzSelfLink), false);

        LocalPrincipalState state = getDocumentNoWait(LocalPrincipalState.class, fritzSelfLink);
        assertNull(state);

        UserState userState = getDocumentNoWait(UserState.class, buildUserServicePath(fritzEmail));
        assertNull(userState);

        ResourceGroupState resourceGroupState = getDocumentNoWait(ResourceGroupState.class,
                UriUtils.buildUriPath(ResourceGroupService.FACTORY_LINK, encode(fritzEmail)));
        assertNull(resourceGroupState);

        UserGroupState userGroupState = getDocumentNoWait(UserGroupState.class,
                UriUtils.buildUriPath(UserGroupService.FACTORY_LINK, encode(fritzEmail)));
        assertNull(userGroupState);

        RoleState roleState = getDocumentNoWait(RoleState.class,
                UriUtils.buildUriPath(RoleService.FACTORY_LINK, encode(fritzEmail)));
        assertNull(roleState);

    }",1
"@Test
    public void testUserSpecificResourceAreCreatedWhenUserIsCreated() throws Throwable {
        // Assert user specific UserGroup, ResourceGroup and Role are created.
        String fritzEmail = ""fritz@admiral.com"";
        String fritzSelfLink = LocalPrincipalFactoryService.SELF_LINK + ""/"" + encode(fritzEmail);

        LocalPrincipalState state = getDocumentNoWait(LocalPrincipalState.class, fritzSelfLink);
        assertNotNull(state);

        UserState userState = getDocumentNoWait(UserState.class, buildUserServicePath(fritzEmail));
        assertNotNull(userState);

        ResourceGroupState resourceGroupState = getDocumentNoWait(ResourceGroupState.class,
                UriUtils.buildUriPath(ResourceGroupService.FACTORY_LINK, encode(fritzEmail)));
        assertNotNull(resourceGroupState);

        UserGroupState userGroupState = getDocumentNoWait(UserGroupState.class,
                UriUtils.buildUriPath(UserGroupService.FACTORY_LINK, encode(fritzEmail)));
        assertNotNull(userGroupState);

        RoleState roleState = getDocumentNoWait(RoleState.class,
                UriUtils.buildUriPath(RoleService.FACTORY_LINK, encode(fritzEmail)));
        assertNotNull(roleState);
        assertEquals(userGroupState.documentSelfLink, roleState.userGroupLink);
        assertEquals(resourceGroupState.documentSelfLink, roleState.resourceGroupLink);
    }",1
"@Test
    public void testAssignRoleToUserGroup() throws Throwable {
        PrincipalRoleAssignment roleAssignment = new PrincipalRoleAssignment();
        roleAssignment.add = new ArrayList<>();
        roleAssignment.add.add(AuthRole.CLOUD_ADMIN.name());

        doRoleAssignment(roleAssignment, USER_GROUP_DEVELOPERS);

        RoleState roleState = getDocument(RoleState.class,
                UriUtils.buildUriPath(RoleService.FACTORY_LINK, AuthRole.CLOUD_ADMIN
                        .buildRoleWithSuffix(encode(USER_GROUP_DEVELOPERS))));
        assertNotNull(roleState);
        assertEquals(UriUtils.buildUriPath(UserGroupService.FACTORY_LINK,
                encode(USER_GROUP_DEVELOPERS)), roleState.userGroupLink);
    }",1
"@Test
    public void testDelete() throws Throwable {
        String admins = project.administratorsUserGroupLinks.iterator().next();
        String members = project.membersUserGroupLinks.iterator().next();
        String viewers = project.viewersUserGroupLinks.iterator().next();
        deleteProject(project);

        // Verify the default UserGroups are deleted
        UserGroupState adminsGroup = getDocumentNoWait(UserGroupState.class, admins);
        assertNull(adminsGroup);

        UserGroupState membersGroups = getDocumentNoWait(UserGroupState.class, members);
        assertNull(membersGroups);

        UserGroupState viewersGroups = getDocumentNoWait(UserGroupState.class, viewers);
        assertNull(viewersGroups);
    }",1
"@Test
    public void executeJavaExtSourceAsZIPTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        int expectedInVar = 3;
        int expectedInVar2 = 4;
        int expectedResult = 7;

        closureDescState.sourceURL = testWebserverUri + ""/test_script_java.zip"";
        closureDescState.source = ""should not be used"";
        closureDescState.runtime = RUNTIME_JAVA_8;
        closureDescState.entrypoint = ""testpackage.Test.test"";

        ResourceConstraints constraints = new ResourceConstraints();
        constraints.timeoutSeconds = 10;
        constraints.ramMB = 300;
        closureDescState.resources = constraints;

        String taskDefPayload = Utils.toJson(closureDescState);
        ClosureDescription closureDescription = createClosureDescription(taskDefPayload,
                serviceClient);
        assertNotNull(closureDescription);

        // Create Closure
        Closure createdClosure = createClosure(closureDescription, serviceClient);
        assertEquals(closureDescription.documentSelfLink, createdClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CREATED, createdClosure.state);

        // Execute the created Closure
        Closure closureRequest = new Closure();
        Map inputs = new HashMap<>();
        inputs.put(""a"", new JsonPrimitive(expectedInVar));
        inputs.put(""b"", new JsonPrimitive(expectedInVar2));
        closureRequest.inputs = inputs;

        executeClosure(createdClosure, closureRequest, serviceClient);

        // Wait for the completion timeout
        String imageRequestLink = waitForBuildCompletion(IMAGE_NAME, closureDescription);

        waitForTaskState(createdClosure.documentSelfLink, TaskState.TaskStage.FINISHED,
                serviceClient);

        Closure fetchedClosure = getClosure(createdClosure.documentSelfLink, serviceClient);

        assertEquals(closureDescription.documentSelfLink, fetchedClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.FINISHED, fetchedClosure.state);

        assertEquals(expectedInVar, fetchedClosure.inputs.get(""a"").getAsInt());
        assertEquals(expectedInVar2, fetchedClosure.inputs.get(""b"").getAsInt());
        assertEquals(expectedResult, fetchedClosure.outputs.get(""result"").getAsInt(), 0);

        cleanResource(imageRequestLink, serviceClient);
        cleanResource(createdClosure.documentSelfLink, serviceClient);
        cleanResource(closureDescription.documentSelfLink, serviceClient);
    }",1
"@Test
    public void executePowershellExtSourceAsZIPTest() throws Throwable {
        // Create Closure Definition
        ClosureDescription closureDescState = new ClosureDescription();
        closureDescState.name = ""test"";

        String expectedInVar = ""a"";
        String expectedResult = ""ac"";

        closureDescState.sourceURL = testWebserverUri + ""/test_script_powershell.zip"";
        closureDescState.source = ""should not be used"";
        closureDescState.runtime = RUNTIME_POWERSHELL_6;
        closureDescState.outputNames = new ArrayList<>(Collections.singletonList(""result""));
        ResourceConstraints constraints = new ResourceConstraints();
        constraints.timeoutSeconds = 60;
        constraints.ramMB = 300;
        closureDescState.resources = constraints;

        String taskDefPayload = Utils.toJson(closureDescState);
        ClosureDescription closureDescription = createClosureDescription(taskDefPayload,
                serviceClient);
        assertNotNull(closureDescription);

        // Create Closure
        Closure createdClosure = createClosure(closureDescription, serviceClient);
        assertEquals(closureDescription.documentSelfLink, createdClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.CREATED, createdClosure.state);

        // Execute the created Closure
        Closure closureRequest = new Closure();
        Map inputs = new HashMap<>();
        inputs.put(""a"", new JsonPrimitive(expectedInVar));
        closureRequest.inputs = inputs;

        executeClosure(createdClosure, closureRequest, serviceClient);

        // Wait for the completion timeout
        String imageRequestLink = waitForBuildCompletion(IMAGE_NAME, closureDescription);

        waitForTaskState(createdClosure.documentSelfLink, TaskState.TaskStage.FINISHED,
                serviceClient);

        Closure fetchedClosure = getClosure(createdClosure.documentSelfLink, serviceClient);

        assertEquals(closureDescription.documentSelfLink, fetchedClosure.descriptionLink);
        assertEquals(TaskState.TaskStage.FINISHED, fetchedClosure.state);

        assertEquals(expectedInVar, fetchedClosure.inputs.get(""a"").getAsString());
        assertEquals(expectedResult, fetchedClosure.outputs.get(""result"").getAsString());

        //        cleanResource(imageRequestLink, serviceClient);
        //        cleanResource(createdClosure.documentSelfLink, serviceClient);
        //        cleanResource(closureDescription.documentSelfLink, serviceClient);
    }",1
"@Test
    public void testUntrustedCertificates() throws Exception {

        // Validate a custom certificate.
        // Is should fail as it is signed by untrusted CA
        try {
            trustManager.checkServerTrusted(
                    getCertificates(""/certs/untrusted-server.crt""), ""RSA"");
            fail(""Should not trust untrusted certificate"");
        }",1
"@Test
    public void testShouldUpdateContainerLinksWhenUpdatesToContainers() throws Throwable {
        compositeComponent = createCompositeComponent();
        ContainerState containerState1 = createContainer(compositeComponent.documentSelfLink);

        // add a new container:
        waitFor(() -> {
            compositeComponent = getDocument(CompositeComponent.class,
                    compositeComponent.documentSelfLink);
            if (compositeComponent.componentLinks == null
                    || compositeComponent.componentLinks.isEmpty()) {
                return false;
            }",1
"@Test
    public void testCloneCompositeDescriptionWithTwoContainers() throws Throwable {
        initObjectsWithTwoContainers();

        CompositeDescription clonedCompositeDesc = cloneCompositeDesc(
                createdCompositeWithTwoContainers, false);

        checkCompositeForEquality(createdCompositeWithTwoContainers, clonedCompositeDesc, false);

        List<String> containerDescriptions = clonedCompositeDesc.descriptionLinks;

        ContainerDescription clonedFirstContainer = getDocument(ContainerDescription.class,
                containerDescriptions.get(0));
        checkContainersForЕquality(createdFirstContainer, clonedFirstContainer, false);

        ContainerDescription clonedSecondContainer = getDocument(ContainerDescription.class,
                containerDescriptions.get(1));
        checkContainersForЕquality(createdSecondContainer, clonedSecondContainer, false);
    }",1
"@Test
    public void testPutExpanded() throws Throwable {
        ContainerDescription container = new ContainerDescription();
        container.name = ""container"";
        container.image = ""registry.hub.docker.com/kitematic/hello-world-nginx"";
        container = doPost(container, ContainerDescriptionService.FACTORY_LINK);

        ComponentDescription containerComponent = new ComponentDescription();
        containerComponent.name = ""container"";
        container.name = ""updated"";
        containerComponent.updateServiceDocument(container);
        containerComponent.type = ResourceType.CONTAINER_TYPE.getContentType();

        CompositeDescription cd = new CompositeDescription();
        cd.name = ""testComposite"";
        cd = doPost(cd, CompositeDescriptionFactoryService.SELF_LINK);

        // Make PUT but as expanded state, so that components are also updated
        CompositeDescriptionExpanded cdUpdate = new CompositeDescriptionExpanded();
        cdUpdate.documentSelfLink = cd.documentSelfLink;
        cdUpdate.name = cd.name;
        cdUpdate.componentDescriptions = new ArrayList<>();
        cdUpdate.componentDescriptions.add(containerComponent);
        cdUpdate = doPut(cdUpdate);

        // Explicitly search for document to validate that the list returns the right document kind
        CompositeDescription foundCd = searchForDocument(CompositeDescription.class,
                cd.documentSelfLink);
        assertEquals(Utils.buildKind(CompositeDescription.class), foundCd.documentKind);

        container = getDocument(ContainerDescription.class, container.documentSelfLink);
        assertEquals(""updated"", container.name);
    }",1
"@Test
    public void testTenantsLinksInCompositeDescriptionEmbedded() throws Throwable {

        testTenantsLinksInCompositeDescription(true);
    }",1
"@Test
    public void testTenantsLinksInCompositeDescriptionNotEmbedded() throws Throwable {

        testTenantsLinksInCompositeDescription(false);
    }",1
"@Test
    public void testContainersCountOnHostWithContainersNoSystem() throws Throwable {
        String hostId = UUID.randomUUID().toString();
        String hostLink = UriUtils.buildUriPath(ComputeService.FACTORY_LINK, hostId);
        // add preexisting container
        addContainerToMockAdapter(hostLink, preexistingContainerId, preexistingContainerNames);

        ComputeDescription hostDescription = createComputeDescription();
        hostDescription = doPost(hostDescription, ComputeDescriptionService.FACTORY_LINK);

        ComputeState cs = createComputeState(hostId, hostDescription);

        cs = doPost(cs, ComputeService.FACTORY_LINK);

        ContainerState containerState = new ContainerState();
        containerState.id = UUID.randomUUID().toString();
        containerState.names = containerNames;
        containerState.parentLink = UriUtils.buildUriPath(
                ComputeService.FACTORY_LINK,
                hostId);
        containerState.powerState = PowerState.STOPPED;
        containerState = doPost(containerState, ContainerFactoryService.SELF_LINK);
        addContainerToMockAdapter(hostLink, containerState.id, containerState.names);

        doOperation(new ContainerHostDataCollectionState(), UriUtils.buildUri(host,
                ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK),
                false,
                Service.Action.PATCH);

        String csLink = cs.documentSelfLink;
        waitFor(() -> {
            ComputeState computeState = getDocument(ComputeState.class, csLink);
            String containers = computeState.customProperties == null ? null
                    : computeState.customProperties
                            .get(ContainerHostService.NUMBER_OF_CONTAINERS_PER_HOST_PROP_NAME);
            String systemContainers = computeState.customProperties == null ? null
                    : computeState.customProperties
                            .get(ContainerHostService.NUMBER_OF_SYSTEM_CONTAINERS_PROP_NAME);
            //the test container created above and the missing container coming from the host.
            host.log(""testContainersCountOnHostWithContainer - countainer count: %s"", containers);
            return ""2"".equals(containers) && ""0"".equals(systemContainers);
        }",1
"@Test
    public void testContainersCountSystemAndNotSystem() throws Throwable {
        String hostId = UUID.randomUUID().toString();
        String hostLink = UriUtils.buildUriPath(ComputeService.FACTORY_LINK, hostId);
        // add preexisting container
        addContainerToMockAdapter(hostLink, preexistingContainerId, preexistingContainerNames);

        ComputeDescription hostDescription = createComputeDescription();
        hostDescription = doPost(hostDescription, ComputeDescriptionService.FACTORY_LINK);

        ComputeState cs = createComputeState(hostId, hostDescription);

        cs = doPost(cs, ComputeService.FACTORY_LINK);

        ContainerState containerState = new ContainerState();
        containerState.id = UUID.randomUUID().toString();
        containerState.names = containerNames;
        containerState.parentLink = UriUtils.buildUriPath(
                ComputeService.FACTORY_LINK, hostId);
        containerState.powerState = PowerState.STOPPED;
        containerState.system = Boolean.TRUE;
        containerState = doPost(containerState, ContainerFactoryService.SELF_LINK);
        addContainerToMockAdapter(hostLink, containerState.id, containerState.names);

        doOperation(new ContainerHostDataCollectionState(), UriUtils.buildUri(host,
                ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK),
                false,
                Service.Action.PATCH);

        String csLink = cs.documentSelfLink;
        waitFor(() -> {
            ComputeState computeState = getDocument(ComputeState.class, csLink);
            String containers = computeState.customProperties == null ? null
                    : computeState.customProperties
                            .get(ContainerHostService.NUMBER_OF_CONTAINERS_PER_HOST_PROP_NAME);
            String systemContainers = computeState.customProperties == null ? null
                    : computeState.customProperties
                            .get(ContainerHostService.NUMBER_OF_SYSTEM_CONTAINERS_PROP_NAME);
            // the test container created above and the missing container coming from the host.
            host.log(""testContainersCountOnHostWithContainer - countainer count: %s"", containers);
            return ""2"".equals(containers) && ""1"".equals(systemContainers);
        }",1
"@Test
    public void testDataCollectionDuringProvisioning() throws Throwable {
        // stop the mock adapter service and start the mock inspector adapter service:
        stopService(mockAdapterService);
        mockAdapterService = null;
        final MockInspectAdapterService mockInspectAdapterService = new MockInspectAdapterService();
        String containerBeingProvisioned = ""containerBeingProvisioned"";
        try {
            String hostId = UUID.randomUUID().toString();
            String hostLink = UriUtils.buildUriPath(ComputeService.FACTORY_LINK, hostId);
            // add preexisting container
            addContainerToMockAdapter(hostLink, preexistingContainerId, preexistingContainerNames);

            URI adapterServiceUri = UriUtils.buildUri(host, ManagementUriParts.ADAPTER_DOCKER);
            host.startService(Operation.createPost(adapterServiceUri), mockInspectAdapterService);
            waitForServiceAvailability(ManagementUriParts.ADAPTER_DOCKER);

            ComputeDescription hostDescription = createComputeDescription();
            hostDescription = doPost(hostDescription, ComputeDescriptionService.FACTORY_LINK);

            ComputeState cs = createComputeState(hostId, hostDescription);

            cs = doPost(cs, ComputeService.FACTORY_LINK);

            // container being provisioned should not be discovered by the data collection
            // Do not set id - the container is still being provisioned
            ContainerState containerState = new ContainerState();
            containerState.names = containerNames;
            containerState.parentLink = UriUtils.buildUriPath(
                    ComputeService.FACTORY_LINK,
                    hostId);
            containerState.powerState = PowerState.PROVISIONING;
            containerState = doPost(containerState, ContainerFactoryService.SELF_LINK);
            addContainerToMockAdapter(hostLink, containerBeingProvisioned, containerState.names);

            doOperation(new ContainerHostDataCollectionState(), UriUtils.buildUri(host,
                    ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK),
                    false,
                    Service.Action.PATCH);

            host.log("">>>> testDiscoverCreateAndInspectContainer: Container Host %s created.""
                            + "" Waiting for data collection..."", cs.documentSelfLink);
            String csLink = cs.documentSelfLink;
            waitFor(() -> {
                ComputeState computeState = getDocument(ComputeState.class, csLink);
                String containers = computeState.customProperties == null ? null
                        : computeState.customProperties
                                .get(ContainerHostService.NUMBER_OF_CONTAINERS_PER_HOST_PROP_NAME);

                if (containers != null) {
                    host.log("">>>> # of containers per host %s is %s"",
                            computeState.documentSelfLink, containers);
                }",1
"@Test
    public void testDataCollectionWhenAHostIsMarkedForDeletion() throws Throwable {
        String hostId = UUID.randomUUID().toString();

        ComputeDescription hostDescription = createComputeDescription();
        hostDescription = doPost(hostDescription, ComputeDescriptionService.FACTORY_LINK);

        ComputeState cs = createComputeState(hostId, hostDescription);
        cs.lifecycleState = LifecycleState.SUSPEND;
        cs = doPost(cs, ComputeService.FACTORY_LINK);

        // create a dummy ContainerState on the ComputeState (that will be marked as missing by the
        // collection)
        missingContainerState = new ContainerState();
        missingContainerState.id = UUID.randomUUID().toString();
        missingContainerState.names = containerNames;
        missingContainerState.parentLink = UriUtils.buildUriPath(
                ComputeService.FACTORY_LINK,
                hostId);
        missingContainerState.powerState = PowerState.STOPPED;
        missingContainerState.system = false;
        missingContainerState = doPost(missingContainerState, ContainerFactoryService.SELF_LINK);

        doOperation(new ContainerHostDataCollectionState(), UriUtils.buildUri(host,
                ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK),
                false,
                Service.Action.PATCH);

        String csLink = cs.documentSelfLink;
        final long timoutInMillis = 5000; // 5sec
        long startTime = System.currentTimeMillis();

        waitFor(() -> {
            ComputeState computeState = getDocument(ComputeState.class, csLink);
            String containers = computeState.customProperties == null ? null
                    : computeState.customProperties
                            .get(ContainerHostService.NUMBER_OF_CONTAINERS_PER_HOST_PROP_NAME);

            if (containers != null && Integer.parseInt(containers) >= 1) {
                fail(""Should not have any containers."");
            }",1
"@Test
    public void testDataCollectionDuringProvisioning() throws Throwable {
        // stop the mock adapter service and start the mock inspector adapter service:
        stopService(mockAdapterService);
        mockAdapterService = null;
        final MockInspectAdapterService mockInspectAdapterService = new MockInspectAdapterService();
        String containerBeingProvisioned = ""containerBeingProvisioned"";
        try {
            String hostId = UUID.randomUUID().toString();
            String hostLink = UriUtils.buildUriPath(ComputeService.FACTORY_LINK, hostId);
            // add preexisting container
            addContainerToMockAdapter(hostLink, preexistingContainerId, preexistingContainerNames);

            URI adapterServiceUri = UriUtils.buildUri(host, ManagementUriParts.ADAPTER_DOCKER);
            host.startService(Operation.createPost(adapterServiceUri), mockInspectAdapterService);
            waitForServiceAvailability(ManagementUriParts.ADAPTER_DOCKER);

            ComputeDescription hostDescription = createComputeDescription();
            hostDescription = doPost(hostDescription, ComputeDescriptionService.FACTORY_LINK);

            ComputeState cs = createComputeState(hostId, hostDescription);

            cs = doPost(cs, ComputeService.FACTORY_LINK);

            // container being provisioned should not be discovered by the data collection
            // Do not set id - the container is still being provisioned
            ContainerState containerState = new ContainerState();
            containerState.names = containerNames;
            containerState.parentLink = UriUtils.buildUriPath(
                    ComputeService.FACTORY_LINK,
                    hostId);
            containerState.powerState = PowerState.PROVISIONING;
            containerState = doPost(containerState, ContainerFactoryService.SELF_LINK);
            addContainerToMockAdapter(hostLink, containerBeingProvisioned, containerState.names);

            doOperation(new ContainerHostDataCollectionState(), UriUtils.buildUri(host,
                    ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK),
                    false,
                    Service.Action.PATCH);

            host.log("">>>> testDiscoverCreateAndInspectContainer: Container Host %s created.""
                            + "" Waiting for data collection..."", cs.documentSelfLink);
            String csLink = cs.documentSelfLink;
            waitFor(() -> {
                ComputeState computeState = getDocument(ComputeState.class, csLink);
                String containers = computeState.customProperties == null ? null
                        : computeState.customProperties
                                .get(ContainerHostService.NUMBER_OF_CONTAINERS_PER_HOST_PROP_NAME);

                if (containers != null) {
                    host.log("">>>> # of containers per host %s is %s"",
                            computeState.documentSelfLink, containers);
                }",1
"@Test
    public void testGetShellWhenEmbeddedShouldFail() throws Throwable {

        ConfigurationState config = new ConfigurationState();
        config.key = ConfigurationUtil.EMBEDDED_MODE_PROPERTY;
        config.value = ""true"";
        config.documentSelfLink = config.key;
        doPost(config, ConfigurationFactoryService.SELF_LINK);

        try {
            getDocument(String.class, ContainerShellService.SELF_LINK);
            fail(""It should have been forbidden!"");
        }",1
"@Test
    public void testGetShellInvalidIdShouldFail() throws Throwable {
        try {
            getDocument(String.class, ContainerShellService.SELF_LINK + ""?id=invalid"");
            fail(""It should have failed!"");
        }",1
"@Test
    public void testGetShellNoIdShouldFail() throws Throwable {
        try {
            getDocument(String.class, ContainerShellService.SELF_LINK);
            fail(""It should have failed!"");
        }",1
"@Test
    public void testContainerStatsNoParam() {
        TestRequestSender sender = host.getTestRequestSender();
        FailureResponse failureResponse = sender.sendAndWaitFailure(Operation
                .createGet(host, ContainerStatsService.SELF_LINK));
        assertEquals(Operation.STATUS_CODE_FAILURE_THRESHOLD, failureResponse.op.getStatusCode());
        assertTrue(failureResponse.failure instanceof IllegalArgumentException);
    }",1
"@Test
    public void testDelete() throws Throwable {
        ComputeDescription computeDescription =
                doPost(new ComputeDescription(), ComputeDescriptionService.FACTORY_LINK);
        DeploymentPolicy deploymentPolicy =
                doPost(createDeploymentPolicy(), DeploymentPolicyService.FACTORY_LINK);

        ResourcePoolState resourcePool = new ResourcePoolState();
        resourcePool.name = ""test-resource-pool"";
        resourcePool = doPost(resourcePool, ResourcePoolService.FACTORY_LINK);

        ComputeState compute = new ComputeState();
        compute.customProperties = new HashMap<>();
        compute.customProperties.put(ContainerHostService.CUSTOM_PROPERTY_DEPLOYMENT_POLICY,
                deploymentPolicy.documentSelfLink);
        compute.descriptionLink = computeDescription.documentSelfLink;
        compute = doPost(compute, ComputeService.FACTORY_LINK);

        GroupResourcePlacementState resourcePlacement = new GroupResourcePlacementState();
        resourcePlacement.deploymentPolicyLink = deploymentPolicy.documentSelfLink;
        resourcePlacement.maxNumberInstances = 1;
        resourcePlacement.name = ""test-group-resource-placement"";
        resourcePlacement.resourcePoolLink = resourcePool.documentSelfLink;
        resourcePlacement = doPost(resourcePlacement, GroupResourcePlacementService.FACTORY_LINK);

        try {
            doDelete(UriUtils.buildUri(host, deploymentPolicy.documentSelfLink), true);
            fail(""expect validation error during deletion"");
        }",1
"@Test
    public void testDeleteWhenActiveReservation() throws Throwable {
        GroupResourcePlacementState placementState = createAndStoreGroupResourcePlacement();
        placementState = makeResourcePlacementReservationRequest(placementState, 5);

        boolean expectedFailure = true;
        try {
            DeploymentProfileConfig.getInstance().setTest(false);
            doDelete(UriUtils.buildUri(host, placementState.documentSelfLink), expectedFailure);
            fail(""expect validation error during deletion"");
        }",1
"@Test
    public void testGetGroupResourcePlacementState() throws Throwable {
        GroupResourcePlacementState placementState = new GroupResourcePlacementState();
        placementState.name = ""reservation-test"";
        placementState.tenantLinks = Collections.singletonList(""testGroup"");
        placementState.maxNumberInstances = 10;
        placementState.resourcePoolLink = resourcePool.documentSelfLink;

        GroupResourcePlacementState outPlacementState = doPost(placementState,
                GroupResourcePlacementService.FACTORY_LINK);

        GroupResourcePlacementState[] result = new GroupResourcePlacementState[] { null }",1
"@Test
    public void testMemoryPlacementPatchRequest() throws Throwable {
        GroupResourcePlacementState placementState = createAndStoreGroupResourcePlacement();
        String descLink = containerDescription.documentSelfLink;
        int count = 8;

        boolean expectFailure = false;

        placementState = makeResourcePlacementReservationRequest(count, descLink, placementState,
                expectFailure);

        // Set the memory limit to something smaller than what's already reserved
        placementState.memoryLimit = 700;
        expectFailure = true;

        host.testStart(1);
        host.send(Operation
                .createPut(UriUtils.buildUri(host, placementState.documentSelfLink))
                .setBody(placementState)
                .setCompletion(expectFailure ? host.getExpectedFailureCompletion()
                        : host.getCompletion()));
        host.testWait(""Asd"", (int) TimeUnit.MINUTES.toSeconds(1));

        releasePlacement(placementState, descLink, count);
    }",1
"@Test
    public void testUpdateWhenNoActiveReservations() throws Throwable {
        GroupResourcePlacementState placementState = createAndStoreGroupResourcePlacement();
        String newName = ""newName"";
        int newMaxInstance = 7;
        String newResourcePoolLink = resourcePool.documentSelfLink;
        int newPriority = 23;
        long newMemoryLimit = MIN_MEMORY;
        long newStorageLimit = 5789L;
        int newCpuShares = 45;
        List<String> newTenantLinks = Arrays.asList(BUSINESS_GROUP);

        placementState.name = newName;
        placementState.maxNumberInstances = newMaxInstance;
        placementState.priority = newPriority;
        placementState.resourcePoolLink = newResourcePoolLink;
        placementState.memoryLimit = newMemoryLimit;
        placementState.storageLimit = newStorageLimit;
        placementState.cpuShares = newCpuShares;
        placementState.tenantLinks = newTenantLinks;

        doOperation(placementState, UriUtils.buildUri(host, placementState.documentSelfLink),
                false, Action.PUT);

        placementState = getDocument(GroupResourcePlacementState.class,
                placementState.documentSelfLink);

        assertEquals(newName, placementState.name);
        assertEquals(newMaxInstance, placementState.maxNumberInstances);
        assertEquals(newPriority, placementState.priority);
        assertEquals(newResourcePoolLink, placementState.resourcePoolLink);
        assertEquals(newMemoryLimit, placementState.memoryLimit);
        assertEquals(newStorageLimit, placementState.storageLimit);
        assertEquals(newCpuShares, placementState.cpuShares);
        assertEquals(newTenantLinks, placementState.tenantLinks);

        doDelete(UriUtils.buildUri(host, placementState.documentSelfLink), false);
    }",1
"@Test
    public void testHostPortProfileServices() throws Throwable {
        verifyService(
                FactoryService.create(HostPortProfileService.class),
                HostPortProfileService.HostPortProfileState.class,
                (prefix, index) -> {
                    return createHostPortProfile();
                }",1
"@Test
    public void testDiscoverExistingVolumeOnHost() throws Throwable {
        // add preexisting volume to the adapter service
        addVolumeToMockAdapter(COMPUTE_HOST_LINK, TEST_PREEXISTING_VOLUME_NAME, LOCAL_DRIVER, LOCAL_SCOPE);

        // run data collection on preexisting volume
        startAndWaitHostVolumeListDataCollection();

        List<ContainerVolumeState> volumeStates = getVolumeStates();
        assertEquals(1, volumeStates.size());
        ContainerVolumeState preexistingVolumeState = volumeStates.get(0);
        assertNotNull(""Preexisting volume not created or can't be retrieved."", preexistingVolumeState);
        assertEquals(TEST_PREEXISTING_VOLUME_NAME, preexistingVolumeState.name);
        assertTrue(Boolean.TRUE.equals(preexistingVolumeState.external));
        assertTrue(""Preexisting volume belongs to the host."",
                COMPUTE_HOST_LINK.equals(preexistingVolumeState.originatingHostLink));
    }",1
"@Test
    public void testContainerServices() throws Throwable {
        verifyService(
                FactoryService.create(ContainerNetworkService.class),
                ContainerNetworkState.class,
                (prefix, index) -> {
                    ContainerNetworkState networkState = new ContainerNetworkState();
                    networkState.id = prefix + ""id"" + index;
                    networkState.name = prefix + ""name"" + index;

                    Ipam ipam = new Ipam();
                    ipam.driver = IPAM_DRIVER;

                    IpamConfig ipamConfig = new IpamConfig();
                    ipamConfig.subnet = String.format(SUBNET_TEMPLATE, index % 256);
                    ipamConfig.ipRange = String.format(IP_RANGE_TEMPLATE, index % 256, index % 256);
                    ipamConfig.gateway = String.format(GATEWAY_TEMPLATE, index % 256);
                    ipamConfig.auxAddresses = new HashMap<>();
                    ipamConfig.auxAddresses.put(prefix + IPAM_ADDITIONAL_HOST_KEY,
                            String.format(IPAM_ADDITIONAL_HOST_IP_ADDRESS_TEMPLATE, index % 256));

                    ipam.config = new IpamConfig[] { ipamConfig }",1
"@Test
    public void testPatchDriverOptions() throws Throwable {
        ContainerNetworkState network = createNetwork(""tenant1"");
        URI networkUri = UriUtils.buildUri(host, network.documentSelfLink);

        // Test add option to empty map
        ContainerNetworkState patch = new ContainerNetworkState();
        patch.options = new HashMap<>();
        patch.options.put(DRIVER_OPTIONS_KEY_1, DRIVER_OPTIONS_VALUE_1);

        doOperation(patch, networkUri, false, Action.PATCH);
        ContainerNetworkState updatedNetwork = getDocument(ContainerNetworkState.class,
                network.documentSelfLink);
        assertEquals(1, updatedNetwork.options.size());
        assertEquals(DRIVER_OPTIONS_VALUE_1,
                updatedNetwork.options.get(DRIVER_OPTIONS_KEY_1));

        // Test append option to existing list
        patch = new ContainerNetworkState();
        patch.options = new HashMap<>();
        patch.options.put(DRIVER_OPTIONS_KEY_2, DRIVER_OPTIONS_VALUE_2);

        doOperation(patch, networkUri, false, Action.PATCH);
        updatedNetwork = getDocument(ContainerNetworkState.class, network.documentSelfLink);
        assertEquals(2, updatedNetwork.options.size());
        assertEquals(DRIVER_OPTIONS_VALUE_1,
                updatedNetwork.options.get(DRIVER_OPTIONS_KEY_1));
        assertEquals(DRIVER_OPTIONS_VALUE_2,
                updatedNetwork.options.get(DRIVER_OPTIONS_KEY_2));

        // Test overwrite existing options
        patch = new ContainerNetworkState();
        patch.options = new HashMap<>();
        patch.options.put(DRIVER_OPTIONS_KEY_1, DRIVER_OPTIONS_VALUE_2);
        patch.options.put(DRIVER_OPTIONS_KEY_2, DRIVER_OPTIONS_VALUE_1);

        doOperation(patch, networkUri, false, Action.PATCH);
        updatedNetwork = getDocument(ContainerNetworkState.class, network.documentSelfLink);
        assertEquals(2, updatedNetwork.options.size());
        assertEquals(DRIVER_OPTIONS_VALUE_1,
                updatedNetwork.options.get(DRIVER_OPTIONS_KEY_2));
        assertEquals(DRIVER_OPTIONS_VALUE_2,
                updatedNetwork.options.get(DRIVER_OPTIONS_KEY_1));
    }",1
"@Test
    public void testPatchExpiration() throws Throwable {
        ContainerNetworkState network = createNetwork(null);
        URI networkUri = UriUtils.buildUri(host, network.documentSelfLink);

        ContainerNetworkState patch = new ContainerNetworkState();
        long nowMicrosUtc = Utils.fromNowMicrosUtc(TimeUnit.SECONDS.toMicros(30));
        patch.documentExpirationTimeMicros = nowMicrosUtc;

        doOperation(patch, networkUri, false, Action.PATCH);
        ContainerNetworkState updatedNetwork = getDocument(ContainerNetworkState.class,
                network.documentSelfLink);
        assertEquals(nowMicrosUtc, updatedNetwork.documentExpirationTimeMicros);

        patch = new ContainerNetworkState();
        patch.documentExpirationTimeMicros = -1;

        doOperation(patch, networkUri, false, Action.PATCH);
        updatedNetwork = getDocument(ContainerNetworkState.class, network.documentSelfLink);
        assertEquals(0, updatedNetwork.documentExpirationTimeMicros);
    }",1
"@Test
    public void testQueryResultLimit() throws Throwable {
        final String queryTaskDocumentSelfLink = UriUtils.buildUriPath(
                ServiceUriPaths.CORE_QUERY_TASKS, ""/testQueryTaskResultLimit"");
        QuerySpecification qs = new QuerySpecification();
        qs.query = Query.Builder.create().addKindFieldClause(ContainerDescription.class).build();
        QueryTask qt = QueryTask.create(qs);
        qt.documentSelfLink = queryTaskDocumentSelfLink + 1;

        final AtomicReference<QueryTask> q = new AtomicReference<>();
        host.testStart(1);
        new ServiceDocumentQuery<>(host, ContainerDescription.class)
                .query(qt, handler(false, q, qt.documentSelfLink));
        host.testWait();
        qt = q.getAndSet(null);
        assertNotNull(qt);
        assertEquals(ServiceDocumentQuery.DEFAULT_QUERY_RESULT_LIMIT,
                qt.querySpec.resultLimit);

        Integer resourceLimit = 1000;
        qs = new QuerySpecification();
        qs.query = Query.Builder.create().addKindFieldClause(ContainerDescription.class).build();
        qt = QueryTask.create(qs);
        qt.querySpec.resultLimit = resourceLimit;
        qt.documentSelfLink = queryTaskDocumentSelfLink + 2;
        host.testStart(1);
        new ServiceDocumentQuery<>(host, ContainerDescription.class)
                .query(qt, handler(false, q, qt.documentSelfLink));
        host.testWait();
        qt = q.getAndSet(null);
        assertNotNull(qt);
        assertEquals(resourceLimit, qt.querySpec.resultLimit);

        qs = new QuerySpecification();
        qs.query = Query.Builder.create().addKindFieldClause(ContainerDescription.class).build();
        qt = QueryTask.create(qs);
        QueryUtil.addCountOption(qt);
        qt.documentSelfLink = queryTaskDocumentSelfLink + 3;
        host.testStart(1);
        new ServiceDocumentQuery<>(host, ContainerDescription.class)
                .query(qt, handler(true, q, qt.documentSelfLink));
        host.testWait();
        qt = q.getAndSet(null);
        assertNotNull(qt);
        assertNull(qt.querySpec.resultLimit);
    }",1
"@Test
    public void testQueryTaskDeleted() throws Throwable {
        final String queryTaskDocumentSelfLink = UriUtils.buildUriPath(
                ServiceUriPaths.CORE_QUERY_TASKS, ""/testQueryTaskResultLimit"");
        final String queryTaskLink = queryTaskDocumentSelfLink + 1;
        QuerySpecification qs = new QuerySpecification();
        qs.query = Query.Builder.create().addKindFieldClause(ContainerDescription.class).build();
        QueryTask qt = QueryTask.create(qs);
        qt.documentSelfLink = queryTaskLink;
        int fiveSec = 5000000;
        qt.documentExpirationTimeMicros = ServiceUtils.getExpirationTimeFromNowInMicros(fiveSec);

        final AtomicReference<QueryTask> q = new AtomicReference<>();
        host.testStart(1);
        new ServiceDocumentQuery<>(host, ContainerDescription.class)
                .query(qt, handler(false, q, qt.documentSelfLink));
        host.testWait();
        qt = q.getAndSet(null);
        //validate query task exists
        assertNotNull(qt);
        // validate query task is deleted
        waitFor(() -> {
            QueryTask queryTask = getDocumentNoWait(QueryTask.class, queryTaskLink);
            return queryTask == null;
        }",1
"@Test
    public void verifyDefaultContainerDescriptionCreatedOnStartup() throws Throwable {

        ContainerDescription agentContainerDesc = getDocument(
                ContainerDescription.class,
                SystemContainerDescriptions.AGENT_CONTAINER_DESCRIPTION_LINK);
        assertNotNull(agentContainerDesc);
        assertEquals(SystemContainerDescriptions.AGENT_CONTAINER_NAME,
                agentContainerDesc.name);
        String expectedImageName = String.format(""%s:%s"",
                SystemContainerDescriptions.AGENT_IMAGE_NAME,
                SystemContainerDescriptions.getAgentImageVersion());
        assertEquals(expectedImageName, agentContainerDesc.image);
    }",1
"@Test
    public void testNoDuplicateResultWhenBothMatch() throws Throwable {
        verifyTemplateSearchResult(TEST_COMMON);
    }",1
"@Test
    public void testUpdateContainerPorts() throws Throwable {
        ComputeService.ComputeState computeState = createComputeHost();
        ContainerState containerState = createContainerState(computeState.documentSelfLink, true);
        HostPortProfileService.HostPortProfileState profile = createHostPortProfile(computeState,
                containerState, new Long[] { new Long(5000), new Long(3045) }",1
"@Test
    public void testReleaseRetiredContainerPorts() throws Throwable {
        ComputeService.ComputeState computeState = createComputeHost();
        ContainerState containerState = createContainerState(computeState.documentSelfLink, false);
        doPut(containerState);
        HostPortProfileService.HostPortProfileState profile = createHostPortProfile(computeState,
                containerState, new Long[] { new Long(5000), new Long(3045) }",1
"@Test
    public void testToReadableErrorMessage() throws Throwable {
        ContainerHostService service = new ContainerHostService();
        Method m = service.getClass().getDeclaredMethod(""toReadableErrorMessage"", Throwable.class,
                Operation.class);
        m.setAccessible(true);

        Exception e = new Exception();
        String result = (String) m.invoke(service, e, null);
        assertNotNull(result);
        assertTrue(result.contains(""Unexpected error:""));

        e = new io.netty.handler.codec.DecoderException(""Received fatal alert: bad_certificate"");
        result = (String) m.invoke(service, e, null);
        assertNotNull(result);
        assertTrue(result.contains(""Check login credentials""));

        e = new IllegalStateException(""Socket channel closed:"");
        result = (String) m.invoke(service, e, null);
        assertNotNull(result);
        assertTrue(result.contains(""Check login credentials""));

        e = new Exception(new ConnectTimeoutException());
        result = (String) m.invoke(service, e, null);
        assertNotNull(result);
        assertTrue(result.contains(""Connection timeout""));

        e = new Exception(new ProtocolException());
        result = (String) m.invoke(service, e, null);
        assertNotNull(result);
        assertTrue(result.contains(""Protocol exception""));

        e = new IllegalArgumentException();
        result = (String) m.invoke(service, e, null);
        assertNotNull(result);
        assertTrue(result.contains(""Illegal argument exception:""));
    }",1
"@Test
    public void testConvertDockerComposeToCompositeTemplate() throws IOException {
        CompositeTemplate expectedTemplate = deserializeCompositeTemplate(
                getContent(""composite.wordpress.yaml""));

        String expectedTemplateYaml = serializeCompositeTemplate(expectedTemplate);

        // Docker Compose with environment values as array

        DockerCompose compose1 = deserializeDockerCompose(
                getContent(""docker.wordpress.1.yaml""));

        CompositeTemplate template1 = fromDockerComposeToCompositeTemplate(compose1);
        template1.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template1.components);

        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 2,
                template1.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 0,
                template1.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template1.components);

        String template1Yaml = serializeCompositeTemplate(template1);

        assertEqualsYamls(expectedTemplateYaml, template1Yaml, true);

        // Docker Compose with environment values as dictionary

        DockerCompose compose2 = deserializeDockerCompose(
                getContent(""docker.wordpress.2.yaml""));

        CompositeTemplate template2 = fromDockerComposeToCompositeTemplate(compose2);
        template2.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template2.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 2,
                template1.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 0,
                template1.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template1.components);

        String template2Yaml = serializeCompositeTemplate(template2);

        assertEqualsYamls(expectedTemplateYaml, template2Yaml, true);
    }",1
"@Test
    public void testConvertDockerComposeToCompositeTemplateWithNetwork() throws IOException {

        // Docker Compose with simple network entities

        CompositeTemplate expectedTemplate = deserializeCompositeTemplate(
                getContent(""composite.simple.network.yaml""));

        String expectedTemplateYaml = serializeCompositeTemplate(expectedTemplate);

        DockerCompose compose1 = deserializeDockerCompose(
                getContent(""docker.simple.network.yaml""));

        CompositeTemplate template1 = fromDockerComposeToCompositeTemplate(compose1);
        template1.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template1.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 3,
                template1.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 2,
                template1.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template1.components);

        String template1Yaml = serializeCompositeTemplate(template1);

        assertEqualsYamls(toUnixLineEnding(expectedTemplateYaml),
                toUnixLineEnding(getContent(""composite.simple.network.expected2.yaml"")), true);
        assertEqualsYamls(toUnixLineEnding(template1Yaml),
                toUnixLineEnding(getContent(""composite.simple.network.yaml"")), true);

        // Docker Compose with complex network entities

        expectedTemplate = deserializeCompositeTemplate(
                getContent(""composite.complex.network.yaml""));

        expectedTemplateYaml = serializeCompositeTemplate(expectedTemplate);

        DockerCompose compose2 = deserializeDockerCompose(
                getContent(""docker.complex.network.yaml""));

        CompositeTemplate template2 = fromDockerComposeToCompositeTemplate(compose2);
        template2.name = expectedTemplate.name; // because of the timestamp

        assertComponentTypes(template2.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 3,
                template2.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 3,
                template2.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template2.components);

        String template2Yaml = serializeCompositeTemplate(template2);

        assertEqualsYamls(toUnixLineEnding(getContent(""composite.simple.network.expected.yaml"")),
                toUnixLineEnding(template2Yaml), true);
    }",1
"@Test
    public void testDeserializeCompositeTemplateWithBindings() throws IOException {
        String expectedContent = getContent(""composite.bindings.yaml"");

        CompositeTemplate compositeTemplate = deserializeCompositeTemplate(expectedContent);

        ContainerDescription wpData = (ContainerDescription) compositeTemplate.components
                .get(""wordpress"").data;
        assertEquals(null, wpData._cluster);
        assertFalse(wpData.customProperties.containsKey(""mysql_user""));

        assertEquals(1, compositeTemplate.bindings.size());

        List<Binding> bindings = compositeTemplate.bindings.iterator().next().bindings;
        assertEquals(3, bindings.size());

        Map<Boolean, List<Binding>> partitionedBindings = bindings.stream()
                .collect(Collectors.partitioningBy(b -> b.isProvisioningTimeBinding()));

        assertEquals(1, partitionedBindings.get(false).size());

        Binding binding = partitionedBindings.get(false).get(0);
        assertFalse(binding.isProvisioningTimeBinding());
        assertEquals(""db~_cluster"", binding.placeholder.bindingExpression);

        // provisioning time bindings
        assertEquals(2, partitionedBindings.get(true).size());

        binding = partitionedBindings.get(true).get(0);
        assertTrue(binding.isProvisioningTimeBinding());
        assertEquals(""_resource~db~address"", binding.placeholder.bindingExpression);

        binding = partitionedBindings.get(true).get(1);
        assertTrue(binding.isProvisioningTimeBinding());
        assertEquals(""_resource~db~env~MYSQL_USER"", binding.placeholder.bindingExpression);

        // validate ""normalizeBindings""

        String expectedContentSerialized = serializeCompositeTemplate(compositeTemplate);

        assertFalse(expectedContent.contains(""bindings:""));
        assertFalse(expectedContentSerialized.contains(""bindings:""));

        assertTrue(expectedContent.contains(""${db~_cluster}",1
"@Test
    public void testDeserializeSerializeComplexDockerComposeWithNetwork() throws IOException {

        String expectedContent = getContent(""docker.complex.network.yaml"");

        DockerCompose compose = deserializeDockerCompose(expectedContent);

        String content = serializeDockerCompose(compose);

        assertEqualsYamls(toUnixLineEnding(expectedContent), toUnixLineEnding(content));

        CompositeTemplate template = fromDockerComposeToCompositeTemplate(compose);

        assertNull(template.id);
        assertNull(template.status);
        assertComponentTypes(template.components);
        assertContainersComponents(ResourceType.CONTAINER_TYPE.getContentType(), 3,
                template.components);
        assertContainersComponents(ResourceType.NETWORK_TYPE.getContentType(), 3,
                template.components);
        assertContainersComponents(ResourceType.VOLUME_TYPE.getContentType(), 0,
                template.components);

        String contentTemplate = serializeCompositeTemplate(template);

        assertTrue((contentTemplate != null) && (!contentTemplate.isEmpty()));
    }",1
"@Test
    public void testSeriaizeDeserializeCompositeTemplateWithHealthCheck() throws IOException {

        // Assert that healthConfig.ignoreOnProvision is serialized when false
        String expectedContent = getContent(""composite.simple.health.yaml"");

        CompositeTemplate template = deserializeCompositeTemplate(expectedContent);

        ContainerDescription data = (ContainerDescription) template.components.get(""hello"").data;
        assertNotNull(data.healthConfig);
        assertEquals(false, data.healthConfig.ignoreOnProvision);

        // Assert that healthConfig.ignoreOnProvision is serialized when true
        data.healthConfig.ignoreOnProvision = true;
        String content = serializeCompositeTemplate(template);

        template = deserializeCompositeTemplate(content);

        data = (ContainerDescription) template.components.get(""hello"").data;
        assertNotNull(data.healthConfig);
        assertEquals(true, data.healthConfig.ignoreOnProvision);

        // Assert that healthConfig.ignoreOnProvision is not serialized when null
        data.healthConfig = null;
        content = serializeCompositeTemplate(template);
        assertFalse(content.contains(""health_config""));
    }",1
"@Test
    public void testWrongDeserializationExceptions() throws IOException {
        try {
            deserializeCompositeTemplate(getContent(""composite.bad.yaml""));
            fail(""wrong content!"");
        }",1
"@Test
    public void testConstructKubeConfigWithBearerToken() {
        String clusterAddress = ""https://testhost:8443"";
        String token = ""bearer_token"";

        AuthCredentialsServiceState creds = new AuthCredentialsServiceState();
        creds.privateKey = token;
        creds.type = AuthCredentialsType.Bearer.toString();
        KubeConfig config = KubernetesUtil.constructKubeConfig(clusterAddress, creds);

        assertNotNull(config);
        assertEquals(token, config.users.get(0).user.token);
    }",1
"@Test
    public void testConstructKubeConfigWithPassword() {
        String clusterAddress = ""https://testhost:8443"";
        String username = ""user1"";
        String password = ""password123"";

        AuthCredentialsServiceState creds = new AuthCredentialsServiceState();
        creds.userEmail = username;
        creds.privateKey = password;
        creds.type = AuthCredentialsType.Password.toString();
        KubeConfig config = KubernetesUtil.constructKubeConfig(clusterAddress, creds);

        assertNotNull(config);
        assertEquals(username, config.users.get(0).user.username);
        assertEquals(password, config.users.get(0).user.password);
    }",1
"@Test
    public void testDeserializeKubernetesEntityHasCorrectClass() throws IOException {
        assertEquals(Pod.class,
                KubernetesUtil.deserializeKubernetesEntity(podYaml).getClass());
        assertEquals(PodTemplate.class,
                KubernetesUtil.deserializeKubernetesEntity(podTemplateYaml).getClass());
        assertEquals(ReplicationController.class,
                KubernetesUtil.deserializeKubernetesEntity(replicationControllerYaml).getClass());
        assertEquals(Deployment.class,
                KubernetesUtil.deserializeKubernetesEntity(deploymentYaml).getClass());
        assertEquals(Service.class,
                KubernetesUtil.deserializeKubernetesEntity(serviceYamlFormat).getClass());
        assertEquals(BaseKubernetesObject.class,
                KubernetesUtil.deserializeKubernetesEntity(secretYaml).getClass());
    }",1
"@Test
    public void testFromContainerDescriptionHealthConfigToPodContainerProbe() {
        Probe expectedProbe1 = new Probe();
        expectedProbe1.exec = new ExecAction();
        expectedProbe1.exec.command = new String[] { ""test"", ""command"" }",1
"@Test
    public void testGetStateTypeFromSelfLink() {
        String selfLink = ""/resources/kubernetes-pods/376fdq673"";
        Class<? extends BaseKubernetesState> expectedClass = PodState.class;
        Class<? extends BaseKubernetesState> actualClass = getStateTypeFromSelfLink(selfLink);
        assertEquals(expectedClass, actualClass);
    }",1
"@Test
    public void testSetApplicationLabelOnReplicationController() throws IOException {
        KubernetesDescription kd = new KubernetesDescription();
        kd.kubernetesEntity = replicationControllerYaml;
        kd.type = KubernetesUtil.REPLICATION_CONTROLLER_TYPE;

        String testCompositeId = ""123456"";

        kd = KubernetesUtil.setApplicationLabel(kd, testCompositeId);

        ReplicationController replicationController = kd
                .getKubernetesEntity(ReplicationController.class);

        assertNotNull(replicationController);
        assertNotNull(replicationController.metadata);
        assertNotNull(replicationController.metadata.labels);
        assertEquals(testCompositeId,
                replicationController.metadata.labels.get(KUBERNETES_LABEL_APP_ID));

        assertNotNull(replicationController.spec);
        assertNotNull(replicationController.spec.template);
        assertNotNull(replicationController.spec.template.metadata);
        assertNotNull(replicationController.spec.template.metadata.labels);
        assertEquals(testCompositeId,
                replicationController.spec.template.metadata.labels.get(KUBERNETES_LABEL_APP_ID));
    }",1
"@Test
    public void testSetApplicationLabelOnService() throws IOException {
        KubernetesDescription kd = new KubernetesDescription();
        kd.kubernetesEntity = serviceYamlFormat;
        kd.type = SERVICE_TYPE;

        String testCompositeId = ""123456"";

        kd = KubernetesUtil.setApplicationLabel(kd, testCompositeId);

        Service service = kd.getKubernetesEntity(Service.class);

        assertNotNull(service);
        assertNotNull(service.metadata);
        assertNotNull(service.metadata.labels);
        assertEquals(testCompositeId, service.metadata.labels.get(KUBERNETES_LABEL_APP_ID));
    }",1
"@Test
    public void testUpdateNoEpz() throws Throwable {
        // create through the config service
        ElasticPlacementZoneConfigurationState state = createState(false);
        state.resourcePoolState = buildRpState();
        ElasticPlacementZoneConfigurationState createdState = sendState(state, Action.POST);

        // update through the config service
        ElasticPlacementZoneConfigurationState patchState = createState(false);
        patchState.resourcePoolState.documentSelfLink =
                createdState.resourcePoolState.documentSelfLink;
        patchState.resourcePoolState.name = ""new-name"";
        ElasticPlacementZoneConfigurationState latestState = sendState(patchState, Action.PATCH);

        // validate returned state
        assertEquals(""new-name"", latestState.resourcePoolState.name);
        assertNotNull(latestState.resourcePoolState.query);

        // validate the actual RP state
        ResourcePoolState rp = getDocument(ResourcePoolState.class,
                createdState.resourcePoolState.documentSelfLink);
        assertEquals(""new-name"", rp.name);
    }",1
"@Test
    public void testPatchNoChange() throws Throwable {
        // create a non-elastic RP
        ResourcePoolState rp = createRp();
        assertEquals(EnumSet.noneOf(ResourcePoolProperty.class), rp.properties);
        assertTrue(isNonElasticQuery(rp.query));

        // create EPZ for the RP
        String epzLink = createEpz(rp.documentSelfLink, ""tag1"", ""tag2"").documentSelfLink;

        ElasticPlacementZoneState patchState = new ElasticPlacementZoneState();
        patchState.tagLinksToMatch = tagSet(""tag1"");

        Operation patchOp = Operation.createPatch(host, epzLink).setBody(patchState).forceRemote();
        Operation returnedOp = ((CompletableFuture<Operation>) host.sendWithDeferredResult(patchOp)
                .toCompletionStage()).get(60, TimeUnit.SECONDS);
        assertEquals(Operation.STATUS_CODE_NOT_MODIFIED, returnedOp.getStatusCode());
    }",1
"@Test
    public void testCreate() {
        Endpoint endpoint = new Endpoint();
        endpoint.apiEndpoint = ""http://localhost"";
        endpoint.uaaEndpoint = ""https://localhost"";

        createEndpoint(endpoint);

        endpoint.apiEndpoint = null;
        endpoint.uaaEndpoint = ""http://localhost"";
        createEndpointExpectFailure(endpoint, ser -> {
            assertEquals(Operation.STATUS_CODE_BAD_REQUEST, ser.statusCode);
            assertEquals(""'API endpoint' is required"", ser.message);
        }",1
"@Test
    public void testDelete() throws Throwable {
        Endpoint endpoint = new Endpoint();
        endpoint.apiEndpoint = ""http://localhost"";
        endpoint.uaaEndpoint = ""https://localhost"";

        endpoint = createEndpoint(endpoint);

        delete(endpoint.documentSelfLink);
        endpoint = getDocumentNoWait(Endpoint.class, endpoint.documentSelfLink);
        assertNull(endpoint);
    }",1
"@Test
    public void testDeleteEndpointAndClusters() throws Throwable {
        Endpoint endpoint = new Endpoint();
        endpoint.apiEndpoint = ""http://localhost"";
        endpoint.uaaEndpoint = ""https://localhost"";

        endpoint = createEndpoint(endpoint);
        ClusterDto clusterDto = createCluster(endpoint.documentSelfLink);

        delete(endpoint.documentSelfLink);
        endpoint = getDocumentNoWait(Endpoint.class, endpoint.documentSelfLink);
        assertNull(endpoint);

        clusterDto = getDocumentNoWait(ClusterDto.class, clusterDto.documentSelfLink);
        assertNull(endpoint);
    }",1
"@Test
    public void testContainerHostDataCollectionServiceCreatedOnStartUp() throws Throwable {
        waitForServiceAvailability(ContainerHostDataCollectionService
                .HOST_INFO_DATA_COLLECTION_LINK);
        ContainerHostDataCollectionState dataCollectionState = getDocument(
                ContainerHostDataCollectionState.class,
                ContainerHostDataCollectionService.HOST_INFO_DATA_COLLECTION_LINK);

        assertNotNull(dataCollectionState);
    }",1
"@Test
    public void testDefaultGroupPlacementServiceCreatedOnStartUp() throws Throwable {
        waitForServiceAvailability(GroupResourcePlacementService.DEFAULT_RESOURCE_PLACEMENT_LINK);
        GroupResourcePlacementState groupResourcePlacementState = getDocument(
                GroupResourcePlacementState.class,
                GroupResourcePlacementService.DEFAULT_RESOURCE_PLACEMENT_LINK);

        assertNotNull(groupResourcePlacementState);
        assertEquals(GroupResourcePlacementService.DEFAULT_RESOURCE_PLACEMENT_ID,
                groupResourcePlacementState.name);
        assertEquals(GroupResourcePlacementService.DEFAULT_RESOURCE_POOL_LINK,
                groupResourcePlacementState.resourcePoolLink);
        assertEquals(1000000, groupResourcePlacementState.maxNumberInstances);
        assertEquals(100, groupResourcePlacementState.priority);
        assertNull(groupResourcePlacementState.tenantLinks);// assert global default group placement
    }",1
"@Test
    public void testHostContainerListDataCollectionServiceCreatedOnStartUp() throws Throwable {
        waitForServiceAvailability(HostContainerListDataCollection
                .DEFAULT_HOST_CONTAINER_LIST_DATA_COLLECTION_LINK);
        HostContainerListDataCollectionState dataCollectionState = getDocument(
                HostContainerListDataCollectionState.class,
                HostContainerListDataCollection.DEFAULT_HOST_CONTAINER_LIST_DATA_COLLECTION_LINK);

        assertNotNull(dataCollectionState);
        assertEquals(TaskStage.STARTED, dataCollectionState.taskInfo.stage);
    }",1
"@Test
    public void testCreateClusterWithIntercept() throws Throwable {
        ContainerHostSpec hostSpec = new ContainerHostSpec();
        hostSpec.hostState = new ComputeState();
        hostSpec.hostState.id = UUID.randomUUID().toString();
        hostSpec.hostState.address = ""test"";
        hostSpec.hostState.customProperties = new HashMap<>();
        hostSpec.hostState.customProperties.put(ContainerHostService
                        .HOST_DOCKER_ADAPTER_TYPE_PROP_NAME, ""API"");
        hostSpec.hostState.customProperties.put(ContainerHostService.CONTAINER_HOST_TYPE_PROP_NAME,
                ""DOCKER"");

        ClusterDto dto = doPostWithProjectHeader(hostSpec, ClusterService.SELF_LINK, project
                .documentSelfLink, ClusterDto.class);

        ComputeState computeState = getDocument(ComputeState.class, dto.nodeLinks.get(0));

        assertTrue(computeState.tenantLinks.contains(project.documentSelfLink));
    }",1
"@Test
    public void testCreateCompositeComponentIntercept() {
        CompositeComponent state = new CompositeComponent();
        state.name = ""test"";
        state.componentLinks = Collections.singletonList(""test"");

        CompositeComponent doc = doPostWithProjectHeader(state, CompositeComponentFactoryService
                .SELF_LINK, project.documentSelfLink, CompositeComponent.class);

        assertTenantLinks(doc, project.documentSelfLink);
        assertEquals(state.name, doc.name);
        assertEquals(state.componentLinks, doc.componentLinks);
    }",1
"@Test
    public void testCreateContainerVolumeDescriptionIntercept() {
        ContainerVolumeDescription state = new ContainerVolumeDescription();
        state.name = ""test"";
        state.externalName = ""test"";

        ContainerVolumeDescription doc = doPostWithProjectHeader(state,
                ContainerVolumeDescriptionService.FACTORY_LINK, project.documentSelfLink,
                ContainerVolumeDescription.class);

        assertTenantLinks(doc, project.documentSelfLink);
        assertEquals(state.name, doc.name);
        assertEquals(state.externalName, doc.externalName);
    }",1
"@Test
    public void testGetCompositeComponent() {
        CompositeComponent state1 = new CompositeComponent();
        state1.name = ""test"";
        state1.componentLinks = Collections.singletonList(""test"");

        CompositeComponent state2 = new CompositeComponent();
        state2.name = ""test"";
        state2.componentLinks = Collections.singletonList(""test"");

        state1 = doPostWithProjectHeader(state1, CompositeComponentFactoryService
                .SELF_LINK, testProject1.documentSelfLink, CompositeComponent.class);

        state2 = doPostWithProjectHeader(state2, CompositeComponentFactoryService
                .SELF_LINK, testProject2.documentSelfLink, CompositeComponent.class);

        ServiceDocumentQueryResult project1Docs = getDocumentsWithinProject(
                CompositeComponentFactoryService.SELF_LINK, testProject1.documentSelfLink);
        assertEquals(1, project1Docs.documentLinks.size());
        assertTrue(project1Docs.documentLinks.contains(state1.documentSelfLink));

        ServiceDocumentQueryResult project2Docs = getDocumentsWithinProject(
                CompositeComponentFactoryService.SELF_LINK, testProject2.documentSelfLink);
        assertEquals(1, project2Docs.documentLinks.size());
        assertTrue(project2Docs.documentLinks.contains(state2.documentSelfLink));
    }",1
"@Test
    public void testGetContainerVolumeDescription() {
        ContainerVolumeDescription state1 = new ContainerVolumeDescription();
        state1.name = ""test"";
        state1.externalName = ""test"";

        ContainerVolumeDescription state2 = new ContainerVolumeDescription();
        state2.name = ""test"";
        state2.externalName = ""test"";

        state1 = doPostWithProjectHeader(state1,
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject1.documentSelfLink,
                ContainerVolumeDescription.class);

        state2 = doPostWithProjectHeader(state2,
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject2.documentSelfLink,
                ContainerVolumeDescription.class);

        ServiceDocumentQueryResult project1Docs = getDocumentsWithinProject(
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject1.documentSelfLink);
        assertEquals(1, project1Docs.documentLinks.size());
        assertTrue(project1Docs.documentLinks.contains(state1.documentSelfLink));

        ServiceDocumentQueryResult project2Docs = getDocumentsWithinProject(
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject2.documentSelfLink);
        assertEquals(1, project2Docs.documentLinks.size());
        assertTrue(project2Docs.documentLinks.contains(state2.documentSelfLink));
    }",1
"@Test
    public void testGetContainerVolumeDescription() {
        ContainerVolumeDescription state1 = new ContainerVolumeDescription();
        state1.name = ""test"";
        state1.externalName = ""test"";

        ContainerVolumeDescription state2 = new ContainerVolumeDescription();
        state2.name = ""test"";
        state2.externalName = ""test"";

        state1 = doPostWithProjectHeader(state1,
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject1.documentSelfLink,
                ContainerVolumeDescription.class);

        state2 = doPostWithProjectHeader(state2,
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject2.documentSelfLink,
                ContainerVolumeDescription.class);

        ServiceDocumentQueryResult project1Docs = getDocumentsWithinProject(
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject1.documentSelfLink);
        assertEquals(1, project1Docs.documentLinks.size());
        assertTrue(project1Docs.documentLinks.contains(state1.documentSelfLink));

        ServiceDocumentQueryResult project2Docs = getDocumentsWithinProject(
                ContainerVolumeDescriptionService.FACTORY_LINK, testProject2.documentSelfLink);
        assertEquals(1, project2Docs.documentLinks.size());
        assertTrue(project2Docs.documentLinks.contains(state2.documentSelfLink));
    }",1
"@Test
    public void testGetExternalPopularImages() throws Throwable {

        // with the 'container.user.resources.path' configuration attribute set
        // the images of the popular-images.json file there will be returned

        HostInitCommonServiceConfig.startServices(host);

        waitForServiceAvailability(ConfigurationFactoryService.SELF_LINK);
        waitForServiceAvailability(UriUtils.buildUriPath(UriUtils.buildUriPath(
                ConfigurationFactoryService.SELF_LINK, FileUtil.USER_RESOURCES_PATH_VARIABLE)));

        ConfigurationState config = new ConfigurationState();
        config.documentSelfLink = UriUtils.buildUriPath(ConfigurationFactoryService.SELF_LINK, FileUtil.USER_RESOURCES_PATH_VARIABLE);
        config.key = FileUtil.USER_RESOURCES_PATH_VARIABLE;
        config.value = Paths.get(PopularImagesServiceTest.class.getResource(""/containers"").toURI())
                .toString();

        ConfigurationState storedConfig = doPut(config);
        assertNotNull(storedConfig);

        HostInitImageServicesConfig.startServices(host);
        waitForServiceAvailability(PopularImagesService.SELF_LINK);

        Collection<?> images = getDocument(Collection.class, PopularImagesService.SELF_LINK);
        assertNotNull(images);
        assertEquals(5, images.size());
    }",1
"@Test
    public void testGetSingleEventLog() throws Throwable {
        EventLogState createdState = doPost(eventLogState, EventLogFactoryService.SELF_LINK);

        EventLogState retrievedState = getDocument(EventLogState.class, createdState.documentSelfLink);
        assertEventLogEquals(createdState, retrievedState);

        doDelete(UriUtils.buildUri(host, createdState.documentSelfLink), false);
    }",1
"@Test
    public void testAllocationOfContainersWithAffinityAndVolumeFrom() throws Throwable {
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);

        // create first container:
        ContainerDescription desc1 = TestRequestStateFactory.createContainerDescription();
        desc1.documentSelfLink = UUID.randomUUID().toString();
        desc1.name = ""name1"";
        desc1.portBindings = null;
        desc1 = doPost(desc1, ContainerDescriptionService.FACTORY_LINK);
        assertNotNull(desc1);
        addForDeletion(desc1);

        String contextId = UUID.randomUUID().toString();
        // all instances of this request should be allocated on the same hosts because of the pod.
        ContainerAllocationTaskState allocationTask1 = createContainerAllocationTask(
                desc1.documentSelfLink, 1);
        allocationTask1.customProperties.put(RequestUtils.FIELD_NAME_CONTEXT_ID_KEY, contextId);
        allocationTask1 = allocate(allocationTask1);
        ContainerState container1 = getDocument(ContainerState.class,
                allocationTask1.resourceLinks.iterator().next());

        // create second container with afinity dependent on the first container:
        ContainerDescription desc2 = TestRequestStateFactory.createContainerDescription();
        desc2.documentSelfLink = UUID.randomUUID().toString();
        desc2.name = ""name2-links"";
        desc2.portBindings = null;
        desc2.affinity = new String[] { desc1.name }",1
"@Test
    public void testAllocationOfContainersWithSameHostPodConstraint() throws Throwable {
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);
        createDockerHost(createDockerHostDescription(), createResourcePool(), true);

        String pod = ""host-pod1"";

        // create a description with a pod defined:
        ContainerDescription desc1 = TestRequestStateFactory.createContainerDescription();
        desc1.documentSelfLink = UUID.randomUUID().toString();
        desc1.name = ""linked-container1"";
        desc1.pod = pod;
        desc1.portBindings = null;
        desc1 = doPost(desc1, ContainerDescriptionService.FACTORY_LINK);
        assertNotNull(desc1);
        addForDeletion(desc1);

        String contextId = UUID.randomUUID().toString();
        // all instances of this request should be allocated on the same hosts because of the pod.
        ContainerAllocationTaskState allocationTask1 = createContainerAllocationTask(
                desc1.documentSelfLink, 1);
        allocationTask1.customProperties.put(RequestUtils.FIELD_NAME_CONTEXT_ID_KEY, contextId);
        allocationTask1 = allocate(allocationTask1);
        ContainerState container = getDocument(ContainerState.class,
                allocationTask1.resourceLinks.iterator().next());

        String hostLink = container.parentLink;

        // loop a few times to make sure the right host is not chosen by a chance
        for (int i = 0; i < 5; i++) {
            ContainerDescription desc2 = TestRequestStateFactory.createContainerDescription();
            desc2.documentSelfLink = UUID.randomUUID().toString();
            desc2.name = ""linked-container"" + i;
            desc2.pod = pod;
            desc2.portBindings = null;
            desc2 = doPost(desc2, ContainerDescriptionService.FACTORY_LINK);
            assertNotNull(desc2);
            addForDeletion(desc2);

            // all instances of this request should be allocated on the same host as the one already
            // selected by the previous request since the desc1.pod == desc2.pod
            ContainerAllocationTaskState allocationTask2 = createContainerAllocationTask(
                    desc2.documentSelfLink, 2);
            allocationTask2.customProperties.put(RequestUtils.FIELD_NAME_CONTEXT_ID_KEY, contextId);
            allocationTask2 = allocate(allocationTask2);
            for (String resourceLink : allocationTask2.resourceLinks) {
                ContainerState currContainer = getDocument(ContainerState.class, resourceLink);
                assertEquals(""Same host not selected for allocation request: ""
                        + allocationTask2.documentSelfLink + "" - in iteration: "" + i, hostLink,
                        currContainer.parentLink);
            }",1
"@Test
    public void testContainerAllocationWithFollowingProvisioningRequest() throws Throwable {
        host.log("">>>>>>Start: testContainerAllocationWithFollowingProvisioningRequest <<<<< "");
        doOperation(containerDesc, UriUtils.buildUri(host, containerDesc.documentSelfLink),
                false, Action.PUT);

        ContainerAllocationTaskState allocationTask = createContainerAllocationTask();
        allocationTask.customProperties = new HashMap<>();
        allocationTask.customProperties.put(RequestUtils.FIELD_NAME_ALLOCATION_REQUEST,
                Boolean.TRUE.toString());
        allocationTask = allocate(allocationTask);

        assertContainerStateAfterAllocation(allocationTask);

        // Request provisioning after allocation:
        RequestBrokerState provisioningRequest = new RequestBrokerState();
        provisioningRequest.resourceType = allocationTask.resourceType;
        provisioningRequest.resourceLinks = allocationTask.resourceLinks;
        provisioningRequest.resourceDescriptionLink = containerDesc.documentSelfLink;
        provisioningRequest.operation = ContainerOperationType.CREATE.id;

        provisioningRequest = doPost(provisioningRequest, RequestBrokerFactoryService.SELF_LINK);
        assertNotNull(provisioningRequest);

        waitForTaskSuccess(allocationTask.documentSelfLink, ContainerAllocationTaskState.class);
    }",1
"@Test
    public void testRedeploymentWithAutoRedeployOptionDisabled() throws Throwable {
        final long timeoutInMillis = 5000; // 5sec
        ContainerDescription cd = createContainerDescription(false);

        ContainerState state = provisionContainer(cd.documentSelfLink);
        // change the power state of one of them
        setContainerPowerState(state, PowerState.ERROR);

        doOperation(new ContainerControlLoopState(), UriUtils.buildUri(host,
                ContainerControlLoopService.CONTROL_LOOP_INFO_LINK),
                false,
                Service.Action.PATCH);

        state = getDocument(ContainerState.class, state.documentSelfLink);
        host.log(""Power state = %s"", state.powerState.name());

        long startTime = System.currentTimeMillis();
        final String link = state.documentSelfLink;
        AtomicBoolean healthyContainersFound = new AtomicBoolean(false);
        waitFor(() -> {
            ContainerState st = getDocument(ContainerState.class, link);
            host.log(""Power state = %s"", st.powerState.name());
            retrieveContainerStates(cd.documentSelfLink)
                    .thenAccept(containerStates -> {
                        long healthyContainers = containerStates.stream()
                                .filter(cs -> PowerState.RUNNING == cs.powerState)
                                .count();
                        host.log(""healthyContainers = %d"", healthyContainers);
                        if (healthyContainers != 0) {
                            healthyContainersFound.set(true);
                        }",1
"@Test
    public void testContainerHostRemovalResourceOperationCycle() throws Throwable {
        request = startRequest(request);
        waitForRequestToComplete(request);

        request = getDocument(RequestBrokerState.class, request.documentSelfLink);
        assertNotNull(request);

        // verify the resources are created as expected:
        assertEquals(request.resourceCount, request.resourceLinks.size());
        List<String> containerStateLinks = findResourceLinks(ContainerState.class,
                request.resourceLinks);

        // create a host removal task
        ContainerHostRemovalTaskState state = new ContainerHostRemovalTaskState();
        state.resourceLinks = new HashSet<>(Collections.singletonList(
                computeHost.documentSelfLink));
        state = doPost(state, ContainerHostRemovalTaskFactoryService.SELF_LINK);

        assertNotNull(""task is null"", state);
        waitForTaskSuccess(state.documentSelfLink, ContainerHostRemovalTaskState.class);

        validateHostRemoved(containerStateLinks);
    }",1
"@Test
    public void testRequestBrokerContainerHostRemovalWithSystemContainerAndVolumes()
            throws Throwable {
        request = startRequest(request);
        waitForRequestToComplete(request);

        request = getDocument(RequestBrokerState.class, request.documentSelfLink);
        assertNotNull(request);

        // create a system container
        ContainerState container = TestRequestStateFactory.createContainer();
        container.descriptionLink = containerDesc.documentSelfLink;
        container.adapterManagementReference = containerDesc.instanceAdapterReference;
        container.groupResourcePlacementLink = groupPlacementState.documentSelfLink;
        container.parentLink = computeHost.documentSelfLink;
        container.system = Boolean.TRUE;
        container = doPost(container, ContainerFactoryService.SELF_LINK);

        // verify the resources are created as expected:
        assertEquals(request.resourceCount, request.resourceLinks.size());
        List<String> containerStateLinks = findResourceLinks(ContainerState.class,
                request.resourceLinks);

        // create a volume
        ContainerVolumeDescription volumeDesc = TestRequestStateFactory
                .createContainerVolumeDescription(""test-volume"");
        volumeDesc = doPost(volumeDesc, ContainerVolumeDescriptionService.FACTORY_LINK);
        addForDeletion(volumeDesc);

        ContainerVolumeState volume = TestRequestStateFactory.createVolume(""test-volume-003"");
        volume.adapterManagementReference = volumeDesc.instanceAdapterReference;
        volume.descriptionLink = volumeDesc.documentSelfLink;
        volume = doPost(volume, ContainerVolumeService.FACTORY_LINK);

        // verify the volume is created as expected
        List<String> containerVolumeStateLinks = findResourceLinks(ContainerVolumeState.class,
                Arrays.asList(volume.documentSelfLink));
        assertEquals(1, containerVolumeStateLinks.size());

        // create a host removal task - RequestBroker
        RequestBrokerState request = new RequestBrokerState();
        request.resourceType = ResourceType.CONTAINER_HOST_TYPE.getName();
        request.resourceLinks = new HashSet<>(Collections.singletonList(
                computeHost.documentSelfLink));
        request.operation = RequestBrokerState.REMOVE_RESOURCE_OPERATION;

        request = startRequest(request);
        waitForRequestToComplete(request);

        // verify that the volume state was removed
        containerVolumeStateLinks = findResourceLinks(ContainerVolumeState.class,
                Arrays.asList(volume.documentSelfLink));
        assertTrue(""ContainerVolumeState not removed: "" + containerVolumeStateLinks,
                containerVolumeStateLinks.isEmpty());

        // verify that the container states were removed
        containerStateLinks = findResourceLinks(ContainerState.class, containerStateLinks);
        assertTrue(""ContainerState not removed: "" + containerStateLinks,
                containerStateLinks.isEmpty());

        // verify that the host was removed
        Collection<String> computeSelfLinks = findResourceLinks(ComputeState.class,
                Collections.singletonList(computeHost.documentSelfLink));

        assertTrue(""ComputeState was not deleted: "" + computeSelfLinks, computeSelfLinks.isEmpty());

        // verify that the containers where removed from the docker mock
        Set<ContainerState> containerStates = getExistingContainersInAdapter();
        for (ContainerState containerState : containerStates) {
            for (String containerLink : containerStateLinks) {
                if (containerState.documentSelfLink.endsWith(containerLink)) {
                    fail(""Container State not removed with link: "" + containerLink);
                }",1
"@Test
    public void testNetworkProvisioningTaskWithProvidedHostIds() throws Throwable {

        ContainerNetworkDescription networkDesc = TestRequestStateFactory
                .createContainerNetworkDescription(""My-Net"");
        networkDesc.documentSelfLink = UUID.randomUUID().toString();
        networkDesc = doPost(networkDesc, ContainerNetworkDescriptionService.FACTORY_LINK);

        ComputeDescription dockerHostDesc = createDockerHostDescription();
        if (dockerHostDesc.customProperties == null) {
            dockerHostDesc.customProperties = new HashMap<>();
        }",1
"@Test
    public void testRemoveAllocatedOnlyContainers() throws Throwable {
        request.customProperties = new HashMap<>();
        request.customProperties.put(RequestUtils.FIELD_NAME_ALLOCATION_REQUEST,
                Boolean.TRUE.toString());
        request = startRequest(request);
        waitForRequestToComplete(request);

        request = getDocument(RequestBrokerState.class, request.documentSelfLink);
        assertNotNull(request);

        // verify the resources are created as expected:
        assertEquals(request.resourceCount, request.resourceLinks.size());
        Collection<String> containerStateLinks = findResourceLinks(ContainerState.class,
                request.resourceLinks);
        assertEquals(request.resourceCount, containerStateLinks.size());
        // verify containers are not provisioned:
        for (String containerSelfLink : containerStateLinks) {
            ContainerState container = getDocument(ContainerState.class, containerSelfLink);
            assertNotNull(container);
            assertNull(container.id);
            waitForContainerPowerState(PowerState.PROVISIONING, container.documentSelfLink);
        }",1
"@Test
    public void testRemoveApplicationWithScaledContainer() throws Throwable {
        ContainerDescription desc1 = TestRequestStateFactory.createContainerDescription(""name1"",
                true, true);
        ContainerDescription desc2 = TestRequestStateFactory.createContainerDescription(""name2"",
                true, false);
        desc2.affinity = new String[] { desc1.name }",1
"@Test
    public void testRemoveOfStaleContainerOperationFromHostRemoval() throws Throwable {
        // try to remove a container as part of host removal when the container was already removed
        testRemoveOfStaleContainerOperationFromContainerRemovalTask(
                ManagementUriParts.REQUEST_HOST_REMOVAL_OPERATIONS);
    }",1
"@Test
    public void testVolumeProvisioningTaskWithProvidedHostIds() throws Throwable {

        ContainerVolumeDescription volumeDesc = TestRequestStateFactory
                .createContainerVolumeDescription(""My-Vol"");
        volumeDesc.documentSelfLink = UUID.randomUUID().toString();
        volumeDesc = doPost(volumeDesc, ContainerVolumeDescriptionService.FACTORY_LINK);

        ComputeDescription dockerHostDesc = createDockerHostDescription();
        if (dockerHostDesc.customProperties == null) {
            dockerHostDesc.customProperties = new HashMap<>();
        }",1
"@Test
    public void testRequestLifeCycle() throws Throwable {
        host.log(""########  Start of testRequestLifeCycle ######## "");
        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();
        createDockerHost(dockerHostDesc, resourcePool);

        // setup Container desc:
        ContainerDescription containerDesc = createContainerDescription();

        // setup Group Placement:
        GroupResourcePlacementState groupPlacementState = createGroupResourcePlacement(
                resourcePool);

        // 1. Request a container instance:
        RequestBrokerState request = TestRequestStateFactory.createRequestState();
        request.resourceDescriptionLink = containerDesc.documentSelfLink;
        request.tenantLinks = groupPlacementState.tenantLinks;
        host.log(""########  Start of request ######## "");
        request = startRequest(request);

        // wait for request completed state:
        request = waitForRequestToComplete(request);

        RequestBrokerGraphResponse graph = getDocument(RequestBrokerGraphResponse.class,
                ManagementUriParts.REQUEST_GRAPH, RequestBrokerGraphService.QUERY_PARAM,
                extractId(request.documentSelfLink));
        assertNotNull(graph);
        assertNotNull(graph.tasks);

        TaskServiceDocumentHistory requestTask = graph.tasks.remove(0);
        assertTaskPassingStages(requestTask, RequestBrokerFactoryService.SELF_LINK,
                RequestBrokerState.SubStage.values());

        TaskServiceDocumentHistory reservationTask = graph.tasks.remove(0);
        assertTaskPassingStages(reservationTask, ReservationTaskFactoryService.SELF_LINK,
                ReservationTaskState.SubStage.values());

        TaskServiceDocumentHistory placementReservationTask = graph.tasks.remove(0);
        assertTaskPassingStages(placementReservationTask,
                PlacementHostSelectionTaskService.FACTORY_LINK,
                PlacementHostSelectionTaskState.SubStage.values());

        TaskServiceDocumentHistory allocationTask = graph.tasks.remove(0);
        assertTaskPassingStages(allocationTask, ContainerAllocationTaskFactoryService.SELF_LINK,
                ContainerAllocationTaskState.SubStage.values());

        TaskServiceDocumentHistory placementTask = graph.tasks.remove(0);
        assertTaskPassingStages(placementTask, PlacementHostSelectionTaskService.FACTORY_LINK,
                PlacementHostSelectionTaskState.SubStage.values());
    }",1
"@Test
    public void testCompositeComponentWithClusterAndLocalContainerVolumeRequestLifeCycle()
            throws Throwable {
        host.log(
                ""########  Start of testCompositeComponentWithClusterAndLocalContainerVolumeRequestLifeCycle ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        String sharedVolumeName = ""Postgres"";
        String volumeName = String.format(""%s:/etc/pgdata/postgres"", sharedVolumeName);

        ContainerVolumeDescription volumeDesc = TestRequestStateFactory
                .createContainerVolumeDescription(sharedVolumeName);
        volumeDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory.createContainerDescription();
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.name = ""Container1"";
        container1Desc.volumes = new String[] { volumeName }",1
"@Test
    public void testCompositeComponentWithContainerNetworkRequestLifeCycle() throws Throwable {
        host.log(
                ""########  Start of testCompositeComponentWithContainerNetworkRequestLifeCycle ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        // ""set"" the same KV-store for the Docker Hosts created
        dockerHostDesc.customProperties.put(
                ContainerHostService.DOCKER_HOST_CLUSTER_STORE_PROP_NAME, ""my-kv-store"");

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        // setup Composite description with 2 containers and 1 network

        String networkName = ""MyNet"";

        ContainerNetworkDescription networkDesc = TestRequestStateFactory
                .createContainerNetworkDescription(networkName);
        networkDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory.createContainerDescription();
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.name = ""Container1"";
        container1Desc.networks = new HashMap<>();
        container1Desc.networks.put(networkName, new ServiceNetwork());

        ContainerDescription container2Desc = TestRequestStateFactory.createContainerDescription();
        container2Desc.documentSelfLink = UUID.randomUUID().toString();
        container2Desc.name = ""Container2"";
        container2Desc.affinity = new String[] { ""!Container1:hard"" }",1
"@Test
    public void testCompositeComponentWithContainerVolumeRequestLifeCycle() throws Throwable {
        host.log(
                ""########  Start of testCompositeComponentWithContainerVolumeRequestLifeCycle ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        String sharedVolumeName = ""Postgres"";
        String volumeName = String.format(""%s:/etc/pgdata/postgres"", sharedVolumeName);

        ContainerVolumeDescription volumeDesc = TestRequestStateFactory
                .createContainerVolumeDescription(sharedVolumeName);
        volumeDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory.createContainerDescription();
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.name = ""Container1"";
        container1Desc.volumes = new String[] { volumeName }",1
"@Test
    public void testRequestFailShouldNotDeleteDescriptionsInUse() throws Throwable {
        host.log(""########  Start of testRequestFailShouldNotDeleteDescriptionsInUse ######## "");

        // ****** Start of testing a single container instance clean up ******
        host.log(""### Request a single container instance."");
        RequestBrokerState request = TestRequestStateFactory.createRequestState();
        request.resourceDescriptionLink = containerDesc.documentSelfLink;

        host.log(""########  Start of request ######## "");
        request = startRequest(request);

        // wait for request completed state:
        waitForRequestToComplete(request);

        host.log(""### Request a single container instance. Expected to fail because there is no placement created.""
                + ""Should not delete the description as there is already a container associated with it ###."");
        request = TestRequestStateFactory.createRequestState();
        request.resourceDescriptionLink = containerDesc.documentSelfLink;
        request.tenantLinks = Arrays.asList(""unknown"");

        host.log(""########  Start of request ######## "");
        request = startRequest(request);

        // wait for request completed state:
        waitForRequestToFail(request);

        final String containerDescLink = containerDesc.documentSelfLink;

        final long timoutInMillis = 3000; // 3sec
        long startRequestTime = System.currentTimeMillis();

        waitFor(() -> {
            if (System.currentTimeMillis() - startRequestTime > timoutInMillis) {
                return true;
            }",1
"@Test
    public void testRequestLifeCycleFailureShouldCleanReservations() throws Throwable {
        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();
        createDockerHost(dockerHostDesc, resourcePool);

        // setup Container desc:
        ContainerDescription containerDesc = createContainerDescription();

        // setup Group Placement:
        GroupResourcePlacementState groupPlacementState = createGroupResourcePlacement(
                resourcePool);
        assertEquals(0, groupPlacementState.allocatedInstancesCount);

        // 1. Request a container instance:
        RequestBrokerState request = TestRequestStateFactory.createRequestState();
        request.resourceDescriptionLink = containerDesc.documentSelfLink;
        request.tenantLinks = groupPlacementState.tenantLinks;
        request.customProperties = new HashMap<>();
        request.customProperties.put(MockDockerAdapterService.FAILURE_EXPECTED,
                Boolean.TRUE.toString());

        request = startRequest(request);

        // 2. Wait for reservation removed substage
        waitForRequestToFail(request);

        // 3. Verify that the group placement has been released.
        groupPlacementState = getDocument(GroupResourcePlacementState.class,
                groupPlacementState.documentSelfLink);
        assertEquals(0, groupPlacementState.allocatedInstancesCount);
    }",1
"@Test
    public void testRequestLifeCycleWithContainerNetworkAndServiceAntiAffinityFilterFailureShouldCleanNetworks()
            throws Throwable {
        host.log(
                ""########  Start of testRequestLifeCycleWithContainerNetworkAndServiceAntiAffinityFilterFailureShouldCleanNetworks ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        // DO NOT ""set"" the same KV-store for the Docker Hosts created!
        // In this way the ContainerToNetworkAffinityFilter and ServiceAntiAffinityHostFilter will
        // work as expected by saying that there are no hosts available.
        // Containers should be set on the same host because of the network but they ""can't""
        // because of the container2 anti-affinity rule.

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        // setup Composite description with 2 containers and 1 network

        String networkName = ""MyNet"";

        ContainerNetworkDescription networkDesc = TestRequestStateFactory
                .createContainerNetworkDescription(networkName);
        networkDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory
                .createContainerDescription(""Container1"");
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.networks = new HashMap<>();
        container1Desc.networks.put(networkName, new ServiceNetwork());

        ContainerDescription container2Desc = TestRequestStateFactory
                .createContainerDescription(""Container2"");
        container2Desc.documentSelfLink = UUID.randomUUID().toString();
        container2Desc.affinity = new String[] { ""!Container1:hard"" }",1
"@Test
    public void testRequestLifeCycleWithContainerNetworkFailureShouldCleanNetworks()
            throws Throwable {
        host.log(
                ""########  Start of testRequestLifeCycleWithContainerNetworkFailureShouldCleanNetworks ######## "");

        // setup Docker Host:
        ResourcePoolState resourcePool = createResourcePool();
        ComputeDescription dockerHostDesc = createDockerHostDescription();

        delete(computeHost.documentSelfLink);
        computeHost = null;

        // ""set"" the same KV-store for the Docker Hosts created
        dockerHostDesc.customProperties.put(
                ContainerHostService.DOCKER_HOST_CLUSTER_STORE_PROP_NAME, ""my-kv-store"");

        ComputeState dockerHost1 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost1);

        ComputeState dockerHost2 = createDockerHost(dockerHostDesc, resourcePool, true);
        addForDeletion(dockerHost2);

        // setup Composite description with 2 containers and 1 network

        String networkName = ""MyNet"";

        ContainerNetworkDescription networkDesc = TestRequestStateFactory
                .createContainerNetworkDescription(networkName);
        networkDesc.documentSelfLink = UUID.randomUUID().toString();

        ContainerDescription container1Desc = TestRequestStateFactory.createContainerDescription();
        container1Desc.documentSelfLink = UUID.randomUUID().toString();
        container1Desc.name = ""Container1"";
        container1Desc.networks = new HashMap<>();
        container1Desc.networks.put(networkName, new ServiceNetwork());

        ContainerDescription container2Desc = TestRequestStateFactory.createContainerDescription();
        container2Desc.documentSelfLink = UUID.randomUUID().toString();
        container2Desc.name = ""Container2"";
        container2Desc.affinity = new String[] { ""!Container1:hard"" }",1
"@Test
    public void testRequestLifecycleWithContainerNetworkShouldCleanNetworkStatesOnProvisionAndDeletionFailure()
            throws Throwable {
        host.log(
                ""########  Start of ""
                        + ""testRequestLifecycleWithContainerNetworkShouldCleanNetworkStatesOnProvisionAndDeletionFailure ######## "");

        // 1. Request a network with expected failure:
        RequestBrokerState request = TestRequestStateFactory.createRequestState(
                ResourceType.NETWORK_TYPE.getName(),
                containerNetworkDesc.documentSelfLink);
        request.tenantLinks = groupPlacementState.tenantLinks;
        request.customProperties.put(
                ReservationAllocationTaskService.CONTAINER_HOST_ID_CUSTOM_PROPERTY, computeHost.id);

        // This should ensure that both the provisioning and the deletion (cleanup) requests to the
        // mock adapter will fail - during the allocation, the custom properties will be copied into
        // the network state. During the provisioning, the mock adapter will read the
        // EXPECTED_FAILURE from the request's custom properties and during deletion (cleanup) -
        // from the network state.
        request.customProperties.put(MockDockerNetworkAdapterService.FAILURE_EXPECTED,
                Boolean.TRUE.toString());

        host.log(""########  Start of request ######## "");
        request = startRequest(request);

        // 2. Wait for reservation removed substage
        waitForRequestToFail(request);

        // and there must be no container network state left
        ServiceDocumentQueryResult networkStates = getDocument(ServiceDocumentQueryResult.class,
                ContainerNetworkService.FACTORY_LINK);
        assertEquals(0L, networkStates.documentCount.longValue());
    }",1
"@Test
    public void testValidateOnStart() throws Throwable {
        RequestBrokerState request = TestRequestStateFactory.createRequestState();
        request.resourceType = ""-"";
        request.resourceDescriptionLink = ""-"";
        RequestBrokerService r = new RequestBrokerService();
        Method m = r.getClass().getDeclaredMethod(""validateStateOnStart"", RequestBrokerState.class);
        m.setAccessible(true);

        validateLocalizableException(() -> {
            try {
                m.invoke(r, request);
            }",1
"@Test
    public void testReservationAllocationTask() throws Throwable {

        verifyService(FactoryService.create(ReservationAllocationTaskService.class),
                ReservationAllocationTaskState.class,
                (prefix, index) -> {
                    ReservationAllocationTaskState reservationState = new ReservationAllocationTaskState();
                    reservationState.tenantLinks = Collections.singletonList(""testGroup"");
                    reservationState.resourceDescriptionLink = prefix + ""test"";
                    reservationState.customProperties = containerDesc.customProperties;
                    reservationState.name = containerDesc.name;
                    reservationState.resourceCount = 1;
                    Assert.assertNull(reservationState.groupResourcePlacementLink);

                    return reservationState;

                }",1
"@Test
    public void testReservationAllocationThroughReservationTask() throws Throwable {
        ReservationTaskState task = new ReservationTaskState();
        task.tenantLinks = containerDesc.tenantLinks;
        task.resourceDescriptionLink = containerDesc.documentSelfLink;
        task.resourceCount = 1;
        task.serviceTaskCallback = ServiceTaskCallback.createEmpty();
        task.groupResourcePlacementLink = null;
        task.resourcePoolsPerGroupPlacementLinks = null;

        task = doPost(task, ReservationTaskFactoryService.SELF_LINK);
        assertNotNull(task);

        ReservationTaskState result = waitForTaskSuccess(task.documentSelfLink,
                ReservationTaskState.class);

        assertNotNull(result.groupResourcePlacementLink);
        assertNotNull(result.resourcePoolsPerGroupPlacementLinks);
        assertTrue(result.resourcePoolsPerGroupPlacementLinks.size() == 1);
        assertTrue(result.groupResourcePlacementLink.contains(containerDesc.name));
        assertTrue(result.resourcePoolsPerGroupPlacementLinks.keySet()
                .contains(result.groupResourcePlacementLink));

        ReservationAllocationTaskState rsvAllocation = getDocument(
                ReservationAllocationTaskState.class,
                task.documentSelfLink);
        assertNotNull(rsvAllocation);
        assertEquals(result.groupResourcePlacementLink, rsvAllocation.groupResourcePlacementLink);
        assertEquals(result.resourcePoolsPerGroupPlacementLinks,
                rsvAllocation.resourcePoolsPerGroupPlacementLinks);

        GroupResourcePlacementState groupResourcePlacement = getDocument(
                GroupResourcePlacementState.class, result.groupResourcePlacementLink);
        assertNotNull(groupResourcePlacement);
        assertNotNull(groupResourcePlacement.resourcePoolLink);

        assertEquals(groupResourcePlacement.documentSelfLink, rsvAllocation.groupResourcePlacementLink);

    }",1
"@Test
    public void testDeploymentPoliciesOnHost() throws Throwable {
        DeploymentPolicy policy = createDeploymentPolicy();

        containerDesc.deploymentPolicyId = extractId(policy.documentSelfLink);
        doPut(containerDesc);

        GroupResourcePlacementState placementState = TestRequestStateFactory
                .createGroupResourcePlacementState();
        placementState = doPost(placementState, GroupResourcePlacementService.FACTORY_LINK);
        addForDeletion(placementState);

        ReservationTaskState task = new ReservationTaskState();
        task.tenantLinks = placementState.tenantLinks;
        task.resourceDescriptionLink = containerDesc.documentSelfLink;
        task.resourceCount = 1;
        task.serviceTaskCallback = ServiceTaskCallback.createEmpty();

        task = doPost(task, ReservationTaskFactoryService.SELF_LINK);
        assertNotNull(task);

        task = waitForTaskSuccess(task.documentSelfLink, ReservationTaskState.class);

        // update the container host and succeed
        computeHost.customProperties.put(ContainerHostService.CUSTOM_PROPERTY_DEPLOYMENT_POLICY,
                policy.documentSelfLink);
        doPut(computeHost);

        task = new ReservationTaskState();
        task.tenantLinks = placementState.tenantLinks;
        task.resourceDescriptionLink = containerDesc.documentSelfLink;
        task.resourceCount = 1;
        task.serviceTaskCallback = ServiceTaskCallback.createEmpty();
        task = doPost(task, ReservationTaskFactoryService.SELF_LINK);
        assertNotNull(task);

        task = waitForTaskSuccess(task.documentSelfLink, ReservationTaskState.class);

        placementState = getDocument(GroupResourcePlacementState.class,
                placementState.documentSelfLink);
        assertEquals(placementState.documentSelfLink, task.groupResourcePlacementLink);
    }",1
"@Test
    public void testDeploymentPoliciesOnPolicy() throws Throwable {
        DeploymentPolicy policy = createDeploymentPolicy();

        containerDesc.deploymentPolicyId = extractId(policy.documentSelfLink);
        doPut(containerDesc);

        GroupResourcePlacementState placementState = TestRequestStateFactory
                .createGroupResourcePlacementState();
        placementState = doPost(placementState, GroupResourcePlacementService.FACTORY_LINK);
        addForDeletion(placementState);

        ReservationTaskState task = new ReservationTaskState();
        task.tenantLinks = placementState.tenantLinks;
        task.resourceDescriptionLink = containerDesc.documentSelfLink;
        task.resourceCount = 1;
        task.serviceTaskCallback = ServiceTaskCallback.createEmpty();

        task = doPost(task, ReservationTaskFactoryService.SELF_LINK);
        assertNotNull(task);

        task = waitForTaskSuccess(task.documentSelfLink, ReservationTaskState.class);

        // update the placement and succeed
        placementState.deploymentPolicyLink = policy.documentSelfLink;
        doPut(placementState);

        task = new ReservationTaskState();
        task.tenantLinks = placementState.tenantLinks;
        task.resourceDescriptionLink = containerDesc.documentSelfLink;
        task.resourceCount = 1;
        task.serviceTaskCallback = ServiceTaskCallback.createEmpty();

        task = doPost(task, ReservationTaskFactoryService.SELF_LINK);
        assertNotNull(task);

        task = waitForTaskSuccess(task.documentSelfLink, ReservationTaskState.class);

        placementState = getDocument(GroupResourcePlacementState.class,
                placementState.documentSelfLink);
        assertEquals(placementState.documentSelfLink, task.groupResourcePlacementLink);
    }",1
"@Test
    public void testReservationTaskLifeCycleWhenNoAvailableGroupPlacements() throws Throwable {
        GroupResourcePlacementState groupPlacementState = doPost(
                TestRequestStateFactory.createGroupResourcePlacementState(),
                GroupResourcePlacementService.FACTORY_LINK);
        addForDeletion(groupPlacementState);

        ReservationTaskState task = new ReservationTaskState();
        task.tenantLinks = groupPlacementState.tenantLinks;
        task.resourceDescriptionLink = containerDesc.documentSelfLink;
        task.resourceCount = groupPlacementState.maxNumberInstances + 1;
        task.serviceTaskCallback = ServiceTaskCallback.createEmpty();

        task = doPost(task, ReservationTaskFactoryService.SELF_LINK);
        assertNotNull(task);

        waitForTaskError(task.documentSelfLink, ReservationTaskState.class);
    }",1
"@Test
    public void testReservationTaskLifeCycleWhenNoAvailableGroupPlacements() throws Throwable {
        GroupResourcePlacementState groupPlacementState = doPost(
                TestRequestStateFactory.createGroupResourcePlacementState(),
                GroupResourcePlacementService.FACTORY_LINK);
        addForDeletion(groupPlacementState);

        ReservationTaskState task = new ReservationTaskState();
        task.tenantLinks = groupPlacementState.tenantLinks;
        task.resourceDescriptionLink = containerDesc.documentSelfLink;
        task.resourceCount = groupPlacementState.maxNumberInstances + 1;
        task.serviceTaskCallback = ServiceTaskCallback.createEmpty();

        task = doPost(task, ReservationTaskFactoryService.SELF_LINK);
        assertNotNull(task);

        waitForTaskError(task.documentSelfLink, ReservationTaskState.class);
    }",1
"@Test
    public void testDeleteEventsWhenNoneAreAvailable() throws Throwable {
        verifyEventsCount(0);

        ServiceDocumentDeleteTaskState deleteTaskState = doPost(request,
                ServiceDocumentDeleteTaskService.FACTORY_LINK);

        waitForTaskSuccess(deleteTaskState.documentSelfLink,
                ServiceDocumentDeleteTaskService.ServiceDocumentDeleteTaskState.class);

        verifyEventsCount(0);
    }",1
"@Test
    public void testAssignmentAndUnassignment() throws Throwable {
        ComputeState compute = createCompute();

        // addition
        updateTags(compute.documentSelfLink,
                Arrays.asList(""prop"", ""key1:value2"", ""key2:value2""),
                Arrays.asList(),
                Arrays.asList(""prop"", ""key1:value2"", ""key2:value2""));

        // addition + removal
        updateTags(compute.documentSelfLink,
                Arrays.asList(""location:somewhere""),
                Arrays.asList(""key2:value2""),
                Arrays.asList(""prop"", ""key1:value2"", ""location:somewhere""));

        // no change
        updateTags(compute.documentSelfLink,
                Arrays.asList(""location:somewhere""),
                Arrays.asList(""key2:value2""),
                Arrays.asList(""prop"", ""key1:value2"", ""location:somewhere""));

        // empty request
        updateTags(compute.documentSelfLink,
                Arrays.asList(),
                Arrays.asList(),
                Arrays.asList(""prop"", ""key1:value2"", ""location:somewhere""));

        // null addition
        updateTags(compute.documentSelfLink,
                null,
                Arrays.asList(),
                Arrays.asList(""prop"", ""key1:value2"", ""location:somewhere""));

        // null removal
        updateTags(compute.documentSelfLink,
                Arrays.asList(),
                null,
                Arrays.asList(""prop"", ""key1:value2"", ""location:somewhere""));

        // removal
        updateTags(compute.documentSelfLink,
                Arrays.asList(),
                Arrays.asList(""key1:value2""),
                Arrays.asList(""prop"", ""location:somewhere""));

        // removal of all
        updateTags(compute.documentSelfLink,
                null,
                Arrays.asList(""prop"", ""location:somewhere""),
                Arrays.asList());
    }",1
"@Test
    public void testDefaultResourcePrefixNameCreatedOnStartUp() throws Throwable {
        waitForServiceAvailability(
                ResourceNamePrefixService.DEFAULT_RESOURCE_NAME_PREFIX_SELF_LINK);
        ResourceNamePrefixState defaultNamePrefixState = getDocument(ResourceNamePrefixState.class,
                ResourceNamePrefixService.DEFAULT_RESOURCE_NAME_PREFIX_SELF_LINK);
        assertNotNull(defaultNamePrefixState);
        assertNull(defaultNamePrefixState.tenantLinks);
    }",1
"@Test
    public void testCreateEventRegistryTopic() {
        EventTopicState state = createEventTopicState(""dummy-link"", EVENT_NAME, EVENT_TASK,
                TaskStage.FINISHED.name(), DefaultSubStage.COMPLETED.name(), false, new String());

        URI uri = UriUtils.buildUri(host, EventTopicService.FACTORY_LINK);
        EventTopicState result = sender
                .sendPostAndWait(uri, state, EventTopicState.class);

        assertNotNull(result);
        assertNotNull(result.documentSelfLink);
        assertNotNull(result.topicTaskInfo);

        assertEquals(state.topicTaskInfo.task, result.topicTaskInfo.task);
        assertEquals(state.topicTaskInfo.stage, result.topicTaskInfo.stage);
        assertEquals(state.topicTaskInfo.substage, result.topicTaskInfo.substage);

        uri = UriUtils.buildUri(host, result.documentSelfLink);
        result = sender.sendGetAndWait(uri, EventTopicState.class);
        assertNotNull(result);
    }",1
"@Test
    public void testCreateionOfChangeComputeNameTopic() {
        // On start service creates new topic. No need for explicit post for creation.
        TestContext context = new TestContext(1, Duration.ofSeconds(120));
        verifyThatTopicExists(CHANGE_COMPUTE_NAME_SELF_LINK, context);
        context.await();
    }",1
"@Test
    public void testTimeout() throws Throwable {
        ExtensibilitySubscriptionCallback state = createExtensibilityCallback(
                ExtensibilitySubscriptionCallback.Status.BLOCKED);

        state.due = LocalDateTime.now().plus(5, SECONDS);
        state.serviceTaskCallback = new ServiceTaskCallback();
        state.serviceTaskCallback.serviceSelfLink = TestStatelessService.SELF_LINK;
        state.replyPayload = new ServiceTaskCallbackResponse();
        state.replyPayload.taskInfo = TaskState.createAsStarted();
        state.replyPayload.taskSubStage = DefaultSubStage.CREATED;
        state.taskStateJson = TestStatelessService.class.getSimpleName();

        DeferredResult<Void> done = new DeferredResult<>();
        this.host.startService(new TestStatelessService(done));
        this.host.waitForServiceAvailable(TestStatelessService.SELF_LINK);

        URI uri = UriUtils.buildUri(host, ExtensibilitySubscriptionCallbackService.FACTORY_LINK);
        sender.sendPostAndWait(uri, state, ExtensibilitySubscriptionCallback.class);

        this.waitFor(""Task did not time out."", () -> done.isDone());
    }",1
"@Test
    public void testCreateAndGet() {
        ExtensibilitySubscription state = createExtensibilityState();

        URI uri = UriUtils.buildUri(host, ExtensibilitySubscriptionService.FACTORY_LINK);
        ExtensibilitySubscription result = sender
                .sendPostAndWait(uri, state, ExtensibilitySubscription.class);

        assertNotNull(result);
        assertNotNull(result.documentSelfLink);
        assertEquals(state.task, result.task);
        assertEquals(state.stage, result.stage);
        assertEquals(state.substage, result.substage);

        uri = UriUtils.buildUri(host, result.documentSelfLink);
        result = sender.sendGetAndWait(uri, ExtensibilitySubscription.class);
        assertNotNull(result);
    }",1
"@Test
    public void testGetEmpty() throws InterruptedException {
        ServiceDocumentQueryResult result = sender.sendAndWait(
                Operation.createGet(host, ExtensibilitySubscriptionService.FACTORY_LINK),
                ServiceDocumentQueryResult.class);
        assertNotNull(result);
        assertNotNull(result.documentCount);
        assertEquals(0L, (long) result.documentCount);
    }",1
"@Test
    public void testRedirect() {
        String movedLocation = ""moved"";
        URI targetUri = UriUtils.buildUri(SAMPLE_HARBOR_URI, SAMPLE_API_PATH);

        HarborApiProxyService service = new HarborApiProxyService();
        service.setHost(VerificationHost.create());
        ServiceClient client = new MockServiceClient() {
            @Override
            public void sendRequest(Operation op) {
                String authHeader = op.getRequestHeader(Operation.AUTHORIZATION_HEADER);
                assertNull(""Authorization header should be empty"", authHeader);
                op.setStatusCode(Operation.STATUS_CODE_MOVED_PERM);
                op.addResponseHeader(Operation.LOCATION_HEADER, movedLocation);
                op.setUri(targetUri);
                op.complete();
            }",1
"@Test
    public void testDeleteDefaultRegistryOnStartup() throws Throwable {
        RegistryState registryState = new RegistryState();
        registryState.documentSelfLink = RegistryService.DEFAULT_INSTANCE_LINK;
        registryState.endpointType = RegistryState.DOCKER_REGISTRY_ENDPOINT_TYPE;
        registryState.address = RegistryService.DEFAULT_REGISTRY_ADDRESS;
        registryState = doPost(registryState, RegistryFactoryService.SELF_LINK);

        assertNotNull(""Failed to create default registry"", registryState);

        ConfigurationState config = new ConfigurationState();
        config.key = RegistryService.DISABLE_DEFAULT_REGISTRY_PROP_NAME;
        config.value = Boolean.toString(true);

        ConfigurationUtil.initialize(config);

        RegistryService.buildDefaultStateInstance(host);

        waitFor(""Ensure default registry is deleted."", () -> {
            List<String> resourceLinks = findResourceLinks(RegistryState.class,
                    Collections.singletonList(RegistryService.DEFAULT_INSTANCE_LINK));
            return resourceLinks.size() == 0;
        }",1
"@Test
    public void testPatch() throws Throwable {
        String testEntry = ""test-entry"";
        UniquePropertiesRequest patch = new UniquePropertiesRequest();
        patch.toAdd = Collections.singletonList(testEntry);

        doPatch(patch, testState.documentSelfLink);

        testState = getDocumentNoWait(UniquePropertiesState.class, testState.documentSelfLink);
        assertEquals(1, testState.uniqueProperties.size());
        assertTrue(testState.uniqueProperties.contains(testEntry));

        try {
            doPatch(patch, testState.documentSelfLink);
            fail(""Adding entry that already exist should fail the operation."");
        }",1
"@Test
    public void testProvisionApplication() throws Exception {
        setupCoreOsHost(DockerAdapterType.API, false, null);
        checkNumberOfNetworks(serviceClient, NUMBER_OF_NETWORKS_PER_APPLICATION);

        ContainerVolumeState volume = setupExternalVolume();
        compositeDescriptionLink = importTemplateWithExternalVolume(serviceClient,
                TEMPLATE_FILENAME, volume.name);

        logger.info(
                ""---------- 5. Request simple application with a container, a network and an external volume. --------"");
        requestContainerAndDelete(getResourceDescriptionLink(false, null));
    }",1
"@Test
    public void testAddHostWithTrailingForwardSlashes() throws Throwable {
        RegistryState rs = new RegistryState();
        rs.address = TEST_REGISTRY_ADDRESS + ""///"";
        rs.name = getClass().getName();
        rs.endpointType = RegistryState.DOCKER_REGISTRY_ENDPOINT_TYPE;

        RegistryHostSpec hs = new RegistryHostSpec();
        hs.hostState = rs;
        hs.acceptHostAddress = true;

        String[] result = new String[] { null }",1
"@Test
    public void testValidateSelfSignNotAccepted() throws Throwable {
        registryState.address = TEST_REGISTRY_ADDRESS;

        Operation op = Operation.createPut(helperWithValidationUri)
                .setBody(hostState)
                .setCompletion((o, e) -> {
                    if (e != null) {
                        host.failIteration(e);
                        return;
                    }",1
"@Test
    public void testSearchImagesWhenRegistriesAreDisabled() throws Exception {
        logger.info(""Assert the default registry is there"");
        RegistryState dockerHub = getDocument(RegistryService.DEFAULT_INSTANCE_LINK,
                RegistryState.class);
        assertNotNull(dockerHub);
        dockerHub.name = dockerHub.address; // required name when updating a registry

        logger.info(""Assert the preconfigured registry is there"");
        RegistryState configuredReg = getDocument(configuredRegistry.documentSelfLink,
                RegistryState.class);
        assertNotNull(configuredReg);

        List<RegistryState> disabledRegistries = disableRegistries(Arrays.asList(dockerHub,
                configuredReg));
        registriesToEnable.addAll(disabledRegistries);

        URI templateSearchUri = UriUtils.buildUri(new URI(getBaseUrl()),
                TemplateSearchService.SELF_LINK);

        final List<String> keyValues = new ArrayList<>(Arrays.asList(
                TemplateSearchService.IMAGES_ONLY_PARAM, Boolean.toString(true),
                TemplateSearchService.QUERY_PARAM, ""vmware""));

        templateSearchUri = UriUtils.extendUriWithQuery(templateSearchUri,
                keyValues.toArray(new String[0]));

        logger.info(""Search URI built: "" + templateSearchUri);

        HashMap<String, String> headers = new HashMap<>();
        headers.put(OperationUtil.PROJECT_ADMIRAL_HEADER, ProjectService.DEFAULT_PROJECT_LINK);

        HttpResponse httpResponse = SimpleHttpsClient.execute(HttpMethod.GET,
                templateSearchUri.toString(), null, headers, null);
        RegistrySearchResponse searchResponse = Utils.fromJson(httpResponse.responseBody,
                RegistrySearchResponse.class);

        assertEquals(0, searchResponse.results.size());
    }",1
"@Test
    public void testSearchImagesWithRegistryFilter() throws Exception {
        // assert the default registry is there
        RegistryState dockerHub = getDocument(RegistryService.DEFAULT_INSTANCE_LINK,
                RegistryState.class);
        assertNotNull(dockerHub);

        URI templateSearchUri = UriUtils.buildUri(new URI(getBaseUrl()),
                TemplateSearchService.SELF_LINK);

        // exclude results from the default registry
        final List<String> keyValues = new ArrayList<>(Arrays.asList(
                TemplateSearchService.IMAGES_ONLY_PARAM, Boolean.toString(true),
                ContainerImageService.REGISTRY_FILTER_QUERY_PARAM_NAME, REGISTRY_NAME,
                TemplateSearchService.QUERY_PARAM, ""vmware""));

        templateSearchUri = UriUtils.extendUriWithQuery(templateSearchUri,
                keyValues.toArray(new String[0]));

        final HashMap<String, String> headers = new HashMap<>();
        headers.put(OperationUtil.PROJECT_ADMIRAL_HEADER, ProjectService.DEFAULT_PROJECT_LINK);
        HttpResponse httpResponse = SimpleHttpsClient.execute(HttpMethod.GET,
                templateSearchUri.toString(), null, headers, null);
        RegistrySearchResponse searchResponse = Utils.fromJson(httpResponse.responseBody,
                RegistrySearchResponse.class);
        assertEquals(2, searchResponse.results.size());
    }",1
"@Test
    public void testForwardIndexHtmlWithXFrameOptions() {
        UiService service = new UiService();
        service.setSelfLink(""/"");
        VerificationHost vh = new VerificationHost() {
            @Override
            public void sendRequest(Operation op) {
                if (op.getUri().getPath().equals(""/index.html"")) {
                    op.setBody(""OK"");
                    op.complete();
                }",1
"@Test
    public void testRedirect() {
        UiService service = new UiService();
        service.setSelfLink(""/sample"");
        service.setHost(new VerificationHost());

        AtomicBoolean completionCalled = new AtomicBoolean();

        service.handleGet(new Operation().setUri(UriUtils.buildUri(""http://localhost/sample""))
                .setCompletion((o, e) -> {
                    assertEquals(""/sample/"", o.getResponseHeader(Operation.LOCATION_HEADER));
                    completionCalled.set(true);

                }",1
"@Test
    public void testMultipleApplications() throws Throwable {
        List<String> tenantLinks = new ArrayList<String>();
        tenantLinks.add(""project1"");
        tenantLinks.add(""project2"");

        ContainerState containerState1 = createContainer(tenantLinks);
        containerState1 = doPost(containerState1, ContainerFactoryService.SELF_LINK);
        ContainerState containerState2 = createContainer(tenantLinks);

        tenantLinks.add(""project3"");
        containerState2 = doPost(containerState2, ContainerFactoryService.SELF_LINK);

        ContainerNetworkState network = createNetwork(tenantLinks);
        network = doPost(network, ContainerNetworkFactoryService.SELF_LINK);

        ContainerVolumeState volume = createVolume(tenantLinks);
        volume = doPost(volume, ContainerVolumeFactoryService.SELF_LINK);

        List<String> componentLinks = new ArrayList<>();
        componentLinks.add(containerState1.documentSelfLink);

        CompositeComponent application = createCompositeComponent(componentLinks);
        application = doPost(application, CompositeComponentFactoryService.SELF_LINK);

        componentLinks = new ArrayList<>();
        componentLinks.add(containerState2.documentSelfLink);
        componentLinks.add(network.documentSelfLink);
        componentLinks.add(volume.documentSelfLink);

        CompositeComponent application2 = createCompositeComponent(componentLinks);
        application2 = doPost(application2, CompositeComponentFactoryService.SELF_LINK);

        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, CompositeComponentsTransformationService.SELF_LINK), false,
                Service.Action.POST);

        application = getDocument(CompositeComponent.class, application.documentSelfLink);
        application2 = getDocument(CompositeComponent.class, application2.documentSelfLink);
        Assert.assertTrue(application.tenantLinks.size() == 2);
        Assert.assertTrue(application.tenantLinks.containsAll(containerState1.tenantLinks));

        Assert.assertTrue(application2.tenantLinks.size() == 3);
        Assert.assertTrue(application2.tenantLinks.containsAll(containerState2.tenantLinks));
        Assert.assertTrue(application2.tenantLinks.containsAll(network.tenantLinks));
        Assert.assertTrue(application2.tenantLinks.containsAll(volume.tenantLinks));
    }",1
"@Test
    public void testSingleApplicationOneContainer() throws Throwable {
        List<String> tenantLinks = new ArrayList<String>();
        tenantLinks.add(""project1"");
        ContainerState containerState = createContainer(tenantLinks);
        containerState = doPost(containerState, ContainerFactoryService.SELF_LINK);
        List<String> componentLinks = new ArrayList<>();
        componentLinks.add(containerState.documentSelfLink);
        CompositeComponent application = createCompositeComponent(componentLinks);
        application = doPost(application, CompositeComponentFactoryService.SELF_LINK);

        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, CompositeComponentsTransformationService.SELF_LINK), false,
                Service.Action.POST);
        application = getDocument(CompositeComponent.class, application.documentSelfLink);
        Assert.assertTrue(application.tenantLinks.size() == 1);
        Assert.assertTrue(application.tenantLinks.containsAll(tenantLinks));
    }",1
"@Test
    public void testThereShouldNotBeDuplicatedTenantLinks() throws Throwable {
        List<String> tenantLinks = new ArrayList<String>();
        tenantLinks.add(""project1"");
        tenantLinks.add(""project2"");

        ContainerState containerState1 = createContainer(tenantLinks);
        containerState1 = doPost(containerState1, ContainerFactoryService.SELF_LINK);
        ContainerState containerState2 = createContainer(tenantLinks);
        containerState2 = doPost(containerState2, ContainerFactoryService.SELF_LINK);

        tenantLinks.add(""project3"");
        ContainerNetworkState network = createNetwork(tenantLinks);
        network = doPost(network, ContainerNetworkFactoryService.SELF_LINK);

        ContainerVolumeState volume = createVolume(tenantLinks);
        volume = doPost(volume, ContainerVolumeFactoryService.SELF_LINK);

        List<String> componentLinks = new ArrayList<>();
        componentLinks.add(containerState1.documentSelfLink);
        componentLinks.add(containerState2.documentSelfLink);
        componentLinks.add(network.documentSelfLink);
        componentLinks.add(volume.documentSelfLink);
        CompositeComponent application = createCompositeComponent(componentLinks);
        application.tenantLinks = new ArrayList<>();
        application.tenantLinks.add(""project1"");
        application.tenantLinks.add(""project2"");
        application = doPost(application, CompositeComponentFactoryService.SELF_LINK);

        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, CompositeComponentsTransformationService.SELF_LINK), false,
                Service.Action.POST);

        application = getDocument(CompositeComponent.class, application.documentSelfLink);
        Assert.assertTrue(application.tenantLinks.size() == 3);
        Assert.assertTrue(application.tenantLinks.containsAll(tenantLinks));
        Assert.assertTrue(application.tenantLinks.containsAll(containerState1.tenantLinks));
        Assert.assertTrue(application.tenantLinks.containsAll(network.tenantLinks));
        Assert.assertTrue(application.tenantLinks.containsAll(volume.tenantLinks));
    }",1
"@Test
    public void testDefaultPlacementDefaultPoolOneHost() throws Throwable {
        List<String> links = getDocumentLinksOfType(ResourcePoolState.class);
        Assert.assertTrue(links.size() == 1);
        ComputeState compute = createComputeState(""host1"",
                GroupResourcePlacementService.DEFAULT_RESOURCE_POOL_LINK);
        compute = doPost(compute, ComputeService.FACTORY_LINK);
        Assert.assertTrue(compute.tagLinks == null);
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ComputePlacementPoolRelationTransformationService.SELF_LINK), false,
                Service.Action.POST);
        compute = getDocument(ComputeState.class, compute.documentSelfLink);
        // check that a tag is added to the compute
        Assert.assertTrue(compute.tagLinks != null);
        Assert.assertTrue(compute.tagLinks.size() == 1);
        Assert.assertTrue(compute.tenantLinks.size() == 1);
        Assert.assertTrue(compute.tenantLinks.get(0).equals(ProjectService.DEFAULT_PROJECT_LINK));
        // Check that the pool has the default project
        ElasticPlacementZoneConfigurationState pool = getDocument(
                ElasticPlacementZoneConfigurationState.class,
                ElasticPlacementZoneConfigurationService.SELF_LINK
                        + links.get(0));
        Assert.assertTrue(pool.epzState.tagLinksToMatch.size() == 1);
        Assert.assertTrue(pool.epzState.tagLinksToMatch.containsAll(compute.tagLinks));
        GroupResourcePlacementState placement = getDocument(GroupResourcePlacementState.class,
                GroupResourcePlacementService.DEFAULT_RESOURCE_PLACEMENT_LINK);
        Assert.assertTrue(placement.tenantLinks.size() == 1);
        Assert.assertTrue(placement.tenantLinks.get(0).equals(ProjectService.DEFAULT_PROJECT_LINK));

        host.testStart(1);
        doPost(compute, ResourcePoolTransformationService.SELF_LINK);
        DeferredResult<List<ComputeState>> hostsWithinPlacementZone = ClusterUtils
                .getHostsWithinPlacementZone(pool.epzState.resourcePoolLink,
                        ProjectService.DEFAULT_PROJECT_LINK, host);
        hostsWithinPlacementZone.whenComplete((computeStates, ex) -> {
            if (ex != null) {
                host.failIteration(ex);
                return;
            }",1
"@Test
    public void testHostWithoutNetworks() throws Throwable {
        List<String> tenantLinks = new ArrayList<String>();
        tenantLinks.add(""project1"");
        ComputeState cs = createComputeState(""TestID1"", tenantLinks);
        cs = doPost(cs, ComputeService.FACTORY_LINK);
        List<String> links = getDocumentLinksOfType(ContainerNetworkState.class);
        Assert.assertTrue(links.isEmpty());
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ContainerNetworksTransformationService.SELF_LINK), false,
                Service.Action.POST);
    }",1
"@Test
    public void testNetworkHasTenantLinks() throws Throwable {
        List<String> tenantLinks = new ArrayList<String>();
        String tenant = ""project1"";
        tenantLinks.add(tenant);
        ComputeState cs = createComputeState(""TestID1"", tenantLinks);
        cs = doPost(cs, ComputeService.FACTORY_LINK);

        ContainerNetworkState containerNetwork1 = createNetwork(cs.documentSelfLink);
        containerNetwork1.tenantLinks = new ArrayList<>();
        containerNetwork1.tenantLinks.add(tenant);
        containerNetwork1 = doPost(containerNetwork1, ContainerNetworkFactoryService.SELF_LINK);
        ContainerNetworkState containerNetwork2 = createNetwork(cs.documentSelfLink);
        containerNetwork2 = doPost(containerNetwork2, ContainerNetworkFactoryService.SELF_LINK);
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ContainerNetworksTransformationService.SELF_LINK), false,
                Service.Action.POST);

        containerNetwork1 = getDocument(ContainerNetworkState.class,
                containerNetwork1.documentSelfLink);
        containerNetwork2 = getDocument(ContainerNetworkState.class,
                containerNetwork2.documentSelfLink);

        Assert.assertTrue(containerNetwork1.tenantLinks.size() == 1);
        Assert.assertTrue(containerNetwork2.tenantLinks.size() == 1);
        Assert.assertTrue(containerNetwork1.tenantLinks.containsAll(tenantLinks));
        Assert.assertTrue(containerNetwork2.tenantLinks.containsAll(tenantLinks));
    }",1
"@Test
    public void testNoNetworksNoHosts() throws Throwable {
        List<String> links = getDocumentLinksOfType(ComputeState.class);
        Assert.assertTrue(links.isEmpty());
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ContainerNetworksTransformationService.SELF_LINK), false,
                Service.Action.POST);
    }",1
"@Test
    public void testMultipleHosts() throws Throwable {
        List<String> tenantLinksHost1 = new ArrayList<String>();
        tenantLinksHost1.add(""project1"");
        tenantLinksHost1.add(""project2"");
        List<String> tenantLinksHost2 = new ArrayList<String>();
        tenantLinksHost2.add(""host2-project"");

        ComputeState cs = createComputeState(""TestID1"", tenantLinksHost1);
        cs = doPost(cs, ComputeService.FACTORY_LINK);
        ComputeState cs2 = createComputeState(""TestID2"", tenantLinksHost2);
        cs2 = doPost(cs2, ComputeService.FACTORY_LINK);

        ContainerState firstContainerHost1 = createContainer(cs.documentSelfLink);
        firstContainerHost1 = doPost(firstContainerHost1, ContainerFactoryService.SELF_LINK);
        ContainerState secondContainerHost1 = createContainer(cs.documentSelfLink);
        secondContainerHost1 = doPost(secondContainerHost1, ContainerFactoryService.SELF_LINK);

        ContainerState firstContainerHost2 = createContainer(cs2.documentSelfLink);
        firstContainerHost2 = doPost(firstContainerHost2, ContainerFactoryService.SELF_LINK);
        ContainerState secondContainerHost2 = createContainer(cs2.documentSelfLink);
        // set tenant links to the container to check that the old tenant links are not overwritten
        secondContainerHost2.tenantLinks = new ArrayList<>();
        String containerTenantLink = ""test-business-group"";
        secondContainerHost2.tenantLinks.add(containerTenantLink);
        secondContainerHost2 = doPost(secondContainerHost2, ContainerFactoryService.SELF_LINK);
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ContainersTransformationService.SELF_LINK), false,
                Service.Action.POST);

        firstContainerHost1 = getDocument(ContainerState.class,
                firstContainerHost1.documentSelfLink);
        secondContainerHost1 = getDocument(ContainerState.class,
                secondContainerHost1.documentSelfLink);
        firstContainerHost2 = getDocument(ContainerState.class,
                firstContainerHost2.documentSelfLink);
        secondContainerHost2 = getDocument(ContainerState.class,
                secondContainerHost2.documentSelfLink);

        Assert.assertTrue(firstContainerHost1.tenantLinks.containsAll(tenantLinksHost1));
        Assert.assertTrue(secondContainerHost1.tenantLinks.containsAll(tenantLinksHost1));
        Assert.assertTrue(secondContainerHost1.tenantLinks.equals(firstContainerHost1.tenantLinks));

        Assert.assertTrue(firstContainerHost2.tenantLinks.containsAll(tenantLinksHost2));
        Assert.assertTrue(secondContainerHost2.tenantLinks.containsAll(tenantLinksHost2));
        Assert.assertTrue(secondContainerHost2.tenantLinks
                .size() == firstContainerHost2.tenantLinks.size() + 1);
        Assert.assertTrue(secondContainerHost2.tenantLinks.contains(containerTenantLink));
    }",1
"@Test
    public void testNoContainersNoHosts() throws Throwable {
        List<String> links = getDocumentLinksOfType(ComputeState.class);
        Assert.assertTrue(links.isEmpty());
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ContainersTransformationService.SELF_LINK), false,
                Service.Action.POST);
    }",1
"@Test
    public void testVolumeHasTenantLinks() throws Throwable {
        List<String> tenantLinks = new ArrayList<String>();
        tenantLinks.add(""project1"");
        String commonTenantLink = ""tenant"";
        tenantLinks.add(commonTenantLink);
        ComputeState cs = createComputeState(""TestID1"", tenantLinks);
        cs = doPost(cs, ComputeService.FACTORY_LINK);

        ContainerVolumeState containerVolume1 = createVolume(cs.documentSelfLink);
        containerVolume1.tenantLinks = new ArrayList<>();
        containerVolume1.tenantLinks.add(commonTenantLink);
        containerVolume1 = doPost(containerVolume1, ContainerVolumeFactoryService.SELF_LINK);
        ContainerVolumeState containerVolume2 = createVolume(cs.documentSelfLink);
        containerVolume2 = doPost(containerVolume2, ContainerVolumeFactoryService.SELF_LINK);
        doOperation(new ServiceDocument(),
                UriUtils.buildUri(host, ContainerVolumesTransformationService.SELF_LINK), false,
                Service.Action.POST);

        containerVolume1 = getDocument(ContainerVolumeState.class,
                containerVolume1.documentSelfLink);
        containerVolume2 = getDocument(ContainerVolumeState.class,
                containerVolume2.documentSelfLink);

        Assert.assertTrue(containerVolume1.tenantLinks.size() == 2);
        Assert.assertTrue(containerVolume2.tenantLinks.size() == 2);
        Assert.assertTrue(containerVolume1.tenantLinks.containsAll(tenantLinks));
        Assert.assertTrue(containerVolume2.tenantLinks.containsAll(tenantLinks));
    }",1
"@Test
    public void testNoPlacementsForPool() throws Throwable {
        ResourcePoolState pool1 = createResourcePool();
        doPost(pool1, ResourcePoolTransformationService.SELF_LINK);
        pool1 = getDocument(ResourcePoolState.class, pool1.documentSelfLink);
        Assert.assertTrue(pool1.tenantLinks == null);
    }",1
"@Test
    public void testPlacementsBolongToDifferentPools() throws Throwable {
        ResourcePoolState pool1 = createResourcePool();

        GroupResourcePlacementState placement1 = new GroupResourcePlacementState();
        placement1.name = ""placement"";
        placement1.resourcePoolLink = pool1.documentSelfLink;
        placement1.tenantLinks = new ArrayList<>();
        placement1.tenantLinks.add(""tenant1"");
        placement1 = doPost(placement1, GroupResourcePlacementService.FACTORY_LINK);

        ResourcePoolState pool2 = createResourcePool();
        GroupResourcePlacementState placement2 = new GroupResourcePlacementState();
        placement2.name = ""placement2"";
        placement2.resourcePoolLink = pool2.documentSelfLink;
        placement2.tenantLinks = new ArrayList<>();
        placement2.tenantLinks.add(""tenant2"");
        placement2 = doPost(placement2, GroupResourcePlacementService.FACTORY_LINK);

        doPost(placement2, ResourcePoolTransformationService.SELF_LINK);
        pool1 = getDocument(ResourcePoolState.class, pool1.documentSelfLink);
        pool2 = getDocument(ResourcePoolState.class, pool2.documentSelfLink);

        // verify the tenant links of the pools
        Assert.assertTrue(pool1.tenantLinks.size() == 1);
        Assert.assertTrue(pool2.tenantLinks.size() == 1);
        Assert.assertTrue(pool1.tenantLinks.contains(""tenant1""));
        Assert.assertTrue(pool2.tenantLinks.contains(""tenant2""));

        // Verify that the pools are not changed
        Assert.assertTrue(getDocument(GroupResourcePlacementState.class,
                placement1.documentSelfLink).resourcePoolLink.equals(pool1.documentSelfLink));
        Assert.assertTrue(getDocument(GroupResourcePlacementState.class,
                placement2.documentSelfLink).resourcePoolLink.equals(pool2.documentSelfLink));
    }",1
"@Test
    public void testGetSendStream() throws IOException {

        TestRemoteEndpoint tre = new TestRemoteEndpoint();
        TyrusSession testSession = createTestSession(tre, endpointWrapper);
        TyrusRemoteEndpoint.Basic rew = new TyrusRemoteEndpoint.Basic(testSession, tre, endpointWrapper);
        OutputStream stream = rew.getSendStream();

        for (byte b : sentBytes) {
            stream.write(b);
        }",1
"@Test
  public void singleSslSocketFactory() {
    HttpRequest request1 = get(""https://localhost"").trustAllCerts();
    HttpRequest request2 = get(""https://localhost"").trustAllCerts();
    assertNotNull(((HttpsURLConnection) request1.getConnection())
        .getSSLSocketFactory());
    assertNotNull(((HttpsURLConnection) request2.getConnection())
        .getSSLSocketFactory());
    assertEquals(
        ((HttpsURLConnection) request1.getConnection()).getSSLSocketFactory(),
        ((HttpsURLConnection) request2.getConnection()).getSSLSocketFactory());
  }",1
"@Test
    public void testNormal01() throws Exception {
        // start mock fluentd
        int port = MockFluentd.randomPort();
        final List<Event> elist = new ArrayList<Event>();
        MockFluentd fluentd = new MockFluentd(port, new MockFluentd.MockProcess() {
            public void process(MessagePack msgpack, Socket socket) throws IOException {
                BufferedInputStream in = new BufferedInputStream(socket.getInputStream());
                try {
                    Unpacker unpacker = msgpack.createUnpacker(in);
                    while (true) {
                        Event e = unpacker.read(Event.class);
                        elist.add(e);
                    }",1
"@Test
    public void testReconnection() throws Exception {
        // start mock fluentd
        int port = MockFluentd.randomPort();
        String host = ""localhost"";
        final List<Event> elist1 = new ArrayList<Event>();
        final AtomicReference<Exception> lastError = new AtomicReference<Exception>();

        FixedThreadManager threadManager = new FixedThreadManager(2);

        // run a fluentd
        MockFluentd fluentd1 = new MockFluentd(port, new MockFluentd.MockProcess() {
            public void process(MessagePack msgpack, Socket socket) throws IOException {
                BufferedInputStream in = new BufferedInputStream(socket.getInputStream());
                try {
                    Unpacker unpacker = msgpack.createUnpacker(in);
                    while (true) {
                        Event e = unpacker.read(Event.class);
                        elist1.add(e);

                        if (elist1.size() >= 1)
                            break;
                    }",1
"@Test
    public void process() throws IOException {
        List<String> sources = Arrays.asList(
                new File(packagePath, ""IntegerExtensions.java"").getPath(),
                new File(packagePath, ""ExampleEntity2.java"").getPath());
        process(QuerydslAnnotationProcessor.class, sources, ""integerExtensions"");
                String qtypeContent = new String(Files.readAllBytes(Paths.get(""target"", ""integerExtensions"", ""com"", ""querydsl"", ""QExampleEntity2.java"")), StandardCharsets.UTF_8);
        //The superclass' id property is inherited, but can't be assigned to the custom QInteger
        assertTrue(qtypeContent.contains(""public final ext.java.lang.QInteger id = new ext.java.lang.QInteger(_super.id);""));
    }",1
"@Test
    public void process_abstractClasses2() throws IOException {
        String path = new File(""src/test/java/com/querydsl/apt/domain/AbstractClasses2Test.java"").getPath();
        process(JPAAnnotationProcessor.class, Collections.singletonList(path),""abstractClasses2"");
    }",1
"@Test
    public void process_generic13Test() throws IOException {
        String path = new File(""src/test/java/com/querydsl/apt/domain/Generic13Test.java"").getPath();
        process(QuerydslAnnotationProcessor.class, Collections.singletonList(path),""Generic13Test"");
    }",1
"@Test
    public void process_inheritance2Test() throws IOException {
        String path = new File(""src/test/java/com/querydsl/apt/inheritance/Inheritance2Test.java"").getPath();
        process(QuerydslAnnotationProcessor.class, Collections.singletonList(path),""InheritanceTest2"");
    }",1
"@Test
    public void process_monitoredCompany() throws IOException {
        String path = new File(PACKAGE_PATH, ""MonitoredCompany.java"").getPath();
        process(QuerydslAnnotationProcessor.class, Collections.singletonList(path),""MonitoredCompany"");
    }",1
"@Test
    public void process_queryEmbedded4() throws IOException {
        String path = new File(""src/test/java/com/querydsl/apt/domain/QueryEmbedded4Test.java"").getPath();
        process(QuerydslAnnotationProcessor.class, Collections.singletonList(path),""QueryEmbedded4Test"");
    }",1
"@Test
    public void rooAnnotationProcessor() throws IOException {
        process(RooAnnotationProcessor.class, CLASSES, ""roo"");

        assertTrue(new File(""target/roo/com/querydsl/apt/domain/QRooEntities_MyEntity.java"").exists());
    }",1
"@Test
    public void verify_package() throws Exception {
        String version = System.getProperty(""version"");
        verify(new File(""target/querydsl-jdo-"" + version + ""-apt-one-jar.jar""));
    }",1
"@Test
    public void verify_package() throws Exception {
        String version = System.getProperty(""version"");
        verify(new File(""target/querydsl-jdo-"" + version + ""-apt-one-jar.jar""));
    }",1
"@Test
  public void testRDF() throws Exception {
    Path tempDir = getTempDir();
    Path dataDir = tempDir.resolve(""data"");
    Path modelDir = tempDir.resolve(""model"");

    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.batch.update-class"", RDFUpdate.class.getName());
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.data-dir"", dataDir);
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.model-dir"", modelDir);
    overlayConfig.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC);
    overlayConfig.put(""oryx.rdf.num-trees"", 10);
    // Low values like 1 are deliberately bad, won't work
    overlayConfig.put(""oryx.rdf.hyperparams.max-depth"", ""[1,"" + MAX_DEPTH + ""]"");
    overlayConfig.put(""oryx.rdf.hyperparams.max-split-candidates"", MAX_SPLIT_CANDIDATES);
    overlayConfig.put(""oryx.input-schema.num-features"", 5);
    overlayConfig.put(""oryx.input-schema.categorical-features"", ""[\""4\""]"");
    overlayConfig.put(""oryx.input-schema.id-features"", ""[\""0\""]"");
    overlayConfig.put(""oryx.input-schema.target-feature"", ""\""4\"""");
    overlayConfig.put(""oryx.ml.eval.candidates"", 2);
    overlayConfig.put(""oryx.ml.eval.parallelism"", 2);
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    startServerProduceConsumeTopics(
        config,
        new RandomCategoricalRDFDataGenerator(3),
        DATA_TO_WRITE,
        WRITE_INTERVAL_MSEC);

    List<Path> modelInstanceDirs = IOUtils.listFiles(modelDir, ""*"");

    checkIntervals(modelInstanceDirs.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC);

    Path latestModelDir = modelInstanceDirs.get(modelInstanceDirs.size() - 1);
    Path modelFile = latestModelDir.resolve(MLUpdate.MODEL_FILE_NAME);
    assertTrue(""No such model file: "" + modelFile, Files.exists(modelFile));

    PMML pmml = PMMLUtils.read(modelFile);

    assertEquals(3, pmml.getExtensions().size());
    Map<String,Object> expected = new HashMap<>();
    expected.put(""maxSplitCandidates"", MAX_SPLIT_CANDIDATES);
    expected.put(""maxDepth"", MAX_DEPTH);
    expected.put(""impurity"", IMPURITY);
    checkExtensions(pmml, expected);

    Pair<DecisionForest,CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(pmml);
    DecisionForest forest = forestEncoding.getFirst();
    CategoricalValueEncodings encoding = forestEncoding.getSecond();
    Map<String,Integer> targetEncoding = encoding.getValueEncodingMap(4);

    int[] zeroOne = { 0, 1 }",1
"@Test
  public void testReadPMMLFromMessage() throws Exception {
    PMML pmml = PMMLUtils.buildSkeletonPMML();
    String pmmlString = PMMLUtils.toString(pmml);
    assertEquals(PMMLUtils.VERSION, AppPMMLUtils.readPMMLFromUpdateKeyMessage(
        ""MODEL"", pmmlString, null).getVersion());

    Path pmmlPath = getTempDir().resolve(""out.pmml"");
    Files.write(pmmlPath, Collections.singleton(pmmlString));
    assertEquals(PMMLUtils.VERSION, AppPMMLUtils.readPMMLFromUpdateKeyMessage(
        ""MODEL-REF"", pmmlPath.toAbsolutePath().toString(), null).getVersion());

    assertNull(AppPMMLUtils.readPMMLFromUpdateKeyMessage(""MODEL-REF"", ""no-such-path"", null));
  }",1
"@Test
  public void testAllItemIDs() {
    List<String> users = target(""/user/allIDs"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_STRING_TYPE);
    Assert.assertEquals(7, users.size());
    for (int user = 0; user < 7; user++) {
      OryxTest.assertContains(users, ""U"" + user);
    }",1
"@Test
  public void testEmptyItems() {
    List<String> items = target(""/knownItems/X1"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_STRING_TYPE);
    Assert.assertEquals(0, items.size());
  }",1
"@Test
  public void testRescorer() {
    List<IDCount> top = target(""/mostPopularItems"").queryParam(""rescorerParams"", ""foo"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_ID_COUNT_TYPE);
    Assert.assertEquals(4, top.size());
    Assert.assertEquals(6, top.get(0).getCount());
    Assert.assertEquals(5, top.get(1).getCount());
  }",1
"@Test
  public void testDelete() {
    Response response = target(""/pref/U1/I2"").request().delete();
    checkResponse(response, ""U1"", ""I2"", """");
  }",1
"@Test
  public void testPostWithBadItemValue() {
    try (Response response = target(""/pref/U2/I2"").request().post(Entity.text(""aBc!""))) {
      Assert.assertEquals(Response.Status.BAD_REQUEST.getStatusCode(), response.getStatus());
    }",1
"@Test
  public void testRecommendToAnonymous() {
    List<IDValue> recs = target(""/recommendToAnonymous/I4=1.0/I5=2.0"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_ID_VALUE_TYPE);
    testTopByValue(7, recs, false);
    Assert.assertEquals(""I7"", recs.get(0).getID());
    Assert.assertEquals(0.35964763f, recs.get(0).getValue(), FLOAT_EPSILON);
  }",1
"@Test
  public void testRescorer() {
    List<IDValue> recs = target(""/recommendToAnonymous/I4=1.0/I5=2.0"")
        .queryParam(""rescorerParams"", ""foo"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_ID_VALUE_TYPE);
    testTopByValue(3, recs, false);
    Assert.assertEquals(""I7"", recs.get(0).getID());
    Assert.assertEquals(2.0f * 0.35964763f, recs.get(0).getValue(), FLOAT_EPSILON);
  }",1
"@Test
  public void testHowMany() {
    testHowMany(""/recommendWithContext/U5/"", 10, 2);
    testHowMany(""/recommendWithContext/U5/"", 2, 2);
    testHowMany(""/recommendWithContext/U5/"", 1, 1);
  }",1
"@Test
  public void testRecommendWithContextWithUnknown() {
    String response = target(""/recommendWithContext/U0/foo/I4=1.0/I5=2.0"").request().get(String.class);
    testCSVTopByScore(5, response);
  }",1
"@Test
  public void testRescorer() {
    List<IDValue> recs = target(""similarity/I0/I4/I6"")
        .queryParam(""rescorerParams"", ""foo"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_ID_VALUE_TYPE);
    testTopByValue(4, recs, false);
    Assert.assertEquals(""I5"", recs.get(1).getID());
    Assert.assertEquals(2.0 * 0.9125432970065859, recs.get(2).getValue(), DOUBLE_EPSILON);
  }",1
"@Test
  public void testSimilarityCSV() {
    String response = target(""/similarity/I0/I4/I6"").request().get(String.class);
    testCSVTopByScore(6, response);
  }",1
"@Test
  public void testZeroSimilarityToItem() {
    List<Double> items = target(""/similarityToItem/I1/I10"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_DOUBLE_TYPE);
    Assert.assertEquals(1, items.size());
    Assert.assertEquals(0.0f, items.get(0), FLOAT_EPSILON);
  }",1
"@Test
  public void testAssign2() {
    String prediction = target(""/assign/10,-1.0"").request().get(String.class);
    Assert.assertEquals(3, Integer.parseInt(prediction));
  }",1
"@Test
  public void testConsole() {
    String html;
    try (Response response = target(""/index.html"").request().accept(MediaType.TEXT_HTML).get()) {
      Assert.assertEquals(""public"", response.getHeaderString(""Cache-Control""));
      Assert.assertEquals(""SAMEORIGIN"", response.getHeaderString(""X-Frame-Options""));
      html = response.readEntity(String.class);
    }",1
"@Test
  public void testGet() {
    try (Response response = target(""/ready"").request().get()) {
      Assert.assertEquals(Response.Status.OK.getStatusCode(), response.getStatus());
    }",1
"@Test
  public void testDistribution() {
    List<IDValue> recs = target(""/classificationDistribution/B,0,"").request()
        .accept(MediaType.APPLICATION_JSON_TYPE).get(LIST_ID_VALUE_TYPE);
    Assert.assertEquals(""X"", recs.get(0).getID());
    Assert.assertEquals((10.0 / 90.0 + 2 * (1000.0 / 111000.0)) / 3,
                        recs.get(0).getValue(),
                        OryxTest.DOUBLE_EPSILON);
    Assert.assertEquals(""Y"", recs.get(1).getID());
    Assert.assertEquals((30.0 / 90.0 + 2 * (10000.0 / 111000.0)) / 3,
                        recs.get(1).getValue(),
                        OryxTest.DOUBLE_EPSILON);
    Assert.assertEquals(""Z"", recs.get(2).getID());
    Assert.assertEquals((50.0 / 90.0 + 2 * (100000.0 / 111000.0)) / 3,
                        recs.get(2).getValue(),
                        OryxTest.DOUBLE_EPSILON);
  }",1
"@Test
  public void testConsole() {
    String html;
    try (Response response = target(""/index.html"").request().accept(MediaType.TEXT_HTML).get()) {
      Assert.assertEquals(""public"", response.getHeaderString(""Cache-Control""));
      Assert.assertEquals(""SAMEORIGIN"", response.getHeaderString(""X-Frame-Options""));
      html = response.readEntity(String.class);
    }",1
"@Test
  public void testFormPredict() throws Exception {
    checkResponse(getFormPostResponse(PREDICT_DATA, ""/predict"", null, null));
  }",1
"@Test
  public void testALSSpeed() throws Exception {
    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.speed.model-manager-class"", ALSSpeedModelManager.class.getName());
    overlayConfig.put(""oryx.speed.streaming.generation-interval-sec"", 5);
    overlayConfig.put(""oryx.als.hyperparams.features"", 2);
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    List<KeyMessage<String,String>> updates =
        startServerProduceConsumeTopics(config,
                                        new MockALSInputGenerator(),
                                        new MockALSModelUpdateGenerator(),
                                        10, 10);

    if (log.isDebugEnabled()) {
      updates.forEach(update -> log.debug(""{}",1
"@Test
  public void testDeleteRecursively() throws IOException {
    Path testDir = createTestDirs();
    IOUtils.deleteRecursively(testDir);
    assertFalse(Files.exists(testDir));
    assertFalse(Files.exists(testDir.resolve(""subFile1"")));
  }",1
"@Test
  public void testListSubdirs2() throws IOException {
    Path testDir = createTestDirs();
    List<Path> files = IOUtils.listFiles(testDir, ""*/subFile*"");
    assertEquals(1, files.size());
    assertContains(files, testDir.resolve(""subDir1"").resolve(""subFile2""));
  }",1
"@Test
  public void testDeleteOldData() throws Exception {
    Path tempDir = getTempDir();
    Path dataDir = tempDir.resolve(""data"");
    Path modelDir = tempDir.resolve(""model"");
    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.batch.update-class"", MockBatchUpdate.class.getName());
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.data-dir"", dataDir);
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.model-dir"", modelDir);
    overlayConfig.put(""oryx.batch.storage.max-age-data-hours"", 0);
    overlayConfig.put(""oryx.batch.storage.max-age-model-hours"", 0);
    overlayConfig.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC);
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();
    startServerProduceConsumeTopics(config, DATA_TO_WRITE, WRITE_INTERVAL_MSEC);
    assertEquals(0, IOUtils.listFiles(dataDir, ""*"").size());
    assertEquals(0, IOUtils.listFiles(modelDir, ""*"").size());
  }",1
"@Test
  public void testUserPassword() throws Exception {
    startServer(buildUserPasswordConfig());

    Authenticator.setDefault(new Authenticator() {
      @Override
      protected PasswordAuthentication getPasswordAuthentication() {
        return new PasswordAuthentication(""oryx"", ""pass"".toCharArray());
      }",1
"@Test
  public void testMLUpdate() throws Exception {
    Path tempDir = getTempDir();
    Path dataDir = tempDir.resolve(""data"");
    Map<String,Object> overlayConfig = new HashMap<>();
    overlayConfig.put(""oryx.batch.update-class"", MockMLUpdate.class.getName());
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.data-dir"", dataDir);
    ConfigUtils.set(overlayConfig, ""oryx.batch.storage.model-dir"", tempDir.resolve(""model""));
    overlayConfig.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC);
    overlayConfig.put(""oryx.ml.eval.test-fraction"", TEST_FRACTION);
    overlayConfig.put(""oryx.ml.eval.threshold"", DATA_TO_WRITE / 2); // Should easily pass threshold
    Config config = ConfigUtils.overlayOn(overlayConfig, getConfig());

    startMessaging();

    List<Integer> trainCounts = MockMLUpdate.getResetTrainCounts();
    List<Integer> testCounts = MockMLUpdate.getResetTestCounts();

    startServerProduceConsumeTopics(config, DATA_TO_WRITE, WRITE_INTERVAL_MSEC);

    // If lists are unequal at this point, there must have been an empty test set
    // which yielded no call to evaluate(). Fill in the blank
    while (trainCounts.size() > testCounts.size()) {
      testCounts.add(0);
    }",1
"@Test
    public void deleteCurrentBranch() throws Exception {
        FileUtil.delete(localGitPath);
        RepositoryManager.create(localGitPath, null);
        RepositoryManager.checkoutExistingBranchOrCreateOrphan(localGitPath, true, null, null, ""newBranch"");

        // as the current branch is ""newBranch"" the deletion will go to tmp branch
        RepositoryManager.deleteBranch(localGitPath, ""newBranch"", false);

        assertThat(RepositoryManager.isOnBranch(localGitPath, ""tmp"")).isTrue();
    }",1
"@Test
    public void migrate_data_previously_store_in_elastic_search() throws Exception {
        String existingId = AbstractDeploymentConfig.generateId(""versionOK"", ""envId"");

        // given a configuration store in ES
        when(alienDao.findById(DeploymentMatchingConfiguration.class, existingId)).thenReturn(new DeploymentMatchingConfiguration(""versionOK"", ""envId""));
        // given the location of the existing config is defined
        Path configLocalPath = Paths.get(""target/deployment_config_dao_test/config"");
        Files.deleteIfExists(configLocalPath);
        when(localGitRepositoryPathResolver.resolve(eq(DeploymentMatchingConfiguration.class), eq(existingId))).thenReturn(configLocalPath);

        // when looking for a config that not existing in Git yet
        DeploymentMatchingConfiguration config = dao.findById(DeploymentMatchingConfiguration.class, existingId);

        // then we get data from ES
        assertThat(config).isNotNull();
        assertThat(config.getId()).isEqualTo(existingId);
        // ES data has been deleted
        verify(alienDao).delete(DeploymentMatchingConfiguration.class, existingId);
        // check data has been migrated into git
        assertThat(Files.exists(configLocalPath)).isTrue();
    }",1
"@Test
    public void testRocksDBInjector() throws Exception {
        RocksDBManager dbManager = new RocksDBManager(tempCrawlPath);
        testInject(dbManager);
    }",1
"@Test
    public void testReportTrigger() {
        XmlHttpResponse resp = new XmlHttpResponse();
        UnitTestHelper.fillResponse(resp, ""leanapps/report.xml"");
        resp.setStatusCode(200);
        fixture.setResponse(resp);
        assertEquals(""NEW_POLICY_NEW_CUSTOMER"", fixture.reportTrigger());
    }",1
"@Test
    public void testParseLalResponse() {
        XmlHttpResponse lalResponse = new XmlHttpResponse();
        UnitTestHelper.fillResponse(lalResponse, ""leanapps/getPolicyCheckResponse.xml"");
        String key = lalResponse.toString();
        assertSame(lalResponse, HttpResponse.parse(key));
    }",1
"@Test
    public void testFindChromedriverExecutable() {
        String exec = factoryFactory.getExecutable(""chromedriver"");

        assertNotNull(""No executable found for chromedriver"", exec);
        File execFile = new File(exec);
        assertTrue(""Executable for chromedriver does not exist: "" + exec, execFile.exists());
        assertTrue(""Executable for chromedriver not executable: "" + exec, execFile.canExecute());
    }",1
"@Test
    public void testTrimElements() {
        String expected = FileUtil.loadFile(""GetWeatherSoapResponse.xml"");
        String formatted = FileUtil.loadFile(""GetWeatherSoapResponseFormatted.xml"");

        String trimmed = XMLFormatter.trimElements(formatted);

        assertEquals(expected, trimmed);
        assertEquals(expected, XMLFormatter.trimElements(trimmed));
    }",1
"@Test
    public void testAllXmlNoText() {
        LalPolicyXPaths.registerNamespace();
        String responseString = FileUtil.loadFile(""leanapps/getPolicyCheckResponse.xml"");
        List<String> all = xPathHelper.getAllXPath(NS_CONTEXT, responseString, ""//*/@xsi:type"");

        assertEquals(13, all.size());
        assertEquals(""ns:PostalAddress"", all.get(1));
    }",1
"@Test
    public void testBadXPath() {
        String responseString = FileUtil.loadFile(""leanapps/getPolicyCheckResponse.xml"");
        assertEquals("""", xPathHelper.getXPath(null, responseString, ""//status""));
        try {
            xPathHelper.getXPath(null, responseString, ""\\status"");
            fail(""expected exception"");
        }",1
"@Test
    public void testXPathWithNamespace() {
        LalPolicyXPaths.registerNamespace();
        String responseString = FileUtil.loadFile(""leanapps/getPolicyCheckResponse.xml"");
        assertEquals(""OK"", xPathHelper.getXPath(NS_CONTEXT, responseString, ""//lal:status/lal:status""));
    }",1
"@Test
    public void testDatabaseCreation() {
        DatabaseSynchronizer dbSynchronizer = new DatabaseSynchronizer();

        dbSynchronizer.drop();
        assertFalse(dbSynchronizer.databaseExists());

        dbSynchronizer.create();
        assertTrue(dbSynchronizer.databaseExists());

        dbSynchronizer.drop();
    }",1
"@Test
    public void testEndpointFilename() {
        assertEquals(""person/Person.java"", new EndpointNaming(""Person"").getFilename());
        assertEquals(""personaddress/PersonAddress.java"", new EndpointNaming(""PersonAddress"").getFilename());
    }",1
"@Test
    public void testEndpointPath() {
        assertEquals(""people"", new EndpointNaming(""Person"").getPath());
        assertEquals(""person-addresses"", new EndpointNaming(""PersonAddress"").getPath());
        assertEquals(""parents"", new EndpointNaming(""Parent"").getPath());
        assertEquals(""parent-addresses"", new EndpointNaming(""ParentAddress"").getPath());
        assertEquals(""children"", new EndpointNaming(""Child"").getPath());
        assertEquals(""grandchildren"", new EndpointNaming(""Grandchild"").getPath());
    }",1
"@Test
    public void testShowFacade() {
        saveObject(1l, ""xpto"", 10);

        login(""amy"");

        String json = get(""/shielded_objects/1"");
        ShieldedObject retrievedObject = from(json, ShieldedObject.class);

        assertEquals(""xpto"", retrievedObject.getStringValue());
        assertNull(retrievedObject.getIntValue());
    }",1
"@Test
  public void testRetrieveFromFile() throws Exception {
    Path testDir = createAndGetTestDir();
    String ioEngineName = ""file:"" + testDir + ""/bucket.cache"";
    testRetrievalUtils(testDir, ioEngineName);
    int[] smallBucketSizes = new int[] { 3 * 1024, 5 * 1024 }",1
"@Test
  public void testCPRequestCost() {
    // in order to pass needsBalance judgement
    conf.setFloat(""hbase.master.balancer.stochastic.cpRequestCost"", 10000f);
    loadBalancer.onConfigurationChange(conf);
    // mock cluster State
    Map<ServerName, List<RegionInfo>> clusterState = new HashMap<ServerName, List<RegionInfo>>();
    ServerName serverA = randomServer(3).getServerName();
    ServerName serverB = randomServer(3).getServerName();
    ServerName serverC = randomServer(3).getServerName();
    List<RegionInfo> regionsOnServerA = randomRegions(3);
    List<RegionInfo> regionsOnServerB = randomRegions(3);
    List<RegionInfo> regionsOnServerC = randomRegions(3);
    clusterState.put(serverA, regionsOnServerA);
    clusterState.put(serverB, regionsOnServerB);
    clusterState.put(serverC, regionsOnServerC);
    // mock ClusterMetrics
    Map<ServerName, ServerMetrics> serverMetricsMap = new TreeMap<>();
    serverMetricsMap.put(serverA, mockServerMetricsWithCpRequests(regionsOnServerA, 0));
    serverMetricsMap.put(serverB, mockServerMetricsWithCpRequests(regionsOnServerB, 0));
    serverMetricsMap.put(serverC, mockServerMetricsWithCpRequests(regionsOnServerC, 0));
    ClusterMetrics clusterStatus = mock(ClusterMetrics.class);
    when(clusterStatus.getLiveServerMetrics()).thenReturn(serverMetricsMap);
    loadBalancer.updateClusterMetrics(clusterStatus);

    // CPRequestCostFunction are Rate based, So doing setClusterMetrics again
    // this time, regions on serverA with more cpRequestCount load
    // serverA : 1000,1000,1000
    // serverB : 0,0,0
    // serverC : 0,0,0
    // so should move two regions from serverA to serverB & serverC
    serverMetricsMap = new TreeMap<>();
    serverMetricsMap.put(serverA, mockServerMetricsWithCpRequests(regionsOnServerA, 1000));
    serverMetricsMap.put(serverB, mockServerMetricsWithCpRequests(regionsOnServerB, 0));
    serverMetricsMap.put(serverC, mockServerMetricsWithCpRequests(regionsOnServerC, 0));
    clusterStatus = mock(ClusterMetrics.class);
    when(clusterStatus.getLiveServerMetrics()).thenReturn(serverMetricsMap);
    loadBalancer.updateClusterMetrics(clusterStatus);

    List<RegionPlan> plans =
      loadBalancer.balanceTable(HConstants.ENSEMBLE_TABLE_NAME, clusterState);
    Set<RegionInfo> regionsMoveFromServerA = new HashSet<>();
    Set<ServerName> targetServers = new HashSet<>();
    for (RegionPlan plan : plans) {
      if (plan.getSource().equals(serverA)) {
        regionsMoveFromServerA.add(plan.getRegionInfo());
        targetServers.add(plan.getDestination());
      }",1
"@Test
  public void testAppendWithReadOnlyTable() throws Exception {
    final TableName tableName = TableName.valueOf(name.getMethodName());
    this.region = initHRegion(tableName, method, CONF, true, Bytes.toBytes(""somefamily""));
    boolean exceptionCaught = false;
    Append append = new Append(Bytes.toBytes(""somerow""));
    append.setDurability(Durability.SKIP_WAL);
    append.addColumn(Bytes.toBytes(""somefamily""), Bytes.toBytes(""somequalifier""),
      Bytes.toBytes(""somevalue""));
    try {
      region.append(append);
    }",1
"@Test
  public void testAtomicBatchPut() throws IOException {
    final Put[] puts = new Put[10];
    MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);
    long syncs = prepareRegionForBachPut(puts, source, false);

    // 1. Straight forward case, should succeed
    OperationStatus[] codes = this.region.batchMutate(puts, true);
    assertEquals(10, codes.length);
    for (int i = 0; i < 10; i++) {
      assertEquals(OperationStatusCode.SUCCESS, codes[i].getOperationStatusCode());
    }",1
"@Test
  public void testBatchPut_whileNoRowLocksHeld() throws IOException {
    final Put[] puts = new Put[10];
    MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);
    long syncs = prepareRegionForBachPut(puts, source, false);

    OperationStatus[] codes = this.region.batchMutate(puts);
    assertEquals(10, codes.length);
    for (int i = 0; i < 10; i++) {
      assertEquals(OperationStatusCode.SUCCESS, codes[i].getOperationStatusCode());
    }",1
"@Test
  public void testBatchPutWithTsSlop() throws Exception {
    // add data with a timestamp that is too recent for range. Ensure assert
    CONF.setInt(""hbase.hregion.keyvalue.timestamp.slop.millisecs"", 1000);
    final Put[] puts = new Put[10];
    MetricsWALSource source = CompatibilitySingletonFactory.getInstance(MetricsWALSource.class);

    long syncs = prepareRegionForBachPut(puts, source, true);

    OperationStatus[] codes = this.region.batchMutate(puts);
    assertEquals(10, codes.length);
    for (int i = 0; i < 10; i++) {
      assertEquals(OperationStatusCode.SANITY_CHECK_FAILURE, codes[i].getOperationStatusCode());
    }",1
"@Test
  public void testCellTTLs() throws IOException {
    IncrementingEnvironmentEdge edge = new IncrementingEnvironmentEdge();
    EnvironmentEdgeManager.injectEdge(edge);

    final byte[] row = Bytes.toBytes(""testRow"");
    final byte[] q1 = Bytes.toBytes(""q1"");
    final byte[] q2 = Bytes.toBytes(""q2"");
    final byte[] q3 = Bytes.toBytes(""q3"");
    final byte[] q4 = Bytes.toBytes(""q4"");

    // 10 seconds
    TableDescriptor tableDescriptor =
      TableDescriptorBuilder.newBuilder(TableName.valueOf(name.getMethodName()))
        .setColumnFamily(ColumnFamilyDescriptorBuilder.newBuilder(fam1).setTimeToLive(10).build())
        .build();

    Configuration conf = new Configuration(TEST_UTIL.getConfiguration());
    conf.setInt(HFile.FORMAT_VERSION_KEY, HFile.MIN_FORMAT_VERSION_WITH_TAGS);

    region = HBaseTestingUtil.createRegionAndWAL(
      RegionInfoBuilder.newBuilder(tableDescriptor.getTableName()).build(),
      TEST_UTIL.getDataTestDir(), conf, tableDescriptor);
    assertNotNull(region);
    long now = EnvironmentEdgeManager.currentTime();
    // Add a cell that will expire in 5 seconds via cell TTL
    region.put(new Put(row).add(new KeyValue(row, fam1, q1, now, HConstants.EMPTY_BYTE_ARRAY,
      new ArrayBackedTag[] {
        // TTL tags specify ts in milliseconds
        new ArrayBackedTag(TagType.TTL_TAG_TYPE, Bytes.toBytes(5000L)) }",1
"@Test
  public void testCheckAndMutateTimestampsAreMonotonic() throws IOException {
    region = initHRegion(tableName, method, CONF, fam1);
    ManualEnvironmentEdge edge = new ManualEnvironmentEdge();
    EnvironmentEdgeManager.injectEdge(edge);

    edge.setValue(10);
    Put p = new Put(row);
    p.setDurability(Durability.SKIP_WAL);
    p.addColumn(fam1, qual1, qual1);
    region.put(p);

    Result result = region.get(new Get(row));
    Cell c = result.getColumnLatestCell(fam1, qual1);
    assertNotNull(c);
    assertEquals(10L, c.getTimestamp());

    edge.setValue(1); // clock goes back
    p = new Put(row);
    p.setDurability(Durability.SKIP_WAL);
    p.addColumn(fam1, qual1, qual2);
    region.checkAndMutate(row, fam1, qual1, CompareOperator.EQUAL, new BinaryComparator(qual1), p);
    result = region.get(new Get(row));
    c = result.getColumnLatestCell(fam1, qual1);
    assertEquals(10L, c.getTimestamp());

    assertTrue(Bytes.equals(c.getValueArray(), c.getValueOffset(), c.getValueLength(), qual2, 0,
      qual2.length));
  }",1
"@Test
  public void testCloseWithFailingFlush() throws Exception {
    final Configuration conf = HBaseConfiguration.create(CONF);
    final WAL wal = createWALCompatibleWithFaultyFileSystem(method, conf, tableName);
    // Only retry once.
    conf.setInt(""hbase.hstore.flush.retries.number"", 1);
    final User user = User.createUserForTesting(conf, this.method, new String[] { ""foo"" }",1
"@Test
  public void testDelete_CheckTimestampUpdated() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] col1 = Bytes.toBytes(""col1"");
    byte[] col2 = Bytes.toBytes(""col2"");
    byte[] col3 = Bytes.toBytes(""col3"");

    byte[] forUnitTestsOnly = Bytes.toBytes(""ForUnitTestsOnly"");

    // Setting up region
    this.region = initHRegion(tableName, method, CONF, fam1);
    // Building checkerList
    List<Cell> kvs = new ArrayList<>();
    kvs.add(new KeyValue(row1, fam1, col1, null));
    kvs.add(new KeyValue(row1, fam1, col2, null));
    kvs.add(new KeyValue(row1, fam1, col3, null));

    NavigableMap<byte[], List<Cell>> deleteMap = new TreeMap<>(Bytes.BYTES_COMPARATOR);
    deleteMap.put(fam1, kvs);
    region.delete(new Delete(forUnitTestsOnly, HConstants.LATEST_TIMESTAMP, deleteMap));

    // extract the key values out the memstore:
    // This is kinda hacky, but better than nothing...
    long now = EnvironmentEdgeManager.currentTime();
    AbstractMemStore memstore = (AbstractMemStore) region.getStore(fam1).memstore;
    Cell firstCell = memstore.getActive().first();
    assertTrue(firstCell.getTimestamp() <= now);
    now = firstCell.getTimestamp();
    for (Cell cell : memstore.getActive().getCellSet()) {
      assertTrue(cell.getTimestamp() <= now);
      now = cell.getTimestamp();
    }",1
"@Test
  public void testFlushResult() throws IOException {
    byte[] family = Bytes.toBytes(""family"");

    this.region = initHRegion(tableName, method, family);

    // empty memstore, flush doesn't run
    HRegion.FlushResult fr = region.flush(true);
    assertFalse(fr.isFlushSucceeded());
    assertFalse(fr.isCompactionNeeded());

    // Flush enough files to get up to the threshold, doesn't need compactions
    for (int i = 0; i < 2; i++) {
      Put put = new Put(tableName.toBytes()).addColumn(family, family, tableName.toBytes());
      region.put(put);
      fr = region.flush(true);
      assertTrue(fr.isFlushSucceeded());
      assertFalse(fr.isCompactionNeeded());
    }",1
"@Test
  public void testFlushSizeAccounting() throws Exception {
    final Configuration conf = HBaseConfiguration.create(CONF);
    final WAL wal = createWALCompatibleWithFaultyFileSystem(method, conf, tableName);
    // Only retry once.
    conf.setInt(""hbase.hstore.flush.retries.number"", 1);
    final User user = User.createUserForTesting(conf, method, new String[] { ""foo"" }",1
"@Test
  public void testGet_Empty() throws IOException {
    byte[] row = Bytes.toBytes(""row"");
    byte[] fam = Bytes.toBytes(""fam"");

    this.region = initHRegion(tableName, method, CONF, fam);
    Get get = new Get(row);
    get.addFamily(fam);
    Result r = region.get(get);

    assertTrue(r.isEmpty());
  }",1
"@Test
  public void testGet_FamilyChecker() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[] fam2 = Bytes.toBytes(""False"");
    byte[] col1 = Bytes.toBytes(""col1"");

    // Setting up region
    this.region = initHRegion(tableName, method, CONF, fam1);
    Get get = new Get(row1);
    get.addColumn(fam2, col1);

    // Test
    try {
      region.get(get);
      fail(""Expecting DoNotRetryIOException in get but did not get any"");
    }",1
"@Test
  public void testGetScanner_WithNoFamilies() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[] fam2 = Bytes.toBytes(""fam2"");
    byte[] fam3 = Bytes.toBytes(""fam3"");
    byte[] fam4 = Bytes.toBytes(""fam4"");

    byte[][] families = { fam1, fam2, fam3, fam4 }",1
"@Test
  public void testGetScanner_WithRegionClosed() throws IOException {
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[] fam2 = Bytes.toBytes(""fam2"");

    byte[][] families = { fam1, fam2 }",1
"@Test
  public void testGetWhileRegionClose() throws IOException {
    Configuration hc = initSplit();
    int numRows = 100;
    byte[][] families = { fam1, fam2, fam3 }",1
"@Test
  public void testRecoveredEditsReplayCompaction() throws Exception {
    testRecoveredEditsReplayCompaction(false);
    testRecoveredEditsReplayCompaction(true);
  }",1
"@Test
  public void testReverseScanner_FromMemStore_SingleCF_FullScan() throws IOException {
    byte[] rowC = Bytes.toBytes(""rowC"");
    byte[] rowA = Bytes.toBytes(""rowA"");
    byte[] rowB = Bytes.toBytes(""rowB"");
    byte[] cf = Bytes.toBytes(""CF"");
    byte[][] families = { cf }",1
"@Test
  public void testReverseScanner_FromMemStoreAndHFiles_MultiCFs1() throws IOException {
    byte[] row0 = Bytes.toBytes(""row0""); // 1 kv
    byte[] row1 = Bytes.toBytes(""row1""); // 2 kv
    byte[] row2 = Bytes.toBytes(""row2""); // 4 kv
    byte[] row3 = Bytes.toBytes(""row3""); // 2 kv
    byte[] row4 = Bytes.toBytes(""row4""); // 5 kv
    byte[] row5 = Bytes.toBytes(""row5""); // 2 kv
    byte[] cf1 = Bytes.toBytes(""CF1"");
    byte[] cf2 = Bytes.toBytes(""CF2"");
    byte[] cf3 = Bytes.toBytes(""CF3"");
    byte[][] families = { cf1, cf2, cf3 }",1
"@Test
  public void testReverseScanner_FromMemStoreAndHFiles_MultiCFs2() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] row2 = Bytes.toBytes(""row2"");
    byte[] row3 = Bytes.toBytes(""row3"");
    byte[] row4 = Bytes.toBytes(""row4"");
    byte[] cf1 = Bytes.toBytes(""CF1"");
    byte[] cf2 = Bytes.toBytes(""CF2"");
    byte[] cf3 = Bytes.toBytes(""CF3"");
    byte[] cf4 = Bytes.toBytes(""CF4"");
    byte[][] families = { cf1, cf2, cf3, cf4 }",1
"@Test
  public void testReverseScanShouldNotScanMemstoreIfReadPtLesser() throws Exception {
    byte[] cf1 = Bytes.toBytes(""CF1"");
    byte[][] families = { cf1 }",1
"@Test
  public void testScanner_DeleteOneFamilyNotAnother() throws IOException {
    byte[] fam1 = Bytes.toBytes(""columnA"");
    byte[] fam2 = Bytes.toBytes(""columnB"");
    this.region = initHRegion(tableName, method, CONF, fam1, fam2);
    byte[] rowA = Bytes.toBytes(""rowA"");
    byte[] rowB = Bytes.toBytes(""rowB"");

    byte[] value = Bytes.toBytes(""value"");

    Delete delete = new Delete(rowA);
    delete.addFamily(fam1);

    region.delete(delete);

    // now create data.
    Put put = new Put(rowA);
    put.addColumn(fam2, null, value);
    region.put(put);

    put = new Put(rowB);
    put.addColumn(fam1, null, value);
    put.addColumn(fam2, null, value);
    region.put(put);

    Scan scan = new Scan();
    scan.addFamily(fam1).addFamily(fam2);
    try (InternalScanner s = region.getScanner(scan)) {
      List<Cell> results = new ArrayList<>();
      s.next(results);
      assertTrue(CellUtil.matchingRows(results.get(0), rowA));

      results.clear();
      s.next(results);
      assertTrue(CellUtil.matchingRows(results.get(0), rowB));
    }",1
"@Test
  public void testScanner_Wildcard_FromMemStore_EnforceVersions() throws IOException {
    byte[] row1 = Bytes.toBytes(""row1"");
    byte[] qf1 = Bytes.toBytes(""qualifier1"");
    byte[] qf2 = Bytes.toBytes(""qualifier2"");
    byte[] fam1 = Bytes.toBytes(""fam1"");
    byte[][] families = { fam1 }",1
"@Test
  public void testSequenceId() throws IOException {
    region = initHRegion(tableName, method, CONF, COLUMN_FAMILY_BYTES);
    assertEquals(HConstants.NO_SEQNUM, region.getMaxFlushedSeqId());
    // Weird. This returns 0 if no store files or no edits. Afraid to change it.
    assertEquals(0, (long) region.getMaxStoreSeqId().get(COLUMN_FAMILY_BYTES));
    HBaseTestingUtil.closeRegionAndWAL(this.region);
    assertEquals(HConstants.NO_SEQNUM, region.getMaxFlushedSeqId());
    assertEquals(0, (long) region.getMaxStoreSeqId().get(COLUMN_FAMILY_BYTES));
    HRegion oldRegion = region;
    try {
      // Open region again.
      region = initHRegion(tableName, method, CONF, COLUMN_FAMILY_BYTES);
      byte[] value = Bytes.toBytes(method);
      // Make a random put against our cf.
      Put put = new Put(value);
      put.addColumn(COLUMN_FAMILY_BYTES, null, value);
      region.put(put);
      // No flush yet so init numbers should still be in place.
      assertEquals(HConstants.NO_SEQNUM, region.getMaxFlushedSeqId());
      assertEquals(0, (long) region.getMaxStoreSeqId().get(COLUMN_FAMILY_BYTES));
      region.flush(true);
      long max = region.getMaxFlushedSeqId();
      HBaseTestingUtil.closeRegionAndWAL(this.region);
      assertEquals(max, region.getMaxFlushedSeqId());
      this.region = null;
    }",1
"@Test
  public void testSkipRecoveredEditsReplayTheLastFileIgnored() throws Exception {
    byte[] family = Bytes.toBytes(""family"");
    this.region = initHRegion(tableName, method, CONF, family);
    final WALFactory wals = new WALFactory(CONF, method);
    try {
      Path regiondir = region.getRegionFileSystem().getRegionDir();
      FileSystem fs = region.getRegionFileSystem().getFileSystem();
      byte[] regionName = region.getRegionInfo().getEncodedNameAsBytes();
      byte[][] columns = region.getTableDescriptor().getColumnFamilyNames().toArray(new byte[0][]);

      assertEquals(0, region.getStoreFileList(columns).size());

      Path recoveredEditsDir = WALSplitUtil.getRegionDirRecoveredEditsDir(regiondir);

      long maxSeqId = 1050;
      long minSeqId = 1000;

      for (long i = minSeqId; i <= maxSeqId; i += 10) {
        Path recoveredEdits = new Path(recoveredEditsDir, String.format(""%019d"", i));
        fs.create(recoveredEdits);
        WALProvider.Writer writer = wals.createRecoveredEditsWriter(fs, recoveredEdits);

        long time = System.nanoTime();
        WALEdit edit = null;
        if (i == maxSeqId) {
          edit = WALEdit.createCompaction(region.getRegionInfo(),
            CompactionDescriptor.newBuilder().setTableName(ByteString.copyFrom(tableName.getName()))
              .setFamilyName(ByteString.copyFrom(regionName))
              .setEncodedRegionName(ByteString.copyFrom(regionName))
              .setStoreHomeDirBytes(ByteString.copyFrom(Bytes.toBytes(regiondir.toString())))
              .setRegionName(ByteString.copyFrom(region.getRegionInfo().getRegionName())).build());
        }",1
"@Test
  public void testStatusSettingToAbortIfAnyExceptionDuringRegionInitilization() throws Exception {
    RegionInfo info;
    try {
      FileSystem fs = mock(FileSystem.class);
      when(fs.exists(any())).thenThrow(new IOException());
      TableDescriptorBuilder tableDescriptorBuilder = TableDescriptorBuilder.newBuilder(tableName);
      ColumnFamilyDescriptor columnFamilyDescriptor =
        ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(""cf"")).build();
      tableDescriptorBuilder.setColumnFamily(columnFamilyDescriptor);
      info = RegionInfoBuilder.newBuilder(tableName).build();
      Path path = new Path(dir + ""testStatusSettingToAbortIfAnyExceptionDuringRegionInitilization"");
      region = HRegion.newHRegion(path, null, fs, CONF, info, tableDescriptorBuilder.build(), null);
      // region initialization throws IOException and set task state to ABORTED.
      region.initialize();
      fail(""Region initialization should fail due to IOException"");
    }",1
"@Test
  public void testToShowNPEOnRegionScannerReseek() throws Exception {
    byte[] family = Bytes.toBytes(""family"");
    this.region = initHRegion(tableName, method, CONF, family);

    Put put = new Put(Bytes.toBytes(""r1""));
    put.addColumn(family, Bytes.toBytes(""q1""), Bytes.toBytes(""v1""));
    region.put(put);
    put = new Put(Bytes.toBytes(""r2""));
    put.addColumn(family, Bytes.toBytes(""q1""), Bytes.toBytes(""v1""));
    region.put(put);
    region.flush(true);

    Scan scan = new Scan();
    scan.readVersions(3);
    // open the first scanner
    try (RegionScanner scanner1 = region.getScanner(scan)) {
      LOG.info(""Smallest read point:"" + region.getSmallestReadPoint());

      region.compact(true);

      scanner1.reseek(Bytes.toBytes(""r2""));
      List<Cell> results = new ArrayList<>();
      scanner1.next(results);
      Cell keyValue = results.get(0);
      assertTrue(Bytes.compareTo(CellUtil.cloneRow(keyValue), Bytes.toBytes(""r2"")) == 0);
      scanner1.close();
    }",1
"@Test
  public void testEqualsWithLink() throws IOException {
    Path origin = new Path(""/origin"");
    Path tmp = TEST_UTIL.getDataTestDir();
    Path mob = new Path(""/mob"");
    Path archive = new Path(""/archive"");
    HFileLink link1 = new HFileLink(new Path(origin, ""f1""), new Path(tmp, ""f1""),
      new Path(mob, ""f1""), new Path(archive, ""f1""));
    HFileLink link2 = new HFileLink(new Path(origin, ""f1""), new Path(tmp, ""f1""),
      new Path(mob, ""f1""), new Path(archive, ""f1""));

    StoreFileInfo info1 =
      new StoreFileInfo(TEST_UTIL.getConfiguration(), TEST_UTIL.getTestFileSystem(), null, link1);
    StoreFileInfo info2 =
      new StoreFileInfo(TEST_UTIL.getConfiguration(), TEST_UTIL.getTestFileSystem(), null, link2);

    assertEquals(info1, info2);
    assertEquals(info1.hashCode(), info2.hashCode());
  }",1
"@Test
	public void testOptionSetDefinition() throws Exception {
		final Object ls = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/ls.xml""));
		System.out.println(ls);
		final Object uniq = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/uniq.xml""));
		System.out.println(uniq);
		final Object cut = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/cut.xml""));
		System.out.println(cut);
		final Object sort = new OptionSetDefinitionDataLoader().load(null, Collections.singletonList(""/sort.xml""));
		System.out.println(sort);
	}",1
"@Test
    public void read() throws Exception {
        Map<String, Attributes> entities = LDIFUtils.read(getClass().getResourceAsStream(""/example.ldif""));
        assertThat(entities.size(), is(4));
    }",1
"@Test
    public void readMultipleEntities() throws Exception {
        String ldif = ""dn: dc=example,dc=com\n"" +
            ""objectClass: domain\n"" +
            ""objectClass: top\n"" +
            ""dc: example\n"" +
            ""\n"" +
            ""dn: ou=Users,dc=example,dc=com\n"" +
            ""objectClass: organizationalUnit\n"" +
            ""objectClass: top\n"" +
            ""ou: Users\n"";

        Map<String, Attributes> entities = LDIFUtils.read(new ByteArrayInputStream(ldif.getBytes()));
        assertThat(entities.size(), is(2));
        assertThat(entities.containsKey(""dc=example,dc=com""), is(true));
        assertThat(entities.containsKey(""ou=Users,dc=example,dc=com""), is(true));
    }",1
"@Test
  public void xmlRequestBody() throws Exception {
    server.enqueue(new MockResponse());

    Call<Void> call = service.postXml(SAMPLE_CONTACT);
    call.execute();

    RecordedRequest request = server.takeRequest();
    assertThat(request.getHeader(""Content-Type"")).isEqualTo(""application/xml; charset=utf-8"");
    assertThat(request.getBody().readUtf8()).isEqualTo(SAMPLE_CONTACT_XML);
  }",1
"@Test
  public void testRegularAsyncExecution() {

    ProcessEngine processEngine = null;

    try {
      // Deploy
      processEngine = createProcessEngine(true);
      setClockToCurrentTime(processEngine);
      deploy(processEngine, ""AsyncExecutorTest.testRegularAsyncExecution.bpmn20.xml"");

      // Start process instance. Wait for all jobs to be done
      processEngine.getRuntimeService().startProcessInstanceByKey(""asyncExecutor"");

      // Move clock 3 minutes. Nothing should happen
      addSecondsToCurrentTime(processEngine, 180L);
      ProcessEngine processEngineForException = processEngine;
      assertThatExceptionOfType(ActivitiException.class)
        .isThrownBy(() -> waitForAllJobsBeingExecuted(processEngineForException, 500L));
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""The Task"").count()).isEqualTo(1);
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""Task after timer"").count()).isEqualTo(0);
      assertThat(processEngine.getManagementService().createTimerJobQuery().count()).isEqualTo(1);
      assertThat(getAsyncExecutorJobCount(processEngine)).isEqualTo(0);

      // Move clock 3 minutes and 1 second. Triggers the timer
      addSecondsToCurrentTime(processEngine, 181);
      waitForAllJobsBeingExecuted(processEngine);

      // Verify if all is as expected
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""The Task"").count()).isEqualTo(0);
      assertThat(processEngine.getTaskService().createTaskQuery().taskName(""Task after timer"").count()).isEqualTo(1);
      assertThat(processEngine.getManagementService().createTimerJobQuery().count()).isEqualTo(0);
      assertThat(processEngine.getManagementService().createJobQuery().count()).isEqualTo(0);

      assertThat(getAsyncExecutorJobCount(processEngine)).isEqualTo(1);
    }",1
"@Test
    public void noDefaultProfile() throws IOException {
        final ConfigFile configFile =
                ConfigFileReader.parse(""src/test/resources/unit_test_no_default_config"", ""USER"");
        assertEquals(""default_user"", configFile.get(""user""));
        assertEquals(""default_tenancy"", configFile.get(""tenancy""));
        assertNull(configFile.get(""region""));
    }",1
"@Test
    public void test_v4_1_16() throws Exception {
        NavMesh mesh = loadNavMesh(""graph_v4_1_16.zip"");
        float[] startPos = new float[] { 22.93f, -2.37f, -5.11f }",1
"@Test
	public void testNoMatch() throws Exception {

		SaajSoapMessage message = loadSaajMessage(""200408/response-no-message-id.xml"");
		MessageContext messageContext = new DefaultMessageContext(message, new SaajSoapMessageFactory(messageFactory));

		EndpointInvocationChain endpoint = mapping.getEndpoint(messageContext);

		assertThat(endpoint).isNull();
	}",1
"@Test
    public void should_build_entity_with_static_counter_column() throws Exception {
        setExec(aptUtils -> {
            final String className = TestEntityWithStaticCounterColumn.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            final TypeSpec typeSpec = builder.buildEntityMeta(EntityType.TABLE, typeElement, context, parsingResults, emptyList()).sourceCode;

            assertThat(buildSource(typeSpec)).isEqualTo(
                    readCodeBlockFromFile(""expected_code/entity_meta_builder/should_build_entity_with_static_counter_column.txt""));
        }",1
"@Test
    public void should_build_view_meta() throws Exception {
        setExec(aptUtils -> {
            final String className = TestViewSensorByType.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final EntityMetaCodeGen builder = new EntityMetaCodeGen(aptUtils);
            final List<FieldParser.FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, context);
            final TypeSpec typeSpec = builder.buildEntityMeta(EntityType.VIEW, typeElement, context, parsingResults, emptyList()).sourceCode;

            assertThat(buildSource(typeSpec)).isEqualTo(
                    readCodeBlockFromFile(""expected_code/entity_meta_builder/should_build_view_meta.txt""));
        }",1
"@Test
    public void should_generate_udt_property_class() throws Exception {
        setExec(aptUtils -> {
            final String className = TestUDT.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final UDTMetaCodeGen builder = new UDTMetaCodeGen(aptUtils);

            final GlobalParsingContext globalContext = GlobalParsingContext.defaultContext();
            final EntityParsingContext context = new EntityParsingContext(typeElement,
                    ClassName.get(TestUDT.class), new LowerCaseNaming(), globalContext);
            final List<FieldMetaSignature> parsingResults = getTypeParsingResults(aptUtils, typeElement, globalContext);

            final TypeSpec typeSpec = builder.buildUDTClassProperty(typeElement, context, parsingResults, Collections.emptyList());

            assertThat(typeSpec.toString().trim()).isEqualTo(
                    readCodeBlockFromFile(""expected_code/udt_meta_builder/should_generate_udt_property_class.txt""));

        }",1
"@Test
    public void should_generate_udt_with_custom_constructor_property_class() throws Exception {
        setExec(aptUtils -> {
            final String className = TestUDTWithCustomConstructor.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);

            final UDTMetaCodeGen builder = new UDTMetaCodeGen(aptUtils);

            final GlobalParsingContext globalContext = GlobalParsingContext.defaultContext();
            final EntityParsingContext context = new EntityParsingContext(typeElement,
                    ClassName.get(TestUDT.class), new LowerCaseNaming(), globalContext);
            final List<AccessorsExclusionContext> exclusionContexts = Arrays.asList(
                    new AccessorsExclusionContext(""name"", false, true),
                    new AccessorsExclusionContext(""list"", false, true));
            final List<FieldMetaSignature> fieldMetaSignatures = getTypeParsingResults(aptUtils, typeElement, exclusionContexts, globalContext);

            final List<FieldMetaSignature> constructorInjectedFieldMetaSignatures = fieldMetaSignatures
                    .stream()
                    .filter(fieldMeta -> !fieldMeta.context.fieldName.equals(""date""))
                    .collect(Collectors.toList());

            final TypeSpec typeSpec = builder.buildUDTClassProperty(typeElement, context, fieldMetaSignatures, constructorInjectedFieldMetaSignatures);

            assertThat(typeSpec.toString().trim()).isEqualTo(
                    readCodeBlockFromFile(""expected_code/udt_meta_builder/should_generate_udt_with_custom_constructor_property_class.txt""));

        }",1
"@Test
    public void should_generate_field_info_for_primitiveBoolean() throws Exception {
        setExec(aptUtils -> {
            FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext context = new EntityParsingContext(typeElement, ClassName.get(TestEntityForFieldInfo.class), strategy, globalParsingContext);

            // private boolean primitiveBoolean;
            VariableElement elm = findFieldInType(typeElement, ""primitiveBoolean"");
            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);

            FieldInfoContext fieldInfo = parser.buildFieldInfo(elm, annotationTree, context);

            assertThat(fieldInfo.codeBlock.toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/method_parser/should_generate_field_info_for_primitiveBoolean.txt""));
        }",1
"@Test
    public void should_generate_field_info_for_public_final_columns() throws Exception {
        setExec(aptUtils -> {
            final FieldInfoParser parser = new FieldInfoParser(aptUtils);
            final String className = TestEntityForFieldInfo.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final List<AccessorsExclusionContext> exclusionContexts = Arrays.asList(new AccessorsExclusionContext(""immutableColumn"", true, true));
            final EntityParsingContext context = new EntityParsingContext(typeElement,
                    ClassName.get(TestEntityForFieldInfo.class), strategy, exclusionContexts,
                    globalParsingContext);

            VariableElement elm = findFieldInType(typeElement, ""immutableColumn"");

            final AnnotationTree annotationTree = AnnotationTree.buildFrom(aptUtils,  globalParsingContext, elm);

            FieldInfoContext fieldInfo = parser.buildFieldInfo(elm, annotationTree, context);

            assertThat(fieldInfo.codeBlock.toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/method_parser/should_generate_field_info_for_public_final_columns.txt""));
        }",1
"@Test
    public void should_parse_computed_field_with_codec() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // @Computed(function = ""writetime"",  alias = ""writetime"", targettargetColumnsap""}",1
"@Test
    public void should_parse_field_with_case_sensitive_overriden_name() throws Exception {
        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // @Column(""\""overRiden\"""")
            // private String overridenName;
            VariableElement elm = findFieldInType(typeElement, ""overridenName"");

            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(String.class.getCanonicalName());
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_field_with_case_sensitive_overriden_name.txt""));
        }",1
"@Test
    public void should_parse_list_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private List<TestUDT> listUdt;
            VariableElement elm = findFieldInType(typeElement, ""listUdt"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.List<com.datastax.driver.core.UDTValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_list_udt.txt""));
        }",1
"@Test
    public void should_parse_map_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Map<Integer, TestUDT> mapUdt;
            VariableElement elm = findFieldInType(typeElement, ""mapUdt"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Map<java.lang.Integer, com.datastax.driver.core.UDTValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_map_udt.txt""));
        }",1
"@Test
    public void should_parse_map_with_nested_json() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Map<Integer, @JSON List<Map<Integer, String>>> mapWithNestedJson;
            VariableElement elm = findFieldInType(typeElement, ""mapWithNestedJson"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Map<java.lang.Integer, java.lang.String>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_map_with_nested_json.txt""));
        }",1
"@Test
    public void should_parse_nested_int_array() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            //  private List<@Frozen Map<@Enumerated ProtocolVersion, List<int[]>>> nestedArrays;
            VariableElement elm = findFieldInType(typeElement, ""nestedArrays"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.List<java.util.Map<java.lang.String, java.util.List<int[]>>>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_nested_int_array.txt""));
        }",1
"@Test
    public void should_parse_nested_tuple() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Map<Integer, Tuple2<Integer, String>> nestedTuple;
            VariableElement elm = findFieldInType(typeElement, ""nestedTuple"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Map<java.lang.Integer, com.datastax.driver.core.TupleValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_nested_tuple.txt""));
        }",1
"@Test
    public void should_parse_nested_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private TestNestedUDT nestedUDT;
            VariableElement elm = findFieldInType(typeElement, ""nestedUDT"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(UDTValue.class.getCanonicalName());
            assertThat(parsingResult.udtMetaSignature.isPresent()).isTrue();
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_nested_udt.txt""));
        }",1
"@Test
    public void should_parse_non_frozen_udt() throws Exception {
        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = new GlobalParsingContext(V3_6.INSTANCE, InsertStrategy.ALL_FIELDS, new LowerCaseNaming(),
                    EXPLICIT_ENTITY_FIELD_FILTER, EXPLICIT_UDT_FIELD_FILTER, Optional.empty());
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalContext);

            // @Column
            // private TestUDT nonFrozenUDT;
            VariableElement elm = findFieldInType(typeElement, ""nonFrozenUDT"");

            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(UDTValue.class.getCanonicalName());
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_non_frozen_udt.txt""));
        }",1
"@Test
    public void should_parse_optional_protocol_version_from_inline_codec() throws Exception {

        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = globalParsingContext;
            new CodecRegistryParser(aptUtils).parseCodecs(env, globalContext);
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy,
                    globalContext);

            // @Column
            // private Optional<@Enumerated(Encoding.ORDINAL) ProtocolVersion> optionalEncodingAsOrdinal;
            VariableElement elm = findFieldInType(typeElement, ""optionalEncodingAsOrdinal"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.lang.Integer"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_optional_protocol_version_from_inline_codec.txt""));
        }",1
"@Test
    public void should_parse_optional_string() throws Exception {

        setExec(aptUtils -> {
            final GlobalParsingContext globalContext = globalParsingContext;
            new CodecRegistryParser(aptUtils).parseCodecs(env, globalContext);
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy,
                    globalContext);

            // @Column
            // private Optional<String> optionalString;
            VariableElement elm = findFieldInType(typeElement, ""optionalString"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.lang.String"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_optional_string.txt""));
        }",1
"@Test
    public void should_parse_set_nesting() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Set<Map<Integer,String>> setNesting;
            VariableElement elm = findFieldInType(typeElement, ""setNesting"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Set<java.util.Map<java.lang.Integer, java.lang.String>>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_set_nesting.txt""));
        }",1
"@Test
    public void should_parse_set_udt() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Set<TestUDT> setUdt;
            VariableElement elm = findFieldInType(typeElement, ""setUdt"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(""java.util.Set<com.datastax.driver.core.UDTValue>"");
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_set_udt.txt""));
        }",1
"@Test
    public void should_parse_tuple_nesting() throws Exception {

        setExec(aptUtils -> {
            final FieldParser fieldParser = new FieldParser(aptUtils);
            final String className = TestEntityForCodecs.class.getCanonicalName();
            final TypeElement typeElement = aptUtils.elementUtils.getTypeElement(className);
            final EntityParsingContext entityContext = new EntityParsingContext(typeElement, ClassName.get(TestEntityForCodecs.class), strategy, globalParsingContext);

            // private Tuple2<Integer, List<String>> tupleNesting;
            VariableElement elm = findFieldInType(typeElement, ""tupleNesting"");
            FieldMetaSignature parsingResult = fieldParser.parse(elm, entityContext);

            assertThat(parsingResult.targetType.toString()).isEqualTo(TUPLE_VALUE_CLASSNAME);
            assertThat(parsingResult.buildPropertyAsField().toString().trim().replaceAll(""\n"", """"))
                    .isEqualTo(readCodeLineFromFile(""expected_code/field_parser/should_parse_tuple_nesting.txt""));
        }",1
"@Test
    public void should_fail_validating_schema_when_partition_key_missing() throws Exception {
        //Given
        final Cluster cluster = CassandraEmbeddedServerBuilder.builder()
                .withScript(""EntityWithMissingPartitionKey/schema.cql"")
                .buildNativeCluster();
        cluster.init();

        //When
        exception.expect(AchillesBeanMappingException.class);
        exception.expectMessage(""The mapped partition key(s) [id] for entity "" +
                ""info.archinnov.achilles.internals.entities.EntityWithMissingPartitionKey "" +
                ""do not correspond to live schema partition key(s) [id, bucket]"");

        //Then
        ManagerFactoryBuilder
                .builder(cluster)
                .withManagedEntityClasses(EntityWithMissingPartitionKey.class)
                .build();
    }",1
"@Test
    public void should_query_using_collection_index_fromJSON() throws Exception {
        //Given
        final Long id = RandomUtils.nextLong(0L, Long.MAX_VALUE);
        scriptExecutor.executeScriptTemplate(""EntityWithIndicesForJSON/insertRows.cql"", ImmutableMap.of(""id"", id));

        //When
        final List<EntityWithIndicesForJSON> actual = manager
                .indexed()
                .select()
                .allColumns_FromBaseTable()
                .where()
                .indexed_collectionIndex().Contains_FromJson(""\""4\"""")
                .getList();

        //Then
        assertThat(actual).hasSize(1);
        final EntityWithIndicesForJSON entity = actual.get(0);
        assertThat(entity.getSimpleIndex()).isEqualTo(""411"");
    }",1
"@Test
    public void should_query_using_index_and_clustering_column_fromJSON() throws Exception {
        //Given
        final Long id = RandomUtils.nextLong(0L, Long.MAX_VALUE);
        scriptExecutor.executeScriptTemplate(""EntityWithIndicesForJSON/insertRows.cql"", ImmutableMap.of(""id"", id));

        //When
        final List<EntityWithIndicesForJSON> actual = manager
                .indexed()
                .select()
                .allColumns_FromBaseTable()
                .where()
                .indexed_simpleIndex().Eq(""312"")
                .clust1().Eq_FromJson(""3"")
                .clust3().Eq_FromJson(""\""2\"""")
                .getList();

        //Then
        assertThat(actual).hasSize(1);
        final EntityWithIndicesForJSON entity = actual.get(0);
        assertThat(entity.getSimpleIndex()).isEqualTo(""312"");
    }",1
"@Test
    public void should_build_schema_for_complex_types() throws Exception {
        //Given
        final EntityWithComplexTypes_AchillesMeta meta = new EntityWithComplexTypes_AchillesMeta();
        final CodecRegistry codecRegistry = new CodecRegistry();
        TupleTypeFactory tupleTypeFactory = new TupleTypeFactory(ProtocolVersion.NEWEST_SUPPORTED, codecRegistry);
        UserTypeFactory userTypeFactory = new UserTypeFactory(ProtocolVersion.NEWEST_SUPPORTED, codecRegistry);

        meta.inject(userTypeFactory, tupleTypeFactory);

        //When
        final String actual = meta.generateSchema(context);

        //Then
        assertThat(actual.trim()).isEqualTo(readCodeBlockFromFile(
                ""schema/should_build_schema_for_complex_types.cql""));
    }",1
"@Test
    public void should_build_schema_for_entity_with_composite_partition_key() throws Exception {
        //Given
        final EntityWithCompositePartitionKey_AchillesMeta meta = new EntityWithCompositePartitionKey_AchillesMeta();

        //When
        final String actual = meta.generateSchema(context);

        //Then
        assertThat(actual.trim()).isEqualTo(readCodeBlockFromFile(
                ""schema/should_build_schema_for_entity_with_composite_partition_key.cql""));
    }",1
"@Test
    public void should_build_schema_for_entity_with_simple_partition_key() throws Exception {
        //Given
        final EntityWithSimplePartitionKey_AchillesMeta meta = new EntityWithSimplePartitionKey_AchillesMeta();

        //When
        final String actual = meta.generateSchema(context);

        //Then
        assertThat(actual.trim()).isEqualTo(readCodeBlockFromFile(
                ""schema/should_build_schema_for_entity_with_simple_partition_key.cql""));
    }",1
"@Test
    public void should_build_schema_for_entity_with_static_annotations() throws Exception {
        //Given
        final EntityWithStaticAnnotations_AchillesMeta meta = new EntityWithStaticAnnotations_AchillesMeta();

        //When
        final String actual = meta.generateSchema(context);

        //Then
        assertThat(actual.trim()).isEqualTo(readCodeBlockFromFile(
                ""schema/should_build_schema_for_entity_with_static_annotations.cql""));
    }",1
"@Test
    public void should_build_schema_for_entity_with_static_column() throws Exception {
        //Given
        final EntityWithStaticColumn_AchillesMeta meta = new EntityWithStaticColumn_AchillesMeta();

        //When
        final String actual = meta.generateSchema(context);

        //Then
        assertThat(actual.trim()).isEqualTo(readCodeBlockFromFile(
                ""schema/should_build_schema_for_entity_with_static_column.cql""));
    }",1
"@Test
    public void should_build_schema_for_simple_entity() throws Exception {
        //Given
        final SimpleEntity_AchillesMeta meta = new SimpleEntity_AchillesMeta();

        //When
        final String actual = meta.generateSchema(context);

        //Then
        assertThat(actual.trim()).isEqualTo(readCodeBlockFromFile(
                ""schema/should_build_schema_for_simple_entity.cql""));
    }",1
"@Test
  public void shouldNotFailForEmptyPaths() throws MalformedURLException {
    URL url = new URL(""file://"" + file.getAbsolutePath());
    FileSystemReader fileSystemReader = FileSystemReader.getInstance(url);
    assertThat(fileSystemReader, notNullValue());
    assertThat(fileSystemReader.getSubPackagesOfPackage("""").size(), is(0));
    assertThat(fileSystemReader.getTypesInPackage("""").size(), is(0));
  }",1
"@Test
  public void throwsProperException() throws MalformedURLException {
    String anyUrl = anyUrl();
    try {
      FileSystemReader.getInstance(new URL(anyUrl));
      fail(""Expected exception not thrown!"");
    }",1
"@Test
    public void testWrite() throws Exception {
        Bean bean1 = new Bean();
        bean1.setStringField(""str"");
        bean1.setBooleanField(true);
        bean1.setCharField('s');
        bean1.setDoubleField(10.1);
        bean1.setFloatField(1.5f);
        bean1.setIntField(10);
        bean1.setLongField(100);
        bean1.setEnumField(AnEnum.ValueA);
        bean1.setEnumBean(AnEnumBean.Two);

        JSONWriter jsonWriter = new DefaultJSONWriter();
        jsonWriter.setEnumAsBean(false);
        String json = jsonWriter.write(bean1);
        TestUtils.assertEquals(DefaultJSONWriter.class.getResource(""jsonwriter-write-bean-01.txt""), json);
    }",1
"@Test
  public void createValidModel() {
    factory = new GroovyModelFactory() {
      @Override
      protected InputStream getModelResourceAsStream()
          throws IOException {
        return TestGroovyModelFactory.class.getResourceAsStream(""wro.groovy"");
      }",1
"@Test
  public void createValidModelContainingHiphen() {
    factory = new GroovyModelFactory() {
      @Override
      protected InputStream getModelResourceAsStream()
          throws IOException {
        return getClass().getResourceAsStream(""wroWithHiphen.groovy"");
      }",1
"@Test
  public void createIncompleteModel() {
    factory = new JsonModelFactory() {
      @Override
      protected InputStream getModelResourceAsStream()
          throws IOException {
        return getClass().getResourceAsStream(""incomplete-wro.json"");
      }",1
"@Test
  public void testFromFolder()
      throws Exception {
    final URL url = getClass().getResource(""../ngannotate"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", victim);
  }",1
"@Test
  public void testFromFolder()
      throws Exception {
    final URL url = getClass().getResource(""../ngmin"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", victim);
  }",1
"@Test
  public void testFromFolder()
      throws IOException {
    final URL url = getClass().getResource(""csslint"");

    final File testFolder = new File(url.getFile());
    WroTestUtils.compareFromSameFolder(testFolder, new WildcardFileFilter(""*.css""), Transformers.noOpTransformer(),
        victim);
  }",1
"@Test
  public void testAdvancedOptimization()
      throws IOException {
    victim.setCompilationLevel(CompilationLevel.ADVANCED_OPTIMIZATIONS);
    final URL url = getClass().getResource(""google"");

    final File expectedFolder = new File(url.getFile(), ""expectedAdvanced"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", (ResourcePreProcessor) victim);
  }",1
"@Test
  public void testPackFromFolder()
      throws Exception {
    final ResourcePostProcessor processor = JsonHPackProcessor.packProcessor();
    final URL url = getClass().getResource(""jsonhpack"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""pack"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", processor);
  }",1
"@Test
  public void testFromFolder()
      throws Exception {
    final ResourcePostProcessor processor = new NodeTypeScriptProcessor();
    final URL url = getClass().getResource(""typescript"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", processor);
  }",1
"@Test
  public void shouldUglifyFiles()
      throws IOException {
    final ResourcePostProcessor processor = new UglifyJsProcessor();
    final URL url = getClass().getResource(""uglify"");

    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", processor);
  }",1
"@Test
  public void shouldMininimizeCss()
      throws IOException {
    final URL url = getClass().getResource(""yui"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""css"", victim);
  }",1
"@Test
  public void shouldSetResponseLength()
      throws IOException {
    final String resourceUri = ""classpath:"" + packagePath + ""/"" + ""test.css"";
    when(mockAuthorizationManager.isAuthorized(resourceUri)).thenReturn(true);
    when(request.getParameter(ResourceProxyRequestHandler.PARAM_RESOURCE_ID)).thenReturn(resourceUri);
    when(mockUriLocator.locate(anyString())).thenReturn(new ClasspathUriLocator().locate(resourceUri));

    victim.handle(request, response);
    final int expectedLength = IOUtils.toString(getInputStream(""test.css""), Charset.defaultCharset()).length();

    verify(response, times(1)).setContentLength(expectedLength);
  }",1
"@Test
  public void testDuplicatedResourcesShouldBeSkipped()
      throws Exception {
    new GenericTestBuilder().processAndCompare(""/repeatedResources.js"", ""classpath:ro/isdc/wro/manager/repeated-out.js"");
  }",1
"@Test
  public void testFromFolder()
      throws Exception {
    final ResourcePreProcessor processor = new WroManagerProcessor();
    final URL url = getClass().getResource(""wroManager"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", processor);
  }",1
"@Test
  public void testMinimizeAttributeIsTrueOnResource()
      throws Exception {
    new GenericTestBuilder().processAndCompare(""/resourceMinimizeTrue.js"",
        ""classpath:ro/isdc/wro/manager/sample.min.js"");
  }",1
"@Test
  public void shouldBeNullWhenDestinationFolderIsUnrelatedToBuildDirectory() {
    final File unrelatedFolder = new File(getClass().getResource("""").getFile()).getParentFile();
    victim.setDestinationFolder(unrelatedFolder);
    assertEquals(null, victim.resolve());
  }",1
"@Test
  public void shouldGenerateXmlReportFileWithCheckstyleFormat()
      throws Exception {
    generateAndCompareReportUsingFormat(FormatterType.CHECKSTYLE.getFormat(), ""csslint-checkstyle.xml"");
  }",1
"@Test
  public void shouldGenerateXmlReportFileWithDefaultFormat()
      throws Exception {
    generateAndCompareReportUsingFormat(null, ""csslint-default.xml"");
  }",1
"@Test
  public void shouldNotFailWhenThresholdIsGreaterThanNumberOfErrors()
      throws Exception {
    mojo.setFailThreshold(5);
    setWroWithValidResources();
    mojo.execute();
  }",1
"@Test
  public void shouldGenerateReportWithDefaultFormat()
      throws Exception {
    generateAndCompareReportFile(null, ""jshint-default.xml"");
  }",1
"@Test
  public void shouldGenerateReportWithDefaultFormat() throws Exception {
    generateAndCompareReportFile(null, ""jslint-default.xml"");
  }",1
"@Test
  public void testWroXmlWithInvalidResourcesAndIgnoreMissingResourcesTrue()
      throws Exception {
    setWroWithInvalidResources();
    victim.setIgnoreMissingResources(true);
    victim.execute();
  }",1
"@Test
  public void testMojoWithConfigurableWroManagerFactoryWithValidAndEmptyConfigFileSet()
      throws Exception {
    setWroWithValidResources();
    victim.setIgnoreMissingResources(true);
    victim.setWroManagerFactory(ConfigurableWroManagerFactory.class.getName());
    victim.execute();
  }",1
"@Test
  public void testMojoWithCustomManagerFactoryWithInvalidResourceAndIgnoreMissingResources()
      throws Exception {
    setWroWithInvalidResources();
    victim.setIgnoreMissingResources(true);
    victim.setWroManagerFactory(CustomManagerFactory.class.getName());
    victim.execute();
  }",1
"@Test
  public void shouldDetectGroupReferenceFromImportedModel() {
    final WroModel model = loadModelFromLocation(""shouldDetectGroupReferenceFromImportedModel.xml"");
    assertEquals(2, model.getGroups().size());
  }",1
"@Test
  public void testTwoConcurrentCreationCalls() {
    testSuccessfulCreation();
    factory.create();
  }",1
"@Test
  public void shouldFindWildcardResourcesForFolderContainingSpaces()
      throws IOException {
    victim.locate(createUri(""/folder with spaces/**.css"", ""test""));
  }",1
"@Test
  public void testWildcard2Resources()
      throws IOException {
    victim.locate(createUri(""/css/*.cs?""));
  }",1
"@Test
  public void shouldLocateWildcard3Resources()
      throws IOException {
    victim.locate(createUri(""*.???""));
  }",1
"@Test
  public void shouldFindAllChildFoldersAndFiles()
      throws IOException {
    final ThreadLocal<Collection<String>> filenameListHolder = new ThreadLocal<Collection<String>>();
    final UriLocator uriLocator = createJarLocator(filenameListHolder);
    uriLocator.locate(""classpath:com/app/**"");
    final Collection<String> filenameList = filenameListHolder.get();
    assertNotNull(filenameList);
    assertEquals(
            Arrays.toString(new String[]{
                    ""com/app/level1"", ""com/app/level1/level2"", ""com/app/level1/level2/styles"",
                    ""com/app/level1/level2/styles/style.css"", ""com/app/level1/level2/level2.css"", ""com/app/level1/level1.css""
            }",1
"@Test
  public void shouldGetJarFileFromFile() {
    final String actual = jarStreamLocator.getJarFile(new File(""file:path/to/file!one/two/three.class"")).getPath();
    final String expected = FilenameUtils.separatorsToSystem(""path/to/file"");
    assertEquals(expected, actual);
  }",1
"@Test
  public void testLocateJarStreamDelegate()
      throws IOException {
    final InputStream is = jarStreamLocator.locateStream(""classpath:com/test/app/*.js"", new File(""src/test/resources/""));
    final String content = readLines(is).get(0);
    assertTrue(content.contains(""1.js""));
    assertTrue(content.contains(""2.js""));
    assertTrue(content.contains(""3.js""));
    assertTrue(!content.contains(""1.css""));
    
    closeQuietly(is);
  }",1
"@Test
  public void testCopyrightStripperProcessor()
      throws Exception {
    final ResourcePreProcessor decoratedProcessor = new CssMinProcessor();
    final ResourcePreProcessor processor = CopyrightKeeperProcessorDecorator.decorate(decoratedProcessor);
    final URL url = ResourcePreProcessor.class.getResource(""copyright"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""css"", processor);
  }",1
"@Test
  public void shouldRemoveOriginalUrl()
      throws Exception {
    compareResultsFromFolderUsingProcessor(""expectedEmptyReplace"", createProcessorWithHandler(new ItemHandler() {
      public String replace(final String originalDeclaration, final String originalUrl) {
        return originalDeclaration.replace(originalUrl, """");
      }",1
"@Test
  public void shouldGenerateCorrectDataURIForCSSWithCharset()
      throws IOException {
    final String expected = ""data:text/css;charset=UTF-8;base64,aW5wdXQuYnV0dG9uIHsKCWJhY2tncm91bmQ6IHVybChodHRwOi8vd3JvNGouZ29vZ2xlY29kZS5jb20vc3ZuL3dpa2kvaW1nL2ZvbGRlclN0cnVjdHVyZS5wbmcpOwoJYmFja2dyb3VuZC1pbWFnZTogdXJsKCJodHRwOi8vd3JvNGouZ29vZ2xlY29kZS5jb20vc3ZuL3dpa2kvaW1nL2ZvbGRlclN0cnVjdHVyZS5wbmciKTsKCWZpbHRlcjogcHJvZ2lkOkRYSW1hZ2VUcmFuc2Zvcm0uTWljcm9zb2Z0LkFscGhhSW1hZ2VMb2FkZXIoc3JjPSdodHRwOi8vd3JvNGouZ29vZ2xlY29kZS5jb20vc3ZuL3dpa2kvaW1nL2ZvbGRlclN0cnVjdHVyZS5wbmcnLCBzaXppbmdNZXRob2Q9J3NjYWxlJyk7Cn0KLm11bHRpbGluZUFuZFNwYWNlcyB7CiAgYmFja2dyb3VuZDogCiAgICAgdXJsKCAiaHR0cDovL3dybzRqLmdvb2dsZWNvZGUuY29tL3N2bi93aWtpL2ltZy9mb2xkZXJTdHJ1Y3R1cmUucG5nICIgKTsKICBiYWNrZ3JvdW5kLWltYWdlIDogCiAgICAgdXJsKCAiaHR0cDovL3dybzRqLmdvb2dsZWNvZGUuY29tL3N2bi93aWtpL2ltZy9mb2xkZXJTdHJ1Y3R1cmUucG5nICIgKSAgICAgCn0KQGZvbnQtZmFjZSB7CiAgICBzcmM6IHVybChodHRwOi8vd3JvNGouZ29vZ2xlY29kZS5jb20vc3ZuL3dpa2kvaW1nL2ZvbGRlclN0cnVjdHVyZS5wbmcpOwp9"";
    final String actual = dataUriGenerator.generateDataURI(getInputStream(""dataUri.css""), ""dataUri.css"");
    WroTestUtils.compare(expected, actual);
  }",1
"@Test
  public void shouldGenerateCorrectDataUriForPng()
      throws Exception {
    final String expected = ""data:image/png;base64,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"";
    final String actual = dataUriGenerator.generateDataURI(getInputStream(""dataUri.png""), ""dataUri.png"");
    
    assertEquals(expected, actual);
  }",1
"@Test
  public void testFromFolder()
      throws Exception {
    final URL url = getClass().getResource(""conformColors"");
    
    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""css"", processor);
  }",1
"@Test
  public void testFromFolder()
      throws Exception {
    final URL url = getClass().getResource(""consoleStripper"");
    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", processor);
  }",1
"@Test
  public void shouldHandleWrongCss()
      throws Exception {
    final ResourcePostProcessor processor = new ExceptionHandlingProcessorDecorator(new CssMinProcessor());
    
    final URL url = getClass().getResource(""cssmin"");
    
    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expectedInvalid"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""css"", processor);
  }",1
"@Test
  public void testFromFolder()
      throws Exception {
    Context.get().getConfig().setIgnoreMissingResources(false);
    final URL url = getClass().getResource(""cssImport"");
    
    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expectedLess"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""css"", victim);
  }",1
"@Test
  public void testFromFolder()
      throws IOException {
    final ResourcePostProcessor processor = new MultiLineCommentStripperProcessor();
    
    final URL url = getClass().getResource(""multiline"");
    
    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""*"", processor);
  }",1
"@Test
  public void testProcessor()
      throws Exception {
    final Properties properties = new Properties();
    properties.setProperty(""prop1"", ""value1"");
    properties.setProperty(""prop2"", ""value2"");
    properties.setProperty(""prop3"", ""value3"");
    properties.setProperty(""prop4"", ""value4"");
    final ResourcePreProcessor processor = new PlaceholderProcessor().setPropertiesFactory(WroUtil.simpleObjectFactory(properties));
    final URL url = getClass().getResource(""placeholder"");

    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""css"", processor);
  }",1
"@Test
  public void testFromFolder()
      throws IOException {
    final ResourcePreProcessor processor = new SemicolonAppenderPreProcessor();
    
    final URL url = getClass().getResource(""semicolonAppender"");
    
    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""js"", processor);
  }",1
"@Test
  public void testFromFolder()
      throws Exception {
    final URL url = getClass().getResource(""variablizeColors"");
    
    final File testFolder = new File(url.getFile(), ""test"");
    final File expectedFolder = new File(url.getFile(), ""expected"");
    WroTestUtils.compareFromDifferentFoldersByExtension(testFolder, expectedFolder, ""css"", processor);
  }",1
"@Test
	public void testGuessCurrentDump() throws IOException {
		this.dm.setFileContents(
				this.dmPath.resolve(""current-dump.xml.bz2""), """");
		MwLocalDumpFile df = new MwLocalDumpFile(
				""/current-dump.xml.bz2"");
		assertTrue(df.isAvailable());
		assertEquals(df.getDumpContentType(), DumpContentType.CURRENT);
	}",1
"@Test
	public void shouldFindValidWebjar() throws Exception {
		assertNotEmpty(victim.locate(""webjars:jquery.js""));
		assertNotEmpty(victim.locate(""webjars:jquery/"" + ExternalLibrary.JQUERY.version() + ""/jquery.js""));
		assertNotEmpty(victim.locate(""webjars:/jquery/"" + ExternalLibrary.JQUERY.version() + ""/jquery.js""));
	}",1
"@Test
	public void shouldLocateWebjarResourceContainingQuestionMarkInUri() throws Exception {
		victim.locate(""webjars:font-awesome/"" + ExternalLibrary.FONT_AWESOME.version() + ""/webfonts/fa-regular-400.woff?v=""
				+ ExternalLibrary.FONT_AWESOME.version());
	}",1
"@Test
	public void shouldNotFailWhenThereIsAWebjarResourceOutsideOfJar() throws IOException {
		assertNotEmpty(victim.locate(""webjars:webjarFail.js""));
	}",1
"@Test
  public void testWildcardLocator()
      throws IOException {
    locator = new DefaultWildcardStreamLocator() {
      @Override
      void triggerWildcardExpander(final Collection<File> allFiles, final WildcardContext wildcardContext)
          throws IOException {
        assertEquals(2, allFiles.size());
      }",1
"@Test
  public void shouldRemoveImportsFromComments()
      throws Exception {
    compareResultsFromFolderUsingProcessor(""expectedRemoveImportsFromComments"", createImportsRemovalProcessor());
  }",1
"@Test
    public void testIsDevOpsAdmin() throws Throwable {
        Method setAuthCtxMethod = Operation.class.getDeclaredMethod(""setAuthorizationContext"",
                AuthorizationContext.class);

        Claims guestClaims = new Claims.Builder().setSubject(GuestUserService.SELF_LINK)
                .getResult();
        AuthorizationContext guestContext = AuthorizationContext.Builder.create()
                .setClaims(guestClaims).getResult();

        // TODO Currently all authorized non-guest users are devOpsAdmins. Needs to be changed after
        // roles are introduced. Also, a case for developer authorization context and cloud admin
        // need to be added.
        Claims devOpsClaims = new Claims.Builder()
                .setSubject(AuthUtil.buildUserServicePathFromPrincipalId(encode(""some-user@local"")))
                .getResult();
        AuthorizationContext devOpsContext = AuthorizationContext.Builder.create()
                .setClaims(devOpsClaims).getResult();

        setAuthCtxMethod.setAccessible(true);

        Operation op = new Operation();
        setAuthCtxMethod.invoke(op, (AuthorizationContext) null);
        assertEquals(null, op.getAuthorizationContext());
        assertFalse(""<null> authorization context should not be treated as devOps admin context"",
                AuthUtil.isDevOpsAdmin(op));

        setAuthCtxMethod.invoke(op, guestContext);
        assertFalse(""Guest authorization context should not be trated as devOps admin context"",
                AuthUtil.isDevOpsAdmin(op));

        setAuthCtxMethod.invoke(op, devOpsContext);
        assertTrue(""Any non-guest authorized user should be a devOps admin"",
                AuthUtil.isDevOpsAdmin(op));

        setAuthCtxMethod.setAccessible(false);
    }",1
"@Test
    public void testExportService() throws InterruptedException {
        int port = NetUtils.getAvailablePort();
        URL serviceurl = URL.valueOf(""dubbo://127.0.0.1:"" + port + ""/test?proxy=jdk&timeout="" + Integer.MAX_VALUE);
        DemoService demo = new DemoServiceImpl();
        Invoker<DemoService> invoker = proxy.getInvoker(demo, DemoService.class, serviceurl);
        protocol.export(invoker);
        synchronized (EnumBak.class) {
            EnumBak.class.wait();
        }",1
"@Test
  public void testCompactFormat() throws IOException {
    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    appendCompactFormatProperty(""a"", ""b"");
    appendCompactFormatProperty(""c"", ""d"", true);
    appendCompactFormatProperty(""e"", ""f"", false, ""g"");
    endConfig();
    Path fileResource = new Path(CONFIG);
    Configuration conf = new Configuration(false);
    conf.addResource(fileResource);

    assertEquals(""b"", conf.get(""a""));

    assertEquals(""d"", conf.get(""c""));
    Set<String> s = conf.getFinalParameters();
    assertEquals(1, s.size());
    assertTrue(s.contains(""c""));

    assertEquals(""f"", conf.get(""e""));
    String[] sources = conf.getPropertySources(""e"");
    assertEquals(2, sources.length);
    assertEquals(""g"", sources[0]);
    assertEquals(fileResource.toString(), sources[1]);
  }",1
"@Test
  public void testConcurrentAccesses() throws Exception {
    out = new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    declareProperty(""some.config"", ""xyz"", ""xyz"", false);
    endConfig();
    Path fileResource = new Path(CONFIG);
    Configuration conf = new Configuration();
    conf.addResource(fileResource);

    class ConfigModifyThread extends Thread {
      final private Configuration config;
      final private String prefix;

      public ConfigModifyThread(Configuration conf, String prefix) {
        config = conf;
        this.prefix = prefix;
      }",1
"@Test
  public void testDoubleValues() throws IOException {
    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    appendProperty(""test.double1"", ""3.1415"");
    appendProperty(""test.double2"", ""003.1415"");
    appendProperty(""test.double3"", ""-3.1415"");
    appendProperty(""test.double4"", "" -3.1415 "");
    appendProperty(""test.double5"", ""xyz-3.1415xyz"");
    endConfig();
    Path fileResource = new Path(CONFIG);
    conf.addResource(fileResource);
    assertEquals(3.1415, conf.getDouble(""test.double1"", 0.0), DOUBLE_DELTA);
    assertEquals(3.1415, conf.getDouble(""test.double2"", 0.0), DOUBLE_DELTA);
    assertEquals(-3.1415, conf.getDouble(""test.double3"", 0.0), DOUBLE_DELTA);
    assertEquals(-3.1415, conf.getDouble(""test.double4"", 0.0), DOUBLE_DELTA);
    try {
      conf.getDouble(""test.double5"", 0.0);
      fail(""Property had invalid double value, but was read successfully."");
    }",1
"@Test
  public void testDumpProperty() throws IOException {
    StringWriter outWriter = new StringWriter();
    ObjectMapper mapper = new ObjectMapper();
    String jsonStr = null;
    String xmlStr = null;
    try {
      Configuration testConf = new Configuration(false);
      out = new BufferedWriter(new FileWriter(CONFIG));
      startConfig();
      appendProperty(""test.key1"", ""value1"");
      appendProperty(""test.key2"", ""value2"", true);
      appendProperty(""test.key3"", ""value3"");
      endConfig();
      Path fileResource = new Path(CONFIG);
      testConf.addResource(fileResource);
      out.close();

      // case 1: dump an existing property
      // test json format
      outWriter = new StringWriter();
      Configuration.dumpConfiguration(testConf, ""test.key2"", outWriter);
      jsonStr = outWriter.toString();
      outWriter.close();
      mapper = new ObjectMapper();
      SingleJsonConfiguration jconf1 =
          mapper.readValue(jsonStr, SingleJsonConfiguration.class);
      JsonProperty jp1 = jconf1.getProperty();
      assertEquals(""test.key2"", jp1.getKey());
      assertEquals(""value2"", jp1.getValue());
      assertEquals(true, jp1.isFinal);
      assertEquals(fileResource.toString(), jp1.getResource());

      // test xml format
      outWriter = new StringWriter();
      testConf.writeXml(""test.key2"", outWriter);
      xmlStr = outWriter.toString();
      outWriter.close();
      Configuration actualConf1 = getActualConf(xmlStr);
      assertEquals(1, actualConf1.size());
      assertEquals(""value2"", actualConf1.get(""test.key2""));
      assertTrue(actualConf1.getFinalParameters().contains(""test.key2""));
      assertEquals(fileResource.toString(),
          actualConf1.getPropertySources(""test.key2"")[0]);

      // case 2: dump an non existing property
      // test json format
      try {
        outWriter = new StringWriter();
        Configuration.dumpConfiguration(testConf,
            ""test.unknown.key"", outWriter);
        outWriter.close();
      }",1
"@Test
  public void testEntityReference() throws Exception {
    tearDown();
    out=new BufferedWriter(new FileWriter(CONFIG));
    writeHeader();
    declareEntity(""configuration"", ""d"", ""d"");
    writeConfiguration();
    appendProperty(""a"", ""b"");
    appendProperty(""c"", ""&d;"");
    endConfig();

    // verify that the includes file contains all properties
    Path fileResource = new Path(CONFIG);
    conf.addResource(fileResource);
    assertEquals(conf.get(""a""), ""b"");
    assertEquals(conf.get(""c""), ""d"");
    tearDown();
  }",1
"@Test
  public void testEnumFromXml() throws IOException {
    out=new BufferedWriter(new FileWriter(CONFIG_FOR_ENUM));
    startConfig();
    appendProperty(""test.enum"","" \t \n   FOO \t \n"");
    appendProperty(""test.enum2"","" \t \n   Yak.FOO \t \n"");
    endConfig();

    Configuration conf = new Configuration();
    Path fileResource = new Path(CONFIG_FOR_ENUM);
    conf.addResource(fileResource);
    assertSame(Yak.FOO, conf.getEnum(""test.enum"", Yak.FOO));
    boolean fail = false;
    try {
      conf.getEnum(""test.enum2"", Yak.FOO);
    }",1
"@Test
  public void testGetClassByNameOrNull() throws Exception {
    Configuration config = new Configuration();
    Class<?> clazz = config.getClassByNameOrNull(""java.lang.Object"");
    assertNotNull(clazz);
  }",1
"@Test
  public void testHexValues() throws IOException{
    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    appendProperty(""test.hex1"", ""0x10"");
    appendProperty(""test.hex2"", ""0xF"");
    appendProperty(""test.hex3"", ""-0x10"");
    // Invalid?
    appendProperty(""test.hex4"", ""-0x10xyz"");
    endConfig();
    Path fileResource = new Path(CONFIG);
    conf.addResource(fileResource);
    assertEquals(16, conf.getInt(""test.hex1"", 0));
    assertEquals(16, conf.getLong(""test.hex1"", 0));
    assertEquals(15, conf.getInt(""test.hex2"", 0));
    assertEquals(15, conf.getLong(""test.hex2"", 0));
    assertEquals(-16, conf.getInt(""test.hex3"", 0));
    assertEquals(-16, conf.getLong(""test.hex3"", 0));
    try {
      conf.getLong(""test.hex4"", 0);
      fail(""Property had invalid long value, but was read successfully."");
    }",1
"@Test
  public void testHumanReadableValues() throws IOException {
    out = new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    appendProperty(""test.humanReadableValue1"", ""1m"");
    appendProperty(""test.humanReadableValue2"", ""1M"");
    appendProperty(""test.humanReadableValue5"", ""1MBCDE"");

    endConfig();
    Path fileResource = new Path(CONFIG);
    conf.addResource(fileResource);
    assertEquals(1048576, conf.getLongBytes(""test.humanReadableValue1"", 0));
    assertEquals(1048576, conf.getLongBytes(""test.humanReadableValue2"", 0));
    try {
      conf.getLongBytes(""test.humanReadableValue5"", 0);
      fail(""Property had invalid human readable value, but was read successfully."");
    }",1
"@Test
  public void testIncludesWithFallback() throws Exception {
    tearDown();
    out=new BufferedWriter(new FileWriter(CONFIG2));
    startConfig();
    appendProperty(""a"",""b"");
    appendProperty(""c"",""d"");
    endConfig();

    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    startInclude(CONFIG2);
    startFallback();
    appendProperty(""a"", ""b.fallback"");
    appendProperty(""c"", ""d.fallback"", true);
    endFallback();
    endInclude();
    appendProperty(""e"",""f"");
    appendProperty(""g"",""h"");
    startInclude(""MissingConfig.xml"");
    startFallback();
    appendProperty(""i"", ""j.fallback"");
    appendProperty(""k"", ""l.fallback"", true);
    endFallback();
    endInclude();
    endConfig();

    // verify that the includes file contains all properties
    Path fileResource = new Path(CONFIG);
    conf.addResource(fileResource);
    assertEquals(""b"", conf.get(""a""));
    assertEquals(""d"", conf.get(""c""));
    assertEquals(""f"", conf.get(""e""));
    assertEquals(""h"", conf.get(""g""));
    assertEquals(""j.fallback"", conf.get(""i""));
    assertEquals(""l.fallback"", conf.get(""k""));
    tearDown();
  }",1
"@Test
  public void testIntegerValues() throws IOException{
    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    appendProperty(""test.int1"", ""20"");
    appendProperty(""test.int2"", ""020"");
    appendProperty(""test.int3"", ""-20"");
    appendProperty(""test.int4"", "" -20 "");
    appendProperty(""test.int5"", "" -20xyz "");
    endConfig();
    Path fileResource = new Path(CONFIG);
    conf.addResource(fileResource);
    assertEquals(20, conf.getInt(""test.int1"", 0));
    assertEquals(20, conf.getLong(""test.int1"", 0));
    assertEquals(20, conf.getLongBytes(""test.int1"", 0));
    assertEquals(20, conf.getInt(""test.int2"", 0));
    assertEquals(20, conf.getLong(""test.int2"", 0));
    assertEquals(20, conf.getLongBytes(""test.int2"", 0));
    assertEquals(-20, conf.getInt(""test.int3"", 0));
    assertEquals(-20, conf.getLong(""test.int3"", 0));
    assertEquals(-20, conf.getLongBytes(""test.int3"", 0));
    assertEquals(-20, conf.getInt(""test.int4"", 0));
    assertEquals(-20, conf.getLong(""test.int4"", 0));
    assertEquals(-20, conf.getLongBytes(""test.int4"", 0));
    try {
      conf.getInt(""test.int5"", 0);
      fail(""Property had invalid int value, but was read successfully."");
    }",1
"@Test
  public void testOverlay() throws IOException{
    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    appendProperty(""a"",""b"");
    appendProperty(""b"",""c"");
    appendProperty(""d"",""e"");
    appendProperty(""e"",""f"", true);
    endConfig();

    out=new BufferedWriter(new FileWriter(CONFIG2));
    startConfig();
    appendProperty(""a"",""b"");
    appendProperty(""b"",""d"");
    appendProperty(""e"",""e"");
    endConfig();

    Path fileResource = new Path(CONFIG);
    conf.addResource(fileResource);

    //set dynamically something
    conf.set(""c"",""d"");
    conf.set(""a"",""d"");

    Configuration clone=new Configuration(conf);
    clone.addResource(new Path(CONFIG2));

    assertEquals(clone.get(""a""), ""d"");
    assertEquals(clone.get(""b""), ""d"");
    assertEquals(clone.get(""c""), ""d"");
    assertEquals(clone.get(""d""), ""e"");
    assertEquals(clone.get(""e""), ""f"");

  }",1
"@Test
  public void testVariableSubstitution() throws IOException {
    // stubbing only environment dependent functions
    Configuration mock = Mockito.spy(conf);
    Mockito.when(mock.getProperty(""user.name"")).thenReturn(""hadoop_user"");
    Mockito.when(mock.getenv(""FILE_NAME"")).thenReturn(""hello"");

    out=new BufferedWriter(new FileWriter(CONFIG));
    startConfig();
    declareProperty(""my.int"", ""${intvar}",1
"@Test
  public void testDelegationTokensOpsHttpKerberized() throws Exception {
    testDelegationTokensOps(false, true);
  }",1
"@Test
  public void testDelegationTokensOpsHttpPseudo() throws Exception {
    testDelegationTokensOps(false, false);
  }",1
"@Test
  public void testKMSJMX() throws Exception {
    Configuration conf = new Configuration();
    final File confDir = getTestDir();
    conf = createBaseKMSConf(confDir, conf);
    final String processName = ""testkmsjmx"";
    conf.set(KMSConfiguration.METRICS_PROCESS_NAME_KEY, processName);
    writeConf(confDir, conf);

    runServer(null, null, confDir, new KMSCallable<Void>() {
      @Override
      public Void call() throws Exception {
        final URL jmxUrl = new URL(
            getKMSUrl() + ""/jmx?user.name=whatever&qry=Hadoop:service=""
                + processName + "",name=JvmMetrics"");
        LOG.info(""Requesting jmx from "" + jmxUrl);
        final StringBuilder sb = new StringBuilder();
        final InputStream in = jmxUrl.openConnection().getInputStream();
        final byte[] buffer = new byte[64 * 1024];
        int len;
        while ((len = in.read(buffer)) > 0) {
          sb.append(new String(buffer, 0, len));
        }",1
"@Test
  public void testKMSTimeout() throws Exception {
    File confDir = getTestDir();
    Configuration conf = createBaseKMSConf(confDir);
    conf.setInt(CommonConfigurationKeysPublic.KMS_CLIENT_TIMEOUT_SECONDS, 1);
    writeConf(confDir, conf);

    ServerSocket sock;
    int port;
    try {
      sock = new ServerSocket(0, 50, InetAddress.getByName(""localhost""));
      port = sock.getLocalPort();
    }",1
"@Test
  public void testOSSFileReaderTask() throws Exception {
    Path smallSeekFile = setPath(""/test/smallSeekFileOSSFileReader.txt"");
    long size = 5 * 1024 * 1024;

    ContractTestUtils.generateTestFile(this.fs, smallSeekFile, size, 256, 255);
    LOG.info(""5MB file created: smallSeekFileOSSFileReader.txt"");
    ReadBuffer readBuffer = new ReadBuffer(12, 24);
    AliyunOSSFileReaderTask task = new AliyunOSSFileReaderTask(""1"",
        ((AliyunOSSFileSystem)this.fs).getStore(), readBuffer);
    //NullPointerException, fail
    task.run();
    assertEquals(readBuffer.getStatus(), ReadBuffer.STATUS.ERROR);
    //OK
    task = new AliyunOSSFileReaderTask(
        ""test/test/smallSeekFileOSSFileReader.txt"",
        ((AliyunOSSFileSystem)this.fs).getStore(), readBuffer);
    task.run();
    assertEquals(readBuffer.getStatus(), ReadBuffer.STATUS.SUCCESS);
  }",1
"@Test
  public void testSeekFile() throws Exception {
    Path smallSeekFile = setPath(""/test/smallSeekFile.txt"");
    long size = 5 * 1024 * 1024;

    ContractTestUtils.generateTestFile(this.fs, smallSeekFile, size, 256, 255);
    LOG.info(""5MB file created: smallSeekFile.txt"");

    FSDataInputStream instream = this.fs.open(smallSeekFile);
    int seekTimes = 5;
    LOG.info(""multiple fold position seeking test...:"");
    for (int i = 0; i < seekTimes; i++) {
      long pos = size / (seekTimes - i) - 1;
      LOG.info(""begin seeking for pos: "" + pos);
      instream.seek(pos);
      assertTrue(""expected position at:"" + pos + "", but got:""
          + instream.getPos(), instream.getPos() == pos);
      LOG.info(""completed seeking at pos: "" + instream.getPos());
    }",1
"@Test
  public void testListStatusThrowsExceptionForNonExistentFile()
      throws Exception {
    String testFile = ""test/hadoop/file"";
    Path testPath = qualifiedPath(testFile, fc2);
    try {
      fc1.listStatus(testPath);
      Assert.fail(""Should throw FileNotFoundException"");
    }",1
"@Test
  public void testStructureGenerator() throws Exception {
    StructureGenerator sg = new StructureGenerator();
    String[] args = new String[]{""-maxDepth"", ""2"", ""-minWidth"", ""1"",
        ""-maxWidth"", ""2"", ""-numOfFiles"", ""2"",
        ""-avgFileSize"", ""1"", ""-outDir"", OUT_DIR.getAbsolutePath(), ""-seed"", ""1""}",1
"@Test
  public void testFinalDestinationBaseDirectChild() {
    finalDestination(l(MAGIC_PATH_PREFIX, BASE, ""3.txt""));
  }",1
"@Test
  public void testFinalDestinationMagic1() {
    assertEquals(l(""first"", ""2""),
        finalDestination(l(""first"", MAGIC_PATH_PREFIX, ""2"")));
  }",1
"@Test
  public void testLastElementSingle() {
    assertEquals(""first"", lastElement(l(""first"")));
  }",1
"@Test
  public void testParentDeepMagic() {
    assertParents(a(""parent1"", ""parent2""), DEEP_MAGIC);
  }",1
"@Test
  public void testPathEscapes() throws IOException {
    Path path = new Path(TEST_ROOT_DIR, ""foo%bar"");
    writeFile(fileSys, path, 1);
    FileStatus status = fileSys.getFileStatus(path);
    assertEquals(fileSys.makeQualified(path), status.getPath());
    cleanupFile(fileSys, path);
  }",1
"@Test
  public void testSyncable() throws IOException {
    FileSystem fs = fileSys.getRawFileSystem();
    Path file = new Path(TEST_ROOT_DIR, ""syncable"");
    FSDataOutputStream out = fs.create(file);
    final int bytesWritten = 1;
    byte[] expectedBuf = new byte[] {'0', '1', '2', '3'}",1
"@Test
  public void testBasicPaths() {
    URI uri = fSys.getUri();
    Assert.assertEquals(chrootedTo.toUri(), uri);
    Assert.assertEquals(fSys.makeQualified(
        new Path(System.getProperty(""user.home""))),
        fSys.getWorkingDirectory());
    Assert.assertEquals(fSys.makeQualified(
        new Path(System.getProperty(""user.home""))),
        fSys.getHomeDirectory());
    /*
     * ChRootedFs as its uri like file:///chrootRoot.
     * This is questionable since path.makequalified(uri, path) ignores
     * the pathPart of a uri. So our notion of chrooted URI is questionable.
     * But if we were to fix Path#makeQualified() then  the next test should
     *  have been:

    Assert.assertEquals(
        new Path(chrootedTo + ""/foo/bar"").makeQualified(
            FsConstants.LOCAL_FS_URI, null),
        fSys.makeQualified(new Path( ""/foo/bar"")));
    */
    
    Assert.assertEquals(
        new Path(""/foo/bar"").makeQualified(FsConstants.LOCAL_FS_URI, null),
        fSys.makeQualified(new Path(""/foo/bar"")));
  }",1
"@Test
  public void testListLocatedFileStatus() throws Exception {
    final Path mockMount = new Path(""mockfs://foo/user"");
    final Path mockPath = new Path(""/usermock"");
    final Configuration conf = new Configuration();
    conf.setClass(""fs.mockfs.impl"", MockFileSystem.class, FileSystem.class);
    ConfigUtil.addLink(conf, mockPath.toString(), mockMount.toUri());
    FileSystem vfs = FileSystem.get(URI.create(""viewfs:///""), conf);
    vfs.listLocatedStatus(mockPath);
    final FileSystem mockFs =
        ((MockFileSystem) getChildFileSystem((ViewFileSystem) vfs,
            new URI(""mockfs://foo/""))).getRawFileSystem();
    verify(mockFs).listLocatedStatus(new Path(mockMount.toUri().getPath()));
  }",1
"@Test
  public void testBlockReaderLocalByteBufferFastLaneReadsNoChecksumNoReadahead()
      throws IOException {
    runBlockReaderLocalTest(new TestBlockReaderLocalByteBufferFastLaneReads(),
        false, 0);
  }",1
"@Test
  public void testBlockReaderLocalByteBufferReadsNoChecksum()
      throws IOException {
    runBlockReaderLocalTest(
        new TestBlockReaderLocalByteBufferReads(),
        false, HdfsClientConfigKeys.DFS_DATANODE_READAHEAD_BYTES_DEFAULT);
  }",1
"@Test
  public void testBlockReaderLocalOnFileWithoutChecksumNoReadahead()
      throws IOException {
    runBlockReaderLocalTest(new TestBlockReaderLocalOnFileWithoutChecksum(),
        true, 0);
  }",1
"@Test
  public void testBlockReaderLocalReadCorruptNoReadahead()
      throws IOException {
    runBlockReaderLocalTest(new TestBlockReaderLocalReadCorrupt(), true, 0);
  }",1
"@Test
  public void testBlockReaderLocalReadZeroBytesNoChecksum()
      throws IOException {
    runBlockReaderLocalTest(new TestBlockReaderLocalReadZeroBytes(),
        false, HdfsClientConfigKeys.DFS_DATANODE_READAHEAD_BYTES_DEFAULT);
  }",1
"@Test
  public void testBlackListIpClient() throws IOException {
    Configuration conf = new Configuration();
    FileUtils.write(blacklistFile,
        InetAddress.getLocalHost().getHostAddress(), true);
    conf.set(BlackListBasedTrustedChannelResolver
            .DFS_DATATRANSFER_CLIENT_FIXED_BLACK_LIST_FILE,
        blacklistFile.getAbsolutePath());

    resolver.setConf(conf);
    assertFalse(resolver.isTrusted());

  }",1
"@Test
  public void testStartStop() throws IOException {
    Configuration conf = new Configuration();
    MiniJournalCluster c = new MiniJournalCluster.Builder(conf)
      .build();
    c.waitActive();
    try {
      URI uri = c.getQuorumJournalURI(""myjournal"");
      String[] addrs = uri.getAuthority().split("";"");
      assertEquals(3, addrs.length);
      
      JournalNode node = c.getJournalNode(0);
      String dir = node.getConf().get(DFSConfigKeys.DFS_JOURNALNODE_EDITS_DIR_KEY);
      assertEquals(
          new File(MiniDFSCluster.getBaseDirectory() + ""journalnode-0"")
            .getAbsolutePath(),
          dir);
    }",1
"@Test
  public void testMetaSaveMissingReplicas() throws Exception {
    List<DatanodeStorageInfo> origStorages = getStorages(0, 1);
    List<DatanodeDescriptor> origNodes = getNodes(origStorages);
    BlockInfo block = makeBlockReplicasMissing(0, origNodes);
    File file = new File(""test.log"");
    PrintWriter out = new PrintWriter(file);
    bm.metaSave(out);
    out.flush();
    FileInputStream fstream = new FileInputStream(file);
    DataInputStream in = new DataInputStream(fstream);
    BufferedReader reader = new BufferedReader(new InputStreamReader(in));
    StringBuilder buffer = new StringBuilder();
    String line;
    try {
      while ((line = reader.readLine()) != null) {
        buffer.append(line);
      }",1
"@Test
  public void testBlocksCounter() throws Exception {
    DatanodeDescriptor dd = BlockManagerTestUtil.getLocalDatanodeDescriptor(true);
    assertEquals(0, dd.numBlocks());
    BlockInfo blk = new BlockInfoContiguous(new Block(1L), (short) 1);
    BlockInfo blk1 = new BlockInfoContiguous(new Block(2L), (short) 2);
    DatanodeStorageInfo[] storages = dd.getStorageInfos();
    assertTrue(storages.length > 0);
    // add first block
    assertEquals(AddBlockResult.ADDED, storages[0].addBlock(blk));
    assertEquals(1, dd.numBlocks());
    // remove a non-existent block
    assertFalse(BlocksMap.removeBlock(dd, blk1));
    assertEquals(1, dd.numBlocks());
    // add an existent block
    assertNotEquals(AddBlockResult.ADDED, storages[0].addBlock(blk));
    assertEquals(1, dd.numBlocks());
    // add second block
    assertEquals(AddBlockResult.ADDED, storages[0].addBlock(blk1));
    assertEquals(2, dd.numBlocks());
    // remove first block
    assertTrue(BlocksMap.removeBlock(dd, blk));
    assertEquals(1, dd.numBlocks());
    // remove second block
    assertTrue(BlocksMap.removeBlock(dd, blk1));
    assertEquals(0, dd.numBlocks());    
  }",1
"@Test
  public void testRemoveIncludedNode() throws IOException {
    FSNamesystem fsn = Mockito.mock(FSNamesystem.class);

    // Set the write lock so that the DatanodeManager can start
    Mockito.when(fsn.hasWriteLock()).thenReturn(true);

    DatanodeManager dm = mockDatanodeManager(fsn, new Configuration());
    HostFileManager hm = new HostFileManager();
    HostSet noNodes = new HostSet();
    HostSet oneNode = new HostSet();
    HostSet twoNodes = new HostSet();
    DatanodeRegistration dr1 = new DatanodeRegistration(
      new DatanodeID(""127.0.0.1"", ""127.0.0.1"", ""someStorageID-123"",
          12345, 12345, 12345, 12345),
      new StorageInfo(HdfsServerConstants.NodeType.DATA_NODE),
      new ExportedBlockKeys(), ""test"");
    DatanodeRegistration dr2 = new DatanodeRegistration(
      new DatanodeID(""127.0.0.1"", ""127.0.0.1"", ""someStorageID-234"",
          23456, 23456, 23456, 23456),
      new StorageInfo(HdfsServerConstants.NodeType.DATA_NODE),
      new ExportedBlockKeys(), ""test"");

    twoNodes.add(entry(""127.0.0.1:12345""));
    twoNodes.add(entry(""127.0.0.1:23456""));
    oneNode.add(entry(""127.0.0.1:23456""));

    hm.refresh(twoNodes, noNodes);
    Whitebox.setInternalState(dm, ""hostConfigManager"", hm);

    // Register two data nodes to simulate them coming up.
    // We need to add two nodes, because if we have only one node, removing it
    // will cause the includes list to be empty, which means all hosts will be
    // allowed.
    dm.registerDatanode(dr1);
    dm.registerDatanode(dr2);

    // Make sure that both nodes are reported
    List<DatanodeDescriptor> both =
        dm.getDatanodeListForReport(HdfsConstants.DatanodeReportType.ALL);

    // Sort the list so that we know which one is which
    Collections.sort(both);

    Assert.assertEquals(""Incorrect number of hosts reported"",
        2, both.size());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:12345"", both.get(0).getInfoAddr());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:23456"", both.get(1).getInfoAddr());

    // Remove one node from includes, but do not add it to excludes.
    hm.refresh(oneNode, noNodes);

    // Make sure that only one node is still reported
    List<DatanodeDescriptor> onlyOne =
        dm.getDatanodeListForReport(HdfsConstants.DatanodeReportType.ALL);

    Assert.assertEquals(""Incorrect number of hosts reported"",
        1, onlyOne.size());
    Assert.assertEquals(""Unexpected host reported"",
        ""127.0.0.1:23456"", onlyOne.get(0).getInfoAddr());

    // Remove all nodes from includes
    hm.refresh(noNodes, noNodes);

    // Check that both nodes are reported again
    List<DatanodeDescriptor> bothAgain =
        dm.getDatanodeListForReport(HdfsConstants.DatanodeReportType.ALL);

    // Sort the list so that we know which one is which
    Collections.sort(bothAgain);

    Assert.assertEquals(""Incorrect number of hosts reported"",
        2, bothAgain.size());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:12345"", bothAgain.get(0).getInfoAddr());
    Assert.assertEquals(""Unexpected host or host in unexpected position"",
        ""127.0.0.1:23456"", bothAgain.get(1).getInfoAddr());
  }",1
"@Test
  public void testGetDatanodeByHost() throws Exception {
    assertEquals(map.getDatanodeByHost(""1.1.1.1""), dataNodes[0]);
    assertEquals(map.getDatanodeByHost(""2.2.2.2""), dataNodes[1]);
    DatanodeDescriptor node = map.getDatanodeByHost(""3.3.3.3"");
    assertTrue(node == dataNodes[2] || node == dataNodes[3]);
    assertNull(map.getDatanodeByHost(""4.4.4.4""));
  }",1
"@Test
  public void testInjectionEmpty() throws IOException {
    SimulatedFSDataset fsdataset = getSimulatedFSDataset(); 
    assertBlockReportCountAndSize(fsdataset, 0);
    int bytesAdded = addSomeBlocks(fsdataset);
    assertBlockReportCountAndSize(fsdataset, NUMBLOCKS);
    assertBlockLengthInBlockReports(fsdataset);
    
    // Inject blocks into an empty fsdataset
    //  - injecting the blocks we got above.
    SimulatedFSDataset sfsdataset = getSimulatedFSDataset();
    injectBlocksFromBlockReport(fsdataset, sfsdataset);
    assertBlockReportCountAndSize(fsdataset, NUMBLOCKS);
    assertBlockLengthInBlockReports(fsdataset, sfsdataset);

    assertEquals(bytesAdded, sfsdataset.getDfsUsed());
    assertEquals(sfsdataset.getCapacity()-bytesAdded, sfsdataset.getRemaining());
  }",1
"@Test
  public void testGreedyPlannerBalanceVolumeSet() throws Exception {
    URI clusterJson = getClass()
        .getResource(""/diskBalancer/data-cluster-3node-3disk.json"").toURI();
    ClusterConnector jsonConnector = ConnectorFactory.getCluster(clusterJson,
        null);
    DiskBalancerCluster cluster = new DiskBalancerCluster(jsonConnector);
    cluster.readClusterInfo();
    Assert.assertEquals(3, cluster.getNodes().size());
    cluster.setNodesToProcess(cluster.getNodes());
    DiskBalancerDataNode node = cluster.getNodes().get(0);
    GreedyPlanner planner = new GreedyPlanner(10.0f, node);
    NodePlan plan = new NodePlan(node.getDataNodeName(),
        node.getDataNodePort());
    planner.balanceVolumeSet(node, node.getVolumeSets().get(""SSD""), plan);
  }",1
"@Test
  public void testGreedyPlannerComputePlan() throws Exception {
    URI clusterJson = getClass()
        .getResource(""/diskBalancer/data-cluster-3node-3disk.json"").toURI();
    ClusterConnector jsonConnector = ConnectorFactory.getCluster(clusterJson,
        null);
    DiskBalancerCluster cluster = new DiskBalancerCluster(jsonConnector);
    cluster.readClusterInfo();
    Assert.assertEquals(3, cluster.getNodes().size());
    cluster.setNodesToProcess(cluster.getNodes());
    List<NodePlan> plan = cluster.computePlan(10.0f);
    Assert.assertNotNull(plan);
  }",1
"@Test
  public void testLoadsCorrectClusterConnector() throws Exception {
    ClusterConnector connector = ConnectorFactory.getCluster(getClass()
            .getResource(""/diskBalancer/data-cluster-3node-3disk.json"").toURI()
        , null);
    assertEquals(connector.getClass().toString(),
        ""class org.apache.hadoop.hdfs.server.diskbalancer.connectors."" +
            ""JsonNodeConnector"");

  }",1
"@Test
  public void testResolverWithNoPreference() throws IOException {
    MultipleDestinationMountTableResolver mountTableResolver =
        mockAvailableSpaceResolver(1.0f);
    // Since we don't have any preference, it will
    // always chose the maximum-available-space subcluster.
    PathLocation loc = mountTableResolver.getDestinationForPath(""/space"");
    assertEquals(""subcluster9"",
        loc.getDestinations().get(0).getNameserviceId());

    loc = mountTableResolver.getDestinationForPath(""/space/subdir"");
    assertEquals(""subcluster9"",
        loc.getDestinations().get(0).getNameserviceId());
  }",1
"@Test
  public void testDefaultNameServiceEnable() throws IOException {
    assertTrue(mountTable.isDefaultNSEnable());
    mountTable.setDefaultNameService(""3"");
    mountTable.removeEntry(""/"");

    assertEquals(""3->/unknown"",
        mountTable.getDestinationForPath(""/unknown"").toString());

    Map<String, String> map = getMountTableEntry(""4"", ""/unknown"");
    mountTable.addEntry(MountTable.newInstance(""/unknown"", map));
    mountTable.setDefaultNSEnable(false);
    assertFalse(mountTable.isDefaultNSEnable());

    assertEquals(""4->/unknown"",
        mountTable.getDestinationForPath(""/unknown"").toString());
    try {
      mountTable.getDestinationForPath(""/"");
      fail(""The getDestinationForPath call should fail."");
    }",1
"@Test
  public void testGetConnectionWithConcurrency() throws Exception {
    Map<ConnectionPoolId, ConnectionPool> poolMap = connManager.getPools();
    Configuration copyConf = new Configuration(conf);
    copyConf.setInt(RBFConfigKeys.DFS_ROUTER_MAX_CONCURRENCY_PER_CONNECTION_KEY, 20);

    ConnectionPool pool = new ConnectionPool(
        copyConf, TEST_NN_ADDRESS, TEST_USER1, 1, 10, 0.5f,
        ClientProtocol.class, null);
    poolMap.put(
        new ConnectionPoolId(TEST_USER1, TEST_NN_ADDRESS, ClientProtocol.class),
        pool);
    assertEquals(1, pool.getNumConnections());
    // one connection can process the maximum number of requests concurrently.
    for (int i = 0; i < 20; i++) {
      ConnectionContext cc = pool.getConnection();
      assertTrue(cc.isUsable());
      cc.getClient();
    }",1
"@Test
  public void testAddOrderMountTable() throws IOException {
    testAddOrderMountTable(DestinationOrder.HASH);
    testAddOrderMountTable(DestinationOrder.LOCAL);
    testAddOrderMountTable(DestinationOrder.RANDOM);
    testAddOrderMountTable(DestinationOrder.HASH_ALL);
  }",1
"@Test
  public void testSharedEditsMissingLogs() throws Exception {
    removeStandbyNameDirs();

    CheckpointSignature sig = nn0.getRpcServer().rollEditLog();
    assertEquals(3, sig.getCurSegmentTxId());

    // Should have created edits_1-2 in shared edits dir
    URI editsUri = cluster.getSharedEditsDir(0, maxNNCount - 1);
    File editsDir = new File(editsUri);
    File currentDir = new File(editsDir, ""current"");
    File editsSegment = new File(currentDir,
        NNStorage.getFinalizedEditsFileName(1, 2));
    GenericTestUtils.assertExists(editsSegment);
    GenericTestUtils.assertExists(currentDir);

    // Delete the segment.
    assertTrue(editsSegment.delete());

    // Trying to bootstrap standby should now fail since the edit
    // logs aren't available in the shared dir.
    LogCapturer logs = GenericTestUtils.LogCapturer.captureLogs(
        LoggerFactory.getLogger(BootstrapStandby.class));
    try {
      assertEquals(BootstrapStandby.ERR_CODE_LOGS_UNAVAILABLE, forceBootstrap(1));
    }",1
"@Test
  public void testSingleProxyFailover() throws Exception {
    String singleNS = ""mycluster-"" + Time.monotonicNow();
    URI singleNNUri = new URI(""hdfs://"" + singleNS);
    Configuration singleConf = new Configuration();
    singleConf.set(HdfsClientConfigKeys.DFS_NAMESERVICES, singleNS);
    singleConf.set(HdfsClientConfigKeys.
        DFS_HA_NAMENODES_KEY_PREFIX + ""."" + singleNS, ""nn1"");

    singleConf.set(HdfsClientConfigKeys.
            DFS_NAMENODE_RPC_ADDRESS_KEY + ""."" + singleNS + "".nn1"",
        RandomStringUtils.randomAlphabetic(8) + "".foo.bar:9820"");
    ClientProtocol active = Mockito.mock(ClientProtocol.class);
    Mockito
        .when(active.getBlockLocations(anyString(), anyLong(), anyLong()))
        .thenThrow(new RemoteException(""java.io.FileNotFoundException"",
            ""File does not exist!""));

    RequestHedgingProxyProvider<ClientProtocol> provider =
        new RequestHedgingProxyProvider<>(singleConf, singleNNUri,
            ClientProtocol.class, createFactory(active));
    try {
      provider.getProxy().proxy.getBlockLocations(""/tmp/test.file"", 0L, 20L);
      Assert.fail(""Should fail since the active namenode throws""
          + "" FileNotFoundException!"");
    }",1
"@Test
  public void testMissingBlock() throws Exception {
    // Create a file with single block with two replicas
    Path file = getTestPath(""testMissingBlocks"");
    createFile(file, 100, (short)1);
    
    // Corrupt the only replica of the block to result in a missing block
    LocatedBlock block = NameNodeAdapter.getBlockLocations(
        cluster.getNameNode(), file.toString(), 0, 1).get(0);
    cluster.getNamesystem().writeLock();
    try {
      bm.findAndMarkBlockAsCorrupt(block.getBlock(), block.getLocations()[0],
          ""STORAGE_ID"", ""TEST"");
    }",1
"@Test
  public void testReadWriteOps() throws Exception {
    MetricsRecordBuilder rb = getMetrics(NN_METRICS);
    long startWriteCounter = MetricsAsserts.getLongCounter(""TransactionsNumOps"",
        rb);
    Path file1_Path = new Path(TEST_ROOT_DIR_PATH, ""ReadData.dat"");

    //Perform create file operation
    createFile(file1_Path, 1024, (short) 2);

    // Perform read file operation on earlier created file
    readFile(fs, file1_Path);
    MetricsRecordBuilder rbNew = getMetrics(NN_METRICS);
    assertTrue(MetricsAsserts.getLongCounter(""TransactionsNumOps"", rbNew) >
        startWriteCounter);
  }",1
"@Test
  public void testDiffReportWithRenameAndAppend() throws Exception {
    final Path root = new Path(""/"");
    final Path foo = new Path(root, ""foo"");
    DFSTestUtil.createFile(hdfs, foo, BLOCKSIZE, REPLICATION, SEED);

    SnapshotTestHelper.createSnapshot(hdfs, root, ""s0"");
    final Path bar = new Path(root, ""bar"");
    hdfs.rename(foo, bar);
    DFSTestUtil.appendFile(hdfs, bar, 10); // append 10 bytes
    SnapshotTestHelper.createSnapshot(hdfs, root, ""s1"");

    // we always put modification on the file before rename
    verifyDiffReport(root, ""s0"", ""s1"",
        new DiffReportEntry(DiffType.MODIFY, DFSUtil.string2Bytes("""")),
        new DiffReportEntry(DiffType.MODIFY, DFSUtil.string2Bytes(""foo"")),
        new DiffReportEntry(DiffType.RENAME, DFSUtil.string2Bytes(""foo""),
            DFSUtil.string2Bytes(""bar"")));
  }",1
"@Test
  public void testBackupNodeTailsEdits() throws Exception {
    Configuration conf = new HdfsConfiguration();
    HAUtil.setAllowStandbyReads(conf, true);
    MiniDFSCluster cluster = null;
    FileSystem fileSys = null;
    BackupNode backup = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf)
                                  .numDataNodes(0).build();
      fileSys = cluster.getFileSystem();
      backup = startBackupNode(conf, StartupOption.BACKUP, 1);
      
      BackupImage bnImage = (BackupImage) backup.getFSImage();
      testBNInSync(cluster, backup, 1);
      
      // Force a roll -- BN should roll with NN.
      NameNode nn = cluster.getNameNode();
      NamenodeProtocols nnRpc = nn.getRpcServer();
      nnRpc.rollEditLog();
      assertEquals(bnImage.getEditLog().getCurSegmentTxId(),
          nn.getFSImage().getEditLog().getCurSegmentTxId());
      
      // BN should stay in sync after roll
      testBNInSync(cluster, backup, 2);
      
      long nnImageBefore =
        nn.getFSImage().getStorage().getMostRecentCheckpointTxId();
      // BN checkpoint
      backup.doCheckpoint();
      
      // NN should have received a new image
      long nnImageAfter =
        nn.getFSImage().getStorage().getMostRecentCheckpointTxId();
      
      assertTrue(""nn should have received new checkpoint. before: "" +
          nnImageBefore + "" after: "" + nnImageAfter,
          nnImageAfter > nnImageBefore);

      // BN should stay in sync after checkpoint
      testBNInSync(cluster, backup, 3);

      // Stop BN
      StorageDirectory sd = bnImage.getStorage().getStorageDir(0);
      backup.stop();
      backup = null;
      
      // When shutting down the BN, it shouldn't finalize logs that are
      // still open on the NN
      EditLogFile editsLog = FSImageTestUtil.findLatestEditsLog(sd);
      assertEquals(editsLog.getFirstTxId(),
          nn.getFSImage().getEditLog().getCurSegmentTxId());
      assertTrue(""Should not have finalized "" + editsLog,
          editsLog.isInProgress());
      
      // do some edits
      assertTrue(fileSys.mkdirs(new Path(""/edit-while-bn-down"")));
  
      // start a new backup node
      backup = startBackupNode(conf, StartupOption.BACKUP, 1);

      testBNInSync(cluster, backup, 4);
      assertNotNull(backup.getNamesystem()
          .getFileInfo(""/edit-while-bn-down"", false, false, false));
      
      // Trigger an unclean shutdown of the backup node. Backup node will not
      // unregister from the active when this is done simulating a node crash.
      backup.stop(false);
           
      // do some edits on the active. This should go through without failing.
      // This will verify that active is still up and can add entries to
      // master editlog.
      assertTrue(fileSys.mkdirs(new Path(""/edit-while-bn-down-2"")));
      
    }",1
"@Test
  public void testChooseTarget() throws Exception {
    doTestChooseTargetNormalCase();
    doTestChooseTargetSpecialCase();
  }",1
"@Test
  public void testAskForTransactionsMidfile() throws IOException {
    File f = new File(TestEditLog.TEST_DIR + ""/askfortransactionsmidfile"");
    NNStorage storage = setupEdits(Collections.<URI>singletonList(f.toURI()), 
                                   10);
    StorageDirectory sd = storage.dirIterator(NameNodeDirType.EDITS).next();
    
    FileJournalManager jm = new FileJournalManager(conf, sd, storage);
    
    // 10 rolls, so 11 rolled files, 110 txids total.
    final int TOTAL_TXIDS = 10 * 11;
    for (int txid = 1; txid <= TOTAL_TXIDS; txid++) {
      assertEquals((TOTAL_TXIDS - txid) + 1, getNumberOfTransactions(jm, txid,
          true, false));
    }",1
"@Test
  public void testInprogressRecoveryMixed() throws IOException {
    File f1 = new File(TestEditLog.TEST_DIR + ""/mixtest0"");
    File f2 = new File(TestEditLog.TEST_DIR + ""/mixtest1"");
    File f3 = new File(TestEditLog.TEST_DIR + ""/mixtest2"");
    
    List<URI> editUris = ImmutableList.of(f1.toURI(), f2.toURI(), f3.toURI());

    // abort after the 5th roll 
    NNStorage storage = setupEdits(editUris,
                                   5, new AbortSpec(5, 1));
    Iterator<StorageDirectory> dirs = storage.dirIterator(NameNodeDirType.EDITS);
    StorageDirectory sd = dirs.next();
    FileJournalManager jm = new FileJournalManager(conf, sd, storage);
    assertEquals(6*TXNS_PER_ROLL, getNumberOfTransactions(jm, 1, true, false));
    
    sd = dirs.next();
    jm = new FileJournalManager(conf, sd, storage);
    assertEquals(5*TXNS_PER_ROLL + TXNS_PER_FAIL, getNumberOfTransactions(jm, 1,
        true, false));

    sd = dirs.next();
    jm = new FileJournalManager(conf, sd, storage);
    assertEquals(6*TXNS_PER_ROLL, getNumberOfTransactions(jm, 1, true, false));
  }",1
"@Test
  public void testDisplayRecentEditLogOpCodes() throws IOException {
    // start a cluster
    Configuration conf = getConf();
    MiniDFSCluster cluster = null;
    FileSystem fileSys = null;
    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES)
        .enableManagedDfsDirsRedundancy(false).build();
    cluster.waitActive();
    fileSys = cluster.getFileSystem();
    final FSNamesystem namesystem = cluster.getNamesystem();

    FSImage fsimage = namesystem.getFSImage();
    for (int i = 0; i < 20; i++) {
      fileSys.mkdirs(new Path(""/tmp/tmp"" + i));
    }",1
"@Test
  public void testValidateEditLogWithCorruptBody() throws IOException {
    File testDir = new File(TEST_DIR, ""testValidateEditLogWithCorruptBody"");
    SortedMap<Long, Long> offsetToTxId = Maps.newTreeMap();
    final int NUM_TXNS = 20;
    File logFile = prepareUnfinalizedTestEditLog(testDir, NUM_TXNS,
        offsetToTxId);
    // Back up the uncorrupted log
    File logFileBak = new File(testDir, logFile.getName() + "".bak"");
    Files.copy(logFile, logFileBak);
    EditLogValidation validation =
        EditLogFileInputStream.scanEditLog(logFile, Long.MAX_VALUE, true);
    assertTrue(!validation.hasCorruptHeader());
    // We expect that there will be an OP_START_LOG_SEGMENT, followed by
    // NUM_TXNS opcodes, followed by an OP_END_LOG_SEGMENT.
    assertEquals(NUM_TXNS + 1, validation.getEndTxId());
    // Corrupt each edit and verify that validation continues to work
    for (Map.Entry<Long, Long> entry : offsetToTxId.entrySet()) {
      long txOffset = entry.getKey();
      long txId = entry.getValue();

      // Restore backup, corrupt the txn opcode
      Files.copy(logFileBak, logFile);
      corruptByteInFile(logFile, txOffset);
      validation = EditLogFileInputStream.scanEditLog(logFile,
          Long.MAX_VALUE, true);
      long expectedEndTxId = (txId == (NUM_TXNS + 1)) ?
          NUM_TXNS : (NUM_TXNS + 1);
      assertEquals(""Failed when corrupting txn opcode at "" + txOffset,
          expectedEndTxId, validation.getEndTxId());
      assertTrue(!validation.hasCorruptHeader());
    }",1
"@Test
  public void testValidateEmptyEditLog() throws IOException {
    File testDir = new File(TEST_DIR, ""testValidateEmptyEditLog"");
    SortedMap<Long, Long> offsetToTxId = Maps.newTreeMap();
    File logFile = prepareUnfinalizedTestEditLog(testDir, 0, offsetToTxId);
    // Truncate the file so that there is nothing except the header and
    // layout flags section.
    truncateFile(logFile, 8);
    EditLogValidation validation =
        EditLogFileInputStream.scanEditLog(logFile, Long.MAX_VALUE, true);
    assertTrue(!validation.hasCorruptHeader());
    assertEquals(HdfsServerConstants.INVALID_TXID, validation.getEndTxId());
  }",1
"@Test
  public void testDigest() throws IOException {
    Configuration conf = new Configuration();
    MiniDFSCluster cluster = null;
    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
      DistributedFileSystem fs = cluster.getFileSystem();
      fs.setSafeMode(SafeModeAction.ENTER);
      fs.saveNamespace();
      fs.setSafeMode(SafeModeAction.LEAVE);
      File currentDir = FSImageTestUtil.getNameNodeCurrentDirs(cluster, 0).get(
          0);
      File fsimage = FSImageTestUtil.findNewestImageFile(currentDir
          .getAbsolutePath());
      assertEquals(MD5FileUtils.readStoredMd5ForFile(fsimage),
          MD5FileUtils.computeMd5ForFile(fsimage));
    }",1
"@Test
  public void testHasNonEcBlockUsingStripedIDForLoadSnapshot()
      throws IOException{
    // start a cluster
    Configuration conf = new HdfsConfiguration();
    MiniDFSCluster cluster = null;
    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(9)
          .build();
      cluster.waitActive();
      DistributedFileSystem fs = cluster.getFileSystem();
      FSNamesystem fns = cluster.getNamesystem();

      String testDir = ""/test_block_manager"";
      String testFile = ""testfile_loadSnapshot"";
      String testFilePath = testDir + ""/"" + testFile;
      String clientName = ""testUser_loadSnapshot"";
      String clientMachine = ""testMachine_loadSnapshot"";
      long blkId = -1;
      long blkNumBytes = 1024;
      long timestamp = 1426222918;

      Path d = new Path(testDir);
      fs.mkdir(d, new FsPermission(""755""));
      fs.allowSnapshot(d);

      Path p = new Path(testFilePath);
      DFSTestUtil.createFile(fs, p, 0, (short) 1, 1);
      BlockInfoContiguous cBlk = new BlockInfoContiguous(
          new Block(blkId, blkNumBytes, timestamp), (short)3);
      INodeFile file = (INodeFile)fns.getFSDirectory().getINode(testFilePath);
      file.toUnderConstruction(clientName, clientMachine);
      file.addBlock(cBlk);
      TestINodeFile.toCompleteFile(file);

      fs.createSnapshot(d,""testHasNonEcBlockUsingStripeID"");
      fs.truncate(p,0);
      fns.enterSafeMode(false);
      fns.saveNamespace(0, 0);
      cluster.restartNameNodes();
      cluster.waitActive();
      fns = cluster.getNamesystem();
      assertTrue(fns.getBlockManager().hasNonEcBlockUsingStripedID());

      cluster.shutdown();
      cluster = null;
    }",1
"@Test
  public void testPersist() throws IOException {
    Configuration conf = new Configuration();
    testPersistHelper(conf);
  }",1
"@Test
  public void testSaveAndLoadErasureCodingPolicies() throws IOException{
    Configuration conf = new Configuration();
    final int blockSize = 16 * 1024 * 1024;
    conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, blockSize);
    try (MiniDFSCluster cluster =
             new MiniDFSCluster.Builder(conf).numDataNodes(10).build()) {
      cluster.waitActive();
      DistributedFileSystem fs = cluster.getFileSystem();
      DFSTestUtil.enableAllECPolicies(fs);

      // Save namespace and restart NameNode
      fs.setSafeMode(SafeModeAction.ENTER);
      fs.saveNamespace();
      fs.setSafeMode(SafeModeAction.LEAVE);

      cluster.restartNameNodes();
      cluster.waitActive();

      assertEquals(""Erasure coding policy number should match"",
          SystemErasureCodingPolicies.getPolicies().size(),
          ErasureCodingPolicyManager.getInstance().getPolicies().length);

      // Add new erasure coding policy
      ECSchema newSchema = new ECSchema(""rs"", 5, 4);
      ErasureCodingPolicy newPolicy =
          new ErasureCodingPolicy(newSchema, 2 * 1024, (byte) 254);
      ErasureCodingPolicy[] policies = new ErasureCodingPolicy[]{newPolicy}",1
"@Test
  public void testSaveAndLoadFileUnderReplicationPolicyDir()
      throws IOException {
    Configuration conf = new Configuration();
    MiniDFSCluster cluster = null;
    try {
      cluster = new MiniDFSCluster.Builder(conf).build();
      cluster.waitActive();
      FSNamesystem fsn = cluster.getNamesystem();
      DistributedFileSystem fs = cluster.getFileSystem();
      DFSTestUtil.enableAllECPolicies(fs);
      ErasureCodingPolicy replicaPolicy =
          SystemErasureCodingPolicies.getReplicationPolicy();
      ErasureCodingPolicy defaultEcPolicy =
          StripedFileTestUtil.getDefaultECPolicy();

      final Path ecDir = new Path(""/ec"");
      final Path replicaDir = new Path(ecDir, ""replica"");
      final Path replicaFile1 = new Path(replicaDir, ""f1"");
      final Path replicaFile2 = new Path(replicaDir, ""f2"");

      // create root directory
      fs.mkdir(ecDir, null);
      fs.setErasureCodingPolicy(ecDir, defaultEcPolicy.getName());

      // create directory, and set replication Policy
      fs.mkdir(replicaDir, null);
      fs.setErasureCodingPolicy(replicaDir, replicaPolicy.getName());

      // create an empty file f1
      fs.create(replicaFile1).close();

      // create an under-construction file f2
      FSDataOutputStream out = fs.create(replicaFile2, (short) 2);
      out.writeBytes(""hello"");
      ((DFSOutputStream) out.getWrappedStream()).hsync(EnumSet
          .of(SyncFlag.UPDATE_LENGTH));

      // checkpoint
      fs.setSafeMode(SafeModeAction.ENTER);
      fs.saveNamespace();
      fs.setSafeMode(SafeModeAction.LEAVE);

      cluster.restartNameNode();
      cluster.waitActive();
      fs = cluster.getFileSystem();

      assertTrue(fs.getFileStatus(ecDir).isDirectory());
      assertTrue(fs.getFileStatus(replicaDir).isDirectory());
      assertTrue(fs.exists(replicaFile1));
      assertTrue(fs.exists(replicaFile2));

      // check directories
      assertEquals(""Directory should have default EC policy."",
          defaultEcPolicy, fs.getErasureCodingPolicy(ecDir));
      assertEquals(""Directory should hide replication EC policy."",
          null, fs.getErasureCodingPolicy(replicaDir));

      // check file1
      assertEquals(""File should not have EC policy."", null,
          fs.getErasureCodingPolicy(replicaFile1));
      // check internals of file2
      INodeFile file2Node =
          fsn.dir.getINode4Write(replicaFile2.toString()).asFile();
      assertEquals(""hello"".length(), file2Node.computeFileSize());
      assertTrue(file2Node.isUnderConstruction());
      BlockInfo[] blks = file2Node.getBlocks();
      assertEquals(1, blks.length);
      assertEquals(BlockUCState.UNDER_CONSTRUCTION, blks[0].getBlockUCState());
      assertEquals(""File should return expected replication factor."",
          2, blks[0].getReplication());
      assertEquals(""File should not have EC policy."", null,
          fs.getErasureCodingPolicy(replicaFile2));
      // check lease manager
      Lease lease = fsn.leaseManager.getLease(file2Node);
      Assert.assertNotNull(lease);
    }",1
"@Test
  public void testAclGroupDeny() throws IOException {
    INodeFile inodeFile = createINodeFile(inodeRoot, ""file1"", ""bruce"", ""sales"",
      (short)0604);
    addAcl(inodeFile,
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, GROUP, NONE),
      aclEntry(ACCESS, MASK, NONE),
      aclEntry(ACCESS, OTHER, READ));
    assertPermissionGranted(BRUCE, ""/file1"", READ_WRITE);
    assertPermissionGranted(CLARK, ""/file1"", READ);
    assertPermissionDenied(DIANA, ""/file1"", READ);
    assertPermissionDenied(DIANA, ""/file1"", WRITE);
    assertPermissionDenied(DIANA, ""/file1"", EXECUTE);
    assertPermissionDenied(DIANA, ""/file1"", READ_WRITE);
    assertPermissionDenied(DIANA, ""/file1"", READ_EXECUTE);
    assertPermissionDenied(DIANA, ""/file1"", WRITE_EXECUTE);
    assertPermissionDenied(DIANA, ""/file1"", ALL);
  }",1
"@Test
  public void testAclGroupMask() throws IOException {
    INodeFile inodeFile = createINodeFile(inodeRoot, ""file1"", ""bruce"", ""execs"",
      (short)0644);
    addAcl(inodeFile,
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, GROUP, READ_WRITE),
      aclEntry(ACCESS, MASK, READ),
      aclEntry(ACCESS, OTHER, READ));
    assertPermissionGranted(BRUCE, ""/file1"", READ_WRITE);
    assertPermissionGranted(CLARK, ""/file1"", READ);
    assertPermissionDenied(CLARK, ""/file1"", WRITE);
    assertPermissionDenied(CLARK, ""/file1"", EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", READ_WRITE);
    assertPermissionDenied(CLARK, ""/file1"", READ_EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", WRITE_EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", ALL);
  }",1
"@Test
  public void testAclNamedGroup() throws IOException {
    INodeFile inodeFile = createINodeFile(inodeRoot, ""file1"", ""bruce"", ""execs"",
      (short)0640);
    addAcl(inodeFile,
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, GROUP, ""sales"", READ),
      aclEntry(ACCESS, MASK, READ),
      aclEntry(ACCESS, OTHER, NONE));
    assertPermissionGranted(BRUCE, ""/file1"", READ_WRITE);
    assertPermissionGranted(CLARK, ""/file1"", READ);
    assertPermissionGranted(DIANA, ""/file1"", READ);
    assertPermissionDenied(DIANA, ""/file1"", WRITE);
    assertPermissionDenied(DIANA, ""/file1"", EXECUTE);
    assertPermissionDenied(DIANA, ""/file1"", READ_WRITE);
    assertPermissionDenied(DIANA, ""/file1"", READ_EXECUTE);
    assertPermissionDenied(DIANA, ""/file1"", ALL);
  }",1
"@Test
  public void testAclNamedGroupDeny() throws IOException {
    INodeFile inodeFile = createINodeFile(inodeRoot, ""file1"", ""bruce"", ""sales"",
      (short)0644);
    addAcl(inodeFile,
      aclEntry(ACCESS, USER, READ_WRITE),
      aclEntry(ACCESS, GROUP, READ),
      aclEntry(ACCESS, GROUP, ""execs"", NONE),
      aclEntry(ACCESS, MASK, READ),
      aclEntry(ACCESS, OTHER, READ));
    assertPermissionGranted(BRUCE, ""/file1"", READ_WRITE);
    assertPermissionGranted(DIANA, ""/file1"", READ);
    assertPermissionDenied(CLARK, ""/file1"", READ);
    assertPermissionDenied(CLARK, ""/file1"", WRITE);
    assertPermissionDenied(CLARK, ""/file1"", EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", READ_WRITE);
    assertPermissionDenied(CLARK, ""/file1"", READ_EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", WRITE_EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", ALL);
  }",1
"@Test
  public void testAclNamedGroupTraverseDeny() throws IOException {
    INodeDirectory inodeDir = createINodeDirectory(inodeRoot, ""dir1"", ""bruce"",
      ""execs"", (short)0755);
    INodeFile inodeFile = createINodeFile(inodeDir, ""file1"", ""bruce"", ""execs"",
      (short)0644);
    addAcl(inodeDir,
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, GROUP, READ_EXECUTE),
      aclEntry(ACCESS, GROUP, ""sales"", NONE),
      aclEntry(ACCESS, MASK, READ_EXECUTE),
      aclEntry(ACCESS, OTHER, READ_EXECUTE));
    assertPermissionGranted(BRUCE, ""/dir1/file1"", READ_WRITE);
    assertPermissionGranted(CLARK, ""/dir1/file1"", READ);
    assertPermissionDenied(DIANA, ""/dir1/file1"", READ);
    assertPermissionDenied(DIANA, ""/dir1/file1"", WRITE);
    assertPermissionDenied(DIANA, ""/dir1/file1"", EXECUTE);
    assertPermissionDenied(DIANA, ""/dir1/file1"", READ_WRITE);
    assertPermissionDenied(DIANA, ""/dir1/file1"", READ_EXECUTE);
    assertPermissionDenied(DIANA, ""/dir1/file1"", WRITE_EXECUTE);
    assertPermissionDenied(DIANA, ""/dir1/file1"", ALL);
  }",1
"@Test
  public void testAclOther() throws IOException {
    INodeFile inodeFile = createINodeFile(inodeRoot, ""file1"", ""bruce"", ""sales"",
      (short)0774);
    addAcl(inodeFile,
      aclEntry(ACCESS, USER, ALL),
      aclEntry(ACCESS, USER, ""diana"", ALL),
      aclEntry(ACCESS, GROUP, READ_WRITE),
      aclEntry(ACCESS, MASK, ALL),
      aclEntry(ACCESS, OTHER, READ));
    assertPermissionGranted(BRUCE, ""/file1"", ALL);
    assertPermissionGranted(DIANA, ""/file1"", ALL);
    assertPermissionGranted(CLARK, ""/file1"", READ);
    assertPermissionDenied(CLARK, ""/file1"", WRITE);
    assertPermissionDenied(CLARK, ""/file1"", EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", READ_WRITE);
    assertPermissionDenied(CLARK, ""/file1"", READ_EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", WRITE_EXECUTE);
    assertPermissionDenied(CLARK, ""/file1"", ALL);
  }",1
"@Test
  public void testInodePath() throws IOException {
    // For a non .inodes path the regular components are returned
    String path = ""/a/b/c"";
    INode inode = createTreeOfInodes(path);
    // For an any inode look up return inode corresponding to ""c"" from /a/b/c
    FSDirectory fsd = Mockito.mock(FSDirectory.class);
    Mockito.doReturn(inode).when(fsd).getInode(Mockito.anyLong());

    // Tests for FSDirectory#resolvePath()
    // Non inode regular path
    String resolvedPath = FSDirectory.resolvePath(path, fsd);
    assertEquals(path, resolvedPath);

    // Inode path with no trailing separator
    String testPath = ""/.reserved/.inodes/1"";
    resolvedPath = FSDirectory.resolvePath(testPath, fsd);
    assertEquals(path, resolvedPath);

    // Inode path with trailing separator
    testPath = ""/.reserved/.inodes/1/"";
    resolvedPath = FSDirectory.resolvePath(testPath, fsd);
    assertEquals(path, resolvedPath);

    // Inode relative path
    testPath = ""/.reserved/.inodes/1/d/e/f"";
    resolvedPath = FSDirectory.resolvePath(testPath, fsd);
    assertEquals(""/a/b/c/d/e/f"", resolvedPath);

    // A path with just .inodes  returns the path as is
    testPath = ""/.reserved/.inodes"";
    resolvedPath = FSDirectory.resolvePath(testPath, fsd);
    assertEquals(testPath, resolvedPath);

    // Root inode path
    testPath = ""/.reserved/.inodes/"" + INodeId.ROOT_INODE_ID;
    resolvedPath = FSDirectory.resolvePath(testPath, fsd);
    assertEquals(""/"", resolvedPath);

    // An invalid inode path should remain unresolved
    testPath = ""/.invalid/.inodes/1"";
    resolvedPath = FSDirectory.resolvePath(testPath, fsd);
    assertEquals(testPath, resolvedPath);

    // Test path with nonexistent(deleted or wrong id) inode
    Mockito.doReturn(null).when(fsd).getInode(Mockito.anyLong());
    testPath = ""/.reserved/.inodes/1234"";
    try {
      String realPath = FSDirectory.resolvePath(testPath, fsd);
      fail(""Path should not be resolved:"" + realPath);
    }",1
"@Test
  public void testLocationLimitInListingOps() throws Exception {
    final Configuration conf = new Configuration();
    conf.setInt(DFSConfigKeys.DFS_LIST_LIMIT, 9); // 3 blocks * 3 replicas
    MiniDFSCluster cluster = null;
    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
      cluster.waitActive();
      final DistributedFileSystem hdfs = cluster.getFileSystem();
      ArrayList<String> source = new ArrayList<String>();

      // tmp1 holds files with 3 blocks, 3 replicas
      // tmp2 holds files with 3 blocks, 1 replica
      hdfs.mkdirs(new Path(""/tmp1""));
      hdfs.mkdirs(new Path(""/tmp2""));

      source.add(""f1"");
      source.add(""f2"");

      int numEntries = source.size();
      for (int j=0;j<numEntries;j++) {
          DFSTestUtil.createFile(hdfs, new Path(""/tmp1/""+source.get(j)), 4096,
          3*1024-100, 1024, (short) 3, 0);
      }",1
"@Test
  public void testReplication () {
    replication = 3;
    preferredBlockSize = 128*1024*1024;
    INodeFile inf = createINodeFile(replication, preferredBlockSize);
    assertEquals(""True has to be returned in this case"", replication,
                 inf.getFileReplication());
  }",1
"@Test
  public void testLastContactTime() throws Exception {
    Configuration conf = new Configuration();
    conf.setInt(DFSConfigKeys.DFS_HEARTBEAT_INTERVAL_KEY, 1);
    conf.setInt(DFSConfigKeys.DFS_NAMENODE_HEARTBEAT_RECHECK_INTERVAL_KEY, 1);
    MiniDFSCluster cluster = null;
    HostsFileWriter hostsFileWriter = new HostsFileWriter();
    hostsFileWriter.initialize(conf, ""temp/TestNameNodeMXBean"");

    try {
      cluster = new MiniDFSCluster.Builder(conf, baseDir.getRoot()).numDataNodes(3).build();
      cluster.waitActive();

      FSNamesystem fsn = cluster.getNameNode().namesystem;

      MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();
      ObjectName mxbeanName = new ObjectName(
        ""Hadoop:service=NameNode,name=NameNodeInfo"");

      List<String> hosts = new ArrayList<>();
      for(DataNode dn : cluster.getDataNodes()) {
        hosts.add(dn.getDisplayName());
      }",1
"@Test
  public void testOldInProgress() throws IOException {
    TestCaseDescription tc = new TestCaseDescription();
    tc.addRoot(""/foo1"", NameNodeDirType.IMAGE_AND_EDITS);
    tc.addImage(""/foo1/current/"" + getImageFileName(100), true);
    tc.addImage(""/foo1/current/"" + getImageFileName(200), true);
    tc.addImage(""/foo1/current/"" + getImageFileName(300), false);
    tc.addImage(""/foo1/current/"" + getImageFileName(400), false);
    tc.addLog(""/foo1/current/"" + getInProgressEditsFileName(101), true);
    runTest(tc);
  }",1
"@Test
  public void testNNThroughput() throws Exception {
    Configuration conf = new HdfsConfiguration();
    conf.setInt(DFSConfigKeys.DFS_BLOCK_SIZE_KEY, 16);
    File nameDir = new File(MiniDFSCluster.getBaseDirectory(), ""name"");
    conf.set(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY,
        nameDir.getAbsolutePath());
    DFSTestUtil.formatNameNode(conf);
    NNThroughputBenchmark.runBenchmark(conf, new String[] {""-op"", ""all""}",1
"@Test
  public void testClientSideExceptionOnJustOneDir() throws IOException {
    Configuration conf = new HdfsConfiguration();
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf)
      .numDataNodes(0).build();
    NNStorage mockStorage = Mockito.mock(NNStorage.class);
    List<File> localPaths = ImmutableList.of(
        new File(""/xxxxx-does-not-exist/blah""),
        new File(TEST_DIR, ""testfile"")    
        );
       
    try {
      URL fsName = DFSUtil.getInfoServer(
          cluster.getNameNode().getServiceRpcAddress(), conf,
          DFSUtil.getHttpClientScheme(conf)).toURL();

      String id = ""getimage=1&txid=0"";

      TransferFsImage.getFileClient(fsName, id, localPaths, mockStorage, false);      
      Mockito.verify(mockStorage).reportErrorOnFile(localPaths.get(0));
      assertTrue(""The valid local file should get saved properly"",
          localPaths.get(1).length() > 0);
    }",1
"@Test
  public void testChooseTargetWithTopology() throws Exception {
    BlockStoragePolicy policy1 = new BlockStoragePolicy((byte) 9, ""TEST1"",
        new StorageType[]{StorageType.SSD, StorageType.DISK,
            StorageType.ARCHIVE}",1
"@Test
  public void testIdempotentClose() throws Exception {
    final int numBlocks = 2;
    DFSTestUtil.createStripedFile(cluster, filePath, null, numBlocks,
        stripesPerBlock, false, ecPolicy);

    try (DFSInputStream in = fs.getClient().open(filePath.toString())) {
      assertTrue(in instanceof DFSStripedInputStream);
      // Close twice
      in.close();
    }",1
"@Test
  public void testRefreshBlock() throws Exception {
    final int numBlocks = 4;
    DFSTestUtil.createStripedFile(cluster, filePath, null, numBlocks,
        stripesPerBlock, false, ecPolicy);
    LocatedBlocks lbs = fs.getClient().namenode.getBlockLocations(
        filePath.toString(), 0, blockGroupSize * numBlocks);
    final DFSStripedInputStream in = new DFSStripedInputStream(fs.getClient(),
        filePath.toString(), false, ecPolicy, null);

    List<LocatedBlock> lbList = lbs.getLocatedBlocks();
    for (LocatedBlock aLbList : lbList) {
      LocatedStripedBlock lsb = (LocatedStripedBlock) aLbList;
      LocatedBlock[] blks = StripedBlockUtil.parseStripedBlockGroup(lsb,
          cellSize, dataBlocks, parityBlocks);
      for (int j = 0; j < dataBlocks; j++) {
        LocatedBlock refreshed = in.refreshLocatedBlock(blks[j]);
        assertEquals(blks[j].getBlock(), refreshed.getBlock());
        assertEquals(blks[j].getStartOffset(), refreshed.getStartOffset());
        assertArrayEquals(blks[j].getLocations(), refreshed.getLocations());
      }",1
"@Test
  public void testFileMoreThanABlockGroup3() throws Exception {
    testOneFile(""/MoreThanABlockGroup3"",
        blockSize * dataBlocks * 3 + cellSize * dataBlocks
        + cellSize + 123);
  }",1
"@Test
  public void testFileMoreThanOneStripe1() throws Exception {
    testOneFile(""/MoreThanOneStripe1"", cellSize * dataBlocks + 123);
  }",1
"@Test
  public void testFileSmallerThanOneCell1() throws Exception {
    testOneFile(""/SmallerThanOneCell"", 1);
  }",1
"@Test
  public void testFileSmallerThanOneCell2() throws Exception {
    testOneFile(""/SmallerThanOneCell"", cellSize - 1);
  }",1
"@Test
  public void testFileSmallerThanOneStripe2() throws Exception {
    testOneFile(""/SmallerThanOneStripe"", cellSize + 123);
  }",1
"@Test
  public void testStreamFlush() throws Exception {
    final byte[] bytes = StripedFileTestUtil.generateBytes(blockSize *
        dataBlocks * 3 + cellSize * dataBlocks + cellSize + 123);
    try (FSDataOutputStream os = fs.create(new Path(""/ec-file-1""))) {
      assertFalse(
          ""DFSStripedOutputStream should not have hflush() capability yet!"",
          os.hasCapability(StreamCapability.HFLUSH.getValue()));
      assertFalse(
          ""DFSStripedOutputStream should not have hsync() capability yet!"",
          os.hasCapability(StreamCapability.HSYNC.getValue()));
      try (InputStream is = new ByteArrayInputStream(bytes)) {
        IOUtils.copyBytes(is, os, bytes.length);
        os.hflush();
        IOUtils.copyBytes(is, os, bytes.length);
        os.hsync();
        IOUtils.copyBytes(is, os, bytes.length);
      }",1
"@Test
  public void testDFSClient() throws Exception {
    Configuration conf = getTestConfiguration();
    final long grace = 1000L;
    MiniDFSCluster cluster = null;
    LeaseRenewer.setLeaseRenewerGraceDefault(grace);

    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(2).build();
      final String filepathstring = ""/test/LeaseChecker/foo"";
      final Path[] filepaths = new Path[4];
      for(int i = 0; i < filepaths.length; i++) {
        filepaths[i] = new Path(filepathstring + i);
      }",1
"@Test
  public void testInvalidScriptMappingFileReadStatistics() throws Exception {
    // Even though network location of the client machine is unknown,
    // MiniDFSCluster's datanode is on the local host and thus the network
    // distance is 0.
    testReadFileSystemStatistics(0, true, true);
  }",1
"@Test
  public void testListStatusOfSnapshotDirs() throws IOException {
    MiniDFSCluster cluster = new MiniDFSCluster.Builder(getTestConfiguration())
        .build();
    try {
      DistributedFileSystem dfs = cluster.getFileSystem();
      dfs.create(new Path(""/parent/test1/dfsclose/file-0""));
      Path snapShotDir = new Path(""/parent/test1/"");
      dfs.allowSnapshot(snapShotDir);

      FileStatus status = dfs.getFileStatus(new Path(""/parent/test1""));
      assertTrue(status.isSnapshotEnabled());
      status = dfs.getFileStatus(new Path(""/parent/""));
      assertFalse(status.isSnapshotEnabled());
    }",1
"@Test
  public void testStored() throws IOException {
    // reference edits stored with source code (see build.xml)
    final String cacheDir = System.getProperty(""test.cache.data"",
        ""target/test-classes"");
    // binary, XML, reparsed binary
    String editsStored = cacheDir + ""/editsStored"";
    String editsStoredParsedXml = cacheDir + ""/editsStoredParsed.xml"";
    String editsStoredReparsed = cacheDir + ""/editsStoredReparsed"";
    // reference XML version of editsStored (see build.xml)
    String editsStoredXml = cacheDir + ""/editsStored.xml"";

    // parse to XML then back to binary
    assertEquals(0, runOev(editsStored, editsStoredParsedXml, ""xml"", false));
    assertEquals(0,
        runOev(editsStoredParsedXml, editsStoredReparsed, ""binary"", false));

    // judgement time
    assertTrue(""Edits "" + editsStored + "" should have all op codes"",
        hasAllOpCodes(editsStored));
    assertTrue(""Reference XML edits and parsed to XML should be same"",
        FileUtils.contentEqualsIgnoreEOL(new File(editsStoredXml),
            new File(editsStoredParsedXml), ""UTF-8""));
    assertTrue(
        ""Reference edits and reparsed (bin to XML to bin) should be same"",
        filesEqualIgnoreTrailingZeros(editsStored, editsStoredReparsed));
  }",1
"@Test
  public void testWebImageViewer() throws Exception {
    WebImageViewer viewer = new WebImageViewer(
        NetUtils.createSocketAddr(""localhost:0""));
    try {
      viewer.initServer(originalFsimage.getAbsolutePath());
      int port = viewer.getPort();

      // create a WebHdfsFileSystem instance
      URI uri = new URI(""webhdfs://localhost:"" + String.valueOf(port));
      Configuration conf = new Configuration();
      WebHdfsFileSystem webhdfs = (WebHdfsFileSystem)FileSystem.get(uri, conf);

      // verify the number of directories
      FileStatus[] statuses = webhdfs.listStatus(new Path(""/""));
      assertEquals(dirCount, statuses.length);

      // verify the number of files in the directory
      statuses = webhdfs.listStatus(new Path(""/dir0""));
      assertEquals(FILES_PER_DIR, statuses.length);

      // compare a file
      FileStatus status = webhdfs.listStatus(new Path(""/dir0/file0""))[0];
      FileStatus expected = writtenFiles.get(""/dir0/file0"");
      compareFile(expected, status);

      // LISTSTATUS operation to an empty directory
      statuses = webhdfs.listStatus(new Path(""/emptydir""));
      assertEquals(0, statuses.length);

      // LISTSTATUS operation to a invalid path
      URL url = new URL(""http://localhost:"" + port +
                    ""/webhdfs/v1/invalid/?op=LISTSTATUS"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_NOT_FOUND, url);

      // LISTSTATUS operation to a invalid prefix
      url = new URL(""http://localhost:"" + port + ""/foo"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_NOT_FOUND, url);

      // Verify the Erasure Coded empty file status
      Path emptyECFilePath = new Path(""/ec/EmptyECFile.txt"");
      FileStatus actualEmptyECFileStatus =
          webhdfs.getFileStatus(new Path(emptyECFilePath.toString()));
      FileStatus expectedEmptyECFileStatus = writtenFiles.get(
          emptyECFilePath.toString());
      System.out.println(webhdfs.getFileStatus(new Path(emptyECFilePath
              .toString())));
      compareFile(expectedEmptyECFileStatus, actualEmptyECFileStatus);

      // Verify the Erasure Coded small file status
      Path smallECFilePath = new Path(""/ec/SmallECFile.txt"");
      FileStatus actualSmallECFileStatus =
          webhdfs.getFileStatus(new Path(smallECFilePath.toString()));
      FileStatus expectedSmallECFileStatus = writtenFiles.get(
          smallECFilePath.toString());
      compareFile(expectedSmallECFileStatus, actualSmallECFileStatus);

      // GETFILESTATUS operation
      status = webhdfs.getFileStatus(new Path(""/dir0/file0""));
      compareFile(expected, status);

      // GETFILESTATUS operation to a invalid path
      url = new URL(""http://localhost:"" + port +
                    ""/webhdfs/v1/invalid/?op=GETFILESTATUS"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_NOT_FOUND, url);

      // invalid operation
      url = new URL(""http://localhost:"" + port + ""/webhdfs/v1/?op=INVALID"");
      verifyHttpResponseCode(HttpURLConnection.HTTP_BAD_REQUEST, url);

      // invalid method
      url = new URL(""http://localhost:"" + port + ""/webhdfs/v1/?op=LISTSTATUS"");
      HttpURLConnection connection = (HttpURLConnection) url.openConnection();
      connection.setRequestMethod(""POST"");
      connection.connect();
      assertEquals(HttpURLConnection.HTTP_BAD_METHOD,
          connection.getResponseCode());
    }",1
"@Test
  public void testVerifyMD5FileBadDigest() throws Exception {
    MD5FileUtils.saveMD5File(TEST_FILE, MD5Hash.digest(new byte[0]));
    try {
      MD5FileUtils.verifySavedMD5(TEST_FILE, TEST_MD5);
      fail(""Did not throw"");
    }",1
"@Test
  public void testByteRange() throws IOException {
    ByteRangeInputStream.URLOpener oMock = getMockURLOpener(
        new URL(""http://test""));
    ByteRangeInputStream.URLOpener rMock = getMockURLOpener(null);
    ByteRangeInputStream bris = new ByteRangeInputStreamImpl(oMock, rMock);

    bris.seek(0);

    assertEquals(""getPos wrong"", 0, bris.getPos());

    bris.read();

    assertEquals(""Initial call made incorrectly (offset check)"",
        0, bris.startPos);
    assertEquals(""getPos should return 1 after reading one byte"", 1,
        bris.getPos());
    verify(oMock, times(1)).connect(0, false);

    bris.read();

    assertEquals(""getPos should return 2 after reading two bytes"", 2,
        bris.getPos());
    // No additional connections should have been made (no seek)
    verify(oMock, times(1)).connect(0, false);

    rMock.setURL(new URL(""http://resolvedurl/""));

    bris.seek(100);
    bris.read();

    assertEquals(""Seek to 100 bytes made incorrectly (offset Check)"",
        100, bris.startPos);
    assertEquals(""getPos should return 101 after reading one byte"", 101,
        bris.getPos());
    verify(rMock, times(1)).connect(100, true);

    bris.seek(101);
    bris.read();

    // Seek to 101 should not result in another request
    verify(rMock, times(1)).connect(100, true);
    verify(rMock, times(0)).connect(101, true);

    bris.seek(2500);
    bris.read();

    assertEquals(""Seek to 2500 bytes made incorrectly (offset Check)"",
        2500, bris.startPos);

    doReturn(getMockConnection(null))
        .when(rMock).connect(anyLong(), anyBoolean());
    bris.seek(500);
    try {
      bris.read();
      fail(""Exception should be thrown when content-length is not given"");
    }",1
"@Test
  public void testPropagatedClose() throws IOException {
    ByteRangeInputStream bris =
        mock(ByteRangeInputStream.class, CALLS_REAL_METHODS);
    InputStreamAndFileLength mockStream = new InputStreamAndFileLength(1L,
        mock(InputStream.class));
    doReturn(mockStream).when(bris).openInputStream(Mockito.anyLong());
    Whitebox.setInternalState(bris, ""status"",
                              ByteRangeInputStream.StreamStatus.SEEK);

    int brisOpens = 0;
    int brisCloses = 0;
    int isCloses = 0;

    // first open, shouldn't close underlying stream
    bris.getInputStream();
    verify(bris, times(++brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // stream is open, shouldn't close underlying stream
    bris.getInputStream();
    verify(bris, times(brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // seek forces a reopen, should close underlying stream
    bris.seek(1);
    bris.getInputStream();
    verify(bris, times(++brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(++isCloses)).close();

    // verify that the underlying stream isn't closed after a seek
    // ie. the state was correctly updated
    bris.getInputStream();
    verify(bris, times(brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // seeking to same location should be a no-op
    bris.seek(1);
    bris.getInputStream();
    verify(bris, times(brisOpens)).openInputStream(Mockito.anyLong());
    verify(bris, times(brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // close should of course close
    bris.close();
    verify(bris, times(++brisCloses)).close();
    verify(mockStream.in, times(++isCloses)).close();

    // it's already closed, underlying stream should not close
    bris.close();
    verify(bris, times(++brisCloses)).close();
    verify(mockStream.in, times(isCloses)).close();

    // it's closed, don't reopen it
    boolean errored = false;
    try {
      bris.getInputStream();
    }",1
"@Test
  public void testContentSummary() throws Exception {
    final Configuration conf = WebHdfsTestUtil.createConf();
    final Path path = new Path(""/QuotaDir"");
    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
    final WebHdfsFileSystem webHdfs = WebHdfsTestUtil.getWebHdfsFileSystem(conf,
        WebHdfsConstants.WEBHDFS_SCHEME);
    final DistributedFileSystem dfs = cluster.getFileSystem();
    dfs.mkdirs(path);
    dfs.setQuotaByStorageType(path, StorageType.DISK, 100000);
    ContentSummary contentSummary = webHdfs.getContentSummary(path);
    Assert
        .assertTrue((contentSummary.getTypeQuota(StorageType.DISK) == 100000));
  }",1
"@Test
  public void testStoragePolicy() throws Exception {
    final Configuration conf = WebHdfsTestUtil.createConf();
    final Path path = new Path(""/file"");
    cluster = new MiniDFSCluster.Builder(conf).numDataNodes(0).build();
    final DistributedFileSystem dfs = cluster.getFileSystem();
    final WebHdfsFileSystem webHdfs = WebHdfsTestUtil.getWebHdfsFileSystem(conf,
        WebHdfsConstants.WEBHDFS_SCHEME);

    // test getAllStoragePolicies
    Assert.assertTrue(Arrays.equals(dfs.getAllStoragePolicies().toArray(),
        webHdfs.getAllStoragePolicies().toArray()));

    // test get/set/unset policies
    DFSTestUtil.createFile(dfs, path, 0, (short) 1, 0L);
    // get defaultPolicy
    BlockStoragePolicySpi defaultdfsPolicy = dfs.getStoragePolicy(path);
    // set policy through webhdfs
    webHdfs.setStoragePolicy(path, HdfsConstants.COLD_STORAGE_POLICY_NAME);
    // get policy from dfs
    BlockStoragePolicySpi dfsPolicy = dfs.getStoragePolicy(path);
    // get policy from webhdfs
    BlockStoragePolicySpi webHdfsPolicy = webHdfs.getStoragePolicy(path);
    Assert.assertEquals(HdfsConstants.COLD_STORAGE_POLICY_NAME.toString(),
        webHdfsPolicy.getName());
    Assert.assertEquals(webHdfsPolicy, dfsPolicy);
    // unset policy
    webHdfs.unsetStoragePolicy(path);
    Assert.assertEquals(defaultdfsPolicy, webHdfs.getStoragePolicy(path));
  }",1
"@Test
  public void testConfigureLZOCodec() throws IOException {
    // Dummy codec
    String defaultCodec = ""org.apache.hadoop.io.compress.DefaultCodec"";
    Compression.Algorithm.conf.set(
        Compression.Algorithm.CONF_LZO_CLASS, defaultCodec);
    assertEquals(defaultCodec,
        Compression.Algorithm.LZO.getCodec().getClass().getName());
  }",1
"@Test
  public void testCloseStreams() throws IOException {
    File tmpFile = null;
    FileOutputStream fos;
    BufferedOutputStream bos;
    FileOutputStream nullStream = null;

    try {
      tmpFile = new File(GenericTestUtils.getTestDir(), ""testCloseStreams.txt"");
      fos = new FileOutputStream(tmpFile) {
        @Override
        public void close() throws IOException {
          throw new IOException();
        }",1
"@Test
  public void testFix() {
    final String INDEX_LESS_MAP_FILE = ""testFix.mapfile"";
    int PAIR_SIZE = 20;
    MapFile.Writer writer = null;
    try {
      FileSystem fs = FileSystem.getLocal(conf);
      Path dir = new Path(TEST_DIR, INDEX_LESS_MAP_FILE);
      writer = createWriter(INDEX_LESS_MAP_FILE, IntWritable.class, Text.class);
      for (int i = 0; i < PAIR_SIZE; i++)
        writer.append(new IntWritable(0), new Text(""value""));
      writer.close();

      File indexFile = new File(""."", ""."" + INDEX_LESS_MAP_FILE + ""/index"");
      boolean isDeleted = false;
      if (indexFile.exists())
        isDeleted = indexFile.delete();

      if (isDeleted)
        assertTrue(""testFix error !!!"",
            MapFile.fix(fs, dir, IntWritable.class, Text.class, true, conf) == PAIR_SIZE);
    }",1
"@Test
  public void testClose() throws IOException {
    Configuration conf = new Configuration();
    LocalFileSystem fs = FileSystem.getLocal(conf);
  
    // create a sequence file 1
    Path path1 = new Path(GenericTestUtils.getTempPath(""test1.seq""));
    SequenceFile.Writer writer = SequenceFile.createWriter(fs, conf, path1,
        Text.class, NullWritable.class, CompressionType.BLOCK);
    writer.append(new Text(""file1-1""), NullWritable.get());
    writer.append(new Text(""file1-2""), NullWritable.get());
    writer.close();
  
    Path path2 = new Path(GenericTestUtils.getTempPath(""test2.seq""));
    writer = SequenceFile.createWriter(fs, conf, path2, Text.class,
        NullWritable.class, CompressionType.BLOCK);
    writer.append(new Text(""file2-1""), NullWritable.get());
    writer.append(new Text(""file2-2""), NullWritable.get());
    writer.close();
  
    // Create a reader which uses 4 BuiltInZLibInflater instances
    SequenceFile.Reader reader = new SequenceFile.Reader(fs, path1, conf);
    // Returns the 4 BuiltInZLibInflater instances to the CodecPool
    reader.close();
    // The second close _could_ erroneously returns the same 
    // 4 BuiltInZLibInflater instances to the CodecPool again
    reader.close();
  
    // The first reader gets 4 BuiltInZLibInflater instances from the CodecPool
    SequenceFile.Reader reader1 = new SequenceFile.Reader(fs, path1, conf);
    // read first value from reader1
    Text text = new Text();
    reader1.next(text);
    assertEquals(""file1-1"", text.toString());
    
    // The second reader _could_ get the same 4 BuiltInZLibInflater 
    // instances from the CodePool as reader1
    SequenceFile.Reader reader2 = new SequenceFile.Reader(fs, path2, conf);
    
    // read first value from reader2
    reader2.next(text);
    assertEquals(""file2-1"", text.toString());
    // read second value from reader1
    reader1.next(text);
    assertEquals(""file1-2"", text.toString());
    // read second value from reader2 (this throws an exception)
    reader2.next(text);
    assertEquals(""file2-2"", text.toString());
  
    assertFalse(reader1.next(text));
    assertFalse(reader2.next(text));
  }",1
"@Test
  public void testCreateUsesFsArg() throws Exception {
    FileSystem fs = FileSystem.getLocal(conf);
    FileSystem spyFs = Mockito.spy(fs);
    Path p = new Path(GenericTestUtils.getTempPath(""testCreateUsesFSArg.seq""));
    SequenceFile.Writer writer = SequenceFile.createWriter(
        spyFs, conf, p, NullWritable.class, NullWritable.class);
    writer.close();
    Mockito.verify(spyFs).getDefaultReplication(p);
  }",1
"@Test
  public void testFailAbortV1() throws Exception {
    testFailAbortInternal(1);
  }",1
"@Test
  public void testRemoveMap() throws Exception {
    // This test case use two thread to call getIndexInformation and 
    // removeMap concurrently, in order to construct race condition.
    // This test case may not repeatable. But on my macbook this test 
    // fails with probability of 100% on code before MAPREDUCE-2541,
    // so it is repeatable in practice.
    fs.delete(p, true);
    conf.setInt(MRJobConfig.SHUFFLE_INDEX_CACHE, 10);
    // Make a big file so removeMapThread almost surely runs faster than 
    // getInfoThread 
    final int partsPerMap = 100000;
    final int bytesPerFile = partsPerMap * 24;
    final IndexCache cache = new IndexCache(conf);

    final Path big = new Path(p, ""bigIndex"");
    final String user = 
      UserGroupInformation.getCurrentUser().getShortUserName();
    writeFile(fs, big, bytesPerFile, partsPerMap);
    
    // run multiple times
    for (int i = 0; i < 20; ++i) {
      Thread getInfoThread = new Thread() {
        @Override
        public void run() {
          try {
            cache.getIndexInformation(""bigIndex"", partsPerMap, big, user);
          }",1
"@Test
  public void testBzipWithMultibyteDelimiter() throws IOException {
    String testFileName = ""compressedMultibyteDelimiter.txt.bz2"";
    // firstSplitLength < (headers + blockMarker) will pass always since no
    // records will be read (in the test file that is byte 0..9)
    // firstSplitlength > (compressed file length - one compressed block
    // size + 1) will also always pass since the second split will be empty
    // (833 bytes is the last block start in the used data file)
    int firstSplitLength = 100;
    URL testFileUrl = getClass().getClassLoader().getResource(testFileName);
    assertNotNull(""Cannot find "" + testFileName, testFileUrl);
    File testFile = new File(testFileUrl.getFile());
    long testFileSize = testFile.length();
    Path testFilePath = new Path(testFile.getAbsolutePath());
    assertTrue(""Split size is smaller than header length"",
        firstSplitLength > 9);
    assertTrue(""Split size is larger than compressed file size "" +
        testFilePath, testFileSize > firstSplitLength);

    Configuration conf = new Configuration();
    conf.setInt(org.apache.hadoop.mapreduce.lib.input.
        LineRecordReader.MAX_LINE_LENGTH, Integer.MAX_VALUE);

    String delimiter = ""<E-LINE>\r\r\n"";
    conf.set(""textinputformat.record.delimiter"", delimiter);
    testSplitRecordsForFile(conf, firstSplitLength, testFileSize,
        testFilePath);
  }",1
"@Test
  public void testRecordSpanningMultipleSplits()
      throws IOException {
    checkRecordSpanningMultipleSplits(""recordSpanningMultipleSplits.txt"",
        10, false);
  }",1
"@Test
  public void testRecordSpanningMultipleSplitsCompressed()
      throws IOException {
    // The file is generated with bz2 block size of 100k. The split size
    // needs to be larger than that for the CompressedSplitLineReader to
    // work.
    checkRecordSpanningMultipleSplits(""recordSpanningMultipleSplits.txt.bz2"",
        200 * 1000, true);
  }",1
"@Test
  public void testRenameMapOutputForReduce() throws Exception {
    final JobConf conf = new JobConf();

    final MROutputFiles mrOutputFiles = new MROutputFiles();
    mrOutputFiles.setConf(conf);

    // make sure both dirs are distinct
    //
    conf.set(MRConfig.LOCAL_DIR, localDirs[0].toString());
    final Path mapOut = mrOutputFiles.getOutputFileForWrite(1);
    conf.set(MRConfig.LOCAL_DIR, localDirs[1].toString());
    final Path mapOutIdx = mrOutputFiles.getOutputIndexFileForWrite(1);
    Assert.assertNotEquals(""Paths must be different!"",
        mapOut.getParent(), mapOutIdx.getParent());

    // make both dirs part of LOCAL_DIR
    conf.setStrings(MRConfig.LOCAL_DIR, localDirs);

    final FileContext lfc = FileContext.getLocalFSFileContext(conf);
    lfc.create(mapOut, EnumSet.of(CREATE)).close();
    lfc.create(mapOutIdx, EnumSet.of(CREATE)).close();

    final JobId jobId = MRBuilderUtils.newJobId(12345L, 1, 2);
    final TaskId tid = MRBuilderUtils.newTaskId(jobId, 0, TaskType.MAP);
    final TaskAttemptId taid = MRBuilderUtils.newTaskAttemptId(tid, 0);

    LocalContainerLauncher.renameMapOutputForReduce(conf, taid, mrOutputFiles);
  }",1
"@Test
  public void testDuplicateDownload() throws Exception {
    JobID jobId = new JobID();
    JobConf conf = new JobConf();
    conf.setClass(""fs.mock.impl"", MockFileSystem.class, FileSystem.class);

    URI mockBase = new URI(""mock://test-nn1/"");
    when(mockfs.getUri()).thenReturn(mockBase);
    Path working = new Path(""mock://test-nn1/user/me/"");
    when(mockfs.getWorkingDirectory()).thenReturn(working);
    when(mockfs.resolvePath(any(Path.class))).thenAnswer(
        (Answer<Path>) args -> (Path) args.getArguments()[0]);

    final URI file = new URI(""mock://test-nn1/user/me/file.txt#link"");
    final Path filePath = new Path(file);
    File link = new File(""link"");

    when(mockfs.getFileStatus(any(Path.class))).thenAnswer(new Answer<FileStatus>() {
      @Override
      public FileStatus answer(InvocationOnMock args) throws Throwable {
        Path p = (Path) args.getArguments()[0];
        if (""file.txt"".equals(p.getName())) {
          return createMockTestFileStatus(filePath);
        }",1
"@Test
  public void testValueIterator() throws Exception {
    Path tmpDir = new Path(""build/test/test.reduce.task"");
    Configuration conf = new Configuration();
    for (Pair[] testCase: testCases) {
      runValueIterator(tmpDir, testCase, conf, null);
    }",1
"@Test
  public void testValueIteratorWithCompression() throws Exception {
    Path tmpDir = new Path(""build/test/test.reduce.task.compression"");
    Configuration conf = new Configuration();
    DefaultCodec codec = new DefaultCodec();
    codec.setConf(conf);
    for (Pair[] testCase: testCases) {
      runValueIterator(tmpDir, testCase, conf, codec);
    }",1
"@Test
  public void testFormat() throws Exception {
    JobConf job = new JobConf(conf);
    FileSystem fs = FileSystem.getLocal(conf);
    Path dir = new Path(System.getProperty(""test.build.data"",""."") + ""/mapred"");
    Path file = new Path(dir, ""test.seq"");
    
    Reporter reporter = Reporter.NULL;
    
    int seed = new Random().nextInt();
    //LOG.info(""seed = ""+seed);
    Random random = new Random(seed);

    fs.delete(dir, true);

    FileInputFormat.setInputPaths(job, dir);

    // for a variety of lengths
    for (int length = 0; length < MAX_LENGTH;
         length+= random.nextInt(MAX_LENGTH/10)+1) {

      //LOG.info(""creating; entries = "" + length);

      // create a file with length entries
      SequenceFile.Writer writer =
        SequenceFile.createWriter(fs, conf, file,
                                  IntWritable.class, BytesWritable.class);
      try {
        for (int i = 0; i < length; i++) {
          IntWritable key = new IntWritable(i);
          byte[] data = new byte[random.nextInt(10)];
          random.nextBytes(data);
          BytesWritable value = new BytesWritable(data);
          writer.append(key, value);
        }",1
"@Test
  public void testCheckpointCreateDirect() throws Exception {
    checkpointCreate(ByteBuffer.allocateDirect(BUFSIZE));
  }",1
"@Test
  public void testDetermineCacheVisibilities() throws IOException {
    fs.setPermission(TEST_VISIBILITY_PARENT_DIR,
        new FsPermission((short)00777));
    fs.setPermission(TEST_VISIBILITY_CHILD_DIR,
        new FsPermission((short)00777));
    fs.setWorkingDirectory(TEST_VISIBILITY_CHILD_DIR);
    Job job = Job.getInstance(conf);
    Path relativePath = new Path(SECOND_CACHE_FILE);
    Path wildcardPath = new Path(""*"");
    Map<URI, FileStatus> statCache = new HashMap<>();
    Configuration jobConf;

    job.addCacheFile(firstCacheFile.toUri());
    job.addCacheFile(relativePath.toUri());
    jobConf = job.getConfiguration();

    // skip test if scratch dir is not PUBLIC
    assumeTrue(TEST_VISIBILITY_PARENT_DIR + "" is not public"",
        ClientDistributedCacheManager.isPublic(
            jobConf, TEST_VISIBILITY_PARENT_DIR.toUri(), statCache));

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file paths were not found to be publicly visible ""
        + ""even though the full path is publicly accessible"",
        ""true,true"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, null, firstCacheFile, relativePath);

    job = Job.getInstance(conf);
    job.addCacheFile(wildcardPath.toUri());
    jobConf = job.getConfiguration();
    statCache.clear();

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file path was not found to be publicly visible ""
        + ""even though the full path is publicly accessible"",
        ""true"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, null, wildcardPath.getParent());

    Path qualifiedParent = fs.makeQualified(TEST_VISIBILITY_PARENT_DIR);
    fs.setPermission(TEST_VISIBILITY_PARENT_DIR,
        new FsPermission((short)00700));
    job = Job.getInstance(conf);
    job.addCacheFile(firstCacheFile.toUri());
    job.addCacheFile(relativePath.toUri());
    jobConf = job.getConfiguration();
    statCache.clear();

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file paths were found to be publicly visible ""
        + ""even though the parent directory is not publicly accessible"",
        ""false,false"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, qualifiedParent,
        firstCacheFile, relativePath);

    job = Job.getInstance(conf);
    job.addCacheFile(wildcardPath.toUri());
    jobConf = job.getConfiguration();
    statCache.clear();

    ClientDistributedCacheManager.determineCacheVisibilities(jobConf,
        statCache);
    // We use get() instead of getBoolean() so we can tell the difference
    // between wrong and missing
    assertEquals(""The file path was found to be publicly visible ""
        + ""even though the parent directory is not publicly accessible"",
        ""false"", jobConf.get(MRJobConfig.CACHE_FILE_VISIBILITIES));
    checkCacheEntries(statCache, qualifiedParent, wildcardPath.getParent());
  }",1
"@Test
  public void testListLocatedStatus() throws Exception {
    Configuration conf = getConfiguration();
    conf.setBoolean(""fs.test.impl.disable.cache"", false);
    conf.setInt(FileInputFormat.LIST_STATUS_NUM_THREADS, numThreads);
    conf.set(org.apache.hadoop.mapreduce.lib.input.FileInputFormat.INPUT_DIR,
        ""test:///a1/a2"");
    MockFileSystem mockFs =
        (MockFileSystem) new Path(""test:///"").getFileSystem(conf);
    Assert.assertEquals(""listLocatedStatus already called"",
        0, mockFs.numListLocatedStatusCalls);
    JobConf job = new JobConf(conf);
    TextInputFormat fileInputFormat = new TextInputFormat();
    fileInputFormat.configure(job);
    InputSplit[] splits = fileInputFormat.getSplits(job, 1);
    Assert.assertEquals(""Input splits are not correct"", 2, splits.length);
    Assert.assertEquals(""listLocatedStatuss calls"",
        1, mockFs.numListLocatedStatusCalls);
    FileSystem.closeAll();
  }",1
"@Test
  public void testMultipleClose() throws IOException {
    URL testFileUrl = getClass().getClassLoader().
        getResource(""recordSpanningMultipleSplits.txt.bz2"");
    assertNotNull(""Cannot find recordSpanningMultipleSplits.txt.bz2"",
        testFileUrl);
    File testFile = new File(testFileUrl.getFile());
    Path testFilePath = new Path(testFile.getAbsolutePath());
    long testFileSize = testFile.length();
    Configuration conf = new Configuration();
    conf.setInt(org.apache.hadoop.mapreduce.lib.input.
        LineRecordReader.MAX_LINE_LENGTH, Integer.MAX_VALUE);
    FileSplit split = new FileSplit(testFilePath, 0, testFileSize,
        (String[])null);

    LineRecordReader reader = new LineRecordReader(conf, split);
    LongWritable key = new LongWritable();
    Text value = new Text();
    //noinspection StatementWithEmptyBody
    while (reader.next(key, value)) ;
    reader.close();
    reader.close();

    BZip2Codec codec = new BZip2Codec();
    codec.setConf(conf);
    Set<Decompressor> decompressors = new HashSet<Decompressor>();
    for (int i = 0; i < 10; ++i) {
      decompressors.add(CodecPool.getDecompressor(codec));
    }",1
"@Test
  public void testAddInputPathWithMapper() {
    final JobConf conf = new JobConf();
    MultipleInputs.addInputPath(conf, new Path(""/foo""), TextInputFormat.class,
       MapClass.class);
    MultipleInputs.addInputPath(conf, new Path(""/bar""),
       KeyValueTextInputFormat.class, MapClass2.class);
    final Map<Path, InputFormat> inputs = MultipleInputs
       .getInputFormatMap(conf);
    final Map<Path, Class<? extends Mapper>> maps = MultipleInputs
       .getMapperTypeMap(conf);

    assertEquals(TextInputFormat.class, inputs.get(new Path(""/foo"")).getClass());
    assertEquals(KeyValueTextInputFormat.class, inputs.get(new Path(""/bar""))
       .getClass());
    assertEquals(MapClass.class, maps.get(new Path(""/foo"")));
    assertEquals(MapClass2.class, maps.get(new Path(""/bar"")));
  }",1
"@Test
  public void testRuntimeExRun() throws Exception {
    run(false, true);
  }",1
"@Test
  public void testMapFileOutputCommitterV1() throws Exception {
    testMapFileOutputCommitterInternal(1);
  }",1
"@Test
  public void testRecoveryV1() throws Exception {
    testRecoveryInternal(1, 1);
  }",1
"@Test
  public void testBlacklistedNodesXML() throws Exception {
    WebResource r = resource();
    ClientResponse response = r.path(""ws"").path(""v1"").path(""mapreduce"")
        .path(""blacklistednodes"").accept(MediaType.APPLICATION_XML)
        .get(ClientResponse.class);
    assertEquals(MediaType.APPLICATION_XML + ""; "" + JettyUtils.UTF_8,
        response.getType().toString());
    String xml = response.getEntity(String.class);
    verifyBlacklistedNodesInfoXML(xml, appContext);
  }",1
"@Test
  public void testCreateDirsWithoutFileSystem() throws Exception {
    Configuration conf = new YarnConfiguration();
    conf.set(FileSystem.FS_DEFAULT_NAME_KEY, ""hdfs://localhost:1"");
    testTryCreateHistoryDirs(conf, false);
  }",1
"@Test
  public void testMkNodeRecursive() throws IOException {
    boolean result = false;
    System.out.println(""Make node with parent already made, recursive"");
    result = registry.mknode(""test/registryTestNode"", true);
    Assert.assertTrue(result);
    Assert.assertTrue(fs.exists(new Path(""test/registryTestNode"")));

    result = false;
    System.out.println(""Try to make node with no parent, recursive"");
    result = registry.mknode(""test/parent/registryTestNode"", true);
    Assert.assertTrue(result);
    Assert.assertTrue(fs.exists(new Path(""test/parent/registryTestNode"")));

  }",1
"@Test
  public void testAAAALookup() throws Exception {
    ServiceRecord record = getMarshal().fromBytes(""somepath"",
        CONTAINER_RECORD.getBytes());
    getRegistryDNS().register(
        ""/registry/users/root/services/org-apache-slider/test1/components/""
            + ""ctr-e50-1451931954322-0016-01-000002"",
        record);

    // start assessing whether correct records are available
    List<Record> recs = assertDNSQuery(
        ""ctr-e50-1451931954322-0016-01-000002.dev.test."", Type.AAAA, 1);
    assertEquals(""wrong result"", ""172.17.0.19"",
        ((AAAARecord) recs.get(0)).getAddress().getHostAddress());

    recs = assertDNSQuery(""httpd-1.test1.root.dev.test."", Type.AAAA, 1);
    assertTrue(""not an ARecord"", recs.get(0) instanceof AAAARecord);
  }",1
"@Test
  public void testContainerRegistrationPersistanceAbsent() throws Exception {
    ServiceRecord record = marshal.fromBytes(""somepath"",
        CONTAINER_RECORD_YARN_PERSISTANCE_ABSENT.getBytes());
    registryDNS.register(
        ""/registry/users/root/services/org-apache-slider/test1/components/""
            + ""ctr-e50-1451931954322-0016-01-000003"",
         record);

    Name name =
        Name.fromString(""ctr-e50-1451931954322-0016-01-000002.dev.test."");
    Record question = Record.newRecord(name, Type.A, DClass.IN);
    Message query = Message.newQuery(question);
    byte[] responseBytes = registryDNS.generateReply(query, null);
    Message response = new Message(responseBytes);
    assertEquals(""Excepting NXDOMAIN as Record must not have regsisterd wrong"",
        Rcode.NXDOMAIN, response.getRcode());
  }",1
"@Test
  public void testNegativeLookup() throws Exception {
    ServiceRecord record = getMarshal().fromBytes(""somepath"",
        CONTAINER_RECORD.getBytes());
    getRegistryDNS().register(
        ""/registry/users/root/services/org-apache-slider/test1/components/""
            + ""ctr-e50-1451931954322-0016-01-000002"",
        record);

    // start assessing whether correct records are available
    Name name = Name.fromString(""missing.dev.test."");
    Record question = Record.newRecord(name, Type.A, DClass.IN);
    Message query = Message.newQuery(question);

    byte[] responseBytes = getRegistryDNS().generateReply(query, null);
    Message response = new Message(responseBytes);
    assertEquals(""not successful"", Rcode.NXDOMAIN, response.getRcode());
    assertNotNull(""Null response"", response);
    assertEquals(""Questions do not match"", query.getQuestion(),
        response.getQuestion());
    List<Record> sectionArray = response.getSection(Section.AUTHORITY);
    assertEquals(""Wrong number of recs in AUTHORITY"", isSecure() ? 2 : 1,
        sectionArray.size());
    boolean soaFound = false;
    for (Record rec : sectionArray) {
      soaFound = rec.getType() == Type.SOA;
      if (soaFound) {
        break;
      }",1
"@Test
  public void testReverseLookup() throws Exception {
    ServiceRecord record = getMarshal().fromBytes(""somepath"",
        CONTAINER_RECORD.getBytes());
    getRegistryDNS().register(
        ""/registry/users/root/services/org-apache-slider/test1/components/""
            + ""ctr-e50-1451931954322-0016-01-000002"",
        record);

    // start assessing whether correct records are available
    List<Record> recs = assertDNSQuery(
        ""19.0.17.172.in-addr.arpa."", Type.PTR, 1);
    assertEquals(""wrong result"",
        ""httpd-1.test1.root.dev.test."",
        ((PTRRecord) recs.get(0)).getTarget().toString());
  }",1
"@Test
  public void testJksProvider() throws Exception {
    Configuration conf = new Configuration();
    final Path jksPath = new Path(tmpDir.toString(), ""test.jks"");
    final String ourUrl =
        JavaKeyStoreProvider.SCHEME_NAME + ""://file"" + jksPath.toUri();

    File file = new File(tmpDir, ""test.jks"");
    file.delete();
    conf.set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, ourUrl);
    checkSpecificProvider(conf, ourUrl);
    Path path = ProviderUtils.unnestUri(new URI(ourUrl));
    FileSystem fs = path.getFileSystem(conf);
    FileStatus s = fs.getFileStatus(path);
    assertEquals(""rw-------"", s.getPermission().toString());
    assertTrue(file + "" should exist"", file.isFile());

    // check permission retention after explicit change
    fs.setPermission(path, new FsPermission(""777""));
    checkPermissionRetention(conf, ourUrl, path);
  }",1
"@Test
  public void testFileOutput() throws Throwable {
    File f = new File(""target/kdiag.txt"");
    kdiag(ARG_KEYLEN, KEYLEN,
        ARG_KEYTAB, keytab.getAbsolutePath(),
        ARG_PRINCIPAL, ""foo@EXAMPLE.COM"",
        ARG_OUTPUT, f.getAbsolutePath());
    LOG.info(""Output of {}",1
"@Test
  public void testKeytabAndPrincipal() throws Throwable {
    kdiag(ARG_KEYLEN, KEYLEN,
        ARG_KEYTAB, keytab.getAbsolutePath(),
        ARG_PRINCIPAL, ""foo@EXAMPLE.COM"");
  }",1
"@Test
  public void testNoKeytab() throws Throwable {
    kdiagFailure(CAT_KERBEROS, ARG_KEYLEN, KEYLEN,
        ARG_KEYTAB, ""target/nofile"");
  }",1
"@Test
  public void testSecure() throws Throwable {
    kdiagFailure(CAT_CONFIG, ARG_KEYLEN, KEYLEN, ARG_SECURE);
  }",1
"@Test
  public void testCreate() throws Exception {
    Configuration conf = new HdfsConfiguration();
    conf.setBoolean(DFSConfigKeys.DFS_PERMISSIONS_ENABLED_KEY, true);
    conf.set(FsPermission.UMASK_LABEL, ""000"");
    MiniDFSCluster cluster = null;
    FileSystem fs = null;

    try {
      cluster = new MiniDFSCluster.Builder(conf).numDataNodes(3).build();
      cluster.waitActive();
      fs = FileSystem.get(conf);
      FsPermission rootPerm = checkPermission(fs, ""/"", null);
      FsPermission inheritPerm = FsPermission.createImmutable(
          (short)(rootPerm.toShort() | 0300));

      FsPermission dirPerm = new FsPermission((short)0777);
      fs.mkdirs(new Path(""/a1/a2/a3""), dirPerm);
      checkPermission(fs, ""/a1"", dirPerm);
      checkPermission(fs, ""/a1/a2"", dirPerm);
      checkPermission(fs, ""/a1/a2/a3"", dirPerm);

      dirPerm = new FsPermission((short)0123);
      FsPermission permission = FsPermission.createImmutable(
        (short)(dirPerm.toShort() | 0300));
      fs.mkdirs(new Path(""/aa/1/aa/2/aa/3""), dirPerm);
      checkPermission(fs, ""/aa/1"", permission);
      checkPermission(fs, ""/aa/1/aa/2"", permission);
      checkPermission(fs, ""/aa/1/aa/2/aa/3"", dirPerm);

      FsPermission filePerm = new FsPermission((short)0444);
      Path p = new Path(""/b1/b2/b3.txt"");
      FSDataOutputStream out = fs.create(p, filePerm,
          true, conf.getInt(CommonConfigurationKeys.IO_FILE_BUFFER_SIZE_KEY, 4096),
          fs.getDefaultReplication(p), fs.getDefaultBlockSize(p), null);
      out.write(123);
      out.close();
      checkPermission(fs, ""/b1"", inheritPerm);
      checkPermission(fs, ""/b1/b2"", inheritPerm);
      checkPermission(fs, ""/b1/b2/b3.txt"", filePerm);
      
      conf.set(FsPermission.UMASK_LABEL, ""022"");
      permission = 
        FsPermission.createImmutable((short)0666);
      FileSystem.mkdirs(fs, new Path(""/c1""), new FsPermission(permission));
      FileSystem.create(fs, new Path(""/c1/c2.txt""),
          new FsPermission(permission));
      checkPermission(fs, ""/c1"", permission);
      checkPermission(fs, ""/c1/c2.txt"", permission);
    }",1
"@Test
  public void testExternalTokenFiles() throws Exception {
    StringBuilder tokenFullPathnames = new StringBuilder();
    String tokenFilenames = ""token1,token2"";
    String tokenFiles[] = StringUtils.getTrimmedStrings(tokenFilenames);
    final File testDir = new File(""target"",
        TestUserGroupInformation.class.getName() + ""-tmpDir"").getAbsoluteFile();
    String testDirPath = testDir.getAbsolutePath();

    // create path for token files
    for (String tokenFile: tokenFiles) {
      if (tokenFullPathnames.length() > 0) {
        tokenFullPathnames.append("","");
      }",1
"@Test
  public void testCommandLine() throws Exception {
    try {
      try {
        FileUtil.fullyDelete(OUTPUT_DIR.getAbsoluteFile());
      }",1
"@Test
  public void testAtomicCommitExistingFinal() throws IOException {
    TaskAttemptContext taskAttemptContext = getTaskAttemptContext(config);
    JobContext jobContext = new JobContextImpl(taskAttemptContext.getConfiguration(),
        taskAttemptContext.getTaskAttemptID().getJobID());
    Configuration conf = jobContext.getConfiguration();


    String workPath = ""/tmp1/"" + String.valueOf(rand.nextLong());
    String finalPath = ""/tmp1/"" + String.valueOf(rand.nextLong());
    FileSystem fs = null;
    try {
      OutputCommitter committer = new CopyCommitter(null, taskAttemptContext);
      fs = FileSystem.get(conf);
      fs.mkdirs(new Path(workPath));
      fs.mkdirs(new Path(finalPath));

      conf.set(CONF_LABEL_TARGET_WORK_PATH, workPath);
      conf.set(CONF_LABEL_TARGET_FINAL_PATH, finalPath);
      conf.setBoolean(DistCpConstants.CONF_LABEL_ATOMIC_COPY, true);

      assertPathExists(fs, ""Work path"", new Path(workPath));
      assertPathExists(fs, ""Final path"", new Path(finalPath));
      try {
        committer.commitJob(jobContext);
        Assert.fail(""Should not be able to atomic-commit to pre-existing path."");
      }",1
"@Test
  public void testAppendOption() {
    final DistCpOptions.Builder builder = new DistCpOptions.Builder(
        Collections.singletonList(new Path(""hdfs://localhost:8020/source"")),
        new Path(""hdfs://localhost:8020/target/""))
        .withSyncFolder(true)
        .withAppend(true);
    Assert.assertTrue(builder.build().shouldAppend());

    try {
      // make sure -append is only valid when -update is specified
      new DistCpOptions.Builder(
          Collections.singletonList(new Path(""hdfs://localhost:8020/source"")),
          new Path(""hdfs://localhost:8020/target/""))
          .withAppend(true)
          .build();
      fail(""Append should fail if update option is not specified"");
    }",1
"@Test
  public void testPreserve() {
    DistCpOptions options = new DistCpOptions.Builder(
        new Path(""hdfs://localhost:8020/source/first""),
        new Path(""hdfs://localhost:8020/target/""))
        .build();
    Assert.assertFalse(options.shouldPreserve(FileAttribute.BLOCKSIZE));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.REPLICATION));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.PERMISSION));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.USER));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.GROUP));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.CHECKSUMTYPE));

    options = new DistCpOptions.Builder(
        new Path(""hdfs://localhost:8020/source/first""),
        new Path(""hdfs://localhost:8020/target/""))
        .preserve(FileAttribute.ACL)
        .build();
    Assert.assertFalse(options.shouldPreserve(FileAttribute.BLOCKSIZE));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.REPLICATION));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.PERMISSION));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.USER));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.GROUP));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.CHECKSUMTYPE));
    Assert.assertTrue(options.shouldPreserve(FileAttribute.ACL));

    options = new DistCpOptions.Builder(
        new Path(""hdfs://localhost:8020/source/first""),
        new Path(""hdfs://localhost:8020/target/""))
        .preserve(FileAttribute.BLOCKSIZE)
        .preserve(FileAttribute.REPLICATION)
        .preserve(FileAttribute.PERMISSION)
        .preserve(FileAttribute.USER)
        .preserve(FileAttribute.GROUP)
        .preserve(FileAttribute.CHECKSUMTYPE)
        .build();

    Assert.assertTrue(options.shouldPreserve(FileAttribute.BLOCKSIZE));
    Assert.assertTrue(options.shouldPreserve(FileAttribute.REPLICATION));
    Assert.assertTrue(options.shouldPreserve(FileAttribute.PERMISSION));
    Assert.assertTrue(options.shouldPreserve(FileAttribute.USER));
    Assert.assertTrue(options.shouldPreserve(FileAttribute.GROUP));
    Assert.assertTrue(options.shouldPreserve(FileAttribute.CHECKSUMTYPE));
    Assert.assertFalse(options.shouldPreserve(FileAttribute.XATTR));
  }",1
"@Test
  public void testSetNumListtatusThreads() {
    final DistCpOptions.Builder builder = new DistCpOptions.Builder(
        new Path(""hdfs://localhost:8020/source/first""),
        new Path(""hdfs://localhost:8020/target/""));
    // If command line argument isn't set, we expect .getNumListstatusThreads
    // option to be zero (so that we know when to override conf properties).
    Assert.assertEquals(0, builder.build().getNumListstatusThreads());

    builder.withNumListstatusThreads(12);
    Assert.assertEquals(12, builder.build().getNumListstatusThreads());

    builder.withNumListstatusThreads(0);
    Assert.assertEquals(0, builder.build().getNumListstatusThreads());

    // Ignore large number of threads.
    builder.withNumListstatusThreads(MAX_NUM_LISTSTATUS_THREADS * 2);
    Assert.assertEquals(MAX_NUM_LISTSTATUS_THREADS,
        builder.build().getNumListstatusThreads());
  }",1
"@Test
  public void testSetOverwrite() {
    final DistCpOptions.Builder builder = new DistCpOptions.Builder(
        Collections.singletonList(new Path(""hdfs://localhost:8020/source"")),
        new Path(""hdfs://localhost:8020/target/""));
    Assert.assertFalse(builder.build().shouldOverwrite());

    builder.withOverwrite(true);
    Assert.assertTrue(builder.build().shouldOverwrite());

    try {
      builder.withSyncFolder(true).build();
      Assert.fail(""Update and overwrite aren't allowed together"");
    }",1
"@Test
  public void testSetWorkPath() {
    final DistCpOptions.Builder builder = new DistCpOptions.Builder(
        Collections.singletonList(new Path(""hdfs://localhost:8020/source"")),
        new Path(""hdfs://localhost:8020/target/""));
    Assert.assertNull(builder.build().getAtomicWorkPath());

    builder.withAtomicCommit(true);
    Assert.assertNull(builder.build().getAtomicWorkPath());

    final Path workPath = new Path(""hdfs://localhost:8020/work"");
    builder.withAtomicWorkPath(workPath);
    Assert.assertEquals(workPath, builder.build().getAtomicWorkPath());
  }",1
"@Test
  public void testVerboseLog() {
    final DistCpOptions.Builder builder = new DistCpOptions.Builder(
        Collections.singletonList(new Path(""hdfs://localhost:8020/source"")),
        new Path(""hdfs://localhost:8020/target/""));
    Assert.assertFalse(builder.build().shouldVerboseLog());

    try {
      builder.withVerboseLog(true).build();
      fail(""-v should fail if -log option is not specified"");
    }",1
"@Test
  public void testExclusionsOption() {
    DistCpOptions options = OptionsParser.parse(new String[] {
        ""hdfs://localhost:8020/source/first"",
        ""hdfs://localhost:8020/target/""}",1
"@Test
  public void testConstructUrlsFromClasspath() throws Exception {
    File file = new File(testDir, ""file"");
    assertTrue(""Create file"", file.createNewFile());

    File dir = new File(testDir, ""dir"");
    assertTrue(""Make dir"", dir.mkdir());

    File jarsDir = new File(testDir, ""jarsdir"");
    assertTrue(""Make jarsDir"", jarsDir.mkdir());
    File nonJarFile = new File(jarsDir, ""nonjar"");
    assertTrue(""Create non-jar file"", nonJarFile.createNewFile());
    File jarFile = new File(jarsDir, ""a.jar"");
    assertTrue(""Create jar file"", jarFile.createNewFile());

    File nofile = new File(testDir, ""nofile"");
    // don't create nofile

    StringBuilder cp = new StringBuilder();
    cp.append(file.getAbsolutePath()).append(File.pathSeparator)
      .append(dir.getAbsolutePath()).append(File.pathSeparator)
      .append(jarsDir.getAbsolutePath() + ""/*"").append(File.pathSeparator)
      .append(nofile.getAbsolutePath()).append(File.pathSeparator)
      .append(nofile.getAbsolutePath() + ""/*"").append(File.pathSeparator);
    
    URL[] urls = constructUrlsFromClasspath(cp.toString());
    
    assertEquals(3, urls.length);
    assertEquals(file.toURI().toURL(), urls[0]);
    assertEquals(dir.toURI().toURL(), urls[1]);
    assertEquals(jarFile.toURI().toURL(), urls[2]);
    // nofile should be ignored
  }",1
"@Test
  public void testGetResource() throws IOException {
    URL testJar = makeTestJar().toURI().toURL();
    
    ClassLoader currentClassLoader = getClass().getClassLoader();
    ClassLoader appClassloader = new ApplicationClassLoader(
        new URL[] { testJar }",1
"@Test
  public void testJarReplace() throws IOException {
    // Run the command twice with the same output jar file, and expect success.
    testJar();
    testJar();
  }",1
"@Test
  public void testHostFileReaderWithSpaces() throws Exception {
    FileWriter efw = new FileWriter(excludesFile);
    FileWriter ifw = new FileWriter(includesFile);

    efw.write(""#DFS-Hosts-excluded\n"");
    efw.write(""   somehost somehost2"");
    efw.write(""   somehost3 # somehost4"");
    efw.close();

    ifw.write(""#Hosts-in-DFS\n"");
    ifw.write(""   somehost somehost2"");
    ifw.write(""   somehost3 # somehost4"");
    ifw.close();

    HostsFileReader hfp = new HostsFileReader(includesFile, excludesFile);

    int includesLen = hfp.getHosts().size();
    int excludesLen = hfp.getExcludedHosts().size();

    assertEquals(3, includesLen);
    assertEquals(3, excludesLen);

    assertTrue(hfp.getHosts().contains(""somehost3""));
    assertFalse(hfp.getHosts().contains(""somehost5""));
    assertFalse(hfp.getHosts().contains(""somehost4""));

    assertTrue(hfp.getExcludedHosts().contains(""somehost3""));
    assertFalse(hfp.getExcludedHosts().contains(""somehost5""));
    assertFalse(hfp.getExcludedHosts().contains(""somehost4""));

  }",1
"@Test
  public void testGetDeclaredFieldsIncludingInherited() {
    Parent child = new Parent() {
      private int childField;
      @SuppressWarnings(""unused"")
      public int getChildField() { return childField; }",1
"@Test
  public void testBigJar() throws Exception {
    Random r = new Random(System.currentTimeMillis());
    File dir = new File(TEST_ROOT_DIR, Long.toHexString(r.nextLong()));
    Assert.assertTrue(dir.mkdirs());
    File input = generateBigJar(dir);
    File output = new File(dir, ""job2.jar"");
    try {
      try (InputStream is = new FileInputStream(input)) {
        RunJar.unJarAndSave(is, dir, ""job2.jar"", Pattern.compile("".*""));
      }",1
"@Test
  public void testUnJarDoesNotLooseLastModify() throws Exception {
    File unjarDir = getUnjarDir(""unjar-lastmod"");

    // Unjar everything
    RunJar.unJar(new File(TEST_ROOT_DIR, TEST_JAR_NAME),
            unjarDir, MATCH_ANY);

    String failureMessage = ""Last modify time was lost during unJar"";
    assertEquals(failureMessage, MOCKED_NOW, new File(unjarDir, TestRunJar.FOOBAR_TXT).lastModified());
    assertEquals(failureMessage, MOCKED_NOW_PLUS_TWO_SEC, new File(unjarDir, FOOBAZ_TXT).lastModified());
  }",1
"@Test
  public void testUnJarWithPattern() throws Exception {
    File unjarDir = getUnjarDir(""unjar-pattern"");

    // Unjar only a regex
    RunJar.unJar(new File(TEST_ROOT_DIR, TEST_JAR_NAME),
                 unjarDir,
                 Pattern.compile("".*baz.*""));
    assertFalse(""foobar not unpacked"",
                new File(unjarDir, TestRunJar.FOOBAR_TXT).exists());
    assertTrue(""foobaz unpacked"",
               new File(unjarDir, FOOBAZ_TXT).exists());
  }",1
"@Test
  public void testShellCommandTimeout() throws Throwable {
    Assume.assumeFalse(WINDOWS);
    String rootDir = rootTestDir.getAbsolutePath();
    File shellFile = new File(rootDir, ""timeout.sh"");
    String timeoutCommand = ""sleep 4; echo \""hello\"""";
    Shell.ShellCommandExecutor shexc;
    try (PrintWriter writer = new PrintWriter(new FileOutputStream(shellFile))) {
      writer.println(timeoutCommand);
      writer.close();
    }",1
"@Test
  public void testAsyncAPIPollTimeout() {
    testAsyncAPIPollTimeoutHelper(null, false);
    testAsyncAPIPollTimeoutHelper(0L, true);
    testAsyncAPIPollTimeoutHelper(1L, true);
  }",1
"@Test
  public void testCGgroupNotFound() throws Exception {
    writeToFile(""proc/41/cgroup"",
        ""7:devices:/yarn/container_1"",
        ""6:cpuacct,cpu:/yarn/container_1"",
        ""5:pids:/yarn/container_1"",
        ""4:memory:/yarn/container_1""
    );

    CGroupsResourceCalculator calculator = createCalculator();
    calculator.updateProcessTree();
    assertEquals(-1, calculator.getCumulativeCpuTime());
  }",1
"@Test
  public void testEnabledSandboxWithWhitelist()
      throws ContainerExecutionException{
    String[] inputCommand = {
        ""$JAVA_HOME/bin/java jar -Djava.security.manager MyJob.jar""
    }",1
"@Test
  public void testEnforcingMode() throws ContainerExecutionException {
    String[] nonJavaCommands = {
        ""bash malicious_script.sh"",
        ""python malicious_script.py""
    }",1
